# Mathematical 

## Methods and Models

for Economists

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-001.jpg?height=866&width=1117&top_left_y=881&top_left_x=177)

## Angel de la Fuente

## Contents

Preface and Acknowledgments ..... $x i$
PART I. PRELIMINARIES

1. Review of Basic Concepts ..... 3
2. Sets ..... 3
3. A Bit of Logic ..... 6
a. Properties and Quantifiers ..... 6
b. Implication ..... 9
c. Methods of Proof ..... 11
4. Relations ..... 15
a. Equivalence Relations and Decomposition of a Set into Classes ..... 17
b. Order Relations and Ordered Sets ..... 18
5. Functions ..... 20
6. Algebraic Structures ..... 24
a. Groups and Fields ..... 25
b. Vector Spaces ..... 28
7. The Real Number System ..... 29
a. A Set of Axioms for the Real Number System ..... 30
b. The Supremum Property ..... 31
c. Absolute Value ..... 35
8. Complex Numbers ..... 36
Bibliography ..... 37
Notes ..... 38
9. Metric and Normed Spaces ..... 39
10. Metric and Normed Spaces ..... 40
11. Convergence of Sequences in Metric Spaces ..... 46
12. Sequences in $\mathbb{R}$ and $\mathbb{R}^{\mathrm{m}}$ ..... 49
13. Open and Closed Sets ..... 58
a. Interior, Boundary and Closure of a Set ..... 59
b. Limit Points and a Sequential Characterization in Terms of Sequences ..... 61
14. Limits of Functions ..... 64
15. Continuity in Metric Spaces ..... 66
16. Complete Metric Spaces and the Contraction Mapping Theorem ..... 79
a. Cauchy Sequences and Complete Metric Spaces ..... 80
b. Operators and the Contraction Mapping Theorem ..... 85
17. Compactness and the Extreme-Value Theorem ..... 90
a. Compactness and Some Characterizations ..... 90
b. Relation with Other Topological Properties ..... 95
c. Continuous Functions on Compact Sets ..... 98
18. Connected Sets ..... 100
19. Equivalent Metrics and Norms ..... 104
20. Continuity of Correspondences in $E^{n}$ ..... 108
Bibliography ..... 114
Notes ..... 115
21. Vector Spaces and Linear Transformations ..... 117
22. Linear Independence and Bases ..... 117
23. Linear Transformations ..... 122
a. Image and Kernel of a Linear Function ..... 123
b. The Inverse of a Linear Transformation ..... 126
24. Isomorphisms ..... 127
25. Linear Mappings between Normed Spaces ..... 132
a. Linear Homeomorphisms ..... 134
b. The Norm of a Linear Mapping ..... 135
c. The Normed Vector Space $L\left(\mathbb{R}^{\mathbf{n}}, \mathbb{R}^{\mathbf{m}}\right)$ ..... 137
26. Change of Basis and Similarity ..... 144
27. Eigenvalues and Eigenvectors ..... 146
Appendix: Polynomial Equations ..... 152
Bibliography ..... 154
Notes ..... 155
28. Differential Calculus ..... 156
29. Differentiable Univariate Real Functions ..... 156
30. Partial and Directional Derivatives ..... 163
31. Differentiability ..... 169
32. Continuous Differentiability ..... 179
33. Homogeneous Functions ..... 187
Bibliography ..... 190
Notes ..... 190

## PART II. STATICS

5. Static Models and Comparative Statics ..... 195
6. Linear Models ..... 196
7. Comparative Statics and the Implicit-Function Theorem ..... 200
a. Derivatives of Implicit Functions and Comparative Statics ..... 202
b. The Implicit-Function Theorem ..... 205
8. Existence of Equilibrium ..... 218
a. The Intermediate Value Theorem ..... 219
b. Fixed Point Theorems ..... 221
9. Problems ..... 224
Bibliography ..... 227
Notes ..... 228
10. Convex Sets and Concave Functions ..... 229
11. Convex Sets and Separation Theorems in $\mathbb{R}^{\mathbb{M}}$ ..... 229
a. Convex Combinations and Convex Hull ..... 231
b. Topological Properties of Convex Sets ..... 234
c. Relative Interior and Boundary of a Convex Set ..... 237
d. Separation Theorems ..... 241
12. Concave Functions ..... 245
a. Some Characterizations ..... 246
b. Properties of Concave Functions ..... 251
c. Concavity for Smooth Functions ..... 258
13. Quasiconcave Functions ..... 261
Appendix: Quadratic Forms ..... 268
Bibliography ..... 272
Notes ..... 272
14. Static Optimization ..... 274
15. Nonlinear Programming ..... 274
a. Convex Constraint Set ..... 277
b. Equality Constraints: The Lagrange Problem ..... 282
c. Inequality Constraints: The Kuhn-Tucker Problem ..... 291
d. Concave Programming without Differentiability ..... 297
16. Comparative Statics and Value Functions ..... 300
a. The Theorem of the Maximum ..... 301
b. Comparative Statics of Smooth Optimization Problems ..... 309
c. Value Functions and Envelope Theorems ..... 312
17. Problems and Applications ..... 316
a. Profit Maximization by a Competitive Firm ..... 317
b. Implicit Contracts ..... 319
Bibliography ..... 323
Notes ..... 324
18. Some Applications to Microeconomics ..... 325
19. Consumer Preferences and Utility ..... 327
a. Preference Relations ..... 327
b. Representation by a Utility Function ..... 332
c. Smooth Preferences ..... 338
20. Consumer Theory ..... 339
a. Utility Maximization and Ordinary Demand Functions ..... 340
b. Expenditure Minimization and Compensated Demand ..... 346
c. Relation between Compensated and Ordinary Demands: The Slutsky Equation ..... 352
21. Walrasian General Equilibrium in a Pure Exchange Economy ..... 354
a. Aggregate Demand ..... 356
b. Existence of Competitive Equilibrium ..... 360
c. Welfare Properties of Competitive Equilibrium ..... 368
22. Games in Normal Form and Nash Equilibrium ..... 375
23. Some Useful Models of Imperfect Competition ..... 379
a. Increasing Returns to Specialization in a Dixit-Stiglitz Model ..... 380
b. Fixed Costs, Market Power and Excess Entry in a Cournot Model ..... 383
Bibliography ..... 385
Notes ..... 387
PART III. DYNAMICS
24. Dynamical Systems. I: Basic Concepts and Scalar Systems ..... 391
25. Difference and Differential Equations: Basic Concepts ..... 391
a. Geometrical Interpretation ..... 393
b. Initial- and Boundary-Value Problems ..... 394
c. Some Definitions ..... 396
d. Existence, Uniqueness, and Other Properties of Solutions ..... 398
26. Autonomous Systems ..... 401
a. The Flow of an Autonomous System ..... 402
b. Asymptotic Behavior ..... 408
c. Steady States and Stability ..... 409
27. Autonomous Differential Equations ..... 411
a. Linear Equations with Constant Coefficients ..... 412
b. Nonlinear Autonomous Equations ..... 414
c. A Note on Comparative Dynamics ..... 418
28. Autonomous Difference Equations ..... 419
a. Linear Equations with Constant Coefficients ..... 419
b. Nonlinear Equations ..... 421
29. Solution of Nonautonomous Linear Equations ..... 428
30. Solutions of Continuous-Time Systems ..... 430
a. Local Existence and Uniqueness ..... 431
b. Maximal Solutions ..... 437
c. Dependence on Initial Conditions and Parameters ..... 444
Bibliography ..... 454
Notes ..... 455
31. Dynamical Systems. II: Higher Dimensions ..... 457
32. Some General Results on Linear Systems ..... 457
33. Solution of Linear Systems with Constant Coefficients ..... 459
a. Solution by Diagonalization ..... 460
b. Imaginary Eigenvalues ..... 463
c. Repeated Eigenvalues ..... 465
d. Nonhomogeneous Systems and Stability Conditions ..... 466
e. Stable and Unstable Spaces ..... 470
f. Linear Systems on the Plane ..... 473
34. Autonomous Nonlinear Systems ..... 484
a. Phase Diagrams for Planar Systems ..... 484
b. Local Analysis by Linearization ..... 487
35. Problems ..... 489
Bibliography ..... 491
Notes ..... 492
36. Dynamical Systems III: Some Applications ..... 494
37. A Dynamic IS-LM Model ..... 494
a. Phase Diagram and Stability Analysis ..... 496
b. Effects of Monetary Policy ..... 501
38. An Introduction to Perfect-Foresight Models ..... 503
a. A Model of Stock Prices ..... 503
b. Dornbusch's Overshooting Model ..... 513
39. Neoclassical Growth Models ..... 518
a. Technology and Factor Prices in a Neoclassical World ..... 518
b. The Solow Model ..... 522
c. An Overlapping-Generations Model (Diamond) ..... 527
40. Some Useful Techniques ..... 534
a. Linearization and Derivation of a Convergence Equation ..... 534
b. Solving the Solow Model with Mathematica ..... 538
41. Problems ..... 540
Bibliography ..... 546
Notes ..... 547
42. An Introduction to Dynamic Optimization ..... 549
43. Dynamic Programming ..... 549
a. The Principle of Optimality and Bellman's Equation ..... 550
b. Some Results for Stationary Discounted Problems ..... 558
44. Optimal Control ..... 566
a. The Maximum Principle ..... 567
b. Transversality and Sufficient Conditions ..... 572
c. Constraints Involving State and Control Variables ..... 578
Bibliography ..... 580
Notes ..... 580
45. Some Applications of Dynamic Optimization ..... 582
46. Search Models ..... 582
a. The Basic Model of Job Search ..... 583
b. A Search-Based Macro Model ..... 589
47. Optimal Growth in Discrete Time ..... 598
a. Properties of the Policy Function and the Optimal Capital Sequence ..... 602
b. The Euler Equation and Dynamics ..... 604
48. Investment with Installation Costs ..... 609
a. A Model of Investment with Installation Costs ..... 610
b. Capital Accumulation and Stock Prices in a Small Open Economy ..... 617
49. The Cass-Koopmans Model and Some Applications ..... 622
a. Optimal Consumption for an Infinitely-Lived Household ..... 622
b. Equilibrium and Dynamics in a Model with Taxes on Factor Income ..... 625
c. The Welfare Cost of Factor Taxes ..... 629
50. Problems ..... 643
a. An Efficiency-Wage Model ..... 644
b. Unemployment in a Matching Model ..... 646
c. The Behaviour of the Savings Rate in the CassKoopmans Model ..... 647
d. Productive Government Spending in a Model of Endogenous Growth ..... 649
e. A Model of Endogenous R\&D ..... 650
Bibliography ..... 653
Notes ..... 654
Appendix. Solutions to the Problems ..... 659
Subject Index ..... 827
Author Index ..... 829

## Preface and Acknowledgments

Much of the time of the average graduate student in economics is spent learning a new language, that of mathematics. Although the investment does eventually pay off in many ways, the learning process can be quite painful. I know because I have been there. I remember the long nights spent puzzling over the mysteries of the Hamiltonian, the frustration of not understanding a single one of the papers in my second macroeconomics reading list, the culture shock that came with the transition from the undergraduate textbooks, with their familiar diagrams and intuitive explanations, into Debreu's Theory of Value, and my despair before the terse and incredibly dry prose of the mathematics texts where I sought enlightenment about the arcane properties of contractions.

This book is an attempt to make the transition into graduate economics somewhat less painful. Although some of my readers may never believe me, I have tried to do a number of things that should make their lives a bit easier. The first has been to collect in one place, with a homogeneous notation, most of the mathematical concepts, results, and techniques that are required to follow the standard first- and second-year theory courses. I have also tried to organize this material into a logical sequence and have illustrated its applications to some of the standard models. And last but not least, I have attempted to provide rigorous proofs for most of the results as a way to get the reader used to formal reasoning. Although a lot of effort has gone into making the text as clear as possible, the result is still far from entertaining. Most students without a good undergraduate background in mathematics are likely to find the going a bit rough at times. They have all my sympathy and the assurance that it does build character.

This book has been long in the making. It started out as a set of notes that I wrote for myself during my first year at Penn. Those notes were then refined for the benefit of my younger classmates when I became a teaching assistant, and they finally grew into lecture notes when I had the misfortune to graduate and was forced onto the other side of the lectern. Along the way,

I have had a lot of help. Much of the core material can be traced back to class lectures by Richard Kihlstrom, George Mailath, Beth Allen, David Cass, Maurice Obstfeld, Allan Drazen, Costas Azariadis, and Randy Wright. The first typed version of these notes was compiled jointly with Francis Bloch over a long and sticky Philadelphia summer as a reference for an introductory summer course for incoming students. Francis had the good sense to jump ship right after that, but some of his material is still here in one form or another. Several colleagues and friends have had the patience to read through various portions of the manuscript and have made many useful comments and suggestions. Among these, I would especially like to thank David Pérez and Maite Naranjo, who has also contributed a couple of the more difficult proofs. Thanks are also due to several generations of students at the Universidad Autónoma de Barcelona and various other places, who, while sweating through successive versions of this manuscript, have helped me to improve it in various ways and have detected a fair number of errors, as well as the usual typos. Finally, I would like to thank Conchi Rodriguez, Tere Lorenz, and the rest of the staff at the Instituto de Análisis Económica for their secretarial support and for their heroic behavior at the Xerox machine.

## Review of Basic Concepts

This chapter reviews some basic concepts that will be used throughout the text. One of its central themes is that relations and functions can be used to introduce different types of "structures" in sets. Thus relations of a certain type can be used to order sets according to criteria like precedence, size, or goodness; algebraic operations are defined using functions, and a function that formalizes the notion of distance between two elements of a set can be used to define topological concepts like convergence and continuity. In addition, we also introduce some simple notions of logic and discuss several methods of proof that will be used extensively later on.

## 1. Sets

A set is a collection of objects we call elements. We will denote sets by capital letters, and elements by lowercase letters. If $x$ is an element of a set $X$, we write $x \in X$, and $x \notin X$ otherwise. A set $A$ is a subset of $X$ if all elements of $A$ belong to $X$. This is written $A \subseteq X(A$ is contained in $X)$. Formally, we can write

$$
A \subseteq X \Leftrightarrow(x \in A \Rightarrow x \in X)
$$

where the one-way arrow $(\Rightarrow)$ denotes implication, and the two-way arrow $(\Leftrightarrow)$ indicates equivalence. Two sets, $A$ and $B$, are equal if they have the same elements, that is, $A=B$ if and only if $A \subseteq B$ and $B \subseteq A$. The symbol $\varnothing$ denotes the empty set, a set with no elements. By convention, $\varnothing$ is a subset of any set $X$.

Given a set $X$, the power set of $X$, written $P(X)$ or $2^{X}$, is the set consisting of all the subsets $A$ of $X$. A class or family of sets in $X$ is a subset of $P(X)$, that is, a set whose elements are subsets of $X$. We will use "hollow" capital letters to denote families of sets. For example,

$$
\mathbb{A}=\left\{A_{i} ; A_{i} \subseteq X, i \in I\right\}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-011.jpg?height=470&width=1082&top_left_y=188&top_left_x=196)

Figure 1.1. Union and intersection of two sets.

where $I$ is some index set, such as the set of all natural numbers smaller than some given number $n$.

In what follows we will take as given some set $X$ (the universal set), and assuming that "there is nothing" outside $X$, we will work with its subsets. Given two subsets of $X, A$ and $B$, we define their union, $A \cup B$, as the set

$$
A \cup B=\{x \in X ; x \in A \text { or } x \in B\}
$$

That is, $A \cup B$ is the set of elements of $X$ that belong to $A$ or to $B$ or to both. Similarly, the intersection of $A$ and $B$, denoted by $A \cap B$, is the set whose elements belong to both sets at the same time:

$$
A \cap B=\{x \in X ; x \in A \text { and } x \in B\}
$$

These concepts can be extended in a natural way to classes of more than two sets. Given a family of subsets of $X, \mathbb{A}=\left\{A_{i} ; i \in I\right\}$, its union and intersection are given respectively by

$$
\begin{aligned}
& \cup \mathbb{A}=\cup_{i \in I} A_{i}=\left\{x \in X ; \exists i \in I \text { s.th. } x \in A_{i}\right\} \quad \text { and } \\
& \cap \mathbb{A}=\cap_{i \in I} A_{i}=\left\{x \in X ; x \in A_{i} \forall i \in I\right\}
\end{aligned}
$$

where the existential quantifier " $\exists$ " means "there exists some," the universal quantifier " $\forall$ " means "for all," and "s.th." means "such that." That is, $x$ is an element of the union $\cup \mathbb{A}$ if it belongs to at least one of the sets in the family $\mathbb{A}$, and it is an element of the intersection if it belongs to all sets in the class.

The following theorem summarizes the basic properties of unions and intersections of sets.

Theorem 1.1. Properties of unions and intersections of sets. Let A, B, and C be three subsets of $\mathrm{X}$. Then the following properties hold:
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-012.jpg?height=458&width=1070&top_left_y=178&top_left_x=210)

Figure 1.2. Distributive law.

(i) Commutative law: $\mathrm{A} \cup \mathrm{B}=\mathrm{B} \cup \mathrm{A}$ and $\mathrm{A} \cap \mathrm{B}=\mathrm{B} \cap \mathrm{A}$.

(ii) Associative law: $(\mathrm{A} \cup \mathrm{B}) \cup \mathrm{C}=\mathrm{A} \cup(\mathrm{B} \cup \mathrm{C})=\mathrm{A} \cup \mathrm{B} \cup \mathrm{C}$ and $(\mathrm{A} \cap \mathrm{B}) \cap \mathrm{C}=$ $A \cap(B \cap C)=A \cap B \cap C$.

(iii) Distributive law: $(\mathrm{A} \cup \mathrm{B}) \cap \mathrm{C}=(\mathrm{A} \cap \mathrm{C}) \cup(\mathrm{B} \cap \mathrm{C})$ and $(\mathrm{A} \cap \mathrm{B}) \cup \mathrm{C}=$ $(\mathrm{A} \cup \mathrm{C}) \cap(\mathrm{B} \cup \mathrm{C})$.

Two sets $A$ and $B$ are disjoint if they have no elements in common, that is, if $A \cap B=\varnothing$. More generally, given a family of sets, $\mathbb{A}=\left\{A_{i} ; i \in I\right\}$ in $X$, we say that the elements of $\mathbb{A}$ are pairwise disjoint if

$$
A_{i} \cap A_{j}=\varnothing \forall i \neq j
$$

We will sometimes use the notation $A \subseteq B$ to indicate the union of disjoint sets. The expression $\underline{\cup}_{i \in I} A_{i}$ will denote the union of a family of pairwisedisjoint sets.

A partition of $X$ is a class of pairwise-disjoint sets in $X$ whose union is $X$ itself; that is, $\mathbb{A}=\left\{A_{i} ; i \in I\right\}$ is a partition of $X$ if

$$
\forall i \neq j, A_{i} \cap A_{j}=\varnothing \quad \text { and } \quad \underline{\cup}_{i} A_{i}=X
$$

Given two sets $A$ and $B$ in $X$, their difference $A \sim B$ (or $A-B$ or $A \backslash B$ ) is the set of elements of $A$ that do not belong to $B$ :

$$
A \sim B=\{x \in X ; x \in A \text { and } x \notin B\}
$$

The complement of $A$ (relative to $X$ ) is the set $A^{c}$ or $\sim A$ of elements of $X$ that do not belong to $A$ :

$$
\sim A=A^{c}=\{x \in X ; x \notin A\}
$$

Hence we have

$$
A \sim B=A \cap(\sim B) \text { and } \sim A=X \sim A
$$

Figure 1.3. $A \sim B=A \cap(\sim B)$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-013.jpg?height=354&width=427&top_left_y=192&top_left_x=948)

Let $\mathbb{A}=\left\{A_{i} ; i=1,2, \ldots\right\}$ be a class of sets in $X$, and let $\mathbb{C}=\left\{A_{i}^{c} ; i=1\right.$, $2, \ldots\}$ be the family formed by the complements of the elements of $\mathbb{A}$. The following result says that the complement of the union of $\mathbb{A}$ is equal to the intersection of $\mathbb{C}$, and the complement of the intersection of $\mathbb{A}$ is the union of $\mathbb{C}$.

Theorem 1.2. Duality principle or De Morgan's laws. Let $\mathbb{A}=\left\{\mathrm{A}_{\mathrm{j}} ; \mathrm{i} \in \mathrm{I}\right\}$ be a family of sets in $\mathrm{X}$; then

(i) $\sim\left(\cup_{\mathrm{i} \in \mathrm{I}} \mathrm{A}_{\mathrm{i}}\right)=\cap_{\mathrm{i} \in \mathrm{I}}\left(\sim \mathrm{A}_{\mathrm{i}}\right)$, and

(ii) $\sim\left(\cap_{i \in I} A_{i}\right)=\cup_{i \in \mathbb{I}}\left(\sim A_{i}\right)$.

This result also holds when we consider complements relative to some set that is not the universal set. Hence, if $\mathbb{A}=\left\{A_{i} ; i \in I\right\}$ is a family of subsets of some set $Y$, then

(i) $Y \sim\left(\cup_{i \in I} A_{i}\right)=\cap_{t \in I}\left(Y \sim A_{i}\right)$, and

(ii) $Y \sim\left(\cap_{i \in I} A_{i}\right)=\cup_{i \in I}\left(Y \sim A_{i}\right)$.

## 2. A Bit of Logic

In this section we introduce some basic notions of logic that are often used in proofs.

## (a) Properties and Quantifiers

Fix a set $X$, and let $P$ be a property such that for each element $x$ of $X$, the statement " $x$ has property $P$ " is either true or false (but not both at once, and not neither). If property $P$ holds for $x$, we say that $P(x)$ is true and write $P(x)$. With each such property $P$ we can associate the set $P_{T}$ of elements of $X$ for which $P(x)$ is true:

$$
P_{T}=\{x \in X ; P(x)\}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-014.jpg?height=318&width=454&top_left_y=192&top_left_x=104)

Figure 1.4. Sets associated with composite properties.

Similarly, with every subset $A$ of $X$ we can associate the property "being an element of $A$." In this manner we can establish a correspondence between sets and properties that will allow us to identify logical operations with set operations.

Given a property $P$, its negation $\neg P$ ("not $P$ ") is another property such that $\neg P(x)$ is true if and only if $P(x)$ is false. Because for any $x$ in $X$ precisely one of the two properties $P$ and $\neg P$ will hold, the set associated with $\neg P$ is the complement of $P_{T}$ :

$$
(\neg P)_{T}=\{x \in X ; \neg P(x) \text { is true }\}=\{x \in X ; P(x) \text { is false }\}=\sim P_{T}
$$

Therefore, $P_{T}$ and $(\neg P)_{T}$ form a partition of $X$. That is, for any property $P$,

$$
(\neg P)_{T} \cap P_{T}=\varnothing \quad \text { and } \quad(\neg P)_{T} \cup P_{T}=X
$$

The logical connectives "and" $(\wedge)$ and "or " $(\vee)$ can be used to construct composite properties. Given two properties $P$ and $Q$, their conjunction $P \wedge$ $Q$ (" $P$ and $Q$ ") is the property that holds if and only if both $P$ and $Q$ hold at the same time. Hence, the set associated with $P \wedge Q$ is the intersection of the sets associated with the two original properties. That is,

$$
\begin{aligned}
(P \wedge Q)_{T} & =\{x \in X ; P(x) \text { and } Q(x)\}=\{x \in X ; P(x)\} \cap\{x \in X ; Q(x)\} \\
& =P_{T} \cap Q_{T}
\end{aligned}
$$

In a similar way, we define the (nonexclusive) disjunction of $P$ and $Q$, $P \vee Q$ ("P or $Q$ "), as the property such that $(P \vee Q)(x)$ is true whenever $P(x)$ or $Q(x)$ or both hold. Hence, the set associated with the disjunction of $P$ and $Q$ is the union of $P_{T}$ and $Q_{T}$ :

$$
\begin{aligned}
(P \vee Q)_{T} & =\{x \in X ; P(x) \text { or } Q(x)\}=\{x \in X ; P(x)\} \cup\{x \in X ; Q(x)\} \\
& =P_{T} \cup Q_{T}
\end{aligned}
$$

To construct the negation of a composite property, we can make use of De Morgan's laws. From Theorem 1.2 we have

$$
\sim\left(P_{T} \cup Q_{T}\right)=\left(\sim P_{T}\right) \cap\left(\sim Q_{T}\right) \quad \text { and } \quad \sim\left(P_{T} \cap Q_{T}\right)=\left(\sim P_{T}\right) \cup\left(\sim Q_{T}\right)
$$

from where

$$
\neg(P \vee Q)=(\neg P) \wedge(\neg Q) \text { and } \neg(P \wedge Q)=(\neg P) \vee(\neg Q)
$$

That is, not having the property " $P$ or $Q$ " is equivalent to not having either one, and not having the property " $P$ and $Q$ " is the same as lacking at least one of them.

Quantifiers are often used to indicate that all or some of the elements of a given set have a certain property. To say that all the elements of set $A$ have property $P$, we use the universal quantifier $(\forall)$ and write

$$
\begin{equation*}
\forall x \in A, P(x) \quad \text { (i.e., for all } x \text { in } A, P(x) \text { is true) } \tag{1}
\end{equation*}
$$

To say that some elements of $A$ have a given property, we use the existential quantifier $(\exists):^{1}$

$$
\begin{array}{ll}
\exists x \in A \text {, s.th. } P(x) \quad \text { (i.e., there is at least one element } x \text { of } A \\
& \text { such that } P(x) \text { is true) } \tag{2}
\end{array}
$$

Quantifiers can be seen as generalizations of logical connectives. Hence, if $A$ is a finite set of the form $\left\{x_{1}, x_{2}, \ldots, x_{n}\right\}$, the statements (1) and (2) are equivalent to

$$
P\left(x_{1}\right) \wedge P\left(x_{2}\right) \wedge \ldots \wedge P\left(x_{n}\right) \text { and } P\left(x_{1}\right) \vee P\left(x_{2}\right) \vee \ldots \vee P\left(x_{n}\right)
$$

respectively. The earlier notation, however, has the advantage of being more compact and can also be used for infinite sets.

Expressions involving several quantifiers are commonly encountered. For example, the statement

$$
\begin{equation*}
\forall x \in A, \exists y \in B \text { s.th. } P(x, y) \tag{3}
\end{equation*}
$$

means that "for all $x$ in $A$, there exists an element $y$ in $B$ such that the pair $(x, y)$ has property $P$." In these cases, it is important to keep in mind that the order in which quantifiers appear matters. Thus the statement

$$
\begin{equation*}
\exists y \in B \text { s.th. } \forall x \in A, P(x, y) \tag{4}
\end{equation*}
$$

("there exists an element $y$ in $B$ such that for each $x$ in $A$, the pair $(x, y)$ has property $P^{\prime \prime}$ ) is different from (3): In the first case, the choice of $y$ may depend on the given value of $x$, whereas in (4) we are asserting the existence of at least one $y$ that will work for all possible values of $x$. If we let $A$ and $B$ be the set of real numbers, and $P$ the property that $x+y=0$, for example, statement (3) is true (with $y=-x$ ), but (4) is false.

We often want to negate statements involving quantifiers. If it is not true that all the elements of a set $A$ have property $P$, then clearly it must be the case that some elements of $A$ have property $\neg P$. Hence

$$
\neg[\forall x \in A, P(x)] \Leftrightarrow \exists x \in A \text { s.th. } \neg P(x)
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-016.jpg?height=351&width=418&top_left_y=194&top_left_x=104)

Figure 1.5. Implication as set inclusion.

Similarly, if there exist no elements of $A$ with property $P$, all elements of the set must satisfy $\neg P$. That is,

$$
\neg[\exists x \in A \text {, s.th. } P(x)] \Leftrightarrow \forall x \in A, \neg P(x)
$$

Hence, to negate a statement that makes use of quantifiers, we replace the $\forall$ 's with $\exists$ 's, and vice versa, and negate the properties. The same principle applies to statements involving several quantifiers. For example,

$$
\begin{aligned}
\neg(\forall x \in A, \exists y \in B \text {, s.th. } P(x, y)) & \Leftrightarrow \exists x \in A \text { s.th. } \neg(\exists y \in B \text { s.th. } P(x, y)) \\
& \Leftrightarrow \exists x \in A \text { s.th. } \forall y \in B, \neg P(x, y)
\end{aligned}
$$

That is, we begin with the statement "for all $x$ in $A$, there exists an element $y$ in $B$ such that the pair $(x, y)$ has property $P$." If that is not true, then there must exist some $x$ in $A$ such that for all $y$ in $B$ the pair $(x, y)$ does not have property $P$.

## (b) Implication

We often make statements of the type "property $P$ implies property $Q$ " meaning that all elements that have property $P$ also satisfy $Q$. This statement can be written " $P \Rightarrow Q$ " - an expression that can also be read as

"if $P$ then $Q$,"

" $P$ is a sufficient condition for $Q$," or

" $Q$ is a necessary condition for $P$."

In terms of the associated sets, $" P \Rightarrow Q$ " means that

$$
P_{T} \subseteq Q_{T}
$$

Using quantifiers, the statement $P \Rightarrow Q$ can also be written

$$
\forall x \in P_{T}, Q(x)
$$

That is, if all elements $x$ with property $P$ also satisfy $Q$, then $P_{T}$ must be contained in the set $Q_{T}$, and vice versa.

Figure 1.6.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-017.jpg?height=353&width=426&top_left_y=188&top_left_x=944)

To express " $P \Rightarrow Q$ " in terms of an equivalent property that will be useful later, observe that

$$
P_{T} \subseteq Q_{T} \quad \text { if and only if }\left(\sim P_{T}\right) \cup Q_{T}=X
$$

where $X$ is the universal set. The proof of this equivalence is left as an exercise, but the result should be intuitively clear, for if $Q_{T}$ contains $P_{T}$, all points that lie outside $Q_{T}$ will necessarily be outside $P_{T}$. Hence the statement $P \Rightarrow Q$ is true if and only if

$$
x \in\left(\sim P_{T}\right) \cup Q_{T} \forall x \in X
$$

or, equivalently, the property $(\neg P) \vee Q$ always holds. Figure 1.6 tries to clarify this result.

The negation of $P \Rightarrow Q$, written $P \nRightarrow Q$ or $\neg(P \Rightarrow Q)$, is true whenever there exists at least one $x$ that satisfies $P$ but not $Q$ (that is, when $\exists x \in P_{T}$ s.th. $\neg Q(x)$ ). Drawing on our previous discussion, this is equivalent to saying that $P \nRightarrow Q$ is true when the negation of $(\neg P) \vee Q$ is true for some $x$ in $X$. Applying De Morgan's laws,

$$
\neg((\neg P) \vee Q)=P \wedge(\neg Q)
$$

which implies that $P \Rightarrow Q$ is equivalent to

$$
P_{T} \cap\left(\sim Q_{T}\right) \neq \varnothing
$$

This result is readily apparent using a Venn diagram: As illustrated in Figure 1.6, if $P_{T}$ is not a subset of $Q_{T}$, then there must be elements of $P_{T}$ outside $Q_{T}$; hence the intersection of $P_{T}$ and $\sim Q_{T}$ cannot be empty, and vice versa.

In addition to its negation, there are other statements related to the implication $P \Rightarrow Q$. They are

(i) its converse: $Q \Rightarrow P$,

(ii) its inverse: $\neg P \Rightarrow \neg Q$, and

(iii) its contrapositive statement: $\neg Q \Rightarrow \neg P$.

If both the implication $P \Rightarrow Q$ and its converse $Q \Rightarrow P$ are true, we say that $P$ and $Q$ are equivalent and write $P \Leftrightarrow Q$.

A statement and its contrapositive are equivalent, as is easily seen by applying the equivalence

$$
A \subseteq B \Leftrightarrow(\sim B) \subseteq(\sim A)
$$

to the sets associated with the two properties. This observation is useful because sometimes it is easier to prove the contrapositive than the original statement.

## (c) Methods of Proof

There are several methods that are often used to prove that a statement of the form $P \Rightarrow Q$ or $P \Leftrightarrow Q$ is true. One of the most common is the deductive method, in which we start by assuming that $P$ holds and use this information to verify that $Q$ is also true. Because it is difficult to be much more specific at this level of generality, we shall consider a simple example. There will be many others later.

Example 2.1. Proof of De Morgan's first law. Let $\mathbb{A}=\left\{A_{i} ; i \in I\right\}$ be a family of sets in $X$. We want to prove that

$$
\sim\left(\cup_{i} A_{i}\right)=\cap_{i}\left(\sim A_{i}\right)
$$

That is, we want to show that any element of $\sim\left(\cup_{i} A_{i}\right)$ also belongs to $\cap_{i}\left(\sim A_{i}\right)$, and vice versa. For this, it suffices to verify that the definitions of the two sets are equivalent:

$$
\begin{aligned}
x \in \sim\left(\cup_{i} A_{i}\right) & \Leftrightarrow x \notin \cup_{i} A_{i} \Leftrightarrow \neg\left(\exists i \in I \text { s.th. } x \in A_{i}\right) \\
& \Leftrightarrow \forall i \in I, x \notin A_{i} \Leftrightarrow \forall i \in I, x \in \sim A_{i} \\
& \Leftrightarrow x \in \cap_{i}\left(\sim A_{i}\right)
\end{aligned}
$$

which is what we wanted to show. In words:

(i) Take an arbitrary $x$ in the complement of $\cup_{i} A_{i}$. By definition, $x$ is not an element of $\cup_{i} A_{i}$. Negating the definition of the union of a family of sets $(x$ belongs to $\cup_{i} A_{i}$ if it is an element of any of the $A_{i}^{\prime}$ 's), we obtain that

(ii) $x$ does not belong to any of the $A_{i}$ s; this is the same as saying that for each $i$, $x$ belongs to the complement of $A_{i}$, which in turn is equivalent to the statement that

(iii) $x$ is an element of the intersection of the complements of the $A_{i}$ s,$\cap_{i}\left(-A_{i}\right)$.

(iv) Finally, because this is true for any $x$ in $\cup_{i} A_{i}$, the set of all such $x$ 's (i.e., $\cup_{i} A_{i}$ ) must be contained in $\cap_{i}\left(\sim A_{i}\right)$.

Notice that the reasoning is also valid in the opposite direction. Hence we have proved that

$$
x \in \sim\left(\cup_{i} A_{i}\right) \Rightarrow x \in \cap_{i}\left(\sim A_{i}\right) ; \quad \text { that is, } \sim\left(\cup_{i} A_{i}\right) \subseteq \cap_{i}\left(\sim A_{i}\right)
$$

and

$$
x \in \cap_{i}\left(\sim A_{i}\right) \Rightarrow x \in \sim\left(\cup_{i} A_{i}\right) ; \quad \text { that is, } \cap_{i}\left(\sim A_{i}\right) \subseteq \sim\left(\cup_{i} A_{i}\right)
$$

and we can conclude that the two sets are equal.

Problem 2.2. Prove the following equivalence ( $X$ is the universal set):

$$
P \subseteq Q \Leftrightarrow(\sim P) \cup Q=X
$$

Problem 2.3. Prove the second of De Morgan's laws: Let $\mathbb{A}=\left\{A_{i} ; i \in I\right\}$ be a family of sets in $X$. Then $\sim\left(\cap_{i} A_{i}\right)=\cup_{i}\left(\sim A_{i}\right)$.

The following example shows the usefulness of the equivalence between an implication and its contrapositive.

Theorem 2.4. Given two arbitrary real numbers a and b, we have

$$
\forall \varepsilon>0, \mathrm{a} \leq \mathrm{b}+\varepsilon \Rightarrow \mathrm{a} \leq \mathrm{b} \quad(\mathrm{P} \Rightarrow \mathrm{Q})
$$

Proof. The contrapositive of this statement $(\neg Q \Rightarrow \neg P)$ can be written

$$
a>b \Rightarrow \exists \varepsilon>0, a>b+\varepsilon
$$

This is very easy to prove. Because $a>b, a-b>0$, and there exist real numbers $\varepsilon$ such that $0<\varepsilon<a-b$ (e.g., $(a-b) / 2$ ). For any such number we have

$$
b+\varepsilon<b+(a-b)=a
$$

Another method that is often useful for establishing properties associated with the set of natural numbers is based on the following axiom.

Axiom 2.5. The principle of induction. Let $\mathrm{P}$ be a property that natural numbers (or positive integers) may or may not have. If

(i) there exists some natural number $\mathrm{n}_{0}$ such that $\mathrm{P}\left(\mathrm{n}_{0}\right)$ holds, and

(ii) for any natural number, $\mathrm{P}(\mathrm{n}) \Rightarrow \mathrm{P}(\mathrm{n}+1)$,

then $\mathrm{P}$ holds for all natural numbers larger than or equal to $\mathrm{n}_{0}$.

That is, to prove statements of the form "all natural numbers larger than or equal to $n_{0}$ have property $P$," it is enough to establish that the property holds for $n_{0}$ and that if it holds for $n$ it will also do so for $n+1$. Notice that
this is really a statement about the structure of the set of natural numbers. It tells us that the set of natural numbers larger than or equal to $n_{0}$ is the set $\left\{n_{0}, n_{0}+1,\left(n_{0}+1\right)+1, \ldots\right\}$ (i.e., that this set can be constructed recursively by adding 1 to the previous element, starting from $n_{0}$ ). If we start from zero, this property can be taken as a definition of the set $\mathbb{N}$ of natural numbers and can therefore be seen as an axiom or basic assumption. It does, however, provide a simple way to establish many useful results, as illustrated by the following example.

Example 2.6. A proof by induction. We shall show that for any positive integer $k$,

$$
\begin{equation*}
\sum_{n=1}^{k} n=\frac{k(k+1)}{2} \tag{1}
\end{equation*}
$$

(where $n$ takes on all integer values from 1 to $k$ ). The formula clearly holds for 1 , because then it simply says that

$$
1=\frac{1(1+1)}{2}
$$

Next we will assume that (1) holds for an arbitrary $k$ and show that this implies that it also holds for $k+1$. For this, we add $(k+1)$ to both sides of (1) and rearrange terms to get

$$
\left(\sum_{n=1}^{k} n\right)+(k+1)=\frac{k(k+1)}{2}+(k+1) \Rightarrow \sum_{n=1}^{k+1} n=(k+1)\left(1+\frac{k}{2}\right)=\frac{(k+1)(k+2)}{2}
$$

which completes the proof.

An indirect strategy that is often useful is the proof by contradiction. To show that $P \Rightarrow Q$, it is sufficient to show that its negation, $P \Rightarrow Q$, yields a contradiction, that is, a statement of the form $R \wedge(\neg R)$, which can never be true. Intuitively, the idea is that if a given premise leads to a contradiction, then it cannot possibly be correct. Formally, if we can show that $P \nRightarrow Q$ leads to a contradiction, we will have shown that

$$
P \wedge(\neg Q) \Rightarrow R \wedge(\neg R)
$$

(where we are making use of an equivalence derived earlier). But then the contrapositive statement

$$
(\neg R) \vee R \Rightarrow Q \vee(\neg P)
$$

will also be true. And because the first property is always true (for any $x$ and $R$, either $R$ or $\neg R$ will be true), the second (which, as we have seen, is equiv-
alent to $P \Rightarrow Q$ ) will always hold. As an example, we will prove the following result.

Theorem 2.7. The well-ordering principle. Every nonempty set of positive integers contains a least element.

Proof. Let $P$ be a nonempty set of positive integers, and define $S$ as the set of all positive integers that are strictly smaller than all elements of $P$. That is,

$$
S=\left\{n \in \mathbb{Z}_{+} ; n<p \forall p \in P\right\}
$$

To prove the theorem, we first assume that $P$ does not have a smallest element and attempt to show that this implies that $S$ is the entire set of positive integers. But that would be a contradiction, for then $S$ would contain the set $P$ (which is nonempty by assumption), implying that for any number $p$ in $P$ we would have $p<p$, which clearly is impossible.

Assuming that $P$ has no smallest element, we will proceed by induction:

(i) We observe that 1 , which is the smallest positive integer, must belong to $S$.

(ii) Next, let $k$ be an arbitrary positive integer. We will show that if $k$ belongs to $S$, then so does $k+1$. We proceed by contradiction: Suppose $k$ is strictly smaller than any element of $P$, but $k+1$ is not (i.e., $k \in S$, but $k+1 \notin S$ ).

Then $\left(k+1 \notin S\right.$ implies that) there exists a number $p_{1} \in P$ such that $k+1 \geq p_{1}$. Moreover, because $P$ has no least element, there exists some other number $p_{2} \in P$ such that $p_{2}<p_{1}$. Combining these two inequalities,

$$
\begin{array}{r}
p_{2}<p_{1} \leq k+1 \\
\quad \Rightarrow p_{2}<k+1 \tag{1}
\end{array}
$$

Now, because both $p_{2}$ and $k$ are integers, (1) implies

$$
p_{2} \leq k
$$

and we conclude that $k$ is not strictly smaller than every element of $P$. Hence, we have reached a contradiction, and we conclude that $k \in S$ implies $k+1 \in S$.

Given (i) and (ii), it follows by induction that $S$ is the whole of $\mathbb{Z}_{+}$. Because this leads to a contradiction, we conclude that $P$ must have a least element.

Problem 2.8. The following modification of the induction principle is sometimes useful: Let $P$ be a property that natural numbers (or positive integers) may or may not have. If
(i) $P(0)$ holds and

(ii) if $P$ holds for all integers $k=0,1, \ldots, n-1$, then it also holds for $n$.

Then $P$ holds for all natural numbers.

Complete the following proof of this result: Let $S$ be the set of nonnegative integers for which $P(n)$ is false. We want to show that $S$ is the empty set. Suppose that $S$ is not empty, and use the well-ordering principle and assumptions (i) and (ii) to reach a contradiction.

Problem 2.9. Use the modified induction principle to prove that any integer larger than 1 is either a prime number (it has no integer divisors other than 1 ) or the product of prime numbers.

## 3. Relations

Given two sets $X$ and $Y$, their Cartesian product $X \times Y$ is the set of all ordered pairs formed by an element of $X$ followed by one of $Y$. That is,

$$
X \times Y=\{(x, y) ; x \in X \text { and } y \in Y\}
$$

A (binary) relation from $X$ to $Y$ is a subset $R$ of $X \times Y$. In many cases we work with relations defined on $X \times X$. In this case, we speak of a relation defined on $X$.

If $(x, y) \in R$, we often write $x R y$ or $y \in R(x)$ and say that $y$ is an image of $x$. The image set of $x$ is given by

$$
R(x)=\{y \in Y ;(x, y) \in R\}
$$

If $R$ is a relation from $X$ to $Y$, its inverse relation, $R^{-1}$, is a relation from $Y$ to $X$ defined by

$$
R^{-1}=\{(y, x) ;(x, y) \in R\}
$$

Let $R$ be a relation from $X$ to $Y$. If $A$ is a subset of $X$, the image of $A$ under $R$ is the subset of $Y$ given by

$$
R(A)=\{y \in Y ; \exists x \in A \text { s.th. }(x, y) \in R\}=\cup_{x \in A} R(x)
$$

If $B$ is a subset of $Y$, the inverse image of $B$ under $R$ is its image set under $R^{-1}$ :

$$
R^{-1}(B)=\{x \in X ; \exists y \in B \text { s.th. }(x, y) \in R\}=\cup_{y \in B} R^{-1}(y)
$$

The inverse image of $Y$ (i.e., the set of points of $X$ that each has at least one image in $Y$ ) is the domain of the relation:

$$
D_{R}=R^{-1}(Y)=\{x \in X ; R(x) \neq \varnothing\}
$$

And the image of $X$ under $R$ is the range of $R$ :

$$
R_{R}=R(X)=\left\{y \in Y ; R^{-1}(y) \neq \varnothing\right\}
$$

Given two relations $R$ and $S$ defined on the product set $X \times Y$, we say that $S$ is a subrelation of $R$ if $S \subseteq R$ or, equivalently, if $x S y \Rightarrow x R y$. We can also say that $S$ is a restriction of $R$, or that $R$ is an extension of $S$. For example, weak vector dominance ( $\geq$ ), defined by

$$
x \geq y \Leftrightarrow x_{i} \geq y_{i} \forall i=1, \ldots, n
$$

is a binary relation defined on $\mathbb{R}^{\mathbf{n}} \times \mathbb{R}^{\mathbf{n}}$. Strict vector dominance ( $>$ ), defined in a similar way, but with strict inequalities, is a subrelation of weak vector dominance ( $\geq$ ), because $x>y$ implies $x \geq y$.

Let $R$ be a relation from $X$ to $Y$, and $S$ a relation from $Y$ to $Z$. Their composition, $R \circ S$ is the relation from $X$ to $Z$ given by

$$
R \circ S=\{(x, z) ; \exists y \in Y \text { s.th. }(x, y) \in R \text { and }(y, z) \in S\}
$$

Intuitively, the concept of "relation" provides a way to formalize the idea that two objects (typically two elements of the same set) stand in a certain relationship to each other. For example, if $x$ and $y$ are real numbers, one may be larger than the other. If $x$ and $y$ denote consumption bundles, a given consumer may prefer one to the other. The notation $x R y$, interpreted as " $x$ stands in a certain relation to $y$," is therefore more suggestive than the notation $(x, y) \in R$, although they are equivalent. However, the formal definition of "relation as a set" is convenient from a mathematical point of view. It allows us, for example, to think in terms of subsets of $R$, or to decompose $R$ in smaller "factors."

As we will see, the notion of relation is a basic instrument that can be used to define different types of structures on a set. In Section 4 we will introduce the concept of "function" as a special type of relation. That, in turn, will allow us to introduce an algebraic or topological structure in a set by defining functions with convenient properties that we will call "operations" or "metrics." Before getting into these subjects, the discussion in the rest of this section will focus on two types of relations that can be used to impose a certain "order" in a given set. An equivalence relation allows us to partition a set into a collection of subsets of "equivalent" elements, and an order relation allows us to classify the elements of a set according to criteria of preference and goodness or precedence and size. Because such relations are defined in terms of certain properties that relations may have, we begin by introducing these properties.

Definition 3.1. Let $R$ be a binary relation defined on $X$. We say that $R$ is reflexive if $\forall x \in X, x R x$, symmetric if $\forall x, y \in X, x R y \Leftrightarrow y R x$, antisymmetric if $\forall x, y \in X,(x R y$ and $y R x) \Rightarrow x=y$, and transitive if $\forall x, y, z \in X,(x R y$ and $y R z) \Rightarrow x R z$.

## (a) Equivalence Relations and Decomposition of a Set into Classes

Definition 3.2. Equivalence relation. A binary relation $R$ defined on a set $X$ is an equivalence relation if it is reflexive, symmetric, and transitive.

Sometimes we are interested in decomposing a given set into a collection of pairwise-disjoint sets whose union is equal to the original set (i.e., into a partition). Such a partition of a set is called a decomposition of the set into (equivalence) classes. A natural way to achieve such a partition is to specify an equivalence relation $R$ on $X$ and then assign to each class all those elements that are related to each other under $R$.

Theorem 3.3. Partition of a set into classes. $A$ set $\mathrm{X}$ can be partitioned into classes by using an equivalence relation $\mathrm{R}$ as a criterion for assigning two elements to the same class. Conversely, every partition of a set defines an equivalence relation on it.

Proof. Let $R$ be an equivalence relation on $X$. For each $a$ in $X$, define the set

$$
C_{a}=\{x \in X ; x R a\}
$$

It is obvious that each element of $X$ belongs to at least one such set, and also that some of these sets may be equal. To prove that the relation defines a partition, we must show that any two such sets, $C_{a}$ and $C_{b}$, are either disjoint or identical (if $a R b$ ).

Suppose $C_{a}$ and $C_{b}$ have a common element, say $c$. By assumption, $c R a$ and $c R b$. By symmetry, $a R c$, and by transitivity,

$$
(a R c \text { and } c R b) \Rightarrow a R b
$$

Hence $a$ and $b$ are in the same class of elements, and we conclude that if $C_{a}$ and $C_{b}$ have any common elements, they are the same set. That is, the pairwise-disjoint sets of this type form a partition of $X$ into equivalence classes.

We observe that every partition of $X$ into pairwise-disjoint classes determines a binary relation on $X$, where $x R y$ means that $x$ and $y$ belong to the
same class. It is clear that this relation is reflexive, symmetric, and transitive (i.e., is an equivalence relation).

Definition 3.4. Quotient set. Let $X$ be a set, and $R$ an equivalence relation on $X$ that determines a partition of $X$ into classes. The set of equivalence classes under $R$ is called the quotient set of $X$ with respect to $R$.

## (b) Order Relations and Ordered Sets

A class of binary relations of particular interest is the one that allows us to formalize the idea that some elements of a set dominate (or are "larger than") others. Such a relation is called an "order relation," and a set in which an order relation has been defined is called an ordered set.

Let " $\geq$ " be a binary relation on the set $X$. We interpret the expression $x \geq y$ as saying that, in some relevant way, $x$ dominates $y$, is larger than $y$, or comes after it. Equivalently, we can work with the inverse relation " $\leq$," where $x \leq y$ is equivalent to $y \geq x$ and indicates that $x$ is "smaller" than $y$ or precedes it. We now define two common types of order relations.

Definition 3.5. Preordering. A binary relation " $\geq$ " defined on a set $X$ is a partial preordering or quasiordering if it is reflexive and transitive, that is, if

$$
\forall x, y, z \in X, x \geq x \text { and }[(x \geq y \text { and } y \geq z) \Rightarrow x \geq z]
$$

We say that $X$ is partially preordered by " $\geq$." If, in addition, any pair of elements $x$ and $y$ of $X$ are comparable under the relation, that is, if

$$
\forall x, y, \in X, x \geq y \text { or } y \geq x \text { or both }
$$

then " $\geq$ " is a complete or total preordering, and we say that $X$ is totally preordered by " $\geq$."

Definition 3.6. Ordering. A binary relation " $\geq$ " defined on a set $X$ is a partial ordering if it is reflexive, transitive, and antisymmetric, that is, if it is a partial preordering and, moreover,

$$
\forall x, y \in X,(x \geq y \text { and } y \geq x) \Rightarrow x=y
$$

We then say that $X$ is partially ordered by " $\geq$." If, in addition, any pair of elements of $X$ are comparable under the relation, " $\geq$ " is a complete or total ordering, and we say that $X$ is totally ordered by it. ${ }^{2}$

The standard order relation defined on the set of real numbers is a complete ordering. This relation is antisymmetric, for given any two real numbers $\alpha$ and $\beta, \alpha \geq \beta$ and $\beta \geq \alpha$ imply $\alpha=\beta$.

Notice that the only difference between a preordering and an ordering is that the preordering need not be antisymmetric; that is, it is possible to have $x \geq y, y \geq x$, and $x \neq y$. In this case, we write $x \sim y$ and say that $x$ and $y$ are equivalent.

A preordering can be decomposed into its symmetric and asymmetric components by defining the following two subrelations:

$$
\begin{aligned}
& x>y \text { if and only if } x \geq y \text { and } y \geq x \\
& x \sim y \text { if and only if } x \geq y \text { and } y \geq x
\end{aligned}
$$

(where $y \geq x$ means "not $y \geq x$ "). In the context of the theory of preferences, these relations would be called the strict preference and indifference relations.

In an ordered set, the concept of the "best" or "largest" element makes sense. Hence, we can talk of maximization with respect to an order relation. We must be a bit careful, however, for if the order relation is not complete, some elements of the set may not be comparable. In this case, we cannot speak of a "maximum," but we can still define some closely related concepts.

Definition 3.7. Maximal and minimal elements. Let $X$ be a set partially preordered by a relation " $\geq$." An element $\bar{x}$ of $X$ is maximal (with respect to " $\geq$ ") if no other element of $X$ dominates it strictly, that is, if

$$
x \geq \bar{x} \Rightarrow x \sim \bar{x} \quad \text { (or } x=\bar{x} \text { for an ordering) }
$$

Similarly, an element $\underline{x}$ of $X$ is minimal if no other element strictly precedes it, that is, if

$$
x \leq \underline{x} \Rightarrow x \sim \underline{x} \quad \text { (or } x=\underline{x} \text { for an ordering) }
$$

where " $\leq$ " is the inverse relation of " $\geq$."

Definition 3.8. Largest and smallest elements. Let $X$ be a set partially preordered by " $\geq$." An element $\bar{z}$ of $X$ is a largest or last element of $X$ if it dominates every element of $X$ (i.e., if $\forall x \in X, \bar{z} \geq x$ ). An element $\underline{z}$ of $X$ is a least or first element of $X$ if it precedes every element of $X$ (i.e., if $\forall x \in X$, $\underline{z} \leq x)$.

Notice that a largest element must be maximal, but a maximal element may not be largest if the preordering is partial, for some elements of $X$ may not be comparable with it. If the preordering is complete, however, maximal elements will also be largest. If the relation " $\geq$ " is an ordering, the largest element, when it exists, is unique and is called the maximum. This need not be the case with a preordering, where we may find several largest elements
that are equivalent but are different from each other. With the appropriate changes, all this is also true for minimal and smallest elements.

## 4. Functions

Among the most important types of relations are those we call functions. Intuitively, a function from a set $X$ to a set $Y$ is a rule that assigns to each element of $X$ a unique element of $Y$. We say that $y$ is the image of $x$ under $f$, and write $y=f(x)$. Conversely, $x$ is an element of the preimage or inverse image of $y$, written $x \in f^{-1}(y)$.

Definition 4.1. Function. Let $X$ and $Y$ be two sets. A function $f$ from $X$ to $Y$, written $f: X \longrightarrow Y$, is a relation from $X$ to $Y$ with the property that for each $x \in X$ there exists a unique element $y \in Y$ such that $(x, y) \in f$.

The image and preimage of a set under a given function, and the function's domain and range, are defined as for any relation. If $f$ is a function from $X$ to $Y$, its domain is $X$, and its range is the set $f(X)$. If $A$ is a subset of $X$, its image set is the subset of $Y$ formed by the images of its elements:

$$
f(A)=\{y \in Y ; \exists x \in A \text { s.th. } y=f(x)\}=\cup_{x \in A} f(x)
$$

Given a subset $B$ of $Y$, its inverse image is the set $f^{-1}(B)$ formed by those elements of $X$ with images in $B$ :

$$
f^{-1}(B)=\{x \in X ; f(x) \in B\}
$$

If $x$ is an element of $X$, and $R$ is a relation, the image of $x, R(x)$, may be any subset of $Y$, including the empty set. If $R$ is a function, however, $R(x)$ contains exactly one point of $Y$. Hence, a relation $R$ is a function if and only if its domain is the whole set $X$ and, moreover,

$$
\left(x, y_{1}\right) \in R \text { and }\left(x, y_{2}\right) \in R \Rightarrow y_{1}=y_{2}
$$

or, equivalently,

$$
\forall x \in X, \exists ! y \in Y \text { s.th. } y=f(x)
$$

where " $\exists$ !" means "there exists exactly one element."

Two functions $f$ and $g$ are equal if they are identical as sets, that is, if $f \subseteq g$ and $g \subseteq f$. This is the same as saying that $f$ and $g$ have the same domain and range and, moreover, for every $x$ in $D_{f}=D_{g}$, we have $f(x)=g(x)$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-028.jpg?height=320&width=1121&top_left_y=191&top_left_x=180)

Figure 1.7. Composition of two functions.

If $f$ is a function and, in addition, its range is the whole set $Y$, that is, if $f(X)=Y$, or

$$
\forall y \in Y, \exists x \in X \text { s.th. } y=f(x)
$$

then we say that $f$ is surjective or onto $Y$. We also say that $f$ is injective or one-to-one if it always assigns different images to different elements of $X$, that is, if

$$
\forall x_{1}, x_{2} \in X, f\left(x_{1}\right)=f\left(x_{2}\right) \Rightarrow x_{1}=x_{2}
$$

or, equivalently, if $x_{1} \neq x_{2}$ implies $f\left(x_{1}\right) \neq f\left(x_{2}\right)$. Finally, the function $f$ is bijective if it is both "one-to-one" and "onto," that is, if each element of $Y$ has an inverse image and that inverse image is unique.

Given a function $f$, its inverse relation $f^{-1}: y \longrightarrow x \in f^{-1}(y)$ may or may not be a function. If it is a function, $f^{-1}$ is said to be the inverse function of $f$. If $f$ is one-to-one, each $y$ in $f(X)$ will have a unique inverse image in $X$, and therefore $f^{-1}$ will be a function of $f(X)$ into $X$. If $f$ is also "onto," $f^{-1}$ will be a function from $Y$ to $X$.

If $f$ is a function of $X$ into $Y$, and $g$ is a function of $Y$ into $Z$, their composition, $g \circ f$ is the function of $X$ into $Z$ defined by $(g \circ f)(x)=g[f(x)]$. The composition of two functions obeys the associative law, that is,

$$
(h \circ g) \circ f=h \circ(g \circ f)=h \circ g \circ f
$$

but it is generally not commutative.

We will now review some elementary results concerning the properties of the image sets and inverse-image sets under a function and introduce some concepts that are defined in terms of functions.

Theorem 4.2. Let $\mathrm{f}: \mathrm{X} \longrightarrow \mathrm{Y}$ be a function, and $\mathbb{B}=\left\{\mathrm{B}_{\mathrm{i}} ; \mathrm{i} \in \mathrm{I}\right\}$ a family of subsets of Y. Then

(i) $\mathrm{f}^{-I}\left(\cup_{\mathrm{i} \in \mathrm{I}} \mathrm{B}_{\mathrm{i}}\right)=\cup_{\mathrm{i} \in \mathrm{I}} \mathrm{f}^{-1}\left(\mathrm{~B}_{\mathrm{i}}\right)$, and

(ii) $\mathrm{f}^{-I}\left(\cap_{\mathrm{i} \in \mathrm{I}} \mathrm{B}_{\mathrm{i}}\right)=\cap_{\mathrm{i} \in \mathrm{I}} \mathrm{f}^{-1}\left(\mathrm{~B}_{\mathrm{i}}\right)$.

Proof

(i) $x \in f^{-1}\left(\cup_{i \in I} B_{i}\right) \Leftrightarrow f(x) \in \cup_{i \in I} B_{i}$

$$
\begin{aligned}
& \Leftrightarrow \exists_{i} \in I \text { s.th. } f(x) \in B_{i} \\
& \Leftrightarrow \exists_{i} \in I \text { s.th. } x \in f^{-1}\left(B_{i}\right) \\
& \Leftrightarrow x \in \cup_{i \in I} f^{-1}\left(B_{i}\right) .
\end{aligned}
$$

(ii) $x \in f^{-1}\left(\cap_{i \in l} B_{i}\right) \Leftrightarrow f(x) \in \cap_{i \in I} B_{i}$

$$
\begin{aligned}
& \Leftrightarrow \forall i \in I, f(x) \in B_{i} \\
& \Leftrightarrow \forall i \in I, x \in f^{-1}\left(B_{i}\right) \\
& \Leftrightarrow x \in \cap_{i \in I} f^{-1}\left(B_{i}\right) .
\end{aligned}
$$

Theorem 4.3. Let $\mathrm{f}: \mathrm{X} \longrightarrow \mathrm{Y}$ be a function, and $\mathbb{A}=\left\{\mathrm{A}_{\mathrm{i}} ; \mathrm{i} \in \mathrm{I}\right\}$ a family of subsets of $\mathrm{X}$. Then

(i) $\mathrm{f}\left(\cup_{i \in I} \mathrm{~A}_{i}\right)=\cup_{i \in \mathrm{I}} \mathrm{f}\left(\mathrm{A}_{\mathrm{i}}\right)$, and

(ii) $\mathrm{f}\left(\cap_{i \in I} \mathbf{A}_{i}\right) \subseteq \cap_{i \in I} f\left(A_{i}\right)$.

## Proof

(i) $y \in f\left(\cup_{i \in I} A_{i}\right) \Leftrightarrow \exists x \in \cup_{i \in I} A_{i}$ s.th. $f(x)=y$

$$
\Leftrightarrow \exists i \in I \text { s.th. } f(x)=y \in f\left(A_{i}\right)
$$

$$
\Leftrightarrow y \in \cup_{i \in I} f\left(A_{i}\right) .
$$

(ii) $y \in f\left(\cap_{i \in I} A_{\mathrm{i}}\right) \Leftrightarrow \exists x \in \cap_{i \in I} A_{i}$ s.th. $f(x)=y$

$$
\begin{aligned}
& \left.\Rightarrow \forall i \in I, \exists x_{i} \in A_{i} \text { s.th. } f\left(x_{i}\right)=y \quad \text { (e.g., } x_{i}=x \forall_{i}\right) \\
& \Leftrightarrow \forall i \in I, y \in f\left(A_{i}\right) \\
& \Leftrightarrow y \in \cap_{i \in I} f\left(A_{i}\right)
\end{aligned}
$$

Problem 4.4. Explain why inclusion works only in one direction in the second part of Theorem 4.3, but in both directions in the first part.

(i) Give an example in which $\cap_{i \in I} f\left(A_{i}\right)$ is strictly larger than $f\left(\cap_{i \in I} A_{i}\right)$.

(ii) Prove that if $f$ is one-to-one, then $\cap_{i \in I} f\left(A_{i}\right)=f\left(\cap_{i \in I} A_{i}\right)$.

Problem 4.5. Given a function $f: X \longrightarrow Y$, two subsets of $X, A_{1}$ and $A_{2}$, and two subsets of $Y, B_{1}$ and $B_{2}$, show that

(i) $f^{-1}\left(\sim B_{1}\right)=\sim f^{-1}\left(B_{1}\right)$,

(ii) $f^{-1}\left(B_{1} \sim B_{2}\right)=f^{-1}\left(B_{1}\right) \sim f^{-1}\left(B_{2}\right)$, and

(iii) if $f$ is bijective, then

$$
f\left(\sim A_{1}\right)=\sim f\left(A_{1}\right) \quad \text { and } \quad f\left(A_{1} \sim A_{2}\right)=f\left(A_{1}\right) \sim f\left(A_{2}\right)
$$

What can we say if $f$ is not bijective?

Problem 4.6. Let $f$ be a function from $X$ to $Y$, with $A$ a subset of $X$, and $B$ a subset of $Y$. Then

$$
f\left[f^{-1}(B)\right] \subseteq B \quad \text { and } \quad A \subseteq f^{-1}[f(A)]
$$

When are the two sets not equal to each other?

## Sequences

A particularly useful family of functions is that formed by functions whose domain is the set of the natural numbers. Let $X$ be an arbitrary set, and $\mathbb{N}$ the set of natural numbers. A function $s: \mathbb{N} \longrightarrow X$ is said to be a sequence in $X$. Intuitively, we can think of a sequence, or rather of its range, as an ordered set of elements of $X$. In the usual notation, $x_{i}$ denotes the value of the sequence at $i$, that is, $s(i)=x_{i}$, and $\left\{x_{n}\right\}$ is used to indicate that we are talking about the sequence "as a whole."

It is sometimes useful to define a sequence recursively. That is, given a function $f$ of $X$ into itself, and an element $a$ of $X$, there exists a unique sequence $\left\{x_{n}\right\}$ in $X$ such that $x_{0}=a$ and $x_{n+1}=f\left(x_{n}\right)$ for $n=1,2, \ldots$

Occasionally we may want to work with a "subset" of a given sequence (i.e., with a subsequence). Formally, let $s: \mathbb{N} \longrightarrow X$ be a sequence, and consider a strictly increasing function $g: \mathbb{N} \longrightarrow \mathbb{N}$. The composite function given by $h(k)=s[g(k)]$ for any positive integer $k$ is a subsequence of $s$. The usual notation for a subsequence of $\left\{x_{n}\right\}$ is $\left\{x_{n_{n}}\right\}$, with two subindices. Intuitively, a subsequence is a sequence formed by deleting some terms from the original one. For any $k=1,2, \ldots$, the increasing function $g()$ selects some positive integer $n_{k}>n_{k-1}$, and we take the corresponding term of the original sequence to form $\left\{x_{n}\right\}$. For example, the even-numbered terms of a sequence form a subsequence.

## Correspondences

A correspondence from $X$ to $Y$ is a function that to each element $x$ of the set $X$ assigns a subset of the set $Y$. Hence, a correspondence $\Psi$ of $X$ to $Y$, denoted by $\Psi: X \rightarrow \rightarrow Y$, is a function $X \rightarrow P(Y)$.

Alternatively, a relation $\Psi$ of $X$ to $Y$ is a correspondence of $X$ to $Y$ if its domain is $X$, that is, if for all $x$ in $X$ we have $\Psi(x) \neq \varnothing$. Hence, every relation from $X$ to $Y$ is a correspondence defined on its domain $D_{R}$. We can also say that a function is a special case of correspondence in which the image set of each element of $X$ is a singleton (i.e., a set formed by a single element).

## Axiom of Choice

One of the basic assumptions of set theory is the so-called axiom of choice. It says that given an arbitrary collection $\mathbb{A}$ of nonempty sets in $X$, there is always a function $f$ from $P(X)$ to $X$ itself such that $f\left(A_{i}\right) \in A_{i}$ for each $A_{i}$ in $\mathbb{A}$. That is, we assume the existence of a "selection function" $f$ that chooses
an element from each of the sets in $\mathbb{A}$. It seems reasonable to assume that this is always possible, but when we cannot give a specific selection criterion, we have to resort to the axiom of choice. This assumption is often used (in many cases implicitly) in proofs in which at some point we make a statement of the form "we take an element $x_{i}$ from each of the sets $A_{i}$ in a given class $\mathbb{A} . "$

## Finite, Infinite, and Countable Sets

When we count the number of elements of a set $X$, we associate with each element a natural number. In other words, counting the elements of a set $X$ amounts to constructing a function from $X$ to the set $\mathbb{N}$ of natural numbers. The generalization of this idea takes us to the concept of cardinality (or cardinal number) of a set.

We say that two sets $A$ and $B$ are numerically equivalent if there exists a bijective function of $A$ onto $B$. If a set $A$ is numerically equivalent to some subset of the set of positive integers, $\mathbb{Z}_{+}$, we say that $A$ is a countable set. If this subset of $\mathbb{Z}_{+}$is of the form $\{1,2, \ldots, n\}$, the set is finite, and its cardinal number is simply the number of its elements. The empty set is considered finite, and its cardinal number is zero. If $A$ is not numerically equivalent to $\{1,2, \ldots, n\}$, we say that it is an infinite set.

Hence, a set $\mathrm{A}$ is countable if is inite or if there exists a bijection from $A$ to the entire set $\mathbb{Z}_{+}$of the positive integers. In the second case, $A$ is an infinite but countable set, and its cardinal number is called $\mathcal{N}_{0}$ ("alephzero"). There are also infinite sets that are not countable, such as the set $\mathbb{R}$ of real numbers.

## Generalization of the Cartesian Product

We have defined the Cartesian product of two sets $X$ and $Y$ as the set of all ordered pairs of the form $(x, y)$, where $x \in X$ and $y \in Y$. Suppose now that we are given a more general class of sets, $\mathbb{A}=\left\{A_{i} ; A_{i} \subseteq X, i \in \mathrm{I}\right\}$. If the index set $I$ is finite, say of the form $I=\{1,2, \ldots, n\}$, the Cartesian product $A=x_{i \in t} A_{i}$ is defined, as may be expected, as the set of all ordered $n$-tuples $x=\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ such that $x_{i} \in A_{i}$ for each $i=1, \ldots, n$. We say that $x_{i}$ is the $i$ th coordinate of $x$, and $A_{i}$ the $i$ th component of $A$. To generalize the concept to an arbitrary family of sets $\mathbb{A}$ (possibly infinite and not countable), we use the concept of function. Hence the Cartesian product $\times \mathbb{A}$ is defined as the set of all functions $f: I \longrightarrow \cup_{i \in I} A_{i}$ such that $f(i) \in A_{i}$ for each $i \in I$.

## 5. Algebraic Structures

In most applications, we work with numerical spaces, that is, sets whose elements are numbers, sequences of numbers, or numerical functions. It
seems natural to impose an algebraic structure on such sets by defining operations.

In general terms, we can define an algebraic structure $A=\left\{\left(X_{i}\right), O\right\}$ as a collection formed by one or more sets $X_{\imath}$ of (generally numeric) elements, together with a second set $O$ of operations defined on the sets $X_{i}$. An operation is simply a function defined on the Cartesian product of two or more sets, and taking values in another set that may or may not be one of the preceding sets. Given a set $X$, an $n$-ary operation in $X$ is a function $*: X^{n} \longrightarrow X$. For example, a binary operation in $X$ is a function $*: X$ $\times X \rightarrow X$ that assigns to each pair of elements $(x, y)$ of $X$ a unique element $z$ of $X$. We often write $z=x * y$. If "*" is a binary operation in $X$, we say that $X$ is closed with respect to the operation "*," or that "*" is a law of internal composition.

We will now define some important algebraic structures. The different structures are characterized by different properties of the operations.

## (a) Groups and Fields

Let $X$ be a set, and " $*$ " a binary operation defined on it. We say that " $*$ " is an associative operation if

$$
\forall x, y, z \in X,(x * y) * z=x *(y * z)
$$

If this property holds, we can write expressions like $x * y * z$ without ambiguity. We say that "*" is commutative (or satisfies the commutative law) if the order of composition does not alter the result, that is, if

$$
\forall x, y \in X, x * y=y * x
$$

The operation "*" defined on $X$ has an identity element if there exists an element $e$ of $X$ such that

$$
\forall x \in X, x * e=x=e * x
$$

Notice that the definition implies that the identity element, when it exists, is unique. To see this, assume that $e$ and $e^{\prime}$ are both identity elements. Then, $e * e^{\prime}=e^{\prime}$ and $e * e^{\prime}=e$, from where $e^{\prime}=e * e^{\prime}=e$.

An element $x^{s}$ is the symmetric or inverse element of $x$ with respect to " $*$ " if the composition of the two is the identity element, that is, if

$$
x * x^{s}=x^{s} * x=e
$$

If the operation is associative, the inverse of $x$, when it exists, is unique, for if $x^{s}$ and $x^{i}$ are both inverses of $x$, we have

$$
x^{s}=x^{s} * e=x^{s} *\left(x * x^{i}\right)=\left(x^{s} * x\right) * x^{i}=e * x^{i}=x^{i}
$$

Let "*" and " $\oplus$ " be two binary operations defined on a set $X$. We say that "*" is a distributive law with respect to " $\oplus$ " if

$$
\forall x, y, z \in X, x *(y \oplus z)=(x * y) \oplus(x * z) \text { and }(y \oplus z) * x=(y * x) \oplus(z * x)
$$

If "*" is commutative, these two properties (distributivity on the left and on the right) are equivalent.

Definition 5.1. Group and commutative group. Let $G$ be a set, and "*" an operation defined on it. We say that $G=\{G, *\}$ is a group if $G$ is closed under "*" and this operation is an associative law, endowed with an identity and with the property that every $x \in G$ has an inverse element with respect to "*." If, in addition, "*" is commutative, we say that $\{G, *\}$ is a commutative group.

Let $\{G, *\}$ be a group, and consider the restriction of "*" to some subset $S$ of $G$. If $S$ is closed with respect to "*" and $\{S, *\}$ satisfies the other conditions in the definition of group, we say that $\{S, *\}$ is a subgroup of $\{G, *\}$. Clearly, $\{S, *\}$ inherits the "manipulative" properties of $\{G, *\}$ (i.e., the associative and commutative laws); hence, in order to show that $\{S, *\}$ is a subgroup, it is sufficient to verify that $S$ contains the identity $e$, and that for each $x$ in $S$, its inverse is also in $S$.

Definition 5.2. Field. A field $F=\{F,+, \cdot\}$ is an algebraic structure formed by a set $F$ together with two binary operations $(+, \cdot)$ defined on it, called addition and multiplication, respectively, which have the following properties:

I. The set $F$ together with the operation of addition is a commutative group. The additive identity is called 0 , and the symmetric element of each $\alpha \in F$ is denoted by $(-\alpha)$. That is, for every $\alpha, \beta, \gamma \in F$, the following properties hold:

1. Associative property: $(\alpha+\beta)+\gamma=\alpha+(\beta+\gamma)$
2. Commutative property: $\alpha+\beta=\beta+\alpha$
3. Existence of the additive identity: $\exists ! 0 \in F$ s.th. $\alpha+0=0+\alpha=\alpha \forall \alpha \in \mathrm{F}$
4. Existence of inverse elements: $\forall \alpha \in F, \exists !(-\alpha) \in F$ s.th. $\alpha+(-\alpha)=(-\alpha)+\alpha$ $=0$

II. Multiplication is an associative and commutative operation, endowed with an identity called $1(\neq 0)$, and every element $\alpha$ of $F$ different from zero has a multiplicative inverse, written $\alpha^{-1}$ or $1 / \alpha$. That is, $\forall \alpha, \beta, \gamma \in F$, we have the following:

1. Associative property: $(\alpha \cdot \beta) \cdot \gamma=\alpha \cdot(\beta \cdot \gamma)$
2. Commutative property: $\alpha \cdot \beta=\beta \cdot \alpha$
3. Existence of a multiplicative identity: $\exists ! 1 \in F$ s.th. $\alpha \cdot 1=1 \cdot \alpha=\alpha \forall \alpha \in F$
4. Existence of inverse elements: $\forall \alpha(\neq 0) \in F, \exists$ ! $\alpha^{-1} \in X$ s.th. $\alpha \cdot \alpha^{-1}=\alpha^{-1} \cdot \alpha$ $=1$

III. Multiplication is distributive with respect to addition:

$$
\forall \alpha, \beta, \gamma \in F, \alpha \cdot(\beta+\gamma)=(\alpha \cdot \beta)+(\alpha \cdot \gamma)=\alpha \cdot \beta+\alpha \cdot \gamma
$$

Let $F=\{F,+, \cdot\}$ be a field, and $S$ a subset of $F$. We say that $\{S,+, \cdot\}$ is a subfield of $F$ if $\{S,+, \cdot\}$ is a field on its own right, that is, if $S$ is closed under both operations and the properties required in the definition hold. As before, if $S$ is a subset of $F$, it will inherit the manipulative properties of $F$ (i.e., the associative, commutative, and distributive properties will hold in $S$, because they hold in the whole $F$ ). To verify that a subset $S$ of $F$ gives rise to a subfield of $F$, therefore, it is sufficient to verify the existence of inverse and identity elements (with respect to addition and multiplication) and that $S$ is closed under both operations.

The most common examples of fields are the real and complex numbers, with the standard definitions of addition and multiplication. In fact, the definition of "field" is based directly on the algebraic properties of the set of real numbers endowed with the standard operations.

All the basic properties of the operations of real numbers can be derived from the field axioms. For example:

(i) $\forall \alpha \in F, \alpha \cdot 0=0$ : Let $\beta=\alpha \cdot 0$; by the distributive law, we have

$$
\beta+\beta=\alpha \cdot 0+\alpha \cdot 0=\alpha \cdot(0+0)=\alpha \cdot 0=\beta
$$

Hence, $\beta+\beta=\beta$; adding the additive inverse of $\beta$ to both sides of this expression, we have

$$
-\beta+\beta=-\beta+\beta+\beta \Rightarrow 0=0+\beta=\beta
$$

(ii) $\forall \alpha \in F,(-1) \cdot \alpha=-\alpha$. Let $\gamma=(-1) \cdot \alpha$; then, using the existence of a zero element and the distributive law together with the previous result,

$$
\alpha+\gamma=1 \cdot \alpha+(-1) \cdot \alpha=\alpha \cdot(-1+1)=\alpha \cdot 0=0
$$

from which we conclude that $\gamma$ is the additive inverse of $\alpha$.

Problem 5.3. Let "*" be a law of internal composition on $X$ that satisfies the associative property and is endowed with an identity element. Prove that if $x$ and $y$ have symmetric elements $x^{s}$ and $y^{s}$, then the symmetric element of $x * y$ is $y^{s} * x^{s}$.

Problem 5.4. Let $X$ be an arbitrary set, and $\{G, *\}$ a group. Show that the set of functions of $X$ into $G$, endowed with the operation defined by the composition of images, that is,

$$
\forall x \in X,(f * g)(x)=f(x) * g(x)
$$

is a group.

Problem 5.5. Show that the intersection of subgroups of $G$ is a subgroup of $G$.

## (b) Vector Spaces

Definition 5.6. Vector space. A vector or linear space $V$ defined over a field $F$ is a set $V$ of elements called vectors, together with a binary operation $V \times V \longrightarrow V$ called vector addition, and an operation $F \times V \longrightarrow$ $V$ called multiplication by a scalar (an element of the field $F$ ). These operations have the following properties:

I. Vector addition is a law of internal composition in $V$ (i.e., $V$ is closed under it), and $\{V,+\}$ is a commutative group, that is, for all $x, y, z \in V$, we have the following:

1. Associative property: $x+(y+z)=(x+y)+z$
2. Commutative property: $x+y=y+x$
3. Existence of the additive identity: $\exists ! \underline{0} \in V: x+\underline{0}=\underline{0}+x=x$
4. Existence of inverse elements: $\forall x \in V, \exists !(-x): x+(-x)=(-x)+x=\underline{0}$

II. For all $x, y \in V$ and for all $\alpha, \beta \in F$, we have the following:

5. Double-distributive property:

$$
\alpha(x+y)=\alpha x+\alpha y \quad \text { and } \quad(\alpha+\beta) x=\alpha x+\beta x
$$

6. Associative law for scalars: $\alpha(\beta x)=(\alpha \beta) x$
7. Neutrality of the scalar multiplicative identity, $1: 1 x=x$

We will normally work with vector spaces defined over the field of real numbers. We will generally use Greek letters to denote scalars, and Latin letters to indicate vectors. Notice that we use the same symbol for vector addition and scalar addition; although they are different operations, this should not be a problem. Notice also that the dot $(\cdot)$ is often omitted when multiplying a vector by a scalar.

Most vector spaces we will encounter in applications are special cases of the following space.

Theorem 5.7. Let $\mathrm{X}$ be a nonempty set, and $\mathrm{F}$ a field. The set of all functions $\mathrm{f}: \mathrm{X} \longrightarrow \mathrm{F}$, with addition and multiplication by a scalar defined by

$$
(\mathrm{f}+\mathrm{g})(\mathrm{x})=\mathrm{f}(\mathrm{x})+\mathrm{g}(\mathrm{x}) \text { and }(\alpha \mathrm{f})(\mathrm{x})=\alpha \mathrm{f}(\mathrm{x}) \forall \mathrm{x} \in \mathrm{X}
$$

is a vector space over $\mathrm{F}$.

It is obvious that most of the vector-space axioms hold given the properties of the field $F$. The zero element is the function $z$ such that $z(x)=0$ for every $x$ in $X$; moreover, given an arbitrary function $f$, its additive inverse $(-f)$ is given by $(-f)(x)=-f(x)$.

If in Theorem 5.7 we take $X$ to be the set of the first $n$ positive integers and $F=\mathbb{R}$, we obtain the vector space $V_{n}(\mathbb{R})$, which is simply the set of vectors in $\mathbb{R}^{\mathrm{n}}$ with vector addition and scalar multiplication defined component by component:

$$
z=x+y \Leftrightarrow z^{i}=x^{i}+y^{i} \text { and } \quad y=\alpha x \Leftrightarrow y^{i}=\alpha x^{i} \quad(\forall i=1, \ldots, n)
$$

If $X$ is the set of natural numbers, and $F$ is $\mathbb{R}$, we obtain the space of infinite real sequences, with vector addition and scalar multiplication defined term by term. With $X=\{(i, j) ; i=1, \ldots, m, j=1, \ldots, n\}$ we have the vector space of $m \times n$ matrices defined over a field $F$, with the usual definitions of matrix addition and multiplication by a scalar, and so forth.

In what follows, we will often suppress the distinction between the vector space $V$ and the underlying set $V$ (as we have already done in the case of fields). Let $V$ be a vector space over a field $F$. If a subset $S$ of $V$ is a vector space under the same operations defined on $V$, we say that $S$ is a vector subspace of $V$. Of course, $S$ inherits the manipulative properties that hold on the whole of $V$; hence in order to establish that it is indeed a vector subspace, it is enough to verify that $S$ is closed under addition and multiplication by a scalar, that the zero vector $\underline{0}$ is an element of $S$, and that for each $x$ in $S,(-x)$ is also an element of $X$. In fact, it is even easier, as shown in the following result, whose proof is left as an exercise.

Theorem 5.8. Let $\mathrm{V}$ be a vector space over a field $\mathrm{F}$, and let $\mathrm{S}$ be a nonempty subset of $\mathrm{V}$. Then $\mathrm{S}$ is a vector subspace of $\mathrm{V}$ if and only if

$$
\forall \alpha, \beta \in \mathrm{F} \text { and } \forall \mathrm{x}, \mathrm{y} \in \mathrm{S} \text {, we have } \alpha \mathrm{x}+\beta \mathrm{y} \in \mathrm{S} \text {. }
$$

## Problem 5.9. Prove Theorem 5.8.

## 6. The Real Number System

Most of the spaces we will be working with are sets constructed in some way starting from the set $\mathbb{R}$ of real numbers. Hence, it is important to review the basic properties of this set. It is possible to construct $\mathbb{R}$ by starting with the natural numbers as undefined concepts, defining next the operations addition, multiplication, subtraction, and division, and introducing new numbers as it becomes necessary to ensure that these operations do not take us outside the set of "existing" numbers. In this manner we will arrive
at the set $\mathbb{Q}$ of the rational numbers. It is then observed that even though each rational number can be represented as a point on a straight line, the converse statement is not true, suggesting that the set $\mathbb{Q}$ has, to put it informally, some holes in it. The problem also manifests itself through the impossibility of finding rational solutions to some simple equations (e.g., $x^{2}=2$ ). To "plug" these holes, we define the irrational numbers and then, finally, the set of real numbers as the union of the rational and irrational numbers.

It is also possible, although perhaps less instructive, to define $\mathbb{R}$ directly as a set that satisfies a number of properties or axioms. That is the path we will take here, because we will later make use of the properties of $\mathbb{R}$ rather than the method of its construction. The set $\mathbb{R}$ appears, then, as a set in which we have defined various structures: an algebraic structure that allows us to perform the usual operations of addition and multiplication, and an order structure, compatible with the cited operations, that permits us to say that some numbers are larger than others. These two sets of properties (which also hold for the rational numbers) are complemented by the so-called axiom of completeness, which completes the list of defining properties of $\mathbb{R}$. Intuitively, this third axiom is what allows us to establish the existence of a bijective function from $\mathbb{R}$ to the points of the line.

Problem 6.1. Show that there is no rational number $a=p / q$ (where $p$ and $q$ are integers with no common divisors) such that $a^{2}=2$. (By contradiction: Assume $p^{2} / q^{2}=2$, and show that this implies that both $p$ and $q$ are even, which contradicts our assumption. At some point, you will have to use the fact that the square of an odd integer is also odd. Prove it.)

## (a) A Set of Axioms for the Real Number System

The set $\mathbb{R}$ can be defined as a complete ordered field, that is, a set that satisfies the three properties or axioms listed next. The existence of such a set can be established starting from the set of natural numbers, in several ways (e.g., Rudin, 1964, pp. 17ff.; Bartle, 1976, pp. 49-50).

Axiom 6.2. Field axioms. The set $\mathbb{R}$, endowed with the operations addition and multiplication, is a field. That is, both addition and multiplication are laws of internal composition (i.e., $\mathbb{R}$ is closed under these operations) that satisfy the associative and commutative properties and are endowed with identity and inverse elements (except for the zero element, the additive identity, which has no multiplicative inverse). Moreover, the following distributive property holds: For every $\alpha, \beta, \gamma \in \mathbb{R},(\alpha+\beta) \gamma=\alpha \gamma+\beta \gamma$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-038.jpg?height=76&width=887&top_left_y=196&top_left_x=290)

Figure 1.8. The axiom of completeness.

Axiom 6.3. Order axioms. There exists a complete ordering " $\leq$ " defined on $\mathbb{R}$ that is compatible with addition and multiplication, in the following sense:

$$
\forall \alpha, \beta, \gamma \in \mathbb{R}, \alpha \leq \beta \Rightarrow \alpha+\gamma \leq \beta+\gamma \quad \text { and } \quad(\alpha \leq \beta \text { and } 0 \leq \gamma) \Rightarrow \alpha \gamma \leq \beta \gamma
$$

That is, inequality between two numbers is preserved if (i) we add an arbitrary real number to both sides or (ii) we multiply both of them by a nonnegative number. The zero element $(0)$ is the additive identity.

Axiom 6.4. Axiom of completeness. Let $\mathrm{L}$ and $\mathrm{H}$ be nonempty sets of real numbers, with the property that

$$
\forall \mathrm{l} \in \mathrm{L} \text { and } \forall \mathrm{h} \in \mathrm{H}, \mathrm{l} \leq \mathrm{h}
$$

Then there exists a real number $\alpha$ such that

$$
\forall \mathrm{l} \in \mathrm{L} \text { and } \forall \mathrm{h} \in \mathrm{H}, \mathrm{l} \leq \alpha \leq \mathrm{h}
$$

Problem 6.5. Let $x, y$, and $z$ be arbitrary real numbers. Using the order axioms, show that the following statements are true:

(i) $\left(x \leq y\right.$ and $\left.x^{\prime} \leq y^{\prime}\right) \Rightarrow x+x^{\prime} \leq y+y^{\prime}$

(ii) $x \leq y \Rightarrow-y \leq-x$

## (b) The Supremum Property

In this section we will explore some of the implications of the axiom of completeness. For this, we need to define some concepts that make use of the order axioms.

Definition 6.6. A bounded set and the bound of a set. Let $X$ be a set of real numbers. If there exists a real number $u$ (not necessarily in $X$ ) such that $x \leq u$ for all $x$ in $X$, we say that $u$ is an upper bound of $X$ and that the set $X$ is bounded above. A lower bound $l$ is defined in an analogous way, except that now we require that $x \geq l$ for all $x \in X$.

Observe that if $u$ is an upper bound of a set $X$, then any number $b$ larger than $u$ is also an upper bound of $X$. Hence, if the set $X$ is bounded above, it will have an infinite number of upper bounds. The smallest of all upper bounds of $X$ is called the supremum (sup) of the set, written sup $X$.

Definition 6.7. Supremum and infimum. Let $X$ be a set of real numbers that is bounded above. The number $s$ is the supremum of $X(s=\sup X)$ if it is its smallest upper bound, that is, if

(i) $s$ is an upper bound for $X: \forall x \in X, x \leq s$, and

(ii) no number smaller than $s$ is an upper bound of $X$ :

$$
\forall y<s, \exists x \in X \text { s.th. } x>y
$$

In the case of a set that is bounded below, the largest lower bound or infimum (inf) of the set is defined in an analogous manner.

Notice that if $s$ is the supremum of $X$, then any number larger than $s$ is not the least upper bound of $X$, and any number smaller than $s$ is not an upper bound. Hence $X$ must contain numbers that are arbitrarily close to $s$. It is also clear that if $A \subseteq B, A \neq \varnothing$, and $B$ is bounded above, then $A$ is also bounded above, and sup $B \geq \sup A$.

The definitions of the upper bound and supremum of a set $X$ do not require that these numbers belong to $X$. If $X$ has a supremum $s$ and $s$ is an element of $X$, we call $s$ the maximum of $X$ and write $s=\max X$. For example, the interval $(0,1]$ has a maximum equal to 1 , whereas $(0,1)$ has no maximum, although it does have a supremum (which is also 1 ).

We can now show that the axiom of completeness is equivalent to the statement that every nonempty set of real numbers that is bounded above has a supremum.

Theorem 6.8. The supremum property. Every nonempty set of real numbers that is bounded above has a supremum. This supremum is a real number.

Observing that $s=\sup X$ is equivalent to $-s=\inf (-X)$, where $-x \in-X$ if and only if $x \in X$, we see also that every nonempty set of real numbers that is bounded below has an infimum.

Proof. Let $X$ be a nonempty set of real numbers with an upper bound, and define $U$ as the set of upper bounds of $X$. By assumption, $U$ is not empty, and by definition, $x \leq u$ for every $u \in U$ and every $x \in X$. By the axiom of completeness, there exists a real number $\alpha$ such that

$$
x \leq \alpha \leq u \forall x \in X \text { and } \forall u \in U
$$

Because $x \leq \alpha$ for all $x$ in $X, \alpha$ is an upper bound of $X$; moreover, because $\alpha \leq u$ for all $u$ in the set $U$ of upper bounds of $X, \alpha$ is the supremum of $X$.

Hence, the axiom of completeness guarantees the existence of a supremum for certain sets of real numbers. The following result shows that the supremum property implies the axiom of completeness, thus establishing the equivalence of the two properties.

Theorem 6.9. The supremum property implies the axiom of completeness.

Proof. Let $L$ and $H$ be nonempty sets of real numbers, with the property that $l \leq h$ for all $l$ in $L$ and all $h$ in $H$. Then each $h$ is an upper bound of $L$, and it follows that $L$ has a supremum, with $\sup L \leq h$ for all $h$ in $H$. Next, because $\sup L$ is a lower bound of $H, H$ has an infimum that cannot be smaller than sup $L$. Hence $L$ has a supremum, $H$ has an infimum, and

$$
l \leq \sup L \leq \inf H \leq h \text { for every } l \text { in } L \text { and every } h \text { in } H
$$

Putting $\alpha=\sup L$ or inf $H$, or both when they coincide, we obtain the axiom of completeness.

The following results reveal two important implications of the axiom of completeness. Theorem 6.12, in particular, establishes the existence of real solutions to the equation $x^{2}=2$.

Theorem 6.10. The Archimedean property. The set $\mathbb{N}$ of the natural numbers is not bounded above (i.e., for any $\mathrm{x} \in \mathbb{R}$, there exists a natural number $\mathrm{n}$ such that $\mathrm{n}>\mathrm{x}$ ).

Problem 6.11. Prove Theorem 6.10. Use the method of contradiction: If the result is false, then there exists a real number $x$ that is an upper bound of $\mathbb{N}$. Use Theorem 6.9 and the definition of supremum to obtain a contradiction.

Theorem 6.12. Existence of $\sqrt{2}$. There exists a real number $\mathrm{x}>0$ such that $\mathrm{x}^{2}=2$.

Proof. Let $Y=\left\{y \in \mathbb{R} ; 0 \leq y^{2} \leq 2\right\}$. The set $Y$ is nonempty (because $0 \in Y$ ) and is bounded above (e.g., by 2 , because $y>2$ implies $y^{2}>2$ ). By the supremum property, $Y$ has a supremum that we will call $x$. We will prove that $x^{2}=2$ by showing that we can exclude the other possibilities: If $x^{2}<2$, then we can find a number larger than $x$ that lies in $Y$, and if $x^{2}>2$, we can find a positive number smaller than $x$ that is an upper bound for $Y$. Because both of these statements contradict the fact that $x$ is the least upper bound of $Y$, the result follows.

First, we will show that if $x^{2}<2$, then $x$ cannot be the supremum of $Y$. Assume that sup $Y=x$ and $x^{2}<2$. Then $2-x^{2}>0$ and (by the Archimedean property) we can select a positive integer $n>1$ such that

$$
\begin{equation*}
n>\frac{2 x+1}{2-x^{2}} \Leftrightarrow \frac{2 x+1}{n}<2-x^{2} \tag{1}
\end{equation*}
$$

Then, using (1), we have

$$
\left(x+\frac{1}{n}\right)^{2}=x^{2}+\frac{2 x}{n^{2}}+\frac{1}{n^{2}} \leq x^{2}+\frac{2 x+1}{n}<x^{2}+\left(2-x^{2}\right)=2
$$

Hence, $0<(x+(1 / n))^{2}<2$, implying that $x+1 / n \in Y$. That is, we have found an element of $Y$ larger than $x=\sup Y$, which is clearly impossible. Hence $x^{2}$ cannot be strictly smaller than 2 .

Similarly, assume that $x^{2}>2$, and let $m$ be a positive integer such that

$$
\begin{equation*}
m>\frac{1}{x} \text { and } m>\frac{2 x}{x^{2}-2} \quad\left(\text { i.e., } x>\frac{1}{m} \text { and } \frac{2 x}{m}<x^{2}-2\right) \tag{2}
\end{equation*}
$$

Then

$$
\left(x-\frac{1}{m}\right)^{2}=x^{2}-\frac{2 x}{m}+\frac{1}{m^{2}}>x^{2}-\frac{2 x}{m}>x^{2}-\left(x^{2}-2\right)=2
$$

Hence $0<x-(1 / m),(x-(1 / m))^{2}>2$, and therefore $x-1 / m>y$ for all $y$ in $Y$. We have found a positive number smaller than $x$ that is an uper bound of $Y$. Because this contradicts the fact that $x$ is the supremum of $Y$, it cannot be true that $x^{2}>2$. This leaves us with only the possibility that $x^{2}=2$.

An extension of this argument can be used to establish the existence of $n$th roots of positive real numbers.

Problem 6.13. Let $A$ and $B$ be nonempty sets of real numbers, both of them bounded above, and let $C$ be the set

$$
C=\{c=a+b ; a \in A, b \in B\}
$$

Show that $C$ has a supremum that is given by

$$
\sup C=\sup A+\sup B
$$

Problem 6.14. The semiopen interval $(a, b]$ is the set of real numbers $x$ such that $a<x \leq b$. Other intervals, such as $(a, b)$ and $[a, b]$, are defined in an analogous manner. Show that a nonempty set $S$ of real numbers is an interval if and only if whenever $x$ and $y$ are in $S$, any real number $z$ such that $x<z<y$ lies also in $S$.

Hint: Let $S$ be a set with the desired property, and define $a=\inf S$ (or $a=-\infty$ if $S$ is not bounded below) and $b=\sup S$ (or $b=\infty$ if $S$ is not bounded above). Using the definitions of supremum and infimum, show that $(a, b) \subseteq S \subseteq[a, b]$.

## (c) Absolute Value

An important function defined on $\mathbb{R}$ is the one that assigns to each real number its absolute value. The function $|\cdot|: \mathbb{R} \rightarrow \mathbb{R}$ is defined by $|x|=\max \{x,-x\}$ or

$$
|x|=\left\{\begin{array}{r}
x \text { if } x \geq 0 \\
-x \text { if } x<0
\end{array}\right.
$$

Among other things, the absolute-value function allows us to introduce the notion of distance between two numbers, because $|x-y|$ corresponds to the length of the real line segment that joins the points corresponding to $x$ and $y$. As we will see in Chapter 2, once we have defined a measure of distance in a set, we can introduce a topological structure that will allow us to define concepts like continuity and convergence.

Problem 6.15. Show that if $a \geq 0$, then $|x| \leq a$ if and only if $-a \leq x \leq a$.

We will now establish a very important inequality.

Theorem 6.16. Triangle inequality for real numbers. Let $\mathrm{x}$ and $\mathrm{y}$ be two real numbers; then

$$
|x+y| \leq|x|+|y|
$$

Proof. By definition of absolute value, we have

$$
-|x| \leq x \leq|x| \text { and }-|y| \leq y \leq|y|
$$

Adding up these two inequalities, side by side,

$$
-(|x|+|y|) \leq x+y \leq|x|+|y| \Rightarrow|x+y| \leq|x|+|y|
$$

Problem 6.17. Given real numbers $x_{i}, i=1,2, \ldots, n$, show the following:

(i) $\left|\sum_{i=1}^{n} x_{i}\right| \leq \sum_{i=1}^{n}\left|x_{i}\right|$ (by induction using the triangle inequality),

(ii) $|a-c| \leq|a-b|+|b-c|$ (look for an adequate substitution in the triangle inequality).

## 7. Complex Numbers

We have seen that one of the reasons that motivate the construction of $\mathbb{R}$ is the desire for a number system in which the equation $x^{2}=2$ has a solution. A similar reason motivates the construction of the set of imaginary numbers. This set is a field that contains the square roots of negative numbers, including the solution to the equation $x^{2}=-1$. In this section we will briefly discuss a "larger" number system, that of the complex numbers, which contains both the real numbers and the imaginary numbers. Because we will make rather limited use of complex numbers later in this book, we will simply introduce some basic notions, without proofs or much formal discussion.

A complex number is a number of the form

$$
c=a+i b
$$

where $a$ and $b$ are real numbers, and $i$ is the imaginary unit, $i=\sqrt{-1}$. The number $a$ is the real part of $c(\operatorname{Re} c)$, and $b$ is its imaginary part $(\operatorname{Im} c)$. A complex vector $x=\left(c_{1}, \ldots, c_{n}\right)$ is simply a vector whose components are complex numbers.

The conjugate of a complex number $c=a+i b$ is the number $\bar{c}=a-i b$, with the sign of the imaginary part reversed. The conjugate of a complex vector $x=\left(c_{1}, \ldots, c_{n}\right)$ is $\bar{x}=\left(\bar{c}_{1}, \ldots, \bar{c}_{n}\right)$, the vector whose components are the complex conjugates of the components of the original vector.

The modulus of a complex number is the norm of the vector that represents it in the complex plane. That is,

$$
|c|=r=\sqrt{a^{2}+b^{2}}
$$

Observe that a complex number and its conjugate have the same modulus and that the product of a complex number and its conjugate is the square of their common modulus:

$$
(a+i b)(a-i b)=a^{2}-b^{2} i^{2}=a^{2}-b^{2}(-1)=a^{2}+b^{2}=r^{2}
$$

It is often convenient to represent a complex number as a point with coordinates $(a, b)$ in a plane (the complex plane) in which the vertical axis measures the imaginary component, and the horizontal axis the real component. Let $\theta$ be the angle formed by the vector representing a complex number $c$ and the horizontal axis of the complex plane, as illustrated in Figure 1.9. We observe that

$$
\cos \theta=a / r \Rightarrow a=r \cos \theta \text { and } \sin \theta=b / r \Rightarrow b=r \sin \theta
$$

Hence we can write the number $c=a+i b$ in trigonometric form:

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-044.jpg?height=833&width=975&top_left_y=189&top_left_x=251)

Figure 1.9. Graphical representation of a complex number.

$$
c=a+i b=r \cos \theta+i r \sin \theta=r(\cos \theta+i \sin \theta)
$$

Using the MacLaurin series representation of the sine, cosine, and exponential functions, we obtain Euler's formula:

$$
e^{i \theta}=\cos \theta+i \sin \theta
$$

which allows us to write the complex number $c$ in yet another equivalent way:

$$
c=a+i b=r(\cos \theta+i \sin \theta)=r e^{i \theta}
$$

Observe that the norm of $e^{i \theta}$ is $\sqrt{\cos ^{2} \theta+\sin ^{2} \theta}=1$; thus $e^{i \theta}$ lies on the unit circumference in the complex plane. As the angle $\theta$ varies from 0 to $2 \pi$ radians, the number $e^{i \theta}$ rotates around the origin at a constant distance equal to 1 .

## Bibliography

Apostol, T. 1974. Mathematical Analysis, 2nd ed. Reading, MA: Addison-Wesley. Apostol, T. 1991. Calculus, vol. 1, 2nd ed. Barcelona: Ed. Reverté. Bartle, R. 1976. The Elements of Real Analysis, 2nd ed. New York: Wiley. Blackorby, C. 1989. "Orderings" and "Preorderings." In: J. Eatwell, M. Milgate, and

P. Newman (ed.), The New Palgrave: Utility and Probability. New York: Norton.

Bryant, V. 1990. Yet Another Introduction to Analysis. Cambridge University Press. Clark, C. 1982. Elementary Mathematical Analysis, 2nd ed. Belmont, CA:

Wadsworth.

Gemignani, M. 1972. Elementary Topology, 2nd ed. New York: Dover.

Haaser, N. B., and Sullivan, J. A. 1991. Real Analysis. New York: Dover.

Kolmogorov, A. N., and Fomin, S. V. 1970. Introductory Real Analysis. New York: Dover.

Lange, S. 1989. Undergraduate Analysis, 2nd ed. Berlin: Springer-Verlag.

Michel, P. 1984. Cours de Mathématiques pour Economistes. Paris: Economica.

Rudin, W. 1964. Principles of Mathematical Analysis, 2nd ed. New York: McGrawHill.

Yamane, T. 1977. Matemáticas para economistas, 2nd ed. Barcelona: Ariel.

## Notes

1 The symbol " 3 !" is used to indicate that there is a unique element with a certain property. Thus, the expression $\exists ! x \in A$ s.th. $P(x)$ means "there exists precisely one element of $A$ that has property $P$.

2 Some authors use the term "ordering" to refer to what we call a "complete preordering." Then their "preordering" would mean "partial preordering" in our terminology. In applications to economic theory, usually there is no chance of confusion, because orderings (in our sense) are not used in the theory of consumer preferences.

3 A complete ordering on $X$ is a reflexive, transitive, and antisymmetric binary relation with the property that any two elements of $X$ are comparable under the relation. See Section 3(b).

## Metric and Normed Spaces

The reader should be familiar with low-dimensional Euclidean spaces, particularly the real line and the Cartesian plane. Given two points, $x$ and $y$, in one of these spaces, the distance between them, $d(x, y)$, is the length of the straight line segment that connects them. If $x$ and $y$ are real numbers, this corresponds to the absolute value of their difference, that is $d(x, y)=|x-y|$; if $x$ and $y$ are points in the plane with coordinates $\left(x_{1}, x_{2}\right)$ and $\left(y_{1}, y_{2}\right)$, respectively, the distance between them is given by the Euclidean norm of the difference vector:

$$
d(x, y)=\|x-y\|_{E}=\sqrt{\left(x_{1}-y_{1}\right)^{2}+\left(x_{2}-y_{2}\right)^{2}}
$$

Equipped with a notion of distance, we can define two concepts of fundamental importance in mathematical analysis: continuity of a function, and limit of a sequence. Recall, for example, that a sequence $\left\{x_{n}\right\}$ of real numbers converges to a limit $x$ if

$$
\forall \varepsilon>0, \exists N \text { s.th. } n>N \Rightarrow\left|x_{n}-x\right|<\varepsilon
$$

that is, if, given an arbitrarily small number $\varepsilon>0$, there exists some positive integer $N$ such that all terms in the sequence of order higher than $N$ are contained within an open interval centered at $x$ with radius $\varepsilon$. In a similar way, the definition of continuity also makes use of the concept of distance. We say that a function $f: \mathbb{R} \longrightarrow \mathbb{R}$ is continuous at a point $x$ if

$$
\forall \varepsilon>0, \exists \delta>0 \text { s.th. }|y-x|<\delta \Rightarrow|f(y)-f(x)|<\varepsilon
$$

Intuitively, a continuous function maps points that are close to each other into images that are also close by, and a sequence $\left\{x_{n}\right\}$ converges to $x$ if by taking $n$ large enough we can force $x_{n}$ to be arbitrarily close to $x$. What is essential in both definitions is the notion of distance, rather than the specific formulas that define it. This observation suggests that if we can define an appropriate measure of distance, we can generalize con-
vergence, continuity, and other topological concepts to more complicated sets without losing completely the geometric intuition we get from the study of the plane. This takes us to the concept of metric space, which is simply a set in which we have defined a useful notion of distance (i.e., one that preserves those properties of the familiar Euclidean distance we really need to get useful results). Experience has shown that these basic properties are the following:

(i) The distance between two points is always nonnegative and is zero if and only if the two points are in fact the same.

(ii) The distance from $x$ to $y$ is the same as the distance from $y$ to $x$.

(iii) The shortest route between two points is the straight line. One way to say this is as follows: Given any three points $x, y$, and $z$, it is always true that

$$
d(x, z) \leq d(x, y)+d(y, z)
$$

As we will see shortly, these three properties are sufficient to characterize a distance function that will allow us to define all the important topological concepts in a very general class of spaces.

## 1. Metric and Normed Spaces

Definition 1.1. Metric or distance function. A metric or distance function defined on a set $X$ is a real-valued, nonnegative function $d: X \times X \longrightarrow \mathbb{R}_{+}$ such that for every $x, y$, and $z$ in $X$ we have

(i) $d(x, y) \geq 0$, with equality if and only if $x=y$,

(ii) $d(x, y)=d(y, x)$,

(iii) $d(x, z) \leq d(x, y)+d(y, z)$ (triangle inequality).

Definition 1.2. Metric space. A metric space is a pair $(X, d)$, where $X$ is a set, and $d$ a metric defined on it.

Given a metric space $(X, d)$ and a subset $Y$ of $X$, it is clear that the restriction of $d$ to $Y$, denoted $\left.d\right|_{Y}$, is a metric defined on $Y$. Hence the pair $\left(Y,\left.d\right|_{Y}\right)$ is also a metric space, or a metric subspace of $(X, d)$.

We often work with sets endowed with both an algebraic structure and a distance function. Such spaces are particularly useful because they allow us to perform algebraic operations on their elements, in addition to defining topological concepts like convergence or open sets. We now introduce an important family of such sets, the so-called normed vector spaces.

We begin by defining a norm on the set of points $X$ underlying a vector space $V$. A norm is a function that assigns to each vector in $X$ a nonnega-
tive real number that we interpret as its magnitude. It is therefore a generalization of the absolute value of a real number or the length of a vector in the plane.

Definition 1.3. Norm. Let $V$ be a vector space, and $X$ the underlying set of points. A real-valued function $\|\cdot\|: X \longrightarrow \mathbb{R}$ is called a norm if it satisfies the following properties for all $x$ and $y$ in $X$ and any scalar $\alpha$.

(i) nonnegativity: $\|x\| \geq 0$

(ii) only the zero vector has zero norm: $\|x\|=0 \Leftrightarrow x=\underline{0}$

(iii) triangle inequality: $\|x+y\| \leq\|x\|+\|y\|$

(iv) $\|\alpha x\|=|\alpha|\|x\|$

Definition 1.4. Normed vector space. A normed vector space is a vector space $V$ equipped with a norm.

A normed space naturally becomes a metric space if we define the distance between two vectors as the norm of their difference, that is,

$$
d(x, y)=\|x-y\|
$$

Observe that the function $d(\cdot, \cdot)$ automatically satisfies the definition of metric. We say that $d()$ is the metric generated by the norm $\|\cdot\|$. When we speak of topological properties in a normed vector space, it will always be in terms of this metric.

The information that a certain set endowed with a distance function is a metric space can be very useful, because it allows us to use a lot of results that hold generally in metric spaces. Usually, verifying that such a pair is a metric space is fairly easy, except possibly for the triangle inequality. We will now consider some examples of useful metric spaces.

Example 1.5. $n$-dimensional Euclidean space. It is easy to go from the plane or three-dimensional space to a Euclidean space of arbitrary (but finite) dimension $n$. We shall denote this space by $E^{n}=\left(\mathbb{R}^{\mathrm{n}}, d_{E}\right)$. That is, $X$ is now the set of $n$-dimensional vectors

$$
\mathbb{R}^{\mathbf{n}}=\left\{x=\left(x^{1}, x^{2}, \ldots, x^{n}\right) ; x^{i} \in \mathbb{R} \forall i=1, \ldots, n\right\}
$$

and the metric is the Euclidean distance between two vectors, defined as the Euclidean norm of their difference, $x-y=x+(-y)$ :

$$
d_{E}(x, y)=\|x-y\|_{E}=\sqrt{\sum_{i=1}^{n}\left(x^{i}-y^{i}\right)^{2}}
$$

In order to show that $\left(\mathbb{R}^{\mathrm{n}}, \boldsymbol{d}_{E}\right)$ is indeed a metric space, it is sufficient to verify that $\|\cdot\|_{E}$ is a norm. It is obvious that $\|\cdot\|_{E}$ satifies the first two defining
properties of a norm; verifying that the triangle inequality holds takes a bit more work. We begin by proving a related result.

Theorem 1.6. Cauchy-Schwarz inequality. Let $\alpha_{\mathrm{i}}$ and $\beta_{\mathrm{i}}, \mathrm{i}=1, \ldots, \mathrm{n}$, be real numbers; then

$$
\left(\sum_{\mathrm{i}=1}^{\mathrm{n}} \alpha_{\mathrm{i}} \beta_{\mathrm{i}}\right)^{2} \leq\left(\sum_{\mathrm{i}=1}^{\mathrm{n}} \alpha_{\mathrm{i}}^{2}\right)\left(\sum_{\mathrm{i}=1}^{\mathrm{n}} \beta_{\mathrm{i}}^{2}\right)
$$

Proof. For any real number $\lambda$, we have

$$
0 \leq \sum_{i=1}^{n}\left(\alpha_{i}-\lambda \beta_{i}\right)^{2}=\sum_{i=1}^{n} \alpha_{i}^{2}-2 \lambda \sum_{i=1}^{n} \alpha_{i} \beta_{i}+\lambda^{2} \sum_{i=1}^{n} \beta_{i}^{2}
$$

Now, putting $\lambda=\sum_{i=1}^{n} \alpha_{i} \beta_{i} / \Sigma_{i=1}^{n} \beta_{i}^{2}$, we see that

$$
\begin{gathered}
\sum_{i=1}^{n} \alpha_{i}^{2}-2 \frac{\sum_{i=1}^{n} \alpha_{i} \beta_{i}}{\sum_{i=1}^{n} \beta_{i}^{2}} \sum_{i=1}^{n} \alpha_{i} \beta_{i}+\frac{\left(\sum_{i=1}^{n} \alpha_{i} \beta_{i}\right)^{2}}{\left(\sum_{i=1}^{n} \beta_{i}^{2}\right)^{2}} \sum_{i=1}^{n} \beta_{i}^{2} \geq 0 \Leftrightarrow \\
\sum_{i=1}^{n} \alpha_{i}^{2}-\frac{\left(\sum_{i=1}^{n} \alpha_{i} \beta_{i}\right)^{2}}{\sum_{i=1}^{n} \beta_{i}^{2}} \geq 0 \Leftrightarrow\left(\sum_{i=1}^{n} \alpha_{i} \beta_{i}\right)^{2} \leq\left(\sum_{i=1}^{n} \alpha_{i}^{2}\right)\left(\sum_{i=1}^{n} \beta_{i}^{2}\right)
\end{gathered}
$$

Taking the square root on each side of the Cauchy-Schwarz inequality, we obtain

$$
\sum_{i=1}^{n} \alpha_{i} \beta_{i} \leq \sqrt{\sum_{i=1}^{n} \alpha_{i}^{2}} \sqrt{\sum_{i=1}^{n} \beta_{i}^{2}}
$$

Using this result, it is easy to verify that the triangle inequality holds in $E^{n}$. Given any three vectors $x, y, z \in \mathbb{R}^{\mathrm{n}}$, we have

$$
\begin{aligned}
{\left[d_{E}(x, z)\right]^{2}=} & \sum_{i=1}^{n}\left(x^{i}-z^{i}\right)^{2}=\sum_{i=1}^{n}\left[\left(x^{i}-y^{i}\right)+\left(y^{i}-z^{i}\right)\right]^{2} \\
= & \sum_{i=1}^{n}\left(x^{i}-y^{i}\right)^{2}+\sum_{i=1}^{n}\left(y^{i}-z^{i}\right)^{2}+2 \sum_{i=1}^{n}\left(x^{i}-y^{i}\right)\left(y^{i}-z^{i}\right) \\
& \leq \sum_{i=1}^{n}\left(x^{i}-y^{i}\right)^{2}+\sum_{i=1}^{n}\left(y^{i}-z^{i}\right)^{2} \\
& +2 \sqrt{\sum_{i=1}^{n}\left(x^{i}-y^{i}\right)^{2}} \sqrt{\sum_{i=1}^{n}\left(y^{i}-z^{i}\right)^{2}} \\
= & {\left[d_{E}(x, y)\right]^{2}+\left[d_{E}(y, z)\right]^{2}+2 d_{E}(x, y) d_{E}(y, z) } \\
= & {\left[d_{E}(x, y)+d_{E}(y, z)\right]^{2} }
\end{aligned}
$$

which implies the desired result,

$$
d_{E}(x, z) \leq d_{E}(x, y)+d_{E}(y, z)
$$

Problem 1.7. The Cauchy-Schwarz-Bunyakovsky inequality. Let $f$ and $g$ be continuous functions $[a, b] \longrightarrow \mathbb{R}$. Adapt the preceding proof to establish the following analogue of Theorem 1.6 for integrals:

$$
\left(\int_{a}^{b} f(x) g(x) d x\right)^{2} \leq\left(\int_{a}^{b}[f(x)]^{2} d x\right)\left(\int_{a}^{b}[g(x)]^{2} d x\right)
$$

A given set (vector space) may have several different metrics (norms) defined on it. For example, an alternative to the Euclidean norm in $\mathbb{R}^{\mathrm{n}}$ is the sup norm, defined for any $x \in \mathbb{R}^{\mathbf{n}}$ as the absolute value of its largest component:

$$
\|x\|_{s}=\max _{i}\left\{\mid x^{i} ; ; i=1,2, \ldots, n\right\}
$$

Two norms $\|\cdot\|_{1}$ and $\|\cdot\|_{2}$ defined on the same vector space are said to be Lipschitz-equivalent if there exist positive real numbers $m$ and $M$ such that for any vector $x$, we have

$$
m\|x\|_{1} \leq\|x\|_{2} \leq M\|x\|_{1}
$$

Lipschitz-equivalent metrics are defined in an analogous manner. Intuitively, two metrics are Lipschitz-equivalent if they always agree on whether or not two given points are close to each other. As we will see later, this implies that equivalent metrics preserve such important properties as openness and convergence.

Problem 1.8. Show that the sup norm, $\|\cdot\|_{s}: \mathbb{R}^{\mathbf{n}} \longrightarrow \mathbb{R}$, as defined earlier, is a norm.

Problem 1.9. Show that the sup norm $\|\cdot\|_{s}$ and the Euclidean norm $\|\cdot\|_{E}$ are Lipschitz-equivalent norms by proving that for any $n$-vector $x$, $\|x\|_{s} \leq\|x\|_{E} \leq \sqrt{n}\|x\|_{s}$.

Example 1.10. Product spaces. Let $\left(X, d_{1}\right)$ and $\left(Y, d_{2}\right)$ be metric spaces. We define the product space of these two spaces as the pair $\left(X \times Y, d_{\pi}\right)$ where the product metric, $d_{\pi}: X \times Y \longrightarrow \mathbb{R}_{+}$, is defined by

$$
\begin{equation*}
d_{\pi}\left[(x, y),\left(x^{\prime}, y^{\prime}\right)\right]=\sqrt{\left[d_{1}\left(x, x^{\prime}\right)\right]^{2}+\left[d_{2}\left(y, y^{\prime}\right)\right]^{2}} \tag{1}
\end{equation*}
$$

(or, alternatively, by $d_{\pi}=d_{1}+d_{2}$ or $d_{\pi}=\max \left\{d_{1}, d_{2}\right\}$ ). This definition can be extended in the obvious way to the case of any finite number of metric spaces. The following problem asks the reader to verify that $\left(X \times Y, d_{\pi}\right)$ is itself a metric space.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-051.jpg?height=783&width=849&top_left_y=180&top_left_x=323)

Figure 2.1.

Problem 1.11. Show that $d_{\pi}$ is a metric.

Example 1.12. Some function spaces. It is often convenient to define a metric on a set of functions. For example, consider the set $X$ of continuous functions $[a, b] \rightarrow \mathbb{R}$. Two useful metrics on this set are the sup metric, defined for any $f$ and $g$ in $X$ by

$$
d_{s}(f, g)=\sup _{x \in[a, b]}|f(x)-g(x)|
$$

and the $L^{2}$ metric, given by

$$
d_{2}(f, g)=\left(\int_{a}^{b}[f(x)-g(x)]^{2} d x\right)^{1 / 2}
$$

Notice that these two metrics capture rather different ideas about what it means for two functions to be "close." According to the sup metric, $d_{s}(f, g)$ will be small only if $f$ and $g$ are close for all values of $x$, whereas in the $L^{2}$ metric it suffices that they be close on average over their domain. These two metrics are not equivalent, for functions that are arbitrarily close on average may be very far from each other over a small interval, as illustrated by Figure 2.1.

In some applications we are interested in how similar functions are in terms of both their values and their derivatives. If we let $X$ be the set of
functions $[a, b] \longrightarrow \mathbb{R}$ that are $r \geq 1$ times continuously differentiable (see Chapter 4), an appropriate metric can then be defined as follows. Given $r$, the $C^{i}$ metric on $X$ is defined, for $i \leq r$, by

$$
d_{i}(f, g)=\sup _{x \in[a, b]}\left\{|f(x)-g(x)|,\left|f^{\prime}(x)-g^{\prime}(x)\right|, \ldots,\left|f^{(i)}(x)-g^{(i)}(x)\right|\right\}
$$

where $f^{(i)}$ is the $i$ th derivative of $f$.

We conclude this section with some additional definitions. Given a metric space $(X, d)$, the open ball with center at $x$ and radius $\varepsilon$ is the set

$$
B_{\varepsilon}(x)=\{y \in X ; d(x, y)<\varepsilon\}
$$

The closed ball $B_{\varepsilon}[x]$ is defined in the same manner, but with a weak inequality. We will often write the $\varepsilon$-ball with center at $x$. Unless it is otherwise indicated, it will be understood that the ball is open.

A set $S$ in a metric space is bounded if we can find a closed ball of finite radius that contains it. Formally, given a metric space $(X, d)$, we say that a subset $S$ of $X$ is bounded if there exists some point $x$ in $X$, and some real number $B$, such that $d(x, s) \leq B$ for all $s \in S$. ${ }^{1}$ Equivalently, $S$ is bounded if it has a finite diameter, where

$$
\operatorname{diam} S=\sup \left\{d\left(s, s^{\prime}\right) ; s, s^{\prime} \in S\right\}
$$

A function $f$ from some set $Z$ into $(X, d)$ is bounded if $f(Z)$ is bounded.

Given a metric, we can define, in addition to the distance between two points, the distance between a point and a set or between two sets. Given a metric space $(X, d)$, let $A$ be a subset of $X$, and $x$ some point in $X$. The distance from $x$ to $A$ is defined as

$$
d(x, A)=\inf _{a \in A} d(x, a)
$$

If $A$ and $B$ are two subsets of $X$, the distance between them is given by

$$
d(A, B)=\inf _{a \in A} d(B, a)=\inf \{d(a, b) ; a \in A, b \in B\}
$$

Problem 1.13. Prove that the union of any finite collection of bounded sets is bounded. (Prove it for two sets; the result then follows by induction. Draw a picture.)

Problem 1.14. Using the triangle inequality, show that for any $x, y$, and $z$ in a normed vector space, the following are true:

(i)

$\|x-y\| \geq\|x\|-\|y\|$ and

(ii) $\|x-z\| \leq\|x-y\|+\|y-z\|$

Problem 1.15. Show that the set of bounded real sequences is a metric space, with the norm defined by $d(x, y)=\sup _{n}\left|x_{n}-y_{n}\right|$.

Problem 1.16. Let $\left(X_{2}, d_{2}\right)$ be a metric space, $X_{1}$ a set, and $f: X_{1} \longrightarrow X_{2}$ a one-to-one function. Define a function $d_{1}$ ( ) by

$$
d_{1}(x, y)=d_{2}[f(x), f(y)] \forall x, y \in X_{1}
$$

Show that $\left(X_{1}, d_{1}\right)$ is a metric space.

Problem 1.17. Give an example of two sets $A$ and $B$ in a metric space such that $A \cap B=\varnothing$, but $d(A, B)=0$.

Problem 1.18. Prove that the set $C[a, b]$ of continuous real functions defined on the interval $[a, b]$ is a metric space when the distance between two functions $f$ and $g$ is defined by

$$
d(f, g)=\sup _{x \in[a, b]}|f(x)-g(x)|
$$

Problem 1.19. Show that the following inequality holds for any $x \in \mathbb{R}^{\mathrm{n}}$ :

$$
\|x\|_{E} \leq \sum_{i=1}^{n}\left|x_{i}\right|
$$

Hint: Prove it directly for $n=2$, and then proceed by induction.

## 2. Convergence of Sequences in Metric Spaces

We have seen that a sequence in $X$ is a function $s: \mathbb{N} \rightarrow X$ whose domain is the set of natural numbers and whose range is a subset of $X$. If $(X, d)$ is a metric space, we can define convergence exactly as for sequences of real numbers.

Definition 2.1. Convergence in metric spaces. Let $(X, d)$ be a metric space, and $\left\{x_{n}\right\}$ a sequence in $X$. We say that $\left\{x_{n}\right\}$ converges to $x \in X$, or that the sequence has limit $x$, if

$$
\forall \varepsilon>0, \exists N(\varepsilon) \text { s.th. } n>N(\varepsilon) \Rightarrow d\left(x_{n}, x\right)<\varepsilon \quad\left[\text { or, } x_{n} \in B_{\varepsilon}(x)\right]
$$

If $\left\{x_{n}\right\}$ has limit $x$, we write $\left\{x_{n}\right\} \rightarrow x$ or $\lim _{n \rightarrow \infty} x_{n}=x$. A sequence that does not converge is said to diverge.

That is, a sequence is convergent if its terms get closer and closer to some point $x$, to the extent that, given an arbitrarily small number $\varepsilon>0$, we can

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-054.jpg?height=238&width=652&top_left_y=194&top_left_x=104)

Figure 2.2.

always find some positive integer $N(\varepsilon)$ (which will in general depend on the chosen $\varepsilon$ ) such that all terms of the sequence of order higher than $N(\varepsilon)$ will lie within the $\varepsilon$-ball centered at $x$. Equivalently, the sequence $\left\{x_{n}\right\}$ of points of $X$ has limit $x$ if and only if the sequence of real numbers $\left\{d\left(x_{n}, x\right)\right\}$ converges to zero.

Problem 2.2. Using the formal definition of limit, show that
(i) $\lim _{n \rightarrow \infty} \frac{1}{n}=0$
(ii) $\lim _{n \rightarrow \infty} \frac{1}{\sqrt{n}}=0$
(iii) $\lim _{n \rightarrow \infty} \frac{n^{2}+2}{3 n^{2}+4}=\frac{1}{3}$

Imagine you are given some arbitrarily small $\varepsilon$. You must produce a positive integer $N$ such that...

Before we can speak of the limit of a sequence, we must show that it is uniquely defined. This is done in the following result, which shows that if a sequence has a limit, then it is unique.

Theorem 2.3. Uniqueness of the limit. A sequence $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ in a metric space (X, d) has at most one limit.

Proof. We will prove the result by contradiction. Intuitively, $\left\{x_{n}\right\}$ cannot approach two different limits. If it did, we would be able to find terms of the sequence that would be, simultaneously, close to two "far-away" points.

Suppose $\left\{x_{n}\right\}$ had two different limits, $x$ and $x^{\prime}$. Then $d\left(x, x^{\prime}\right)>0$, and we could construct two disjoint open balls, $B_{\varepsilon}(x)$ and $B_{\varepsilon^{\prime}}\left(x^{\prime}\right)$, each centered at a different limit, as illustrated in Figure 2.2. ${ }^{2}$ If both $x$ and $x^{\prime}$ were limits of $\left\{x_{n}\right\}$, there would exist positive integers $N(\varepsilon)$ and $N\left(\varepsilon^{\prime}\right)$ such that $x_{n} \in B_{\varepsilon}(x)$ for all $n>N(\varepsilon)$ and $x_{n} \in B_{\varepsilon^{\prime}}\left(x^{\prime}\right)$ for all $n>N\left(\varepsilon^{\prime}\right)$. It would follow that $x_{n} \in B_{\varepsilon}(x) \cap B_{\varepsilon^{\prime}}\left(x^{\prime}\right)=\varnothing$ for all $n>\max \left\{N(\varepsilon), N\left(\varepsilon^{\prime}\right)\right\}$, but that would be impossible (we would have found an element of an empty set).

Problem 2.4. Let $\left\{x_{n}\right\}$ be a convergent sequence with limit $x$. Show that every subsequence of $\left\{x_{n}\right\}$ converges to $x$.

Theorem 2.5. Every convergent sequence in a metric space is bounded.

Proof. Assume $\left\{x_{n}\right\} \rightarrow x$. Then there exists some $N$ such that $d\left(x_{n}, x\right)<1$ for all $n>N$. Define

$$
m=\max \left\{1, d\left(x_{1}, x\right), \ldots, d\left(x_{N}, x\right)\right\}
$$

which is finite and well defined, because we are taking the maximum of a finite set of real numbers. By construction, $d\left(x_{n}, x\right) \leq m$ for all $n$; hence the bounded ball $B_{m}(x)$ contains the whole sequence, and the distance between any two terms of $\left\{x_{n}\right\}$ cannot exceed the ball's diameter; that is, for any $x_{i}$ and $x_{k}$,

$$
d\left(x_{\mathrm{i}}, x_{k}\right) \leq d\left(x_{i}, x\right)+d\left(x, x_{k}\right)=2 m<\infty
$$

We now introduce a concept closely related to that of limit. It is possible that a sequence may contain one or more convergent subsequences, even if it does not converge itself. We call the limits of such subsequences cluster points (of the original sequence).

Definition 2.6. Cluster point. Let $\left\{x_{n}\right\}$ be a sequence in a metric space $(X, d)$, and $c$ a point in $X$. We say that $c$ is a cluster point of $\left\{x_{n}\right\}$ if any open ball with center at $c$ contains infinitely many terms of the sequence. That is,

$$
\forall \varepsilon>0 \text { and } \forall N, \exists n>N \text { s.th. } x_{n} \in B_{\varepsilon}(c)
$$

Note carefully the difference between the definitions of limit and cluster point: If $x$ is the limit of $\left\{x_{n}\right\}$, any $\varepsilon$-ball around $x$ will contain all terms of the sequence except for the first $N(\varepsilon)$. For a cluster point $c$, we require only that any ball around $c$ contain an infinite number of points of the sequence. This is a weaker condition, for we may still have an infinite number of terms outside the ball. Hence, the limit of a sequence is a cluster point, but the converse statement need not be true. For example, the sequence defined by

$$
x_{n}=0 \text { for } n \text { even and } x_{n}=1 \text { for } n \text { odd }
$$

has two cluster points but does not converge.

Let $y$ be the limit of some subsequence $\left\{x_{n_{k}}\right\}$ of $\left\{x_{n}\right\}$. Then $y$ is a cluster point of $\left\{x_{n}\right\}$, because any $B_{\varepsilon}(y)$ will contain an infinite number of terms of $\left\{x_{n_{k}}\right\}$ and hence of $\left\{x_{n}\right\}$. In a metric space (but not necessarily in more general topological spaces), the converse statement is true.

Theorem 2.4. Let $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ be a sequence in a metric space ( $\left.\mathrm{X}, \mathrm{d}\right)$. If $\mathrm{c}$ is a cluster point of $\left\{\mathrm{x}_{\mathrm{n}}\right\}$, then there exists some subsequence $\left\{\mathrm{x}_{\mathrm{n}_{\mathrm{k}}}\right\}$ of $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ with limit $\mathbf{c}$.

The proof of this result is an example of a proof by construction. To show that something exists, we show that we can construct it using the given assumptions.

Proof. If $c$ is a cluster point of $\left\{x_{n}\right\}$, we have, by definition,

$$
\begin{equation*}
\forall \varepsilon>0 \text { and } \forall N, \exists n>N \text { s.th. } x_{n} \in B_{\varepsilon}(c) \tag{1}
\end{equation*}
$$

To construct a subsequence with limit $c$, consider a sequence of open balls with center at $c$ and radius $1 / k,\left\{B_{1 / k}(c)\right\}$. It follows from (1) that for each $k$ there exists some $n_{k}$ such that $x_{n_{k}} \in B_{1 / k}(c)$ and that, moreover, it is possible to choose $n_{k}>n_{k-1}$ for all $k$ (so that $\left\{x_{n_{k}}\right\}$ is indeed a subsequence). As $k$ increases without bound, the radius of the balls goes to zero, implying that $\left\{x_{n_{k}}\right\} \rightarrow c$.

## 3. Sequences in $\mathbb{R}$ and $\mathbb{R}^{\mathrm{m}}$

Most spaces of interest in our applications are constructed starting from the real numbers. We shall therefore find it useful to establish some important properties of sequences in $\mathbb{R}$.

A sequence of real numbers $\left\{x_{n}\right\}$ is increasing if $x_{n+1} \geq x_{n}$ for all $n$, and decreasing if $x_{n+1} \leq x_{n}$. An increasing or decreasing sequence is said to be monotonic. The following result says that every increasing sequence of real numbers that is bounded above converges to its supremum. In the same way, it can be shown that every decreasing real sequence that is bounded below converges to its infimum. Hence, every monotonic bounded sequence of real numbers converges.

Theorem 3.1. Every increasing sequence of real numbers that is bounded above converges to its supremum.

If $\left\{x_{n}\right\}$ is increasing and has limit $x$, we often write $\left\{x_{n}\right\} \uparrow x$.

Proof. Let $\left\{x_{n}\right\}$ be an increasing real sequence, and assume that it is bounded above. By the supremum property, ${ }^{3}\left\{x_{n}\right\}$ has a supremum that we will call $s$. We want to show that $s$ is the limit of the sequence, that is, that for any given $\varepsilon>0$ we can find some positive integer $N$ such that $x_{n} \in B_{\varepsilon}(s)$ for all $n \geq N$.

Fix some arbitrary $\varepsilon>0$. By the definition of supremum, $x_{n} \leq s$ for all $n$; moreover, $s-\varepsilon$ is not an upper bound of $\left\{x_{n}\right\}$, so there exists some term $x_{N}$ of the sequence such that $x_{N}>s-\varepsilon$. Finally, because $\left\{x_{n}\right\}$ is increasing, we have $x_{n}>s-\varepsilon$ for all $n \geq N$. We have shown that for the given $\varepsilon$, there exists some $N$ such that

Figure 2.3.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-057.jpg?height=133&width=634&top_left_y=181&top_left_x=588)

$$
n \geq N \Rightarrow s-\varepsilon<x_{n} \leq s<s+\varepsilon \Rightarrow\left|x-x_{n}\right|<\varepsilon
$$

Finally, because $\varepsilon$ is arbitrary, we conclude that $\left\{x_{n}\right\} \rightarrow s$.

A real sequence $\left\{x_{n}\right\}$ is bounded if it is bounded both above and below, that is, if there exist real numbers $l$ and $u$ such that

$$
l \leq x_{n} \leq u \text { for all } n \in \mathbb{N}
$$

or, equivalently, if there exists some number $B$ such that $\left|x_{n}\right| \leq B$ for all $n$. We have seen that every convergent sequence in a metric space is bounded. In general, the converse is not true: There exist bounded divergent sequences. However, for the case of $\mathbb{R}$, it can be shown that every bounded sequence contains at least one convergent subsequence. To prove this important result, we will need the following theorem:

Theorem 3.2. Every sequence of real numbers contains either an increasing subsequence or a decreasing subsequence, and possibly both.

Proof. Given an arbitrary sequence of real numbers $\left\{x_{n}\right\}$, define the set

$$
S=\left\{s \in \mathbb{N} ; x_{s}>x_{n} \forall n>s\right\}
$$

To put an intuitive interpretation on $S$, imagine an infinite number of people seated in a very long line of seats in a movie theater, with the screen at the right "end" of the line, and interpret $x_{n}$ as the height of the $n$th person in the line. Then $S$ is the set of people who can see the movie (i.e., the subset of the audience consisting of individuals who are taller than all those in front of them). Notice that there are only two possibilities: Either an infinite number of people can see the movie, or only a finite number of them can. We will show that in the first case we can construct a decreasing subsequence of $\left\{x_{n}\right\}$, and in the second an increasing one.

Observe that the set $\left\{x_{n_{k}} ; n_{k} \in S\right\}$, thought of as a (possibly finite) sequence, is always decreasing, by the definition of $S$, for if $n_{k} \in S$, we must have $x_{n_{k}}>x_{n_{k+1}}$. (Intuitively, the people who can see the screen must be arranged in order of decreasing height.) Hence, if $S$ is unbounded (i.e., if we can always find another person farther down the line who can see the screen), we are done, for $\left\{x_{n_{k}} ; n_{k} \in S\right\}$ is an (infinite) decreasing subsequence of $\left\{x_{n}\right\}$.

The other possibility is that $S$ is finite (i.e., bounded above). By the supremum property, $S$ then has a supremum that we call $N$ (roughly, $N$ is the last
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-058.jpg?height=668&width=1122&top_left_y=179&top_left_x=176)

Figure 2.4. Construction of a decreasing subsequence.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-058.jpg?height=659&width=909&top_left_y=1003&top_left_x=178)

Figure 2.5. Construction of an increasing subsequence.

person who can see the screen). We will now construct an increasing sequence starting with the $(N+1)$ th person. Put $k_{1}=N+1$. Now, because person $k_{1}$ can't see ( $\left.k_{1} \notin S\right)$, there must exist a person farther down the line who is taller (i.e., $\exists n>k_{1}$ s.th. $x_{n} \geq x_{k_{1}}$ ). Call the first such person $k_{2}$. Now, $k_{2}>N$ can't see either, so there must be an even taller person farther down, and so on. In this manner we can construct an increasing subsequence $\left\{x_{k_{i}}\right\}$, by starting with the first person who can't see and taking at each stage the individual who is blocking the view of the previous one.

Now, let $\left\{x_{n}\right\}$ be a bounded sequence of real numbers. The preceding theorem tells us that $\left\{x_{n}\right\}$ contains at least a monotonic subsequence. Clearly, this subsequence must be bounded, so we can apply Theorem 3.1 (or its analogue for decreasing sequences) to obtain the following result:

Theorem 3.3. Bolzano-Weierstrass. Every bounded real sequence contains at least one convergent subsequence.

Problem 3.4. We want to show that every real sequence $\left\{x_{n}\right\}$ contained in $[a, b]$ has a subsequence that converges to a point $x$ in the interval. Because $\left\{x_{n}\right\}$ is bounded, the Bolzano-Weierstrass theorem ensures that it does indeed have a convergent subsequence. Assume that the limit of this subsequence lies outside $[a, b]$ (e.g., $x>b$ ). Show that this leads to a contradiction. (First, draw a picture.)

The following two results tell us that taking the limits of convergent sequences "preserves" weak inequalities and algebraic operations.

Theorem 3.5. Let $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ and $\left\{\mathrm{y}_{\mathrm{n}}\right\}$ be convergent real sequences, with $\left\{\mathrm{x}_{\mathrm{n}}\right\} \rightarrow \mathrm{x}$, and $\left\{\mathrm{y}_{\mathrm{n}}\right\} \rightarrow \mathrm{y}$. If $\mathrm{x}_{\mathrm{n}} \leq \mathrm{y}_{\mathrm{n}}$ for all $\mathrm{n}$, then $\mathrm{x} \leq \mathrm{y}$.

Proof. Fix some $\varepsilon>0$. Because $\left\{x_{n}\right\} \rightarrow x$, and $\left\{y_{n}\right\} \rightarrow y$, there exist positive integers $N_{x}(\varepsilon / 2)$ and $N_{y}(\varepsilon / 2)$ such that

$\left|x_{n}-x\right|<\varepsilon / 2$ for all $n>N_{x}(\varepsilon / 2)$ and $\left|y_{n}-y\right|<\varepsilon / 2$ for all $n>N_{y}(\varepsilon / 2)$

Putting $N=\max \left\{N_{x}(\varepsilon / 2), N_{y}(\varepsilon / 2)\right\}$, both inequalities in (1) hold simultaneously. Hence, for $n>N$, we have

$$
\begin{equation*}
x_{n}>x-\varepsilon / 2 \text { and } y_{n}<y+\varepsilon / 2 \tag{2}
\end{equation*}
$$

and we can write

$$
\begin{equation*}
x-y=\left(x-x_{n}\right)+\left(x_{n}-y_{n}\right)+\left(y_{n}-y\right)<\varepsilon \tag{3}
\end{equation*}
$$

because $x_{n}-y_{n} \leq 0$ by assumption. Finally, because $x-y<\varepsilon$ for any positive $\varepsilon$, it must be true that $x-y \leq 0$.

In fact, the assumptions of the theorem can be weakened: All we need is that there exist some $N$ such that $x_{n} \leq y_{n}$ for all $n>N$. Observe also that the theorem does not hold for strict inequalities. (Can you construct an example of two sequences that have the same limit even though $x_{n}<y_{n}$ for all $n$ ?)

Theorem 3.6. Let $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ and $\left\{\mathrm{y}_{\mathrm{n}}\right\}$ be convergent real sequences, with $\left\{\mathrm{x}_{\mathrm{n}}\right\} \rightarrow \mathrm{x}$ and $\left\{\mathrm{y}_{\mathrm{n}}\right\} \rightarrow \mathrm{y}$. Then
(i) $\left\{\mathrm{x}_{\mathrm{n}}+\mathrm{y}_{\mathrm{n}}\right\} \rightarrow \mathrm{x}+\mathrm{y}$,

(ii) $\left\{\mathrm{x}_{\mathrm{n}} \mathrm{y}_{\mathrm{n}}\right\} \rightarrow \mathrm{xy}$,

(iii) $\left\{\mathrm{x}_{\mathrm{n}} / \mathrm{y}_{\mathrm{n}}\right\} \rightarrow \mathrm{x} / \mathrm{y}$ provided $\mathrm{y} \neq 0$ and $\mathrm{y}_{\mathrm{n}} \neq 0$ for all $\mathrm{n}$.

## Proof

(i) Using the triangle inequality, we can write

$$
\begin{equation*}
\left|\left(x_{n}+y_{n}\right)-(x+y)\right|=\left|\left(x_{n}-x\right)+\left(y_{n}-y\right)\right| \leq\left|x_{n}-x\right|+\left|y_{n}-y\right| \tag{1}
\end{equation*}
$$

Now, fix an arbitrary $\varepsilon>0$. Because $\left\{x_{n}\right\} \rightarrow x$ and $\left\{y_{n}\right\} \rightarrow y$, there exist positive integers $N_{x}(\varepsilon / 2)$ and $N_{y}(\varepsilon / 2)$ such that

$$
\begin{equation*}
\left|x_{n}-x\right|<\varepsilon / 2 \forall n>N_{x}(\varepsilon / 2) \text { and }\left|y_{n}-y\right|<\varepsilon / 2 \forall n>N_{y}(\varepsilon / 2) \tag{2}
\end{equation*}
$$

Write $N=\max \left\{N_{x}(\varepsilon / 2), N_{y}(\varepsilon / 2)\right\}$. Then, for every $n>N$, both inequalities in (2) hold simultaneously, and we have, using (1):

$$
\left|\left(x_{n}+y_{n}\right)-(x+y)\right| \leq\left|x_{n}-x\right|+\left|y_{n}-y\right|<\varepsilon / 2+\varepsilon / 2=\varepsilon
$$

(ii) Proceeding in a similar fashion, we have

$$
\begin{align*}
\left|x_{n} y_{n}-x y\right| & =\left|x_{n} y_{n}-x y_{n}+x y_{n}-x y\right|=\left|\left(x_{n}-x\right) y_{n}+x\left(y_{n}-y\right)\right| \\
& \leq\left|x_{n}-x\right|\left|y_{n}\right|+|x|\left|y_{n}-y\right| \tag{3}
\end{align*}
$$

Fix some $\varepsilon>0$. By assumption, $\left\{y_{n}\right\}$ is convergent and therefore bounded (Theorem 3.3); hence, there exists some positive number $B$ such that

$$
\begin{equation*}
\left|y_{n}\right| \leq B \text { for all } n \tag{4}
\end{equation*}
$$

Next, because both sequences converge, we can find an integer $N_{x}$ such that

$$
\begin{equation*}
\left|x_{n}-x\right|<\frac{\varepsilon}{2 B} \forall n>N_{x} \tag{5}
\end{equation*}
$$

and, provided $|x| \neq 0$, another $N_{y}$ such that

$$
\begin{equation*}
\left|y_{n}-y\right|<\frac{\varepsilon}{2|x|} \forall n>N_{y} \tag{6}
\end{equation*}
$$

Put $N=\max \left\{N_{x}, N_{y}\right\}$ if $|x| \neq 0$, and $N=N_{x}$ otherwise. Going back to (3), we have, for any $n>N$ :

$$
\left|x_{n} y_{n}-x y\right| \leq\left|x_{n}-x\right|\left|y_{n}\right|+|x|\left|y_{n}-y\right|<\frac{\varepsilon}{2 B} B+\frac{\varepsilon}{2|x|}|x|=\varepsilon
$$

(if $|x|=0$, the second term after the strict inequality is zero).

(iii) To establish the last part of the theorem, it is sufficient to show that $\left\{1 / y_{n}\right\} \rightarrow$ $1 / y$, provided $y \neq 0$ and no $y_{n}=0$, and then use (ii). We now write

$$
\begin{equation*}
\left|\frac{1}{y_{n}}-\frac{1}{y}\right|=\left|\frac{y_{n}-y}{y_{n} y}\right|=\frac{\left|y_{n}-y\right|}{\left|y_{n}\right||y|} \tag{7}
\end{equation*}
$$

As before, we will now use the convergence of $\left\{y_{n}\right\}$ to put a bound on this expression. By definition of limit, we can find some $N_{1}$ such that

$$
\begin{equation*}
\left|y_{n}-y\right|<\frac{|y|}{2} \text { for all } n>N_{1} \tag{8}
\end{equation*}
$$

Using the triangle inequality,

$$
|y|=\left|\left(y-y_{n}\right)+y_{n}\right| \leq\left|y-y_{n}\right|+\left|y_{n}\right| \Rightarrow\left|y_{n}\right| \geq|y|-\left|y-y_{n}\right|
$$

Using this expression and (8), we have that, for all $n>N_{1}$,

$$
\begin{equation*}
\left|y_{n}\right| \geq|y|-\left|y-y_{n}\right|>\frac{|y|}{2} \tag{9}
\end{equation*}
$$

Next, fix some $\varepsilon>0$. By the convergence of $\left\{y_{n}\right\}$, we can find some $N_{2}>N_{1}$ such that for all $n>N_{2}$ we have

$$
\begin{equation*}
\left|y_{n}-y\right|<\frac{|y|^{2} \varepsilon}{2} \tag{10}
\end{equation*}
$$

Finally, substituting (9) and (10) into (7),

$$
\left|\frac{1}{y_{n}}-\frac{1}{y}\right|=\frac{\left|y_{n}-y\right|}{\left|y_{n}\right||y|}<\frac{|y|^{2} \varepsilon / 2}{|y|^{2} / 2}=\varepsilon
$$

Clearly, if we replace one of the sequences by a constant, the proofs only become simpler. Hence, given any two real numbers $\alpha$ and $\beta$, we have

$$
\left\{\alpha x_{n}\right\} \rightarrow \alpha x, \quad\left\{\alpha+x_{n}\right\} \rightarrow \alpha+x, \quad \text { and } \quad\left\{\alpha x_{n}+\beta y_{n}\right\} \rightarrow \alpha x+\beta y
$$

Moreover,

$$
\left\{x_{n}-y_{n}\right\}=\left\{x_{n}+\left(-1 y_{n}\right)\right\} \rightarrow x+(-y)=x-y
$$

Notice also that the proofs make use of only some basic properties of the absolute value that are shared by any other norm. Hence, it is easy to adapt the foregoing arguments to show that the relevant parts of the last theorem hold for any normed vector space.

We have seen that convergent sequences are necessarily bounded. Hence, unbounded sequences do not have a limit in the proper sense, even if they "tend to infinity," a concept we now define precisely.

Definition 3.7. A sequence of real numbers $\left\{x_{n}\right\}$ tends to infinity, written $\left\{x_{n}\right\} \rightarrow \infty$, if for any number $K$ there exists some integer $N(K)$ such that $x_{n}>K$ for all $n>N(K)$.

The following result is often helpful when we are trying to determine whether or not a given sequence tends to infinity. The proof is left as an exercise.

Theorem 3.8. Let $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ be a sequence of positive real numbers. Then $\left\{\mathrm{x}_{\mathrm{n}}\right\} \rightarrow$ $\infty$ if and only if $\left\{1 / \mathrm{x}_{\mathrm{n}}\right\} \rightarrow 0$.

Problem 3.9. Prove Theorem 3.8.

In many applications we work with sequences in finite-dimensional Euclidean spaces. The following theorem says that in such spaces, a sequence of vectors converges if and only if each one of its coordinate sequences converges. By "coordinate sequences" we mean the real sequences whose terms are the components of each vector in the original sequence. This result can be extended to finite-dimensional normed vector spaces and to product spaces.

Theorem 3.10. A sequence $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ in $\mathrm{E}^{\mathrm{m}}$ converges to a vector $\mathrm{x}=\left(\mathrm{x}^{1}, \mathrm{x}^{2}, \ldots\right.$, $\left.\mathrm{x}^{\mathrm{m}}\right)$ if and only if each coordinate sequence $\left\{\mathrm{x}_{\mathrm{n}}^{\mathrm{i}}\right\}$ converges to $\mathrm{x}^{\mathrm{i}}$.

Proof. Note that $\left\{x_{n}\right\} \rightarrow x$ if and only if $\left\{x_{n}-x\right\} \rightarrow \underline{0}$. Hence, we can consider the case in which the limit $x$ is the zero vector without any loss of generality.

- $(\rightarrow)$ First, assume $\left\{x_{n}\right\} \rightarrow \underline{0}$, and fix some $\varepsilon>0$. By the convergence of $\left\{x_{n}\right\}$ to $\underline{0}$, there exists some $N$ such that $d_{E}\left(x_{n}, \underline{0}\right)<\varepsilon$ for all $n>N$, that is,

$$
n>N \Rightarrow d_{E}\left(x_{n}, \underline{0}\right)=\sqrt{\sum_{i=1}^{m}\left(x_{n}^{2}\right)^{2}}<\varepsilon
$$

Now observe that for any $j=1, \ldots, m$, we have $\left|x_{n}^{j}\right|=\sqrt{\left(x_{n}^{j}\right)^{2}} \leq \sqrt{\sum_{i=1}^{m}\left(x_{n}^{i}\right)^{2}}$. Hence it is also true that for $n>N$, we have $\left|x_{n}^{j}-0\right|<\varepsilon$ for all $j=1, \ldots, m$; that is, each of the coordinate sequences converges to the real number zero.

- $(\leftarrow)$ Now assume that all the component sequences converge. Given some $\varepsilon>0$, we can find positive integers $N_{i}$ such that

$$
\begin{equation*}
\text { for each } i=1,2, \ldots, m, n>N_{i} \Rightarrow\left|x_{n}^{i}\right|<\varepsilon \sqrt{m} \tag{1}
\end{equation*}
$$

If we now define $N=\max _{i} N_{i},(1)$ holds for all the component sequences, provided $n>N$. We have, then,

$$
d_{E}\left(x_{n}, \underline{0}\right)=\sqrt{\sum_{i=1}^{m}\left(x_{n}^{i}\right)^{2}}<\sqrt{m \varepsilon^{2} m}=\varepsilon \text { for all } n>N
$$

Hence, $\left\{x_{n}^{i}\right\} \rightarrow 0$ for all $i$ implies $\left\{x_{n}\right\} \rightarrow \underline{0}$.

Problem 3.11. Convergence in product spaces. Let $\left(X, d_{1}\right)$ and $\left(Y, d_{2}\right)$ be metric spaces, and consider the product space $\left(Z=X \times Y, d_{\pi}\right)$, with the product metric $d_{\pi}$ defined by

$$
\begin{equation*}
d_{\pi}\left(z, z^{\prime}\right)=d_{\pi}\left[(x, y),\left(x^{\prime}, y^{\prime}\right)\right]=\sqrt{\left[d_{1}\left(x, x^{\prime}\right)\right]^{2}+\left[d_{2}\left(y, y^{\prime}\right)\right]^{2}} \tag{1}
\end{equation*}
$$

Show that the sequence $\left\{z_{n}\right\}=\left\{\left(x_{n}, y_{n}\right)\right\}$ converges to $z=(x, y)$ in $(X \times Y$, $\left.d_{\pi}\right)$ if and only if $\left\{x_{n}\right\}$ converges to $x$ in $(X, d)$ and $\left\{y_{n}\right\}$ converges to $y$ in $(Y, d)$.

Problem 3.12. Bolzano-Weierstrass in $\mathbb{E}^{\mathrm{m}}$. Show that every bounded sequence in $\mathbb{E}^{\mathrm{m}}$ contains at least one convergent subsequence.

To end this section, we consider the convergence properties of two commonly encountered families of real sequences.

Theorem 3.13. Let a be a real number, and consider the sequence $\left\{\mathrm{a}^{\mathrm{n}}\right\}$. As $\mathrm{n} \rightarrow \infty$, we have the following:

(i) If $|\mathrm{a}|<1$, then $\left\{\mathrm{a}^{\mathrm{n}}\right\} \rightarrow 0$.

(ii) If $\mathrm{a}>1$, then $\left\{\mathrm{a}^{\mathrm{n}}\right\} \rightarrow \infty$.

(iii) If $\mathrm{a} \leq-1$, then $\left\{\mathrm{a}^{\mathrm{n}}\right\}$ diverges.

Problem 3.14. To prove this theorem, we need the following result, known as the Bernoulli inequality: For each positive integer $n$ and any $x \geq-1$, $(1+x)^{n} \geq 1+n x$. Prove that this is true by induction. Where in the proof do you need the assumption that $x \geq-1$ ?

Problem 3.15. We can now prove Theorem 3.13. Hint: If $|a|<1$ (and $a \neq 0$ ), we can write $|a|=1 /(1+x)$ for some $x>0$; if $a>1$, then $a=1+x$ for some $x>0$. Use the Bernoulli inequality.

Theorem 3.16. Let $\mathrm{b}$ be a real number, and consider the sequence $\left\{\mathrm{n}^{\mathrm{b}}\right\}$. We then have the following:

(i) If $\mathrm{b}<0$, then $\left\{\mathrm{n}^{\mathrm{b}}\right\} \rightarrow 0$.

(ii) If $\mathrm{b}>0$, then $\left\{\mathrm{n}^{\mathrm{b}}\right\} \rightarrow \infty$.

We will now show that when $b>0$ and $a>1$, the ratio $a^{n} / n^{b}$ tends to infinity as $n \rightarrow \infty$; that is, the "exponential" function $a^{n}$ grows faster than any power of $n$. First, however, we need the following result.

Theorem 3.17. Let $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ be a sequence of nonzero real numbers. If

$$
\lim _{n \rightarrow \infty}\left|\frac{x_{n+1}}{x_{n}}\right|=L<1
$$

then $\left\{x_{n}\right\} \rightarrow 0$.

Proof. Fix some $\varepsilon>0$, and choose some $c \in(L, 1)$. Because $0<\left|x_{n+1}\right| x_{n} \mid=$ $\left|x_{n+1}\right| /\left|x_{n}\right| \rightarrow L<c$, there exists some $N$ such that $\left|x_{n+1}\right|<c\left|x_{n}\right|$ for all $n>N$. By induction, we can write

$$
\begin{equation*}
\left|x_{N+k}\right|<c\left|x_{N+k-1}\right|<c^{2}\left|x_{N+k-2}\right|<\ldots<c^{k}\left|x_{N}\right| \tag{1}
\end{equation*}
$$

for any $k>0$. Now, because $c^{k} \rightarrow 0$ as $k \rightarrow \infty$, there exists some $K$ such that $c^{k}<\varepsilon /\left|x_{N}\right|$ for all $k>K$. Thus, for $k>K$, we have

$$
\left|x_{N+k}\right|<c^{k}\left|x_{N}\right|<\frac{\varepsilon}{\left|x_{N}\right|}\left|x_{N}\right|=\varepsilon
$$

and $\left\{x_{n}\right\} \rightarrow 0$.

Theorem 3.18. Let $\mathrm{b}>0$ and $\mathrm{a}>1$; then $\left\{\mathrm{a}^{\mathrm{n}} / \mathrm{n}^{\mathrm{b}}\right\} \rightarrow \infty$.

Proof. Write $x_{n}=n^{b} / a^{n}$. We will show that $\left\{x_{n}\right\} \rightarrow 0$. By Theorem 3.8, this implies $\left\{1 / x_{n}\right\}=\left\{a^{n} / n^{b}\right\} \rightarrow \infty$. Now,

$$
\frac{x_{n+1}}{x_{n}}=\frac{(n+1)^{b}}{a^{n+1}} \frac{a^{n}}{n^{b}}=\frac{1}{a}\left(\frac{n+1}{n}\right)^{b} \text { and therefore } \lim _{n \rightarrow \infty} \frac{x_{n+1}}{x_{n}}=\frac{1}{a}<1
$$

By Theorem 3.17, we conclude that $\left\{x_{n}\right\} \rightarrow 0$.

Problem 3.19. Given a sequence of real numbers $\left\{x_{n}\right\}$, the sequence $\left\{S_{N}\right\}$, defined by $S_{N}=\Sigma_{n=0}^{N} x_{n}$, is called the sequence of partial sums of the infinite series $\Sigma_{n=0}^{\infty} x_{n}$. If $\left\{S_{N}\right\}$ converges to some (finite) limit $S$, then we write $\Sigma_{n=0}^{\infty} x_{n}=S$.

Consider the sequence $\left\{a^{n} ; n=0,1, \ldots\right\}$, where $0<a<1$, and define $S_{N}$ as before. Verify that $(1-a) S_{N}=1-a^{N+1}$. Use this to show that $\Sigma_{n=0}^{\infty} a^{n}=1 /(1-a)$.

Problem 3.20. Given the function

$$
\begin{equation*}
f(x)=\frac{x^{2}+2}{2 x} \tag{1}
\end{equation*}
$$

define a sequence $\left\{x_{n}\right\}$ of rational numbers by

$$
\begin{equation*}
x_{1}=1 \text { and } x_{n+1}=f\left(x_{n}\right) \text { for all } n>1 \tag{2}
\end{equation*}
$$

We have, then,

$$
\begin{equation*}
x_{2}=1.5, \quad x_{3}=1.417 \ldots \tag{3}
\end{equation*}
$$

(i) Prove that if $\left\{x_{n}\right\}$ converges, then its limit is $x=\sqrt{2}$. (Complete the following expression: $x=\lim _{n \rightarrow \infty} x_{n+1}=\lim _{n \rightarrow \infty} f\left(x_{n}\right)=\ldots$ ) We have seen in Chapter 1 (Problem 6.1) that $\sqrt{2}$ is not a rational number. Hence $\left\{x_{n}\right\}$ does not converge in $\mathbb{Q}$. We will show, however, that the given sequence has a real limit.

(ii) Prove that for $n \geq 2$ we have $x_{n} \geq \sqrt{2}$. (Show that $f(x) \geq \sqrt{2}$ using $a^{2}+b^{2} \geq 2 a b$. Why?)

(iii) Calculate the value of $\left(x_{n+1}-x_{n}\right)$ as a function of $x_{n}$ and $x_{n-1}$. Use the resulting expression to prove that for $n \geq 2,\left\{x_{n}\right\}$ is decreasing (by induction).

By the analogue of Theorem 3.1 for decreasing sequences bounded below, $\left\{x_{n}\right\}$ converges to a real number. Hence, there is a real number $x$ such that $x^{2}=2$.

## 4. Open and Closed Sets

Definition 4.1. Open and closed sets. Let $(X, d)$ be a metric space. A set $A$ in $X$ is open if for every $x \in A$ there exists an open ball centered at $x$ that is contained in $A$, that is,

$$
\forall x \in A, \exists \varepsilon>0 \text { s.th. } B_{\varepsilon}(x) \subseteq A
$$

A set $C$ in $X$ is closed if its complement ( $C^{c}$ or $\sim C$ ) is open.

Intuitively, a set $A$ is open if, starting from any point in it, any small movement still leaves us inside the set. ${ }^{4}$ We will now establish some basic properties of open sets.

Theorem 4.2. Properties of open sets. Let (X, d) be a metric space. Then

(i) $\varnothing$ and $\mathrm{X}$ are open in $\mathrm{X}$,

(ii) the union of an arbitrary (possibly infinite) family of open sets is open,

(iii) the intersection of a finite collection of open sets is open.

## Proof

(i) This should be understood as a convention. $X$ and $\varnothing$ are both open and closed in $X^{5}$

(ii) It is obvious: Let $\left\{A_{i} ; A_{i} \subseteq X, i \in I\right\}$ be a family of open sets; then if $x \in \cup_{i} A_{i}, x$ belongs to some particular $A_{i}$, and because $A_{i}$ is open, there exists some $\varepsilon>0$ such that $B_{\varepsilon}(x)$ is contained in $A_{i}$ and therefore in $\cup_{i} A_{i}$.

(iii) Let $\left\{A_{i} ; A_{i} \subseteq X, i=1, \ldots, n\right\}$ be a finite family of open sets. We want to show that $A=\cap_{i=1}^{n} A_{i}$ is open. Take any point $x$ in $A$; by definition, $x$ belongs to each and all of the $A_{i}$ 's, and because these sets are all open, we can find open balls
$B_{\varepsilon i}(x)$ such that for each $i, B_{\varepsilon i}(x) \subseteq A_{i}$. Observe that the smallest such ball is contained in all the $A_{i}$ 's simultaneously, and hence in $A$. That is, if we put $\varepsilon=\min _{i}\left\{\varepsilon_{i}\right\}$, then

$$
B_{\varepsilon}(x) \subseteq B_{\varepsilon i}(x) \subseteq A_{i} \forall i=1, \ldots, n \Rightarrow B_{\varepsilon}(x) \subseteq \cap_{i=1}^{n} A_{i}=A
$$

which shows that $A$ is open.

The condition that the family of sets be finite is important. If we had an infinite number of sets, $\inf _{\mathrm{i}}\left\{\varepsilon_{i}\right\}$ might be zero (note that the minimum might not exist). In that case, there might not be a ball small enough to do the job. For example, if we take the intersection of the infinite family of open intervals

$$
\{(-1,1),(-1 / 2,1 / 2), \ldots,(-1 / n, 1 / n), \ldots\}
$$

we end up with the set $\{0\}$, which is not open.

Using De Morgan's laws ${ }^{6}$ and the previous result, it is easy to show that closed sets have the following properties:

## Theorem 4.3. Properties of closed sets.

(i) $\varnothing$ and $\mathrm{X}$ are closed in $\mathrm{X}$.

(ii) The intersection of an arbitrary collection of closed sets is closed.

(iii) The union of a finite family of closed sets is closed.

Problem 4.4. Prove Theorem 4.3.

## (a) Interior, Boundary, and Closure of a Set

Definition 4.5. Interior, exterior, boundary, and closure of a set. Let $(X, d)$ be a metric space, and $A$ a set in $X$. We say the following:

(i) A point $x_{i} \in X$ is an interior point of $A$ if there exists an open ball centered at $x_{i}, B_{\varepsilon}\left(x_{i}\right)$, that is contained in $A$. The set of all interior points of $A$ is called the interior of $A$ (int $A$ ).

$$
x_{i} \in \text { int } A \Leftrightarrow \exists \varepsilon>0 \text { s.th. } B_{\varepsilon}\left(x_{i}\right) \subseteq A
$$

(ii) A point $x_{e} \in X$ is an exterior point of $A$ if there exists some open ball around $x_{e}$ that is contained in the complement of $A\left(\sim A\right.$ or $\left.A^{c}\right)$. The set of all exterior points of $A$ is called its exterior (ext $A$ ).

$$
x_{e} \in \operatorname{ext} A \Leftrightarrow \exists \varepsilon>0 \text { s.th. } B_{\varepsilon}\left(x_{e}\right) \subseteq(\sim A)
$$

(iii) A point $x_{b} \in X$ is a boundary point of $A$ if any open ball around it intersects both $A$ and its complement. The set of boundary points of $A$ is called its boundary, written bdy $A$ or $\partial A$.

$$
x_{b} \in \partial A \Leftrightarrow \forall \varepsilon>0, B_{\varepsilon}\left(x_{b}\right) \cap A \neq \varnothing \text { and } B_{\varepsilon}\left(x_{b}\right) \cap(\sim A) \neq \varnothing
$$

(iv) A point $x_{c} \in X$ is a closure point of $A$ if any $\varepsilon$-ball around it contains at least one point in $A$. The set of closure points of a set is called its closure, written cl $A$ or $\bar{A}$.

$$
x_{c} \in \operatorname{cl} A \Leftrightarrow \forall \varepsilon>0, B_{\varepsilon}\left(x_{c}\right) \cap A \neq \varnothing
$$

It is clear from the definition that int $A \subseteq A$ : Because any interior point of $A$ lies inside a ball contained in $A$, it must itself be in $A$; in the same manner, ext $A \subseteq(\sim A)$. Also, $A \subseteq \mathrm{cl} A$, for any open ball around a point $x \in A$ contains at least one element of $A$, namely $x$ itself. Hence,

$$
\begin{equation*}
\text { int } A \subseteq A \subseteq \operatorname{cl} A \tag{1}
\end{equation*}
$$

On the other hand, a boundary point of $A$ may belong either to $A$ or to its complement, and the same is true of closure points.

It is also evident that the interior, exterior, and boundary of any set $A$ in $X$ constitute a partition of $X$; that is, they are disjoint sets, and

$$
\begin{equation*}
\operatorname{int} A \cup \operatorname{ext} A \cup \partial A=X \tag{2}
\end{equation*}
$$

Finally, we have

$$
\begin{equation*}
\operatorname{cl} A=\operatorname{int} A \cup \partial A \tag{3}
\end{equation*}
$$

and

$$
\begin{equation*}
\operatorname{ext} A=\operatorname{int}(\sim A) \tag{4}
\end{equation*}
$$

Example 4.6. Let $A$ be the closed ball $B_{\varepsilon}[x]=\{y \in X ; d(x, y) \leq \varepsilon\}$. Then

$$
\begin{aligned}
\operatorname{int} B_{\varepsilon}[x]= & B_{\varepsilon}(x)=\{y \in X ; d(x, y)<\varepsilon\}, \quad \text { ext } B_{\varepsilon}(x)=\{y \in X ; d(x, y)>\varepsilon\}, \\
& \text { bdy } B_{\varepsilon}[x]=\{y \in X ; d(x, y)=\varepsilon\}, \quad \operatorname{cl} B_{\varepsilon}[x]=B_{\varepsilon}[x]
\end{aligned}
$$

Problem 4.7. Prove that $\partial A=\operatorname{cl} A \cap \operatorname{cl}(\sim A)$.

Using the concepts of the interior and closure of a set, we obtain the following characterizations of open and closed sets:

## Theorem 4.8

(i) int $\mathrm{A}$ is the largest open set contained in $\mathrm{A}$.

(ii) $\mathrm{A}$ is open if and only if $\mathrm{A}=$ int $\mathrm{A}$.

(iii) $c l \mathbf{A}$ is the smallest closed set that contains $\mathrm{A}$.

(iv) $\mathrm{A}$ is closed if and only if $\mathrm{A}=c l \mathrm{~A}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-068.jpg?height=669&width=873&top_left_y=192&top_left_x=304)

Figure 2.6. Interior, exterior, boundary, and closure points.

## Proof

(i) First we show that int $A$ is open. By definition of "interior," for each point $x_{i} \in \operatorname{int} A$ there exists some open ball $B_{\varepsilon}\left(x_{i}\right)$ contained in $A$. To show that int $A$ is open, we have to go one step further and verify that $B_{\varepsilon}\left(x_{i}\right)$ is contained in int $A$. Because an open ball is open set, around any point $y$ in $B_{\varepsilon}\left(x_{i}\right)$ we can construct another open ball contained in $B_{\varepsilon}\left(x_{i}\right)$ and hence in $A$. It follows that any point $y \in B_{\varepsilon}\left(x_{i}\right)$ is an interior point and $B_{\varepsilon}\left(x_{i}\right)$ is indeed contained in $A$.

Next, we show that int $A$ is the largest open subset of $A$. If $B$ is any open subset of $A$, then all its points are by definition interior points of $A$. Hence, for any such set, $B \subseteq$ int $A$.

(ii) If $A=\operatorname{int} A$, then $A$ is open, because int $A$ is open. If $A$ is open, then its largest open subset is $A$ itself, and hence $A=\operatorname{int} A$.

Problem 4.9. Prove parts (iii) and (iv) of Theorem 4.8.

## (b) Limit Points and Characterization of Closed Sets in Terms of Sequences

Definition 4.10. Limit points and derived set. Let $(X, d)$ be a metric space, and $A$ a set in $X$. A point $x_{L}$ in $X$ is said to be a limit (or cluster) point of $A$ if every open ball around it contains at least one point of $A$ distinct from $x_{L}$. The set of all limit points of $A$ is called its derived set, denoted by $D(A)$ :

$$
x_{L} \in D(A) \Leftrightarrow \forall \varepsilon>0, B_{\varepsilon}\left(x_{L}\right) \cap\left(A \backslash\left\{x_{L}\right\}\right) \neq \varnothing
$$

Notice that this is more restrictive than the definition of closure point, because now the intersection of $A$ and $B_{\varepsilon}\left(x_{L}\right)$ cannot be just the point $x_{L}$ itself. Points for which this is the case are called isolated points. Hence, closure points are either limit points or isolated points.

Theorem 4.11. Let (X, d) be a metric space, and A a set in X. A point $\mathrm{x}_{\mathrm{L}} \in \mathrm{X}$ is a limit point of $\mathrm{A}$ if and only if there exists a sequence in $\mathrm{A} \backslash\left(\mathrm{x}_{\mathrm{L}}\right\}$ that converges to $\mathrm{x}_{\mathrm{L}}$.

## Proof

- $(\rightarrow)$ Assume that there exists a sequence $\left\{a_{n}\right\}$ in $A \backslash\left\{x_{L}\right\}$ (i.e., with $a_{n} \neq x_{L}$ for all $n$ ), with $\left\{a_{n}\right\} \rightarrow x_{L}$. Then for any given $\varepsilon>0$ there exists some positive integer $N_{\varepsilon}$ such that

$$
d\left(a_{n}, x_{L}\right)<\varepsilon \text { for all } n>N_{\varepsilon}
$$

But then we have $B_{\varepsilon}\left(x_{L}\right) \cap\left(A \backslash\left\{x_{L}\right\}\right) \neq \varnothing$ for the given $\varepsilon$. Because this is true for any $\varepsilon>0, x_{L}$ is a limit point of $A$.

- $(\leftarrow)$ Assume that $x_{L}$ is a limit point of $A$, that is,

$$
\begin{equation*}
\forall r>0, B_{r}\left(x_{L}\right) \cap\left(A \backslash\left\{x_{L}\right\}\right) \neq \varnothing \tag{1}
\end{equation*}
$$

We will show that we can construct a sequence with the desired properties. Put $r_{1}=1$; by (1), there exists some $a_{1} \in B_{r_{1}}\left(x_{L}\right) \cap\left(A \backslash\left\{x_{L}\right\}\right)$. Next, put

$$
r_{2}=\frac{d\left(a_{1}, x_{L}\right)}{2} \leq \frac{1}{2}
$$

and, again by (1), there exists some $a_{2} \in B_{r_{2}}\left(x_{L}\right) \cap\left(A \backslash\left\{x_{L}\right\}\right)$. Continuing in this way, we can construct a sequence $\left\{a_{n}\right\}$ in $A \backslash\left\{x_{L}\right\}$ with the property that

$$
0<d\left(a_{n}, x_{L}\right) \leq \frac{1}{2^{n-1}}
$$

Because $1 /\left(2^{n-1}\right) \rightarrow 0$, so does $d\left(a_{n}, x_{L}\right)$, and therefore $\left\{a_{n}\right\} \rightarrow x_{L}$.

We will now obtain two useful, and closely related, characterizations of closed sets.

Theorem 4.12. A set $\mathrm{A}$ in a metric space is closed if and only if contains all its limit points.

## Proof

- $(\rightarrow)$ Assume that $A$ is closed (i.e., its complement $A^{c}$ is open). Then for any $x \in A^{c}$, there exists some $\varepsilon>0$ such that

$$
B_{\varepsilon}(x) \subseteq A^{c} \Leftrightarrow B_{\varepsilon}(x) \cap A=\varnothing
$$

Hence, no point of $A^{c}$ can be a limit point of $A$, and it follows that all such points must be contained in $A$.

- $(\leftarrow)$ To show that if $A$ contains all its limits points then $A^{c}$ is open, we prove the contrapositive statement: If $A^{c}$ is not open, then it contains some limit points of $A$.

Suppose $A^{c}$ is not open. Then, negating the definition of open set, there exist points in $A^{c}$ with the property that no open ball around them lies entirely in $A^{c}$. Let $x$ be one such point. For any $\varepsilon>0$, the ball $B_{\varepsilon}(x)$ contains at least one point in $A$ - necessarily different from $x$, because $x \in A^{c}$. Hence, $x$ is a limit point of $A$ lying in $A^{\mathrm{c}}$.

Using Theorem 4.11, we can rephrase this last characterization of closedness in terms of sequences: A set $A$ is closed if and only if every convergent sequence in $A$ has its limit in $A$. This suggests a method that is sometimes convenient for showing that a given set $A$ is closed: Consider an arbitrary convergent sequence contained in $A$, and use the set's properties to show that the limit is also contained in it.

Theorem 4.13. A set $\mathrm{A}$ in a metric space is closed if and only if every convergent sequence $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ contained in $\mathrm{A}$ has its limit in $\mathrm{A}$; that is, if $\mathrm{x}_{\mathrm{n}} \in \mathrm{A}$ for all $\mathrm{n}$ and $\left\{\mathrm{x}_{\mathrm{n}}\right\} \rightarrow \mathrm{x}$ imply that $\mathrm{x} \in \mathrm{A}$.

Proof. Assume that every convergent sequence $\left\{x_{n}\right\}$ contained in $A$ has limit $x$ in $A$. Then, in particular, this holds for all such sequences with the property that $x_{n} \neq x$ for all $n$. It follows that $A$ contains all its limit points and is therefore closed.

Conversely, assume that $A$ is closed, and let $\left\{x_{n}\right\}$ be a convergent sequence contained in $A$ with limit $x$. If $x_{n} \neq x$ for all $n$, then $x$ is a limit point of $A$ and therefore belongs to $A$ (because $A$ is closed). Alternatively, $x=x_{n}$ for some $n$, and because $x_{n} \in A$, we have $x \in A$.

Problem 4.14. Show that in a metric, space the closed ball $B_{r}[x]$ is a closed set. (Take a limit point $a$ of $B_{r}[x]$ and consider an arbitrary sequence $\left\{x_{n}\right\}$ in $B_{r}[x]$ with limit $a$. Use the triangle inequality to show that $a$ must be in $B_{r}[x]$.)

Problem 4.15. Let $B$ be a nonempty set of real numbers bounded above. Let $s=\sup B$. Show that $s \in \bar{B}$. Notice that this implies that $s \in B$ if $B$ is closed.

Problem 4.16. Let $A$ be a set in a metric space $(X, d)$. Show that if $A$ is closed and $x \notin A$, then $d(x, A)>0$.

Hint: Prove the contrapositive.

## 5. Limits of Functions

We shall now define the limit of a function between two metric spaces and show that it can be characterized in terms of the limits of sequences.

Definition 5.1. Limit of a function. ${ }^{7}$ Let $(X, d)$ and $(Y, \rho)$ be two metric spaces, with $A$ a set in $X, f$ a function $A \longrightarrow Y$, and $x^{0}$ a (limit) point of $A$. We say that $f$ has a limit $y^{0}$ as $x$ approaches $x^{0}$ if

$$
\forall \varepsilon>0, \exists \delta_{\varepsilon}>0 \text { s.th. } 0<d\left(x, x^{0}\right)<\delta_{\varepsilon} \Rightarrow \rho\left[f(x), y^{0}\right]<\varepsilon
$$

We then write $f(x) \rightarrow y^{0}$ as $x \rightarrow x^{0}$, or $\lim _{x \rightarrow x^{0}} f(x)=y^{0}$.

Intuitively, $f(x)$ approaches $y^{0}$ as $x \rightarrow x^{0}$ if, by choosing $x$ sufficiently close to $x^{0}$, we can bring $f(x)$ as close to $y^{0}$ as we want. Notice that nothing has been said in the definition about the value of $f$ at $x^{0}$; in fact, $x^{0}$ may not even be in the domain of $f$. We require, however, that $x^{0}$ be a limit point of $A$ so that we can always find points in the domain of $f$ as close to $x^{0}$ as we want.

The following result shows that the limit of a function can be characterized in terms of the convergence of sequences.

Theorem 5.2. Let $(\mathrm{X}, \mathrm{d})$ and $(\mathrm{Y}, \mathrm{\rho})$ be two metric spaces, with $\mathrm{f}$ a function $\mathrm{X} \rightarrow \mathrm{Y}$, and $\mathrm{x}^{0}$ a limit point of $\mathrm{X}$. Then $\mathrm{f}$ has limit $\mathrm{y}^{0}$ as $\mathrm{x} \rightarrow \mathrm{x}^{0}$ if and only if for every sequence $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ that converges to $\mathrm{x}^{0}$ in $(\mathrm{X}, \mathrm{d})$, with $\mathrm{x}_{\mathrm{n}} \neq \mathrm{x}^{0}$, the sequence $\left\{\mathrm{f}\left(\mathrm{x}_{\mathrm{n}}\right)\right\}$ converges to $\mathrm{y}^{0}$ in $(\mathrm{Y}, \mathrm{p})$.

## Proof

- $(\rightarrow)$ Assume that $\lim _{x \rightarrow x^{0}} f(x)=y^{0}$, and let $\left\{x_{n}\right\}$ be a sequence in $X$, with $x_{n} \neq x^{0}$ and $\left\{x_{n}\right\} \rightarrow x^{0}$. We want to show that $\left\{f\left(x_{n}\right)\right\} \rightarrow y^{0}$, that is, that

$$
\begin{equation*}
\forall \varepsilon>0, \exists N(\varepsilon) \text { s.th. } \rho\left[f\left(x_{n}\right), y^{0}\right]<\varepsilon \quad \text { for all } n>N(\varepsilon) \tag{1}
\end{equation*}
$$

Fix some arbitrary $\varepsilon>0$. By assumption, $f(x)$ has limit $y^{0}$ as $x \rightarrow x^{0}$, so we can bring $f(x)$ arbitrarily close to $y^{0}$ by choosing $x$ sufficiently close to $x^{0}$; that is, for the given $\varepsilon$,

$$
\begin{equation*}
\exists \delta_{\varepsilon}>0 \text { s.th. } \rho\left[f(x), y^{0}\right]<\varepsilon \quad \text { for all } x \in B_{\delta_{\varepsilon}}\left(x^{0}\right) \backslash\left\{x^{0}\right\} \tag{2}
\end{equation*}
$$

Finally, the fact that $\left\{x_{n}\right\} \rightarrow x^{0}$ guarantees that we can get $x_{n}$ sufficiently close to $x^{0}$ by choosing $n$ large enough. Formally, the convergence of $\left\{x_{n}\right\}$ implies that for the $\delta_{\varepsilon}$ in (2),

$$
\begin{equation*}
\exists N\left(\delta_{\varepsilon}\right) \text { s.th. } x_{n} \in B_{\delta_{\varepsilon}}\left(x^{0}\right) \text { for all } n>N\left(\delta_{\varepsilon}\right) \tag{3}
\end{equation*}
$$

Now, (2) and (3) together imply (1) (with $N(\varepsilon)=N\left(\delta_{\varepsilon}\right)$ ), that is, $\left\{f\left(x_{n}\right)\right\} \rightarrow y^{0}$.

- $(\leftarrow)$ We now want to prove the following statement:
$\left[\forall\left\{x_{n}\right\}\right.$ with $\left\{x_{n}\right\} \rightarrow x^{0}$ and $x_{n} \neq x^{0}$, we have $\left.\left\{f\left(x_{n}\right)\right\} \rightarrow y^{0}\right] \Rightarrow \lim _{x \rightarrow x^{0}} f(x)=y^{0}$

It turns out to be easier to prove the contrapositive statement:

$$
\lim _{x \rightarrow x^{0}} f(x) \neq y^{0} \Rightarrow\left[\exists\left\{x_{n}\right\} \text { with } x_{n} \neq x^{0} \text { and }\left\{x_{n}\right\} \rightarrow x^{0}, \text { s.th. }\left\{f\left(x_{n}\right)\right\} \nrightarrow y^{0}\right]
$$

That is, if $y^{0}$ is not the limit of $f$ as $x \rightarrow x^{0}$, then there exist sequences with $\left\{x_{n}\right\} \rightarrow x^{0}$ and $x_{n} \neq x^{0}$ with the property that the image sequence $\left\{f\left(x_{n}\right)\right\}$ does not converge to $y^{0}$. Now, what does it mean to say that $y^{0}$ is not the limit of $f$ as $x \rightarrow x^{0}$ ? Take the definition of limit,

$$
\forall \varepsilon>0, \exists \delta>0 \text { s.th. } \forall x \in B_{\delta}\left(x^{0}\right) \backslash\left\{x^{0}\right\} \text { we have } \rho\left[f(x), y^{0}\right]<\varepsilon
$$

and negate it, obtaining

$$
\begin{equation*}
\exists \varepsilon>0 \text { s.th. } \forall \delta>0, \exists x \in B_{\delta}\left(x^{0}\right) \backslash\left\{x^{0}\right\} \text { with } \rho\left[f(x), y^{0}\right] \geq \varepsilon \tag{4}
\end{equation*}
$$

We will now show that if $y^{0}$ is not the limit of $f$ as $x \rightarrow x^{0}$, then it is possible to find a sequence $\left\{x_{n}\right\}$ such that $\left\{x_{n}\right\} \rightarrow x^{0}$ and $x_{n} \neq x^{0}$, but $\left\{f\left(x_{n}\right)\right\} \rightarrow y^{0}$. Choose some $\varepsilon$ that works in (4), and consider a sequence of open balls centered at $x^{0}$ with radius $r_{n}=1 / n$. By (4), it is possible to pick for each $n$ a point $x_{n} \in B_{1 / n}\left(x^{0}\right)$ such that $\rho\left[f\left(x_{n}\right), y^{0}\right] \geq \varepsilon$. By construction, $\left\{x_{n}\right\} \rightarrow x^{0}$, but $\left\{f\left(x_{n}\right)\right\} \rightarrow y^{0}$.

This result allows us to obtain some important properties of the limits of functions using earlier results about convergent sequences. We list some of these properties, leaving the proofs as exercises.

Theorem 5.3. Uniqueness of the limit. Let $(\mathrm{X}, \mathrm{d})$ and $(\mathrm{Y}, \mathrm{\rho})$ be metric spaces, with $\mathrm{A}$ a set in $\mathrm{X}, \mathrm{f}$ a function $\mathrm{A} \longrightarrow \mathrm{Y}$, and $\mathrm{x}^{0}$ a limit point of $\mathrm{A}$. Then the limit of $\mathrm{f}$ as $\mathrm{x} \rightarrow \mathrm{x}^{0}$, when it exists, is unique. That is, if $\mathrm{f}(\mathrm{x}) \rightarrow \mathrm{y}^{\prime}$ and $\mathrm{f}(\mathrm{x}) \rightarrow \mathrm{y}^{\prime \prime}$ as $\mathrm{x} \rightarrow \mathrm{x}^{0}$, then $\mathrm{y}^{\prime}=\mathrm{y}^{\prime \prime}$.

Theorem 5.4. Algebra of limits. Let (X, d) be a metric sapce, with (Y, $\|\cdot\|$ ) a normed vector space, $\mathrm{f}$ and $\mathrm{g}$ functions $\mathrm{X} \longrightarrow \mathrm{Y}$, and $\mathrm{x}^{0}$ a limit point of $\mathrm{X}$. Assume that $\mathrm{f}(\mathrm{x}) \rightarrow \mathrm{a}$ and $\mathrm{g}(\mathrm{x}) \rightarrow \mathrm{b}$ as $\mathrm{x} \rightarrow \mathrm{x}^{0}$. Then

(i) $\mathrm{f}(\mathrm{x})+\mathrm{g}(\mathrm{x}) \rightarrow \mathrm{a}+\mathrm{b}$ as $\mathrm{x} \rightarrow \mathrm{x}^{0}$, and

(ii) for any scalar $\lambda, \lambda \mathrm{f}(\mathrm{x}) \rightarrow \lambda \mathrm{a}$ as $\mathrm{x} \rightarrow \mathrm{x}^{0}$.

If $(\mathrm{Y},\|\cdot\|)$ is $\mathbb{R}$ with the usual norm, then

(iii) $\mathrm{f}(\mathrm{x}) \mathrm{g}(\mathrm{x}) \rightarrow \mathrm{ab}$ as $\mathrm{x} \rightarrow \mathrm{x}^{0}$, and

(iv) $\mathrm{f}(\mathrm{x}) / \mathrm{g}(\mathrm{x}) \rightarrow \mathrm{a} / \mathrm{b}$ as $\mathrm{x} \rightarrow x^{0}$, provided $\mathrm{b} \neq 0$.

Theorem 5.5. Preservation of equalities and inequalities. Let (X, d) be a metric space, with $\mathrm{f}$ and $\mathrm{g}$ functions $\mathrm{X} \rightarrow \mathbb{R}$, and $\mathrm{x}^{0}$ a limit point of $\mathrm{X}$. Then
(i) assume that there exists some $\varepsilon>0$ such that $\mathrm{f}(\mathrm{x})=\mathrm{g}(\mathrm{x})$ for all $\mathrm{x} \in \mathrm{B}_{\varepsilon}\left(\mathrm{x}^{0}\right) \backslash\left(\mathrm{x}^{0}\right\}$ and that $\mathrm{f}(\mathrm{x}) \rightarrow \mathrm{a}$ as $\mathrm{x} \rightarrow \mathrm{x}^{0}$; then $\mathrm{g}(\mathrm{x}) \rightarrow \mathrm{a}$ as $\mathrm{x} \rightarrow \mathrm{x}^{0}$, and

(ii) assume that $\mathrm{f}(\mathrm{x}) \rightarrow \mathrm{a}$ and $\mathrm{g}(\mathrm{x}) \rightarrow \mathrm{b}$ as $\mathrm{x} \rightarrow \mathrm{x}^{0}$. If there exists some $\varepsilon>0$ such that $\mathrm{f}(\mathrm{x}) \leq \mathrm{g}(\mathrm{x})$ for all $\mathrm{x} \in \mathrm{B}_{\mathrm{e}}\left(\mathrm{x}^{0}\right) \backslash\left\{\mathrm{x}^{0}\right\}$, then $\mathrm{a} \leq \mathrm{b}$.

Problem 5.6. Use the definition of the limit of a function to show that if

$$
\lim _{x \rightarrow x^{0}} f(x)=a \text { and } \lim _{x \rightarrow x^{0}} g(x)=b
$$

then $\lim _{x \rightarrow x^{0}}[f(x)+g(x)]=a+b$. Prove the same result using the analogous theorem for limits of sequences.

## Limits at Infinity and Infinite Limits

Let $f$ be a function $\mathbb{R} \rightarrow \mathbb{R}$. We say that $f(x) \rightarrow y^{0}$ as $x \rightarrow \infty$ if for every $\varepsilon>0$ there exists some $B>0$ such that $\left|f(x)-y^{0}\right|<\varepsilon$ for all $x>B$. The limit of $f$ as $x \rightarrow-\infty$ is defined in an analogous way.

The foregoing results concerning the preservation of inequalities and the algebra of limits have direct analogues for limits at infinity.

Next, let $(X, d)$ be a metric space, with $f$ a function $X \rightarrow \mathbb{R}$, and $x^{0}$ a limit point of $X$. We say that $f(x) \rightarrow \infty$ as $x \rightarrow x^{0}$ if

$$
\forall B>0, \exists \delta>0 \text { s.th. } f(x)>B \text { for all } x \in B_{\delta}\left(x^{0}\right) \backslash\left\{x^{0}\right\}
$$

In this case, we have to be more careful with the limits of sums, products, and quotients of functions. In particular, let $f$ and $g$ be functions $X \rightarrow \mathbb{R}$, and $x^{0}$ a limit point of $X$. We have the following:

(i) If $\lim _{x \rightarrow x^{0}} f(x)=y^{0}$ and $\lim _{x \rightarrow x^{0}} g(x)=\infty$, then $\lim _{x \rightarrow x^{0}}[f(x)+g(x)]=\infty$, but if $\lim _{x \rightarrow x^{0}}$ $f(x)=-\infty$, the limit of the sum may be anything.

(ii) If $\lim _{x \rightarrow x^{0}} f(x)=y^{0}>0$ and $\lim _{x \rightarrow x^{0}} g(x)=\infty$, then $\lim _{x \rightarrow x^{0}}[f(x) g(x)]=\infty$. However, if $\lim _{x \rightarrow x^{0}} f(x)=0$, nothing can be said without studying $f$ and $g$ further.

(iii) If $\lim _{x \rightarrow x^{0}} f(x)=y^{0}>0, \lim _{x \rightarrow x^{0}} g(x)=0$, and $g(x) \neq 0$ in some open ball around $x^{0}$, then ${ }_{x \rightarrow x^{0}} f(x) / g(x)=\infty$.

## 6. Continuity in Metric Spaces

The familiar concept of continuity for a function from $\mathbb{R}$ to $\mathbb{R}$ can be extended in a natural way to functions mapping one metric space into another. In this section, we define continuity for functions between metric spaces, obtain some useful characterizations of continuous functions, and prove some important results concerning the properties of continuous real functions defined on an interval.

Definition 6.1. Continuous function. Let $(X, d)$ and $(Y, \rho)$ be metric spaces, and $f$ a function $X \longrightarrow Y$. We say that $f$ is continuous at a point $x^{0} \in X$ if

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-074.jpg?height=583&width=1229&top_left_y=186&top_left_x=122)

Figure 2.7.

$$
\forall \varepsilon>0, \exists \delta\left(x^{0}, \varepsilon\right)>0 \text { s.th. } d\left(x, x^{0}\right)<\delta\left(x^{0}, \varepsilon\right) \Rightarrow \rho\left[f(x), f\left(x^{0}\right)\right]<\varepsilon
$$

The function $f$ is continuous on a subset $A$ of $X$ if it is continuous at all points of $A$. If we speak simply of a continuous function, it is understood that the function is continuous at all points in its domain. ${ }^{8}$

Intuitively, a continuous function maps nearby points into images that are also close by. Hence, if $f$ is continuous at $x^{0}$, a small change in $x$ away from $x^{0}$ will not change the value of the function too much. The notation $\delta\left(x^{0}, \varepsilon\right)$ emphasizes that the value of $\delta$ that will work in each case will depend on the value of $\varepsilon$ and on the point $x^{0}$.

The geometric intuition behind the definition is most easily captured by reformulating it in terms of open balls. Hence, a function $f$ is continuous at $x^{0}$ if

$$
\forall \varepsilon>0, \exists \delta>0 \text { s.th. } x \in B_{\delta}\left(x^{0}\right) \Rightarrow f(x) \in B_{\varepsilon}\left(f\left(x^{0}\right)\right)
$$

or, equivalently, if

$$
\begin{equation*}
\forall \varepsilon>0, \exists \delta>0 \text { s.th. } f\left(B_{\delta}\left(x^{0}\right)\right) \subseteq B_{\varepsilon}\left(f\left(x^{0}\right)\right) \tag{1}
\end{equation*}
$$

That is, given an open ball around $f\left(x^{0}\right)$ with arbitrarily small radius $\varepsilon$, we can always find another ball with center at $x^{0}$ and radius $\delta$ whose image under $f$ is contained in the first ball, $B_{\varepsilon}\left(f\left(x^{0}\right)\right)$. The first panel of Figure 2.7 illustrates that this is always possible at a point of continuity. The second panel shows that if $f$ is discontinuous at $x^{0}$, then it is impossible to find such a $\delta$ for any $\varepsilon$ smaller than the jump in the function at $x^{0}$.

Problem 6.2. Preservation of sign. Let $f$ be a continuous function from a metric space $(X, d)$ to $\mathbb{R}$, with the usual metric. Prove (directly) that the set $\{x \in X ; f(x)>0\}$ is open. Intuitively, this result says that a continuous function that is strictly positive (or negative) at a point will maintain its sign within a sufficiently small ball around the original point.

Using the definition of the limit of a function and the characterization of limits of functions in terms of limits of sequences, we obtain immediately two useful characterizations of continuity. Loosely speaking, the first says that a function is continuous at a point if its value coincides with its limit, and the second says that a continuous function preserves convergence of sequences.

Theorem 6.3. Let ( $\mathrm{X}, \mathrm{d})$ and $(\mathrm{Y}, \rho)$ be metric spaces, and $\mathrm{f}$ a function $\mathrm{X} \longrightarrow$ $\mathrm{Y}$. Then $\mathrm{f}$ is continuous at a point $\mathrm{x}^{0}$ in $\mathrm{X}$ if and only if either of the following (equivalent) statements is true:

(i) $\mathrm{f}\left(\mathrm{x}^{0}\right)$ is defined, and either $\mathrm{x}^{0}$ is an isolated point or $\mathrm{x}^{0}$ is a limit point of $\mathrm{X}$ and $\lim _{\mathrm{x} \rightarrow \mathrm{x}} \mathrm{f}(\mathrm{x})=\mathrm{f}\left(\mathrm{x}^{0}\right)$.

(ii) For every sequence $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ convergent to $\mathrm{x}^{0}$ in $(\mathrm{X}, \mathrm{d})$, the sequence $\left\{\mathrm{f}\left(\mathrm{x}_{\mathrm{n}}\right)\right\}$ converges to $\mathrm{f}\left(\mathrm{x}^{0}\right)$ in $(\mathrm{Y}, \mathrm{\rho})$.

Hence, a function $f$ is discontinuous at a limit point $x^{0}$ of $X$ if the limit of $f$ as $x \rightarrow x^{0}$ does not exist or if it exists but is not equal to the value of the function at $x^{0}$. For example, the function

$$
f(x)=\frac{1}{x-1}
$$

is discontinuous at $x=1$ because it does not have a limit as $x \rightarrow 1$. The function defined by

$$
g(x, y)=\frac{x y}{x^{2}+y^{2}} \quad \text { for }(x, y) \neq(0,0) \text { and } f(0,0)=0
$$

is discontinuous for the second reason. Notice that the sequence $\{(1 / n, 1 / n)\}$ converges to $(0,0)$, but the image sequence $f(1 / n, 1 / n)$ does not approach 0 .

Intuitively, a function is continuous except at points corresponding to "breaks" in its graph. Intuition, however, may occasionally need some help, as illustrated by the following example.

Example 6.4. Consider the function $f: \mathbb{R} \longrightarrow \mathbb{R}$, defined by $f(x)=0$ if $x$ is irrational, and by $f(x)=1 / q$ if $x$ is the rational number $p / q$, where $p$ and $q$ are integers with no common factor and $q>0$. We shall show that
$f$ is discontinuous at all rational numbers and continuous at all irrational ones.

What does it mean that a function is not continuous at a point $x^{0}$ ? Negating the definition of continuity, we obtain the following:

$\exists \varepsilon>0$ s.th. $\forall \delta>0, \exists x \in B_{\delta}\left(x^{0}\right)$ with the property that $\rho\left[f(x), f\left(x^{0}\right)\right] \geq \varepsilon$

Hence, to establish discontinuity, we have to produce one such $\varepsilon$.

Now, Let $x^{0}=p / q$ be a rational number, and choose $\varepsilon \leq 1 / q$. Then, for any $\delta>0$, the ball $B_{\delta}\left(x^{0}\right)=\left(x^{0}-\delta, x^{0}+\delta\right)$ contains at least an irrational number $x^{i}$. For this number, $\left|f\left(x^{0}\right)-f\left(x^{i}\right)\right|=1 / q \geq \varepsilon$.

Next, let $x^{0}$ be an irrational number, and fix some arbitrary $\varepsilon>0$. The interval $B_{\delta}\left(x^{0}\right)=\left(x^{0}-1, x^{0}+1\right)$ contains finitely many rational numbers with denominator no greater than $1 / \varepsilon$. Because $x^{0}$ is irrational and therefore cannot be any of these numbers, the distance between $x^{0}$ and the closest such number is a strictly positive number $\delta$. Hence, any $x \in B_{\delta}\left(x^{0}\right)$ is either irrational or a rational number $p / q$ with $q>1 / \varepsilon$. In the first case, $\left|f\left(x^{0}\right)-f(x)\right|=$ 0 , and in the second, $\left|f\left(x^{0}\right)-f(x)\right|=1 / q<\varepsilon$.

Problem 6.5. Let $f: \mathbb{R} \longrightarrow \mathbb{R}$ be the function defined by $f(x)=1$ for $x$ rational and by $f(x)=0$ for $x$ irrational. Show that $f$ is discontinuous everywhere.

Hint: Recall that any interval in the real line contains both rational and irrational numbers.

Problem 6.6. Given a function $f: \mathbb{R} \longrightarrow \mathbb{R}$, define $g: \mathbb{R} \longrightarrow \mathbb{R}^{2}$ by $g(x)=$ $(x, f(x))$. Use the sequential characterization of continuity to show that if $f$ is continuous at some point $x^{0}$, then so is $g$.

Problem 6.7. Consider the finite-dimensional Euclidean space $E^{n}$. For any $k \in\{1,2, \ldots, n\}$, the $k$ th projection mapping, $p_{k}: \mathbb{R}^{\mathrm{n}} \rightarrow \mathbb{R}$, is defined for $x=\left(x_{1}, \ldots, x_{n}\right)$ by $p_{k}(x)=x_{k}$. Show that $p_{k}()$ is a continuous function.

Problem 6.8. Show that in any normed vector space $(X,\|\cdot\|)$ the norm is a continuous function from $X$ to $\mathbb{R}$.

Problem 6.9. Prove that if $f$ is a continuous function, then for any set $A$, $f(\mathrm{cl} A) \subseteq \mathrm{cl}[f(A)]$.

Hint: Use the characterization of continuity in terms of inclusion relations among open balls given in expression (1) right after Definition 6.1.

Using the characterizations of continuity given in Theorem 6.3, it is very easy to prove some important results.

Theorem 6.10. Composite-function theorem. Let ( $\mathrm{X}, \mathrm{d}),\left(\mathrm{Y}, \mathrm{d}^{\prime}\right)$, and $\left(\mathrm{Z}, \mathrm{d}^{\prime \prime}\right)$ be metric spaces. Given two functions $\mathrm{f}: \mathrm{X} \rightarrow \mathrm{Y}$ continuous at $\mathrm{x}^{0} \in \mathrm{X}$ and $\mathrm{g}: \mathrm{Y} \longrightarrow \mathrm{Z}$ continuous at $\mathrm{f}\left(\mathrm{x}^{0}\right) \in \mathrm{Y}$, the composite function $\mathrm{g} \circ \mathrm{f}$ is continuous at $\mathrm{x}^{0}$.

Proof. We will use the sequential characterization of continuity. Let $\left\{x_{n}\right\}$ be any sequence convergent to $x^{0}$ in $(X, d)$. Because $f$ is continuous at $x^{0}$, we have $\left\{f\left(x_{n}\right)\right\} \rightarrow f\left(x^{0}\right)$ for any such sequence. And because $g$ is continuous at $f\left(x^{0}\right),\left\{g\left[f\left(x_{n}\right)\right]\right\} \rightarrow g\left[f\left(x^{0}\right)\right]$ for any $\left\{x_{n}\right\}$ with $\left\{x_{n}\right\} \rightarrow x^{0}$. Hence, $g \circ f$ is continuous at $x^{0}$.

Problem 6.11. Let $f$ and $g$ be functions $\mathbb{R} \rightarrow \mathbb{R}$, and assume that $f$ is continuous at $y^{0}$ and that $g(x) \rightarrow y^{0}$ as $x \rightarrow \infty$. Show that $\lim _{x \rightarrow \infty} f[g(x)]=f\left(y^{0}\right)$.

Using the characterization of continuity in terms of limits and Theorem 5.4 on the algebra of limits, we obtain the following:

Theorem 6.12. Let ( $\mathrm{X}, \mathrm{d})$ be a metric space, and $(\mathrm{Y},\|\cdot\|)$ a normed vector space. Given functions $\mathrm{f}$ and $\mathrm{g}, \mathrm{X} \longrightarrow \mathrm{Y}$, both continuous at $\mathrm{x}^{0} \in \mathrm{X}$, we have the following:

(i) $\mathrm{f}+\mathrm{g}$ is continuous at $\mathrm{x}^{0}$, and

(ii) for any scalar $\lambda, \lambda \mathrm{f}$ is continuous at $\mathrm{x}^{0}$.

If $(\mathrm{Y},\|\cdot\|)$ is $\mathbb{R}$ with the usual norm, then

(iii) $\mathrm{f} \cdot \mathrm{g}$ is continuous at $\mathrm{x}^{0}$, and

(iv) $\mathrm{f} / \mathrm{g}$ is continuous at $\mathrm{x}^{0}$, provided $\mathrm{g}(\mathrm{x}) \neq 0$ in some open ball around $\mathrm{x}^{0}$.

So far, we have been talking about continuity in local terms. That is, we defined the continuity of a function at a point and called the function continuous if it was continuous at all points in its domain. We shall now give a direct characterization of "global" continuity.

Theorem 6.13. Let ( $\mathrm{X}, \mathrm{d})$ and $(\mathrm{Y}, \mathrm{\rho})$ be metric spaces, and $\mathrm{f}$ a function $\mathrm{X} \rightarrow \mathrm{Y}$. Then $\mathrm{f}$ is continuous if and only if for every set $\mathrm{C}$ closed in $(\mathrm{Y}, \mathrm{\rho})$ the set $\mathrm{f}^{-1}(\mathrm{C})$ is closed in $(\mathrm{X}, \mathrm{d})$.

That is, a function is continuous if and only if the inverse images of closed sets are closed. We emphasize that this is true only for inverse images. A

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-078.jpg?height=486&width=1164&top_left_y=167&top_left_x=170)

Figure 2.8.

continuous function does not necessarily map closed sets into closed sets, and a function that does map closed sets into closed sets is not necessarily continuous.

## Proof

- $(\rightarrow) f$ continuous on $X \Rightarrow$ for any $C$ closed in $Y, f^{-1}(C)$ is closed in $X$.

Let $C$ be an arbitrary closed set in $(Y, \rho)$. We will show that $f^{-1}(C)$ is closed in $(X, d)$ by verifying that it contains all its limit points. Let $x$ be an arbitrary limit point of $f^{-1}(C)$; then (by Theorem 4.11) there exists a sequence $\left\{x_{n}\right\}$ in $f^{-1}(C)$ that converges to $x$. Because $f$ is continuous, the sequence $\left\{f\left(x_{n}\right)\right\}$ converges to $f(x)$. By construction, $f\left(x_{n}\right) \in C$ for all $n$, and by assumption, $C$ is closed. Hence, by Theorem 4.13, the limit $f(x)$ must lie in $C$. Now, $f(x) \in C \Leftrightarrow x \in f^{-1}(C)$, implying that $f^{-1}(C)$ contains all its limit points and is therefore closed.

- $(\leftarrow)$ For any $C$ closed in $Y, f^{-1}(C)$ is closed in $X \Rightarrow f$ continuous on $X$.

We will prove the contrapositive statement:

$f$ discontinuous at some point $x^{0}$ in $X \Rightarrow \exists$ closed sets $C$ in $Y$ with $f^{-1}(C)$ not closed

Let $f$ be discontinuous at some point $x^{0}$. Then (negating the characterization of continuity in terms of sequences) there exist sequences $\left\{x_{n}\right\} \rightarrow x^{0}$ in $X$ with $\left\{f\left(x_{n}\right)\right\} f f\left(x^{0}\right)$. That is, there exists some $r>0$ such that

$$
\begin{equation*}
\rho\left[f\left(x_{n}\right), f\left(x^{0}\right)\right] \geq r \text { for all } n \tag{1}
\end{equation*}
$$

(or at least for all $n_{k}$ in some subsequence $\left\{x_{n_{k}}\right\}$ of $\left\{x_{n}\right\}$, in which case the argument goes through unchanged working with the subsequence).

We will use this fact to show that there exists a set with the desired properties. In particular, let $C$ be the closure of the image sequence:

$$
C=\operatorname{cl}\left(\left\{f\left(x_{n}\right)\right\}\right)
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-079.jpg?height=464&width=1177&top_left_y=189&top_left_x=154)

Figure 2.9.

Being the closure of a set, $C$ is closed. We will prove that $f^{-1}(C)$ is not closed by showing that it does not contain all its limit points. In particular, we will show that $x^{0}$ is a limit point of $f^{-1}(C)$ but does not belong to this set. Note that because $C$ contains $\left\{f\left(x_{n}\right)\right\}$, we have $x_{n} \in f^{-1}(C)$ for all $n$, and because $\left\{x_{n}\right\} \rightarrow x^{0}, x^{0}$ is a limit point of $f^{-1}(C)$. However, $f\left(x^{0}\right) \notin C$ (i.e., $f\left(x^{0}\right)$ is not a closure point of $\left\{f\left(x_{n}\right)\right\}$ ), for (1) implies $B_{\varepsilon}\left(f\left(x^{0}\right)\right) \cap\left\{f\left(x_{n}\right)\right\}=\varnothing$ for all $\varepsilon<r$. Hence, $x^{0} \notin f^{-1}(C)$.

Taking complements of the appropriate sets, it is easy to obtain an equivalent characterization of continuity in terms of the inverse images of open sets.

Theorem 6.14. Let ( $\mathrm{X}, \mathrm{d})$ and ( $\mathrm{Y}, \mathrm{\rho})$ be metric spaces, and $\mathrm{f}$ a function $\mathrm{X} \rightarrow \mathrm{Y}$. Then $\mathrm{f}$ is continuous if and only if for every set $\mathrm{A}$ open in $(\mathrm{Y}, \mathrm{\rho})$ the set $\mathrm{f}^{-1}(\mathrm{~A})$ is open in $(\mathrm{X}, \mathrm{d})$.

Problem 6.15. Using Theorem 6.13, prove Theorem 6.14.

Problem 6.16. Let $(X, d)$ be a metric space, and $(Y,\|\cdot\|)$ a normed vector space with zero vector 0 . Given a continuous function $f: X \longrightarrow Y$, adapt the proof of the characterization of continuity in terms of the inverse images of closed sets to show that the set $f^{-1}(\underline{0})$ is closed.

These last characterizations of continuity are of particular interest because they do not contain any explicit reference to a metric. In fact, when we work in general topological spaces (of which metric spaces are a subset), we begin with open (or closed) sets as a primitive concept and then define continuity in terms of their inverse images.

## Uniform Continuity

A stronger concept of continuity that is sometimes useful is that of uniform continuity. We have seen that a function $f$ between two metric spaces $(X, d)$ and $(Y, \rho)$ is continuous on a subset $A$ of $X$ if for all $x$ and $y$ in $A$ we have

$$
\begin{equation*}
\forall \varepsilon>0, \exists \delta(x, \varepsilon)>0 \text { s.th. } d(x, y)<\delta(x, \varepsilon) \Rightarrow \rho[f(x), f(y)]<\varepsilon \tag{1}
\end{equation*}
$$

In general, the value of $\delta$ that satisfies (1) depends not only on the value chosen for $\varepsilon$, but also on the point $x$ at which we are studying the function - hence the notation $\delta(x, \varepsilon)$. If it is possible to find some $\delta(\varepsilon)$ that for any given value of $\varepsilon$ will work for any $x$ in $A$, we say that the function is uniformly continuous on $A$. More formally, we have the following:

Definition 6.17. Uniformly continuous function. A function $f:(X, d) \longrightarrow$ $(Y, \rho)$ is uniformly continuous on a subset $A$ of $X$ if for all $x, y \in A$ and for any $\varepsilon>0$ there exists some number $\delta(\varepsilon)>0$, independent of $x$, such that

$$
d(x, y)<\delta(\varepsilon) \Rightarrow \rho[f(x), f(y)]<\varepsilon
$$

It is clear that uniform continuity on a set implies continuity on the same set, but the converse statement is not true.

## Lipschitz Functions

We now introduce a stronger notion of continuity that will be useful in Chapter 9.

Definition 6.18. Lipschitz and locally Lipschitz functions. Let $X$ and $Y$ be normed vector spaces, and $E$ a subset of $X$. A function $f: X \longrightarrow Y$ is said to be Lipschitz on $E$ if there exists a positive constant $K$ such that for all $x$ and $y$ in $E$ we have

$$
\|f(x)-f(y)\| \leq K\|x-y\|
$$

This condition is called a Lipschitz condition, and the constant $K$ is a Lipschitz constant for $f$ on $E$.

The function $f$ is said to be locally Lipschitz on the set $E$ if for each point $x_{0}$ in $E$ there exists some $\varepsilon>0$ and some $K_{0}>0$ such that $B_{\varepsilon}\left(x_{0}\right) \subseteq E$ and if for all $x$ and $y$ in $B_{\varepsilon}\left(x_{0}\right)$,

$$
\|f(x)-f(y)\| \leq K_{0}\|x-y\|
$$

Problem 6.19. Show that a Lipschitz function is uniformly continuous (and therefore continuous).

## Homeomorphisms

Definition 6.20. Homeomorphism. Let $(X, d)$ and $(Y, \rho)$ be metric spaces. A function $f: X \longrightarrow Y$ is called a homeomorphism if is one-to-one and continuous and its inverse function is continuous on $f(X)$.

That is, a homeomorphism is a continuous function with a continuous inverse. The continuity of $f$ implies that given two nearby points $x^{\prime}$ and $x^{\prime \prime}$ in $X$, their images $y^{\prime}=f\left(x^{\prime}\right)$ and $y^{\prime \prime}=f\left(x^{\prime \prime}\right)$ will also be close by. Given an arbitrary continuous function, however, it is possible that points that are far from each other will be mapped by the function into nearby points, or even into a single point. If $f$ is a homeomorphism, that is impossible, for the inverse relation is also a continuous function. Hence, given two points in $X$, their images under a homeomorphism are close to each other if and only if the points themselves are not far away. Using the characterization of continuity in terms of sequences and inverse images of open sets, we obtain the following characterization of homeomorphism:

Theorem 6.21. A one-to-one function $\mathrm{f}:(\mathrm{X}, \mathrm{d}) \longrightarrow(\mathrm{Y}, \mathrm{\rho})$ is a homeomorphism if and only if either of the following (equivalent) statements is true:

(i) For all $\mathrm{x} \in \mathrm{X}$, the sequence $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ converges to $\mathrm{x}$ in $(\mathrm{X}, \mathrm{d})$ if and only if the image sequence $\left\{\mathrm{f}\left(\mathrm{x}_{\mathrm{n}}\right)\right.$ \} converges to $\mathrm{f}(\mathrm{x})$ in $(\mathrm{Y}, \mathrm{\rho})$.

(ii) Given any open set $\mathrm{A}_{\mathrm{X}}$ in $(\mathrm{X}, \mathrm{d})$, its image $\mathrm{f}\left(\mathrm{A}_{\mathrm{X}}\right)$ is open in $(\mathrm{Y}, \mathrm{\rho})$, and given any set $\mathrm{A}_{\mathrm{Y}}$ open in $(\mathrm{Y}, \rho)$, its inverse image $\mathrm{f}^{-1}\left(\mathrm{~A}_{\mathrm{Y}}\right)$ is open in $(\mathrm{X}, \mathrm{d})$.

Two metric spaces $(X, d)$ and $(Y, \rho)$ are homeomorphic if and only if there exists some homeomorphism $h$ from $X$ onto $Y$ - that is, $Y=h(X)$ or $h^{-1}$ must be defined on the whole set $Y$. The relation "being homeomorphic to" is an equivalence relation on the set of all metric spaces. Intuitively, two homeomorphic metric spaces are identical except for a continuous change of coordinates that preserves convergence and open sets. For many purposes, two homeomorphic metric (or topological) spaces are in fact equivalent. Properties of sets that are invariant under homeomorphisms are known as topological properties.

## Some Properties of Continuous Real Functions

We will now establish some important properties of continuous real functions defined on an interval. In later sections we will see how they can be partially generalized to continuous functions defined on more general spaces.

In many applications, we are interested in finding the maximum (or minimum) of a real-valued function over some given set. In principle, however, a continuous function defined on an arbitrary set may not have a maximum. For the case of a continuous function from $\mathbb{R}$ to $\mathbb{R}$, we will show that a sufficient condition for the existence of a maximum over a set is that the set be a compact interval. We begin by showing that such a function must be bounded.

Theorem 6.22. Let $\mathrm{f}: \mathbb{R} \longrightarrow \mathbb{R}$ be defined and continuous on the closed and bounded interval [ $\mathrm{a}, \mathrm{b}]$. Then $\mathrm{f}$ is bounded on [ $\mathrm{a}, \mathrm{b}$ ]; that is, there exists some real number $\mathrm{M}$ such that $|\mathrm{f}(\mathrm{x})| \leq \mathrm{M}$ for all $\mathrm{x}$ in the interval.

Proof. We will show that if $f$ is both continuous and unbounded on the interval, we arrive at a contradiction. Suppose, for the sake of concreteness, that $f$ is not bounded above on $[a, b]$. Then, for each positive integer $n$, there exists a point $x_{n} \in[a, b]$ such that $f\left(x_{n}\right) \geq n$. By the Bolzano-Weierstrass theorem, the bounded sequence $\left\{x_{n}\right\}$ has a convergent subsequence $\left\{x_{n_{k}}\right\}$ with limit $x^{0}$. Because $[a, b]$ is a closed set, moreover, we have $x^{0} \in[a, b]$, by Theorem 4.13.

Now, by the continuity of $f$ at $x^{0}$,

$$
\begin{equation*}
\lim _{k \rightarrow \infty} f\left(x_{n_{k}}\right)=f\left(x^{0}\right) \tag{1}
\end{equation*}
$$

On the other hand, $\left\{x_{n_{k}}\right\}$ is a subsequence of $\left\{x_{n}\right\}$, and it must therefore be true that for each $k, f\left(x_{n_{k}}\right) \geq n_{k}>k$. Thus,

$$
\begin{equation*}
\lim _{k \rightarrow \infty} f\left(x_{n_{k}}\right)=\infty \tag{2}
\end{equation*}
$$

and we have reached a contradiction. If $f$ is continuous, it cannot be unbounded.

This result tells us that the set $\{f(x) ; x \in[a, b]\}$, being a nonempty and bounded set of real numbers, has a supremum (and an infimum). We will now show that the function also attains its supremum and infimum on the interval (i.e., it has both a maximum and a minimum on $[a, b]$ ).

Theorem 6.23. Extreme-value theorem. Let $\mathrm{f}$ be a continuous real-valued function on the closed and bounded interval [a, $\mathrm{b}$ ]. Then there exist points $\mathrm{x}_{\mathrm{M}}$ and $\mathrm{x}_{\mathrm{m}}$ in [a, $\mathrm{b}$ ] such that for all $\mathrm{x} \in[\mathrm{a}, \mathrm{b}], \mathrm{f}\left(\mathrm{x}_{\mathrm{m}}\right) \leq \mathrm{f}(\mathrm{x}) \leq \mathrm{f}\left(\mathrm{x}_{\mathrm{M}}\right)$.

Proof. We will prove the existence of a maximum. By Theorem 6.22 we know that $\mu=\sup _{x \in[a, b]} f(x)$ exists. We will now show that this value is achieved on the interval (i.e., $\exists x_{M} \in[a, b]$ such that $f\left(x_{M}\right)=\mu$ ).

Observe that no number smaller than $\mu$ is an upper bound of $\{f(x)$; $x \in[a, b]\}$. Hence, for each positive integer $n$, we can find some $x_{n} \in[a, b]$ such that

$$
\begin{equation*}
\left|f\left(x_{n}\right)-\mu\right|<1 / n \tag{1}
\end{equation*}
$$

The sequence $\left\{x_{n}\right\} \subseteq[a, b]$ thus constructed is bounded and therefore has a convergent subsequence $\left\{x_{n_{k}}\right\}$ by the Bolzano-Weierstrass theorem. Call the limit of this subsequence $x_{M}$, and observe that because $[a, b]$ is closed, $x_{M} \in[a, b]$ (Theorem 4.13). It remains to show that $f\left(x_{M}\right)=\mu$.

Now, because $\left\{x_{n_{k}}\right\} \rightarrow x_{M}$ and $f$ is continuous, we have $\left\{f\left(x_{n_{k}}\right)\right\} \rightarrow f\left(x_{M}\right)$, that is,

$$
\begin{equation*}
\forall \varepsilon>0, \exists N_{\varepsilon} \text { s.th. } n_{k}>N_{\varepsilon} \Rightarrow\left|f\left(x_{n_{k}}\right)-f\left(x_{M}\right)\right|<\varepsilon \tag{2}
\end{equation*}
$$

Next, by the triangle inequality, we can write

$$
\left|f\left(x_{M}\right)-\mu\right| \leq\left|f\left(x_{M}\right)-f\left(x_{n_{k}}\right)\right|+\left|f\left(x_{n_{k}}\right)-\mu\right|
$$

for any $n_{k}$. Now choose an arbitrary $\varepsilon>0$. Using (1) and (2), we have that for all $n_{k}$ greater than some $N_{\varepsilon}$,

$$
0 \leq\left|f\left(x_{M}\right)-\mu\right| \leq\left|f\left(x_{M}\right)-f\left(x_{n_{k}}\right)\right|+\left|f\left(x_{n_{k}}\right)-\mu\right|<\varepsilon+\frac{1}{n_{k}}
$$

Because this inequality must hold for all $\varepsilon>0$ and for arbitrarily large $n_{k}$, we conclude that $f\left(x_{M}\right)=\mu$.

Theorem 6.24. Intermediate-value theorem. Let $\mathrm{f}$ be a continuous real-valued function on the closed and bounded interval [a, $\mathrm{b}$ ]. Then for each number $\gamma$ (strictly) between $\mathrm{f}(\mathrm{a})$ and $\mathrm{f}(\mathrm{b})$, there exists a point $\mathrm{c} \in(\mathrm{a}, \mathrm{b})$ such that $\mathrm{f}(\mathrm{c})=\gamma$.

Proof. Assume, for concreteness, that $f(a)<\gamma<f(b)$, and let $c$ be given by

$$
c=\sup \{x \in[a, b] ; f(x) \leq \gamma\}
$$

That is, $c$ is roughly the largest number in the interval for which $f(x)$ is smaller than $\gamma$. Notice that the set $\{x \in[a, b] ; f(x) \leq \gamma\}$ is not empty, because it contains at least $a$, and it is bounded above by $b$. Hence, $c$ is well defined by the supremum property. Notice also that, by construction, $f(x)>\gamma$ for all $x>c$.

To establish that $f(c)=\gamma$, we will use the sign-preservation property of continuous real-valued functions (Problem 6.2) to show that both $f(c)>\gamma$ and $f(c)<\gamma$ lead to a contradiction. In particular, if $f(c)<\gamma$, then $c$ is not an

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-084.jpg?height=628&width=835&top_left_y=190&top_left_x=334)

Figure 2.10.

upper bound of $\{x \in[a, b] ; f(x) \leq \gamma\}$, for there exists some $\delta>0$ such that $f(c+\delta)<\gamma$ (Figure 2.10). Similarly, if $f(c)>\gamma$, then $c$ cannot be the least upper bound of the given set, for then there exists some $\delta^{\prime}>0$ such that $f(x)>\gamma$ for all $x \in(c-\delta, c)$, and therefore $c-\delta^{\prime}$ is a smaller upper bound for $\{x \in[a, b] ; f(x) \leq \gamma\}$ than $c$. Finally, because $f(a)<\gamma<f(b), c$ is neither of these points.

Problem 6.25. We will now give an alternative proof for the intermediatevalue theorem. Let $f$ be a real function of one variable defined and continuous on an interval $[a, b]$. Assume that $f(a)<0<f(b)$. To show that there exists some point $c$ in $(a, b)$ such that $f(c)=0$, we construct two sequences $\left\{l_{n}\right\}$ and $\left\{u_{n}\right\}$ in the following way:

1. Put $l_{1}=a$ and $u_{1}=b$.
2. For each $n$, let $m_{n}=\left(l_{n}+u_{n}\right) / 2$, and evaluate $f$ at $m_{n}$. Then

(a) if $f\left(m_{n}\right)>0$, put $l_{n+1}=l_{n} \quad$ and $u_{n+1}=m_{n}$,

(b) if $f\left(m_{n}\right)<0$, put $l_{n+1}=m_{n}$ and $u_{n+1}=u_{n}$, and

(c) if $f\left(m_{n}\right)=0$, stop.

(Draw a picture. What are we doing?) Using what we have learned about the limits of real sequences,

(i) prove that $\left\{l_{n}\right\}$ and $\left\{u_{n}\right\}$ converge, and call their limits $c^{\prime}$ and $c^{\prime \prime}$;

(ii) show that $c^{\prime}=c^{\prime \prime}$ (i.e., both sequences converge to the same limit).

Hint: Show that $\left\{u_{n}-l_{n}\right\} \rightarrow 0$. Call the common limit of the two sequences $c$. We want to show that this is the point we want.
(iii) Use the continuity of $f$ and the theorem on the preservation of inequalities to conclude that $f(c)=0$.

Theorem 6.26. Let $\mathrm{f}$ be a continuous real function on the closed and bounded interval $[\mathrm{a}, \mathrm{b}]$. Then $\mathrm{f}([\mathrm{a}, \mathrm{b}])$ is a closed interval.

Proof. By the extreme-value theorem, there exist points $x_{M}$ and $x_{m}$ in $[a, b]$ such that $f\left(x_{M}\right) \geq f(x)$ and $f\left(x_{m}\right) \leq f(x)$ for all $x \in[a, b]$. Put $M=f\left(x_{M}\right)$ and $m=f\left(x_{m}\right)$. Then both $m$ and $M$ belong to $f([a, b])$, and this set is contained in $[m, M]$. Let $y$ be any point in $[m, M]$; by the intermediate-value theorem, there is some $c_{y}$ in $(a, b)$ such that $f\left(c_{y}\right)=y$. Hence, any such $y$ is contained in $f([a, b])$, and the result follows.

## Monotonic Functions

Let $f: \mathbb{R} \longrightarrow \mathbb{R}$ be defined on some interval $I=(a, b)$. We say that $f$ is monotonically increasing if for any two points $x$ and $y$ in $I, x>y$ implies $f(x) \geq f(y)$, and monotonically decreasing if the second inequality is reversed. A function is monotonic in a given interval if it is either increasing or decreasing in it.

We will show that monotonic functions have one-sided limits at all points in the interior of their domain and are continuous almost everywhere.

Theorem 6.27. Let $\mathrm{f}$ be monotonically increasing on (a, b). Then the onesided limits

$$
\mathrm{f}\left(\mathrm{x}^{+}\right)=\lim _{\mathrm{y} \rightarrow \mathrm{x}^{+}} \mathrm{f}(\mathrm{y}) \text { and } \mathrm{f}\left(\mathrm{x}^{-}\right)=\lim _{\mathrm{y} \rightarrow \mathrm{x}^{-}} \mathrm{f}(\mathrm{y})
$$

exist at every point $\mathrm{x}$ of (a, b), and moreover,

$$
\begin{equation*}
\sup \{\mathrm{f}(\mathrm{s}) ; \mathrm{a}<\mathrm{s}<\mathrm{x}\}=\mathrm{f}\left(\mathrm{x}^{-}\right) \leq \mathrm{f}(\mathrm{x}) \leq \mathrm{f}\left(\mathrm{x}^{+}\right)=\inf \{\mathrm{f}(\mathrm{s}) ; \mathrm{x}<\mathrm{s}<\mathrm{b}\} \tag{1}
\end{equation*}
$$

Furthermore, for any $\mathrm{x}$ and $\mathrm{y}$ in $(\mathrm{a}, \mathrm{b})$, with $\mathrm{x}<\mathrm{y}$, we have

$$
\begin{equation*}
f\left(x^{+}\right) \leq f\left(x^{-}\right) \tag{2}
\end{equation*}
$$

Proof. Observe that the set $\{f(s) ; a<s<x\}$ is bounded above by $f(x)$ and therefore has a supremum that we will call $\mu$. Clearly, $\mu \leq f(x)$. We want to show that $\mu$ is the limit of $f$ as we approach $x$ from the left, that is, that given any $\varepsilon>0$, there exists some $\delta>0$ such that

$$
|f(y)-\mu|<\varepsilon \quad \text { for all } y \in(x-\delta, x)
$$

For this, fix an arbitrary $\varepsilon>0$. Because $\mu$ is the least upper bound of $\{f(s)$; $a<s<x\}, \mu-\varepsilon$ is not an upper bound, and therefore there exists some $z \in(a, x)$ such that

$$
\mu \geq f(z)>\mu-\varepsilon
$$

Because $f$ is increasing, moreover,

$$
\mu-\varepsilon<f(z) \leq f(y) \leq \mu<\mu+\varepsilon \text { for every } y \in(z, x)
$$

and it follows that

$$
|f(y)-\mu|<\varepsilon \quad \text { for all } y \in(z, x)
$$

which is the first half of (1). The other half follows by the same reasoning.

Next, given two points $x$ and $y$, with $x<y$, we have, by (1) and the monotonicity of the function, that

$$
f\left(x^{+}\right)=\inf \{f(s) ; x<s<b\}=\inf \{f(s) ; x<s<y\}
$$

and

$$
f\left(y^{-}\right)=\sup \{f(s) ; a<s<y\}=\sup \{f(s) ; x<s<y\}
$$

Comparing these expressions, we conclude that $f\left(x^{+}\right) \leq f\left(y^{-}\right)$.

Theorem 6.28. Let $\mathrm{f}$ be monotonic on (a, b). Then the set of points of (a, b) at which $f$ is discontinuous is at most countable.

Proof. Suppose, for concreteness, that $f$ is increasing, and let $D$ be the set of points at which $f$ is discontinuous. With each $x \in D$ we can associate a rational number $r(x)$ such that

$$
f\left(x^{-}\right)<r(x)<f\left(x^{+}\right)
$$

Because $x_{1}<x_{2}$ implies $f\left(x_{1}^{+}\right) \leq f\left(x_{2}^{-}\right)$, we have that $r\left(x_{1}\right) \neq r\left(x_{2}\right)$ if $x_{1} \neq x_{2}$. Hence, we have established a one-to-one correspondence between the set $D$ and a subset of the rational numbers. Because the latter set is countable, so is $D$.

## 7. Complete Metric Spaces and the Contraction Mapping Theorem

Suppose we would like to know whether or not a given sequence $\left\{x_{n}\right\}$ in a metric space converges. If we proceed by applying the definition of convergence given in Section 2, we have to start by guessing what the limit of the sequence is. This is often difficult and frequently inconvenient, for we may want to define an object as the limit of a sequence, and we may be interested in its properties under conditions that are too general to allow a specific limit to be computed. Hence, it would be useful to develop convergence criteria that would not require us to guess the limit.

In this section we will show that in a certain class of spaces, known as complete spaces, convergence can be established by studying the behavior of the terms of a sequence, without specific reference to its limit. In these spaces, moreover, we have available an important fixed-point theorem (the contraction mapping theorem) that is useful in establishing the existence and uniqueness of solutions to certain types of equations that arise frequently in applications.

## (a) Cauchy Sequences and Complete Metric Spaces

Definition 7.1. Cauchy convergence. A sequence $\left\{x_{n}\right\}$ in a metric space $(X, d)$ is convergent in the sense of Cauchy (or is a Cauchy sequence, or, simply, "is Cauchy") if

$$
\forall \varepsilon>0, \exists N(\varepsilon) \text { s.th. } \forall m, n>N(\varepsilon), d\left(x_{m}, x_{n}\right)<\varepsilon
$$

That is, a sequence is Cauchy if its terms get closer and closer to each other. Intuitively, it is obvious that if the terms of a sequence are getting closer and closer to a limit, they will also be getting progressively closer to each other. At first sight, it would seem that this should also work the other way around, for if all the terms of a sequence beyond a certain order can be made to fit inside a ball of arbitrarily small radius, then the sequence must surely converge. However, the two concepts of convergence are not exactly equivalent. Given a metric space $(X, d)$, it is true that every convergent sequence is Cauchy, but the converse statement is not true. Speaking loosely, the reason is that a Cauchy sequence may approach a limit "outside $X$ " if this set has "holes" in it or does not contain its boundary. There is, however, an important class of metric spaces in which the two notions of convergence are equivalent. These are the so-called complete metric spaces. More formally, we have the following:

Theorem 7.2. Every convergent sequence in a metric space is Cauchy.

Proof. Let $(X, d)$ be a metric space, and $\left\{x_{n}\right\}$ a convergent sequence in $X$ with limit $x \in X$. Fix some arbitrary $\varepsilon>0$; then, by the convergence of $\left\{x_{n}\right\}$, there exists some integer $N(\varepsilon / 2)$ such that

$$
\begin{equation*}
\forall n>N(\varepsilon / 2), d\left(x_{n}, x\right)<\varepsilon / 2 \tag{1}
\end{equation*}
$$

Take any two terms of the sequence $x_{p}, x_{q}$ with $p, q>N(\varepsilon / 2)$; by the triangle inequality and (1), we have

$$
d\left(x_{p}, x_{q}\right) \leq d\left(x_{p}, x\right)+d\left(x, x_{q}\right)<\varepsilon
$$

That is, given that $\left\{x_{n}\right\}$ converges to $x$, all terms of the sequence of a sufficiently high order will be close to the limit $x$, and therefore not far from each other. Hence the sequence is Cauchy.

In general, the converse statement is false in an arbitrary metric space. Spaces in which it does hold are said to be "complete."

Definition 7.3. Complete metric space and Banach space. A metric space $(X, d)$ is complete if every Cauchy sequence contained in $X$ converges to some point $x$ in $X$.

A normed vector space that is complete (in its natural metric) is called a Banach space.

Example 7.4. A sequence of rational numbers may have an irrational limit. Hence, $\mathbb{Q}$ is not complete (see Problem 3.20).

Consider the metric space formed by $X=(0,1]$ with the usual metric. The sequence $x_{n}=1 / n$ has limit 0 , which is not in the interval. Hence, this space is not complete. If we add the point $\{0\}$ to obtain the closed interval $[0,1]$, however, the resulting metric space is complete.

Theorem 7.5. Every Cauchy sequence is bounded.

## Problem 7.6. Prove Theorem 7.5.

Problem 7.7. Prove that the sequence $\left\{x_{n}\right\}$ defined in Problem 3.20 is Cauchy. (Use the results from parts (ii) and (iii) of problem 3.20. An argument similar to the one used in the proof of the contraction mapping theorem in the next section will work.) Notice that the sequence $\left\{x_{n}\right\}$ converges in $\mathbb{R}$ (we know $\mathbb{R}$ is complete), but not in $\mathbb{Q}$ (which is not complete).

Theorem 7.8. Let $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ be a Cauchy sequence in a metric space. If $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ has a convergent subsequence with limit $\mathrm{x}^{0}$, then the sequence itself converges to $\mathrm{x}^{0}$.

Proof. Let $\left\{x_{n}\right\}$ be a Cauchy sequence in a metric space, and assume that $\left\{x_{n}\right\}$ has a convergent subsequence $\left\{x_{n_{k}}\right\}$ with limit $x^{0}$. We want to show that $\left\{x_{n}\right\} \rightarrow x^{0}$. The intuition is very simple: Because $\left\{x_{n_{k}}\right\} \rightarrow x^{0}$, all terms of the subsequence $\left\{x_{n_{k}}\right\}$ of sufficiently high order will be close to $x^{0}$; but because $\left\{x_{n}\right\}$ is Cauchy, all terms sufficiently far along in the sequence, even those not in $\left\{x_{n_{k}}\right\}$, cannot be very far from $x^{0}$.

Fix an arbitrary $\varepsilon>0$; because $\left\{x_{n}\right\}$ is Cauchy, there is a positive integer $N_{1}(\varepsilon / 2)$ such that

$$
\begin{equation*}
\forall m, n>N_{1}(\varepsilon / 2), d\left(x_{m}, x_{n}\right)<\varepsilon / 2 \tag{1}
\end{equation*}
$$

and given that $\left\{x_{n_{k}}\right\} \rightarrow x^{0}$, for the same $\varepsilon / 2$ there exists some $N_{2}(\varepsilon / 2)$ such that

$$
\begin{equation*}
\forall n_{k}>N_{2}(\varepsilon / 2), d\left(x_{n_{k}}, x^{0}\right)<\varepsilon / 2 \tag{2}
\end{equation*}
$$

Putting $N \equiv \max \left\{N_{1}, N_{2}\right\}$, (1) and (2) hold simultaneously for any $n>N$, and we have

$$
\begin{equation*}
\forall m, n_{k}>N, d\left(x_{m}, x_{n_{k}}\right)<\varepsilon / 2 \text { and } d\left(x_{n_{k}}, x^{0}\right)<\varepsilon / 2 \tag{3}
\end{equation*}
$$

Using (3) and the triangle inequality, we have, for the given $\varepsilon$ and any $m>N$,

$$
d\left(x_{m}, x^{0}\right) \leq d\left(x_{m}, x_{n_{k}}\right)+d\left(x_{n_{k}}, x^{0}\right)<\varepsilon
$$

for any $n_{k}>N$. This proves the theorem: Notice that $x_{m}$ is any term of sufficiently higher order in $\left\{x_{n}\right\}$ and need not be a term of the subsequence $\left\{x_{n_{k}}\right\}$

Example 7.4 suggests that there may be a connection between complete sets and closed sets. The following result establishes this connection.

Theorem 7.9. Let (X, d) be a complete metric space, and $\mathrm{Y}$ a subset of $\mathrm{X}$. Then $(\mathrm{Y}, \mathrm{d})$ is complete if and only if it is closed.

Proof. Let $\left\{x_{n}\right\}$ be a Cauchy sequence in a closed subset $Y$ of $X$. By the assumption that $(X, d)$ is complete, $\left\{x_{n}\right\}$ converges to a point $x$ in $X$. Because $Y$ is closed and contains the sequence, it must also contain the limit (Theorem 4.13). Hence $Y$ is complete.

If $Y$ is complete, every Cauchy sequence contained in $Y$ converges to a limit in $Y$. Being Cauchy (Theorem 7.2), every convergent sequence in $Y$ has its limit in $Y$, which is therefore closed.

We will now show that every finite-dimensional Euclidean space is complete. The first step - establishing the completeness of $\mathbb{R}$ with the usual metric - is immediate, given some previous results. The extension to $E^{m}$ then follows easily by the equivalence between convergence in $E^{m}$ and convergence of the coordinate sequences in $\mathbb{R}$.

Theorem 7.10. The set $\mathbb{R}$ of the real numbers is complete with the usual metric.

Proof. We want to show that every Cauchy sequence $\left\{x_{n}\right\}$ in $\mathbb{R}$ converges to a real limit. By Theorem 7.5, every such sequence is bounded. Hence, by the Bolzano-Weierstrass theorem, $\left\{x_{n}\right\}$ has a convergent subsequence $\left\{x_{n_{k}}\right\}$ with limit $x$ in $\mathbb{R}$. By Theorem 7.8, "the whole sequence" converges to $x$, and the theorem follows.

Theorem 7.11. Any finite-dimensional Euclidean space $\mathrm{E}^{\mathrm{m}}=\left(\mathbb{R}^{\mathrm{m}}, \mathrm{d}_{\mathrm{E}}\right)$ is complete.

Proof. Let $\left\{x_{k}\right\}$, with $x_{k}=\left(x_{k}^{1}, x_{k}^{2}, \ldots, x_{k}^{m}\right) \in \mathbb{R}^{\mathrm{m}}$, be a Cauchy sequence. For any $\varepsilon>0$, there exists some positive integer $N(\varepsilon)$ such that

$$
\forall p, q>N(\varepsilon), d_{E}\left(x_{p}, x_{q}\right)=\sqrt{\sum_{i=1}^{m}\left(x_{p}^{i}-x_{q}^{i}\right)^{2}}<\varepsilon
$$

It follows that for any $j=1, \ldots, m$,

$$
\left|x_{p}^{j}-x_{q}^{j}\right|=\sqrt{\left(x_{p}^{j}-x_{q}^{j}\right)^{2}} \leq \sqrt{\sum_{i=1}^{m}\left(x_{p}^{i}-x_{q}^{i}\right)^{2}}<\varepsilon
$$

Hence, every component sequence $\left\{x_{k}^{i}\right\}$ is a Cauchy sequence in $\mathbb{R}$.

By the completeness of $\mathbb{R}$, each one of these sequences has a real limit, say $\left\{x_{k}^{j}\right\} \rightarrow x^{j}$. Define $x$ as the vector whose components are the limits of these $m$ real sequences, $x=\left(x^{1}, \ldots, x^{m}\right)$. We have seen (Theorem 3.10) that convergence in $E^{m}$ is equivalent to convergence component by component; hence, $x \in \mathbb{R}^{\mathrm{m}}$ is the limit of the vector sequence $\left\{x_{k}\right\}$. This shows that every Cauchy sequence in $E^{m}$ converges to a point in $\mathbb{R}^{m}$.

Let $C(X)$ be the space of bounded, continuous real-valued functions defined on a set $X$ in $\mathbb{R}^{\mathrm{n}}$. It is easy to show that this set, endowed with the sup norm defined by

$$
\begin{equation*}
\|f\|_{s}=\sup \{\mid f(x) ; ; x \in X\} \tag{1}
\end{equation*}
$$

is a normed vector space. The following theorem shows that this normed space is complete. This result will be useful in Chapters 9 and 12 .

Theorem 7.12. Given a set $\mathrm{X}$ in $\mathbb{R}^{n}$, let $\mathrm{C}(\mathrm{X})$ be the set of bounded continuous functions $\mathrm{f}: \mathrm{X} \longrightarrow \mathbb{R}$, with the sup norm defined by (1). Then $\left[\mathrm{C}(\mathrm{X}),\|\cdot\|_{\mathrm{s}}\right]$ is a complete normed vector space.

Proof. We know already that $\left[C(X),\|\cdot\|_{s}\right]$ is a normed vector space. To prove completeness, we need to show that every Cauchy sequence $\left\{f_{n}\right\}$ of bounded continuous functions converges in the sup norm. We will proceed in three steps: First, we construct a "candidate" function $f()$ for the limit of
the sequence; second, we verify that this function is bounded and continuous; third, we show that $\left\{f_{n}\right\} \rightarrow f$ in the sup norm.

- Given a Cauchy sequence of bounded continuous functions $\left\{f_{n}\right\}$, take some $x$ in $X$ and consider the sequence of real numbers $\left\{f_{n}(x)\right\}$. Note that given any positive integers $m$ and $n$, we have

$$
\left|f_{m}(x)-f_{n}(x)\right| \leq \sup \left\{\left|f_{m}(y)-f_{n}(y)\right| ; y \in X\right\} \equiv\left\|f_{m}-f_{n}\right\|_{s}
$$

Because $\left\{f_{n}\right\}$ is a Cauchy sequence, by choosing $m$ and $n$ high enough we can make $\left|f_{m}(x)-f_{n}(x)\right|$ arbitrarily small for any $x$. Hence, $\left\{f_{n}(x)\right\}$ is a Cauchy sequence of real numbers for any $x$, and because $\mathbb{R}$ is complete with the usual metric, $\left\{f_{n}(x)\right\}$ converges to some (finite) real limit, say $f(x)$.

We can therefore construct a function $f$ that assigns to each $x$ in $X$ the limit $f(x)$ of the sequence of real numbers $\left\{f_{n}(x)\right\}$. This function, which is bounded by construction, will be our candidate for the limit of the sequence of functions $\left\{f_{n}\right\}$.

- To establish the continuity of $f$, fix an arbitrary point $x$ in $X$ and some $\varepsilon>0$. Because $\left\{f_{n}\right\} \rightarrow f$ in the sup norm, there exists a positive integer $N_{1}$ such that $\left\|f-f_{n}\right\|_{s}<\varepsilon / 3$ for all $n>N_{1}$. Hence,

$$
\begin{equation*}
\left|f_{n}(x)-f(x)\right| \leq \sup _{y}\left|f(y)-f_{n}(y)\right| \equiv\left\|f-f_{n}\right\|_{s}<\varepsilon / 3 \tag{1}
\end{equation*}
$$

for any $x$ and all $n>N_{1}$. Moreover, because $f_{n}$ is continuous, there is some $\delta_{1}>0$ such that for the given $x$,

$$
\begin{equation*}
\left|f_{n}(x)-f_{n}(y)\right|<\varepsilon / 3 \text { for all } y \text { such that }\|x-y\|_{E}<\delta_{1} \tag{2}
\end{equation*}
$$

where $\|\cdot\|_{E}$ is the Euclidean norm in $\mathbb{R}^{\mathrm{n}}$. Using (1), (2), and the triangle inequality, the continuity of $f$ at $x$ follows: For any $y \in B_{\delta_{1}}(x)$, and choosing $n>N_{1}$, we have

$$
\begin{aligned}
& |f(x)-f(y)| \leq\left|f(x)-f_{n}(x)\right|+\left|f_{n}(x)-f_{n}(y)\right|+\left|f_{n}(y)-f(y)\right| \\
& \quad \leq\left\|f-f_{n}\right\|_{s}+\left|f_{n}(x)-f_{n}(y)\right|+\left\|f-f_{n}\right\|_{s}<\varepsilon
\end{aligned}
$$

- Finally, we will show that $\left\|f-f_{n}\right\|_{s} \rightarrow 0$ as $n \rightarrow \infty$. Fix some $\varepsilon>0$ and note that because $\left\{f_{n}\right\}$ is Cauchy, there is some $N_{2}$ such that

$$
\begin{equation*}
\left\|f_{n}-f_{m}\right\|_{s}<\varepsilon / 2 \text { for all } m, n>N_{2} \tag{3}
\end{equation*}
$$

By (3) and the triangle inequality, given any $x$ in $X$, we have

$$
\begin{aligned}
& \left|f_{n}(x)-f(x)\right| \leq\left|f_{n}(x)-f_{m}(x)\right|+\left|f_{m}(x)-f(x)\right| \leq\left\|f_{n}-f_{m}\right\|+\left|f_{m}(x)-f(x)\right| \\
& \quad<\varepsilon / 2+\left|f_{m}(x)-f(x)\right|
\end{aligned}
$$

for all $m, n>N_{2}$. Moreover, because $\left\{f_{m}(x)\right\} \rightarrow f(x)$, we can choose $m$ (separately for each $x$ if need be) so that $\left|f_{m}(x)-f(x)\right|<\varepsilon / 2$. Hence, $N_{2}$ is such that given any $n>N_{2}$,

$$
\left|f_{n}(x)-f(x)\right|<\varepsilon \text { for all } x \text { in } X
$$

Thus, for $n$ sufficiently high, $\varepsilon$ is an upper bound for $\left\{\left|f_{n}(x)-f(x)\right| ; x \in X\right\}$, and because $\left\|f_{n}-f\right\|_{s}$ is the smallest such upper bound, we conclude that $\left\|f_{n}-f\right\|_{s} \leq \varepsilon$ for all $n>N_{2}$, that is, $\left\{f_{n}\right\} \rightarrow f$.

## (b) Operators and the Contraction Mapping Theorem

A function $T: X \longrightarrow X$ from a metric space to itself is cometimes called an operator. We say that an operator is a contraction if its application to any two points of $X$ brings them closer to each other. More formally, we have the following definition:

Definition 7.13. Contraction. Let $(X, d)$ be a metric space, and $T: X \longrightarrow X$ an operator in it. We say that $T$ is a contraction of modulus $B$ if for some $\beta \in(0,1)$ we have this: $\forall x, y \in X, d(T x, T y) \leq \beta d(x, y)$. The notation $T x$ is sometimes used instead of $T(x)$.

Theorem 7.14. Every contraction is a continuous mapping.

Proof. Let $T$ be a contraction on $(X, d)$. We want to show that

$$
\forall \varepsilon>0, \exists \delta>0 \text { s.th. } d(x, y)<\delta \Rightarrow d(T x, T y)<\varepsilon
$$

As $T$ is a contraction, we have that for all $x, y \in X$ and some $\beta \in(0,1)$,

$$
d(T x, T y) \leq \beta d(x, y)
$$

Given some $\varepsilon$, choose $\delta$ so that $\delta \leq \varepsilon / \beta$; then the definition of continuity is satisfied, because

$$
d(T x, T y) \leq \beta d(x, y)<\beta \delta \leq \varepsilon
$$

Example 7.15. Let $f:[a, b] \longrightarrow[a, b]$ be a continuous function with positive slope always smaller than 1 . Then $f$ is a contraction, because $(f(y)-f(x)) /(y-x) \leq \beta<1$. Figure 2.11 suggests that no matter how we draw it, $f$ must cut the $45^{\circ}$ line, that is, it must have at least one fixed point $z$ such that $f(z)=z$.

Take any point $x_{0}$ in $[a, b]$ and define a sequence $\left\{x_{n}\left(x_{0}\right)\right\}$ recursively by

$$
x_{1}=f\left(x_{0}\right), x_{2}=f\left(x_{1}\right), \ldots, x_{n+1}=f\left(x_{n}\right)
$$

Graphically, the sequence is constructed as follows: Given the initial value $x_{0}$, we use the graph of the function to find the value of $x_{1}$; then we use the $45^{\circ}$ line to project $x_{1}$ onto the horizontal axis, we go up again to

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-093.jpg?height=736&width=1049&top_left_y=190&top_left_x=216)

Figure 2.11. A contraction mapping.

the graph of $f$ to find $x_{2}$, and so on. The figure suggests that no matter where we choose the initial point $x_{0}$ in $[a, b]$, the sequence converges to the fixed point $z$.

The following theorem says that this result can be generalized to any contraction defined on a complete metric space.

Theorem 7.16. Contraction mapping theorem. Let (X, d) be a complete metric space, and $\mathrm{T}: \mathrm{X} \longrightarrow \mathrm{X}$ a contraction with modulus $\beta<1$. Then

(i) T has precisely one fixed point $\mathrm{x}^{*}$ in $\mathrm{X}$ (i.e., $\exists$ ! $\mathrm{x}^{*} \in \mathrm{X}$ s.th. $\mathrm{Tx}^{*}=\mathrm{x}^{*}$ ), and

(ii) the sequence $\left\{\mathrm{x}_{\mathrm{n}}\left(\mathrm{x}_{0}\right)\right\}$, defined by

$$
\mathbf{x}_{1}=\mathbf{T} \mathbf{x}_{0}, \mathbf{x}_{2}=\mathbf{T} \mathbf{x}_{1}, \ldots, \mathbf{x}_{\mathrm{n}+1}=\mathbf{T} \mathbf{x}_{\mathrm{n}}
$$

converges to $\mathrm{x}^{*}$ for any starting point $\mathrm{x}_{0}$ in $\mathrm{X}$.

Proof

- Existence: Take an arbitrary point $x_{0}$ in $X$ and define the sequence $\left\{x_{n}\left(x_{0}\right)\right\}$ by

$$
x_{1}=T x_{0}, x_{2}=T x_{1}, \ldots, x_{n+1}=T x_{n}
$$

We will first show that this sequence is Cauchy. Then, given that $(X, d)$ is a complete metric space, the sequence converges to a point $x^{*}$ in $X$. We will then show that $x^{*}$ is a fixed point of $T$.

By using the definition of contraction repeatedly, we see that the distance between two successive terms of the sequence $\left\{x_{n}\left(x_{0}\right)\right\}$ is bounded and decreasing in $n$ :

$$
\begin{align*}
d\left(x_{n+1}, x_{n}\right)= & d\left(T x_{n}, T x_{n-1}\right) \leq \beta d\left(x_{n}, x_{n-1}\right) \\
= & \beta d\left(T x_{n-1}, T x_{n-2}\right) \leq \beta^{2} d\left(x_{n-1}, x_{n-2}\right) \\
& \leq \ldots \leq \beta^{n} d\left(x_{1}, x_{0}\right) \tag{1}
\end{align*}
$$

Next, consider the distance between two arbitrary terms of the sequence, $x_{m}$ and $x_{n}$, with $m<n$. Using the triangle inequality,

$$
\begin{align*}
d\left(x_{n}, x_{m}\right) & \leq \sum_{i=m}^{n-1} d\left(x_{i+1}, x_{i}\right) \quad[\text { by }(1)] \\
& \leq \sum_{i=m}^{n-1} \beta^{i} d\left(x_{1}, x_{0}\right)=\beta^{m} d\left(x_{1}, x_{0}\right) \sum_{i=0}^{n-m-1} \beta^{i} \\
& \leq \beta^{m} d\left(x_{1}, x_{0}\right) \sum_{i=0}^{\infty} \beta^{i}=\frac{\beta^{m}}{1-\beta} d\left(x_{1}, x_{0}\right) \tag{2}
\end{align*}
$$

Because $\beta<1, \beta^{m} /(1-\beta) \rightarrow 0$ as $m \rightarrow \infty$. It follows that, given an arbitrary $\varepsilon>0$, we can choose $m$ and $n$ sufficiently large that $d\left(x_{m}, x_{n}\right)<\varepsilon$; hence, $\left\{x_{n}\left(x_{0}\right)\right\}$ is Cauchy for any $x_{0}$, and given that $(X, d)$ is complete by assumption, every such sequence will have a limit in $X$. Take one such point and call it $x^{*}$.

Next, we show that $x^{*}$ is a fixed point of $T$. Being a contraction, $T$ is continuous. Hence we can "take the limit out of the function" and write

$$
T\left(x^{*}\right)=T\left(\lim _{n \rightarrow \infty} x_{n}\right)=\lim _{n \rightarrow \infty} T\left(x_{n}\right)=\lim _{n \rightarrow \infty} x_{n+1}=x^{*}
$$

- Uniqueness: Nothing we have said so far implies uniqueness. It remains to show that $x^{*}$ is independent of the choice of the initial point $x_{0}$ or, equivalently, that there is only one fixed point of $T$. We will prove that if $T$ has two fixed points, they must be equal.

Assume that $x^{\prime}$ and $x^{\prime \prime}$ are both fixed points of $T$ (i.e., $T x^{\prime}=x^{\prime}$ and $T x^{\prime \prime}=x^{\prime \prime}$ ). Because $T$ is a contraction, we have, for some $\beta \in(0,1)$,

$$
d\left(x^{\prime}, x^{\prime \prime}\right)=d\left(T x^{\prime}, T x^{\prime \prime}\right) \leq B d\left(x^{\prime}, x^{\prime \prime}\right)
$$

Because $\beta<1$, this can hold only if $d\left(x^{\prime}, x^{\prime \prime}\right)=0$ (i.e., if $x^{\prime}=x^{\prime \prime}$ ), for otherwise we would arrive at

$$
d\left(x^{\prime}, x^{\prime \prime}\right)<d\left(x^{\prime}, x^{\prime \prime}\right)
$$

a contradication.

The following exercise generalizes this result. It is not necessary that $T$ itself be a contraction; it is enough that its $n$th iteration $\left(T^{n}\right)$ be a contraction for $T$ to have precisely one fixed point. $T^{n}$ is defined recursively by

$$
T^{2} x=T(T x), T^{3} x=T[T(T x)]=T\left(T^{2} x\right), \ldots, T^{n+1} x=T\left(T^{n} x\right)
$$

Problem 7.17. Let $(X, d)$ be a complete metric space, and $T: X \longrightarrow X$ a function whose $n$th iteration $T^{n}$ is a contraction. Show that $T$ has a unique fixed point.

The contraction mapping theorem is a very useful result. It can be used to prove the existence and uniqueness of solutions to several types of equations, including differential equations and some functional equations that arise in connection with dynamic-optimization problems. Moreover, the second part of the theorem suggests a method (the method of successive approximations) for calculating solutions to equations that can be written in the form $T x=x$, where $T$ is a contraction: Beginning with a convenient trial solution, we construct a sequence $\left\{x_{n}\right\}$ recursively with $x_{n+1}=T x_{n}$. If we can find the limit of the sequence, we will also have found the solution to the equation. Otherwise, we can approximate the solution to any desired degree of accuracy by computing sufficiently many terms of the sequence. $^{9}$

The following theorem says, loosely speaking, that if a continuity condition holds, we can do comparative statics with fixed points of contractions.

Theorem 7.18. Continuous dependence of the fixed point on parameters. Let $(\mathrm{X}, \mathrm{d})$ and $(\Omega, \mathrm{\rho})$ be two metric spaces, and $\mathrm{T}(\mathrm{x}, \alpha)$ a function $\mathrm{X} \times \Omega \longrightarrow \mathrm{X}$ If $(\mathrm{X}, \mathrm{d})$ is complete, if $\mathrm{f}$ is continuous in $\alpha$, and if for each $\alpha \in \Omega$ the function $\mathrm{T}_{\alpha}$, defined by $\mathrm{T}_{\alpha}(\mathrm{x})=\mathrm{T}(\mathrm{x}, \alpha)$ for each $\mathrm{x} \in \mathrm{X}$, is a contraction, then the solution function $\mathrm{z}: \Omega \longrightarrow \mathrm{X}$, with $\mathrm{x}^{*}=\mathrm{z}(\alpha)$, which gives the fixed point as $a$ function of the parameters, is continuous.

Proof. Consider a convergent sequence of parameter values, $\left\{\alpha_{n}\right\} \rightarrow \alpha$. To establish the continuity of $z$, it is sufficient to show that

$$
\begin{equation*}
d\left[z\left(\alpha_{n}\right), z(\alpha)\right] \rightarrow 0 \quad \text { as }\left\{\alpha_{n}\right\} \rightarrow \alpha \tag{1}
\end{equation*}
$$

By definition, the function $z$ satisfies the identity $T_{\alpha} z(\alpha) \equiv z(\alpha)$ for any $\alpha$. Using this expression in (1), we have

$$
\begin{aligned}
d\left[z\left(\alpha_{n}\right), z(\alpha)\right] & =d\left[T_{\alpha_{n}} z\left(\alpha_{n}\right), T_{\alpha} z(\alpha)\right] \quad \text { (by the triangle inequality) } \\
& \leq d\left[T_{\alpha_{n}} z\left(\alpha_{n}\right), T_{\alpha_{n}} z(\alpha)\right]+d\left[T_{\alpha_{n}} z(\alpha), T_{\alpha} z(\alpha)\right] \\
& \leq B d\left[z\left(\alpha_{n}\right), z(\alpha)\right]+d\left[T_{\alpha_{n}} z(\alpha), T_{\alpha} z(\alpha)\right]
\end{aligned}
$$

where the second inequality uses the assumption that $T_{\alpha_{n}}$ is a contraction, with modulus $B_{n} \leq B \in(0,1)$. Thus,

$$
d\left[z\left(\alpha_{n}\right), z(\alpha)\right] \leq \beta d\left[z\left(\alpha_{n}\right), z(\alpha)\right]+d\left[T_{\alpha_{n}} z(\alpha), T_{\alpha} z(\alpha)\right]
$$

from where

$$
d\left[z\left(\alpha_{n}\right), z(\alpha)\right] \leq \frac{1}{1-\beta} d\left[T_{\alpha_{n}} z(\alpha), T_{\alpha} z(\alpha)\right]
$$

Now, $T$ is continuous in $\alpha$, so the right-hand side of this expression goes to zero as $\left\{\alpha_{n}\right\} \rightarrow \alpha$. Hence, (1) holds, and $z()$ is continuous.

Recall that given a complete metric space $(X, d)$ and a closed subset $C$ of $X,(C, d)$ is also a complete metric space (Theorem 7.9). Now suppose that $T: X \longrightarrow X$ is a contraction and maps $C$ into itself (i.e., if $x \in C$, then $T x \in C$ ). In that case, $T$ is a contraction on $C$, and the unique fixed point of $T$ in $X$ must lie in $C$. Sometimes this observation allows us to establish certain properties of a fixed point by applying the contraction mapping theorem twice - first in a "large" space $X$ to establish existence, and then again in a closed subset of $X$ in order to show that the fixed point has certain properties. For example, if $(X, d)$ is the space of continuous real and bounded functions with the sup norm (see Section 1), then the subset of $X$ formed by nondecreasing functions is closed. Hence, if a contraction $T$ in $(X, d)$ maps nondecreasing functions into nondecreasing functions, the fixed point of $T$ will be a nondecreasing function.

It is not always easy to determine whether or not a given function is a contraction. The following theorem, due to Blackwell, gives sufficient conditions for an operator in a useful function space to be a contraction. The advantage of this result is that in some economic applications, Blackwell's conditions are very easy to verify.

Theorem 7.19. Blackwell's sufficient conditions for a contraction. Let $\mathrm{B}\left(\mathbb{R}^{n}\right.$, $\mathbb{R})$ be the set of bounded functions $\mathrm{f}: \mathbb{R}^{n} \rightarrow \mathbb{R}$, with the sup norm. If an operator $\mathrm{T}: \mathrm{B}\left(\mathbb{R}^{n}, \mathbb{R}\right) \longrightarrow \mathrm{B}\left(\mathbb{R}^{n}, \mathbb{R}\right)$ satisfies the two conditions

(i) monotonicity: $\forall \mathrm{f}, \mathrm{g} \in \mathrm{B}\left(\mathbb{R}^{\mathrm{n}}, \mathbb{R}\right), \mathrm{f}(\mathrm{x}) \leq \mathrm{g}(\mathrm{x}) \forall \mathrm{x} \Rightarrow \operatorname{Tf}(\mathrm{x}) \leq \operatorname{Tg}(\mathrm{x}) \forall \mathrm{x}$,

(ii) discounting: $\exists \beta \in(0,1)$ s.th. $\forall \mathrm{f} \in \mathrm{B}\left(\mathbb{R}^{n}, \mathbb{R}\right), \mathrm{x} \in \mathbb{R}^{n}$, and $\alpha \geq 0$, we have $\mathrm{T}[\mathrm{f}(\mathrm{x})+\alpha] \leq \mathrm{T} / \mathrm{f}(\mathrm{x})]+\beta \alpha$

then $T$ is a contraction.

Proof. For any $f, g \in B\left(\mathbb{R}^{\mathbf{n}}, \mathbb{R}\right)$, we have

$$
f=g+(f-g) \leq g+\|f-g\|
$$

By assumptions (i) and (ii),

$$
T f \leq T(g+\|f-g\|) \leq T g+\beta\|f-g\| \Rightarrow T f-T g \leq \beta\|f-g\|
$$

Interchanging the roles of $f$ and $g$, we obtain, by the same logic,

$$
T g \leq T(f+\|g-f\|) \leq T f+\beta\|g-f\| \Rightarrow T f-T g \geq-\beta\|f-g\|
$$

Combining the two inequalities, we obtain the desired result:

$$
\|T f-T g\| \leq \beta\|f-g\|
$$

## 8. Compactness and the Extreme-Value Theorem

Let $f$ be a real-valued function defined on some set in a metric space. A problem that frequently arises is that of finding the element of $A$ that will maximize or minimize $f$. In order to guarantee that such a point exists, certain restrictions have to be placed on both the function and the set. For example, we have seen that if $f$ is a function from a set of real numbers $A$ to $\mathbb{R}$, a sufficient condition for the existence of a maximum is that $f$ be continuous and $A$ be a closed and bounded interval. One of the purposes of this section is to extend this result on continuous functions to more general sets. This brings us to the study of compactness.

## (a) Compactness and Some Characterizations

To introduce the notion of compactness, we need some terminology.

Definition 8.1. Cover and open cover. A collection of sets $\mathbb{U}=\left\{U_{i} ; i \in I\right\}$ in a metric space $(X, d)$ is a cover of the set $A$ if $A$ is contained in its union, that is, if $A \subseteq \cup_{i \in I} U_{i}$. If all the sets $U_{i}$ are open, the collection $\mathbb{U}$ is said to be an open cover of $A$.

Definition 8.2. Compact set. A set $A$ in a metric space is compact if every open cover of $A$ has a finite subcover. That is, $A$ is compact if given any open cover $\mathbb{U}=\left\{U_{i} ; i \in I\right\}$ of it, we can find a finite subset of $\mathbb{U},\left\{U_{1}, \ldots, U_{n}\right\}$, that still covers $A$.

Notice that the definition does not say that a set is compact if it has a finite open cover. In fact, every set in a metric space $(X, d)$ has a finite open cover, for the universal set $X$ is open and covers any set in the space.

Example 8.3. $(0,1)$ is not compact. The collection of open intervals $(1 / n, 1)$ for $n \geq 2$ is an open cover of $(0,1)$ because given any $x$ in $(0,1)$, there exists an integer $n$ such that $n>1 / x$, and hence $x \in(1 / n, 1)$. Thus, $(0,1)=\cup_{n=2}^{\infty}(1 / n, 1)$. However, no finite subcollection $\left\{\left(1 / n_{1}, 1\right), \ldots\right.$, $\left(1 / n_{k}, 1\right)$ ) will suffice to cover $(0,1)$, for the union of these sets is $(1 / N, 1)$,
where $N:=\max _{1 \leq i<k} n_{i}$, and given any $N$ there is some strictly positive real number $x$ with $x<1 / N$.

A necessary prerequisite for the existence of a maximum of a function over a set is that the function be bounded on the set. To motivate the foregoing definition (i.e., to try to understand why sets with such strange properties may be useful), consider how we might go about extending the result given in Theorem 6.20 on the boundedness of a continuous function defined over an interval $[a, b]$ to a larger class of sets in an arbitrary metric space.

We begin by observing that a continuous function is locally bounded. Let $f: A \subseteq X \longrightarrow \mathbb{R}$ be continuous, and consider an arbitrary point $a$ in $A$. Then, by the definition of continuity (with $\varepsilon=1$ ), there exists a positive real number $\delta(a)$ (which depends both on the point chosen and on the particular function $f$ we are working with) such that $|f(x)-f(a)|<1$ for all $x \in B_{\delta(a)}(a)$. Hence, $f$ is bounded in $B_{\delta(a)}(a)$ by $K_{a}=|f(a)|+1$.

Now consider what happens when we try to extend this local boundedness property to the whole set $A$. The question is whether or not the continuity of $f$ is sufficient to guarantee the existence of a bound $K$ that will work for all $x$ in $A$ (for the given function). It is tempting to try to define $K$ as the maximum of the $K_{a}$ 's over all points $a$ in $A$, but that will not work in general, for there may be infinitely many such $K_{a}^{\prime}$ 's, and the set of such numbers may not have an upper bound. Notice, however, that the collection of open balls $\left\{B_{\delta(a)}(a)\right\}$ for all $a \in A$ is an open cover of $A$. If $A$ is a compact set, there is a finite collection of such balls, $\left\{B_{\delta\left(a_{1}\right)}\left(a_{1}\right), \ldots, B_{\delta\left(a_{n}\right)}\left(a_{n}\right)\right\}$, that contains all points of $A$. In this case, the maximum of the (finite) set formed by the corresponding local bounds $\left\{K_{a_{1}}, \ldots, K_{a_{n}}\right\}$ is well defined and provides a global bound for the function on the set.

In conclusion, compactness allows us to replace an arbitrary open cover with a finite one. In some cases this is enough of a substitute for finiteness as to allow us to extend to infinite sets some properties that hold trivially in finite ones.

It is not always easy to work directly with the definition of compactness. In the remainder of this section we will develop some characterizations of compactness that frequently are more useful than our original definition. The first of these, known as sequential compactness, is valid in metric spaces, but not necessarily in more general topological spaces.

Definition 8.4. Sequential compactness. A set $A$ in a metric space is sequentially compact if every sequence of elements of $A$ has a convergent subsequence whose limit lies in $A$.

We will now show that compactness and sequential compactness (which is essentially the Bolzano-Weierstrass property) are equivalent in metric spaces. The first half of the equivalence is easily established.

Theorem 8.5. A compact set in a metric space is sequentially compact.

Proof. We will prove the contrapositive statement (a set $A$ in a metric space that is not sequentially compact cannot be compact) by constructing an open cover of $A$ with no finite subcover. If $A$ is not sequentially compact, there is a sequence $\left\{x_{n}\right\}$ of points of $A$ with the property that none of its subsequences converges to a point in $A$. Hence, no point of $A$ is the limit of a subsequence of $\left\{x_{n}\right\}$, and it follows that for every $x$ in $A$ there exists an open ball $B_{\varepsilon(x)}(x)$ that contains only a finite number of elements of $\left\{x_{n}\right\}$. The family $\mathbb{B}=\left\{B_{\varepsilon(x)}(x) ; x \in A\right\}$ is an open cover of $A$. However, no finite subfamily of $\mathbb{B}$ can cover $\left\{x_{n}\right\}$ (and therefore $A$ ), for any such family will contain only a finite number of terms of $\left\{x_{n}\right\}$. Hence, $A$ is not compact.

The converse result takes a bit more work. We begin with some definitions.

Definition 8.6. $\varepsilon$-net and totally bounded set. Given some $\varepsilon>0$ and a set $A$ in a metric space $(X, d)$, an $\varepsilon$-net for $A$ is a set of points $E$ in $X$ such that

$$
A \subseteq \cup_{x \in E} B_{\varepsilon}(x)
$$

A set $A$ in $(X, d)$ is totally bounded if it has a finite $\varepsilon$-net for any $\varepsilon>0$.

That is, a set is totally bounded if it can be covered by a finite number of balls of arbitrarily small radius. Clearly, a totally bounded set is necessarily bounded, but the converse need not be true.

Definition 8.7. Lebesgue number for an open cover. Let $A$ be a set in a metric space, and let $\mathbb{U}$ be an open cover of $A$. We say that a fixed real number $\varepsilon>0$ is a Lebesgue number for $\mathbb{U}$ if for every $x$ in $A$ there exists a set $U(x)$ in $\mathbb{U}$ such that $B_{\varepsilon}(x) \subseteq U(x)$.

Hence, if $\mathbb{U}$ has a Lebesgue number, we can "replace" it with an open cover formed by balls of constant radius, which is often more convenient. Notice that if this "ball cover" has a finite subcover, so does the original one.

Example 8.8. Notice that an open cover may not have a Lebesgue number. As in the previous example, put $A=(0,1)$ and consider the open cover
$\mathbb{U}=\{(1 / n, 1) ; n \geq 2\}$. For any given $\varepsilon>0$, choose $x<\varepsilon$; then $B_{\varepsilon}(x)=(0, x+\varepsilon)$ is not contained in $(1 / n, 1)$ for any $n$.

Theorem 8.9. A sequentially compact set in a metric space is totally bounded.

Proof. We will show that if a set $A$ is not totally bounded, then it cannot be sequentially compact - that is, if for some $\varepsilon>0$ there is no finite $\varepsilon$-net for $A$, we can construct a sequence $\left\{x_{n}\right\}$ in $A$ with no convergent subsequence.

Take any $x_{1}$ in $A$, and let $U_{1}=B_{\varepsilon}\left(x_{1}\right)$. By assumption, $B_{1}$ does not cover $A$, so there is some $x_{2} \in A$, with $x_{2} \notin U_{1}$. Let $U_{2}=B_{\varepsilon}\left(x_{2}\right)$; then $\left\{U_{1}, U_{2}\right\}$ is still not a cover of $A$, and therefore there is some $x_{3} \in A$, with $x_{3} \notin U_{1} \cup U_{2}$. Put $U_{3}=B_{\varepsilon}\left(x_{3}\right), \ldots$, and so forth. By continuing in this fashion, we can construct a sequence $\left\{x_{n}\right\}$ with the property that $d\left(x_{n}, x_{m}\right) \geq \varepsilon$ for all $n$ and $m$, as each new term of the sequence is chosen outside all the $\varepsilon$-balls centered at the previous terms. Clearly, this sequence has no Cauchy subsequences and therefore no convergent subsequences either.

Theorem 8.10. Any open cover of a sequentially compact set in a metric space has a Lebesgue number.

Proof. Let $A$ be a set in a metric space $(X, d)$ with an open cover $\mathbb{U}$. If $\mathbb{U}$ has no Lebesgue number, then for every $\varepsilon>0$ there exists some point $x$ in $A$ such that no set $U$ in $\mathbb{U}$ contains $B_{\varepsilon}(x)$. In particular, for each integer $n$, we can find some point $x_{n}$ in $A$ such that $B_{1 / n}\left(x_{n}\right)$ is not contained in any $U \in \mathbb{U}$. We will show that if $A$ is sequentially compact, no sequence in $A$ can have this property. Hence, given sequential compactness of $A$, a Lebesgue number must exist for any open cover of it (or else we have a contradiction).

By the sequential compactness of $A$, any sequence $\left\{x_{n}\right\}$ of points in $A$ contains a convergent subsequence $\left\{x_{n_{k}}\right\}$ with limit $x \in A$. Because $\mathbb{U}$ covers $A$, $x \in U_{0}$ for some $U_{0} \in \mathbb{U}$, and because $U_{0}$ is open, there exists some integer $m$ such that $B_{2 / m}(x) \subseteq U_{0}$. We will show that $B_{1 / n}\left(x_{n}\right) \subseteq U_{0}$ for some terms in the sequence by exploiting the fact that we can bring $\left\{x_{n_{k}}\right\}$ arbitrarily close to $x$ and make $B_{1 / n_{k}}\left(x_{n_{k}}\right)$ arbitrarily small.

By the convergence of $\left\{x_{n_{k}}\right\}$ to $x$, there is some $N$ such that

$$
x_{n_{k}} \in B_{1 / m}(x) \text { for all } n_{k}>N
$$

Choose $n_{k}>\max \{N, m\}$, and observe that for any point $y$ in $B_{1 / n_{k}}\left(x_{n_{k}}\right)$ we have

$$
d(y, x) \leq d\left(y, x_{n_{k}}\right)+d\left(x_{n_{k}}, x\right)<\frac{1}{n_{k}}+\frac{1}{m}<\frac{1}{m}+\frac{1}{m}=\frac{2}{m}
$$

Hence, for $n_{k}$ sufficiently high, we have $y \in B_{2 / m}(x)$, but then

$$
B_{1 / n_{k}}\left(x_{n_{k}}\right) \subseteq B_{2 / m}(x) \subseteq U_{0}
$$

contradicting the nonexistence of a Lebesgue number.

We can now prove that sequential compactness implies compactness in a metric space.

Theorem 8.11. Any sequentially compact set in a metric space is compact.

Proof. Let $\mathbb{U}$ be an arbitrary open cover of a sequentially compact set $A$ in a metric space. By Theorem 8.10, U has a Lebesgue number $\varepsilon$, and by Theorem 8.9 there exists a finite $\varepsilon$-net (for the same $\varepsilon$ ) $\left\{x_{1}, \ldots, x_{n}\right\}$ for $A$. For each $i=1, \ldots, n$ there is some $U_{i} \in \mathbb{U}$ such that $B_{\varepsilon}\left(x_{i}\right) \subseteq U_{i}$, by the definition of Lebesgue number. Because $A \subseteq \cup_{i=1}^{n} B_{\varepsilon}\left(x_{i}\right) \subseteq \cup_{i=1}^{n} U_{i}$, U has a finite subcover $\left\{U_{1}, \ldots, U_{n}\right\}$.

We will now provide an alternative characterization of compactness in terms of a property of families of closed sets.

Definition 8.12. The finite-intersection property. A nonempty family of sets $\mathbb{A}=\left\{A_{i} ; i \in I\right\}$ has the finite-intersection property if every (nonempty) finite subfamily of $\mathbb{A}$ has a nonempty intersection.

Theorem 8.13. A set $\mathrm{C}$ in a metric (or topological) space (X, d) is compact if and only if every family of closed subsets of $\mathrm{X}$ that has the finiteintersection property has a nonempty intersection.

## Proof

- Suppose $C$ is compact. To show that any family of closed subsets that has the finite-intersection property has a nonempty intersection, we will prove the following equivalent (contrapositive) statement: Let $\mathbb{A}=\left\{A_{i} ; i \in I\right\}$ be a family of closed subsets of $C$ with the property that $\cap \mathbb{A}=\cap_{i \in I} A_{i}=\varnothing$; then there exists some finite subfamily of $\mathbb{A}$ with an empty intersection - that is, there exists some finite set $J \subseteq I$ such that $\cap_{i \in J} A_{i}=\varnothing$.

For each $i$, let $U_{i}=\sim A_{i}$ be the complement of the closed set $A_{i}$. Then each $U_{i}$ is an open set, and we can write, using De Morgan's laws (Theorem 1.2 in Chapter 1),

$$
C \subseteq X=\sim \varnothing=\sim\left(\cap_{i \in I} A_{i}\right)=\cup_{i \in I}\left(\sim A_{i}\right)=\cup_{i \in I} U_{t}
$$

Hence, $\left\{U_{i} ; i \in I\right\}$ is an open cover of $C$. Because $C$ is compact, $\left\{U_{i} ; i \in I\right\}$ contains a finite subcover of $C$. That is, there exists a finite set $J \subseteq I$ such that

$$
C \subseteq \cup_{i \in, l} U_{i}
$$

which implies that

$$
\begin{equation*}
\cap_{i \in J} A_{t}=\sim\left(\cup_{i \in J} U_{i}\right) \subseteq \sim C \tag{1}
\end{equation*}
$$

On the other hand, because each $A_{i}$ is a subset of $C$, so is their intersection; hence, we have

$$
\begin{equation*}
\cap_{i \in J} A_{i} \subseteq C \tag{2}
\end{equation*}
$$

Combining (1) and (2), we conclude that $\cap_{i \in, J} A_{i}=\varnothing$, which establishes the desired result.

- For the converse, assume that $C$ has the property that if the intersection of any family of closed subsets of $C$ is empty, then the intersection of some finite subfamily of them is empty (we are using the contrapositive again). Let $\mathbb{U}=\left\{U_{i} ; i \in I\right\}$ be an arbitrary open cover of $C$, so that

$$
C \subseteq \cup_{i \in I} U_{i}
$$

and observe that this implies that

$$
\begin{equation*}
\sim\left(\cup_{i \in I} U_{i}\right) \subseteq \sim C \tag{1}
\end{equation*}
$$

Next, let

$$
A_{i}=C \cap\left(\sim U_{i}\right)
$$

for each $i$. Using (1) and De Morgan's laws, we have

$$
\cap_{i \in I} A_{i}=\cap_{i \in I}\left(C \cap\left(\sim U_{i}\right)\right)=C \cap\left(\cap_{i \in I}\left(\sim U_{i}\right)\right)=C \cap\left(\sim\left(\cup_{i \in I} U_{i}\right)\right) \subseteq C \cap(\sim C)=\varnothing
$$

Hence, $\mathbb{A}=\left\{A_{i} ; i \in I\right\}$ is a family of closed subsets of $C$ whose intersection is empty. By assumption, there exists some finite subfamily of $\mathbb{A}$ with an empty intersection; that is, there exists some finite set $J \subseteq I$ such that $\cap_{i \in J} A_{i}=\varnothing$, and it follows that

$$
\cap_{i \in J} A_{i}=\cap_{i \in J}\left(C \cap\left(\sim U_{i}\right)\right)=C \cap\left(\cap_{i \in J}\left(\sim U_{i}\right)\right)=C \cap\left(\sim\left(\cup_{i \in J} U_{i}\right)\right)=\varnothing
$$

This implies that $C$ is contained in $\cup_{i \in J} U_{i}$. Hence, $\left\{U_{i} ; i \in J\right\}$ is a finite subcover of $\left\{U_{i} ; i \in I\right\}$, and we conclude that $C$ is compact.

## (b) Relationships with Other Topological Properties

In metric spaces, compactness is closely related to other topological properties, namely, closedness, completeness, and boundedness. In this section we spell out some of the interconnections among these properties.

Theorem 8.14. Any closed subset of a compact space is compact.

Proof. Given a metric space $(X, d)$, let $X$ be compact, and consider a closed subset $C$ of $X$. Let $\mathbb{U}=\left\{U_{i} ; i \in I\right\}$ be an arbitrary open cover of $C$. Because $C$
is closed, its complement $C^{c}$ is open, and $\left\{U_{i} ; i \in I\right\} \cup C^{c}$ is an open cover of $X$. As $X$ is compact, this cover has a finite subcover $\left\{U_{1}, \ldots, U_{n}\right\} \cup C^{c}$. Then $\left\{U_{1}, \ldots, U_{n}\right\}$ is a finite subcover of $C$, which is therefore compact.

Theorem 8.15. A compact set in a metric space is closed.

(This result may not hold in more general topological spaces.)

Proof. Let $A$ be a compact set in a metric space $(X, d)$. We will prove that $A$ is closed by showing that it contains all its limit points. Let $x_{L}$ be an arbitrary limit point of $A$; by Theorem 4.11 there exists a sequence $\left\{x_{n}\right\}$ of points of $A$ with limit $x_{L}$. By the (sequential) compactness of $A,\left\{x_{n}\right\}$ has a convergent subsequence with limit in $A$. By the uniqueness of the limit (see Problem 2.5), $x_{L}$ is the limit of the subsequence and must therefore lie in $A$.

Theorem 8.16. A set in a metric space is compact if and only if is complete and totally bounded.

Proof. We have already seen that a compact set is totally bounded. The proof that compactness implies completeness is left as an exercise. We now prove the converse implication (i.e., that a complete and totally bounded set in a metric space is compact).

Let $C$ be complete and totally bounded. To establish (sequential) compactness, we need to show that any sequence $\left\{x_{n}\right\}$ in $C$ has a subsequence converging to a point in $C$. And because we are assuming completeness, it is enough to show that given any sequence in $C$, we can produce a Cauchy subsequence, for completeness will then guarantee convergence.

Let $\left\{x_{n}\right\}$ be an arbitrary sequence in $C$. Because $C$ is totally bounded, it can be covered by a finite number of balls of radius 1 (a 1-net). Among these balls, there must be one, say $B_{1}$, that contains infinitely many terms of the sequence. These infinitely many points of the original sequence form a new sequence that we call $\left\{x_{n}^{1}\right\}$. Next, we can cover $B_{1}$ with a finite number of balls of radius $1 / 2$, and among these balls there must be one, say $B_{2}$, such that $B_{1} \cap B_{2}$ contains an infinite number of points of $\left\{x_{n}^{1}\right\}$, forming a new sequence $\left\{x_{n}^{2}\right\}$. Continuing in this fashion, we obtain a sequence $\left\{B_{i}\right\}$ of balls with radius $1 / i$ such that $B_{1} \cap B_{2} \cap \ldots \cap B_{i}$ contains infinitely many terms of the original sequence, yielding a new sequence $\left\{x_{n}^{i}\right\}$.

Consider now a "cross-sequence" $\left\{x_{k}^{k}\right\}$ formed by taking one element of each of these sequences (i.e., the $k$ th term of $\left\{x_{k}^{k}\right\}$ is taken from $\left\{x_{n}^{k}\right\}$ ). We observe that, by construction,

$$
x_{k}^{k} \in B_{1} \cap B_{2} \cap \ldots \cap B_{k} \text { for each } k
$$

Hence, given any positive integers $p$ and $q$, with $p<q$, the terms $x_{p}^{p}$ and $x_{q}^{q}$ of $\left\{x_{k}^{k}\right\}$ are contained in the ball $B_{p}$ (of radius $1 / p$ ), and therefore

$$
d\left(x_{p}^{p}, x_{q}^{q}\right)<2 / p
$$

Hence, the subsequence $\left\{x_{k}^{k}\right\}$ is Cauchy: By taking $p$ high enough, we can force all remaining terms of the sequence to fit inside a ball of arbitrarily small radius. By completeness, $\left\{x_{k}^{k}\right\}$ converges to a point in $C$. Hence, we have shown that an arbitrary sequence in $C$ must contain a convergent subsequence with limit in $C$, thus establishing the sequential compactness of the set.

Problem 8.17. Show that a compact set in a metric space is complete.

Problem 8.18. Let $A$ be a compact set, and let $\left\{A_{n}\right\}$ be a "decreasing sequence" of nonempty closed subsets of $A$ such that $A_{n+1} \subseteq A_{n}$. Show that $\cup_{n=1}^{\infty} A_{n}$ is not empty.

From Theorems 8.9 and 8.15, we know that a compact set in a metric space is closed and bounded. The following result tells us that the converse is true for sets of real numbers, thereby establishing an important characterization of compact sets in $\mathbb{R}$ as those that are closed and bounded.

Theorem 8.19. Heine-Borel. Any closed and bounded set of real numbers is compact.

Proof. Note that any bounded set of real numbers must be contained in a closed interval $[a, b]$ with finite end points. Because we know that any closed subset of a compact set is compact, we need only show that $[a, b]$ is compact. By the Bolzano-Weierstrass theorem, any sequence contained in this (bounded) set contains a convergent subsequence, and because $[a, b]$ is closed, the subsequence converges to a point in the interval (Theorem 4.13), establishing sequential compactness (see Problem 3.4).

This result can be easily extended to any finite-dimensional Euclidean space.

Theorem 8.20. Any closed and bounded subset of $\mathbb{R}^{m}$ is compact.

Proof. Let $A$ be a closed and bounded set in $\mathbb{R}^{\mathrm{m}}$. Then there exists some number $M$ such that $\|x\|_{E} \leq M$ for all $x$ in $A$. Hence, $A$ is contained in the cube of side $M$ given by

$$
C_{m}=I \times I \times \ldots \times I, \quad \text { where } I=[-M, M]
$$

As in the previous theorem, it is enough to show that $C_{m}$ is compact, for the closedness of $A$ then guarantees its compactness.

To simplify notation, let $m=2$ (i.e., we will be working in the plane $\mathbb{R}^{2}$ ), and consider $C_{2}=I \times I=[-M, M] \times[-M, M]$ and an arbitrary sequence $\left\{x_{n}\right\}$ in this set, with $x_{n}=\left(x_{n}^{1}, x_{n}^{2}\right)$. Observe that $\left\{x_{n}^{1}\right\}$ and $\left\{x_{n}^{2}\right\}$ are bounded sequences of real numbers contained in the compact set $I=[-M, M]$. By the Heine-Borel theorem, $\left\{x_{n}^{1}\right\}$ has a subsequence $\left\{x_{n_{k}}^{1}\right\}$ convergent to a limit $x^{1}$ in $I$, and the corresponding subsequence of $\left\{x_{n}^{2}\right\},\left\{x_{n_{k}}^{2}\right\}$, has a convergent subsequence $\left\{x_{n_{k}}^{2}\right\}$ with limit $x^{2}$ in $I$. Putting $x_{n_{k_{j}}}=\left(x_{n_{k},}^{1}, x_{n_{k}}^{2}\right)$, it is clear that (by the equivalence between convergence in $E^{2}$ and coordinate-wise convergence in $\mathbb{R}$ )

$$
\left\{x_{n_{k_{j}}}\right\} \rightarrow\left(x^{1}, x^{2}\right) \in I \times I
$$

that is, $\left\{x_{n}\right\}$ has a convergent subsequence with limit in $C_{2}$, which establishes the sequential compactness of $C_{2}$ and therefore of any closed and bounded set in the plane. The argument can be easily extended to any finitedimensional Euclidean space. More generally, it can be shown that a finite product of compact sets is compact (in the sup metric).

(c) Continuous Functions on Compact Sets

Theorem 8.21. Let $(\mathrm{X}, \mathrm{d})$ and $(\mathrm{Y}, \mathrm{\rho})$ be metric spaces, and $\mathrm{f}: \mathrm{X} \rightarrow \mathrm{Y}$ a continuous function. If $\mathrm{C}$ is a compact set in $(\mathrm{X}, \mathrm{d})$, its image $\mathrm{f}(\mathrm{C})$ is compact in $(\mathrm{Y}, \mathrm{\rho})$.

Proof. Let $\left\{y_{n}\right\}$ be an arbitrary sequence in $f(C)$, and consider a companion sequence formed by points $x_{n}$ in $C$ such that $f\left(x_{n}\right)=y_{n}$. By the sequential compactness of $C,\left\{x_{n}\right\}$ has a convergent subsequence, say $\left\{x_{n_{k}}\right\}$, with limit $x$ in $C$. Then, by the continuity of $f$,

$$
\lim _{k \rightarrow \infty} y_{n_{k}}=\lim _{k \rightarrow \infty} f\left(x_{n_{k}}\right)=f\left(\lim _{k \rightarrow \infty} x_{n_{k}}\right)=f(x) \in f(C)
$$

Hence, $\left\{y_{n}\right\}$ has a subsequence $\left\{y_{n_{k}}\right\}$ that converges to a limit in $f(C)$. This establishes the sequential compactness of $f(C)$.

In the case of a real-valued function, the theorem says that the continuous image of a compact set is a compact interval or a collection of them. Because any such set of real numbers contains both its supremum and its infimum, we have the following important corollary:

Theorem 8.22. Extreme value (Weierstrass). Let $\mathrm{C}$ be a compact set in a metric space, and $\mathrm{f}: \mathrm{C} \longrightarrow \mathbb{R}$ a continuous function. Then $\mathrm{f}$ is bounded in $\mathrm{C}$ and attains both its maximum and its minimum in the set. That is, there exist points $\mathrm{x}_{\mathrm{M}}$ and $\mathrm{x}_{\mathrm{m}}$ in $\mathrm{C}$ such that

$$
f\left(x_{M}\right)=\sup f(C) \text { and } f\left(x_{m}\right)=\inf f(C)
$$

Proof. We will prove the existence of a maximum. By the previous theorem, $f(C)$ is a compact set of real numbers and therefore is closed and bounded. Let $\beta$ be its supremum. Then $\beta$ is a limit point of $f(C)$. (Why? $\beta-1 / n$ is not an upper bound for $f(C)$ ). Because $f(C)$ is closed, it follows that $\beta$ is contained in it, that is, there exists some point $x_{M}$ in $C$ such that $\beta=f\left(x_{M}\right)$.

Problem 8.23. Give an alternative proof for Theorem 8.21 using directly the definition of compactness. (Let $\left\{U_{i} ; i \in I\right\}$ be an open cover of $f(C)$.)

Theorem 8.24. Let (X, d) and (Y, $\mathrm{\rho})$ be metric spaces, with $\mathrm{f}: \mathrm{X} \longrightarrow \mathrm{Y}$ a continuous function, and $\mathrm{C}$ a compact set in $(\mathrm{X}, \mathrm{d})$. Then $\mathrm{f}$ is uniformly continuous on $\mathrm{C}$.

Proof. Let $\varepsilon>0$ be given. Because $f$ is continuous, for each point $x$ in $C$ we can find a positive number $\delta(x)$ such that

$$
\begin{equation*}
d(x, y)<\delta(x) \Rightarrow \rho[f(x), f(y)]<\varepsilon / 2 \tag{1}
\end{equation*}
$$

For each $x \in C$, let $B(x)$ be the set of all points $y$ in $C$ for which $d(x, y)<$ $\delta(x) / 2$. The collection of all such $B(x)$ 's (one for each point in $C$ ) is an open cover of $C$, and because $C$ is compact, there is a finite collection of points in $C$, say $\left\{x_{1}, \ldots, x_{n}\right\}$, such that

$$
\begin{equation*}
C \subseteq B\left(x_{1}\right) \cup \ldots \cup B\left(x_{n}\right) \tag{2}
\end{equation*}
$$

Put

$$
\delta=\frac{\min \left\{\delta\left(x_{1}\right), \ldots, \delta\left(x_{n}\right)\right\}}{2}
$$

and observe that $\delta>0$ because this is a finite collection of positive numbers (this is why we need compactness, it guarantees that we can find a finite subcover; note that the infimum of an infinite collection of positive numbers may be zero).

Let $x$ and $y$ be points in $C$ such that $d(x, y)<\delta$. By (2), there is some point $x_{m}$ such that $x \in B\left(x_{m}\right)$, and hence

$$
\begin{equation*}
d\left(x, x_{m}\right)<\frac{\delta\left(x_{m}\right)}{2} \tag{3}
\end{equation*}
$$

Moreover,

$$
\begin{equation*}
d\left(y, x_{m}\right) \leq d(y, x)+d\left(x, x_{m}\right)<\delta+\frac{\delta\left(x_{m}\right)}{2} \leq \delta\left(x_{m}\right) \tag{4}
\end{equation*}
$$

Hence, both $x$ and $y$ are sufficiently close to $x_{m}$ that we can use (1) to conclude that

$$
\rho[f(y), f(x)] \leq \rho\left[f(y), f\left(x_{m}\right)\right]+\rho\left[f\left(x_{m}\right), f(x)\right]<\varepsilon
$$

A similar argument will yield the following result.

Theorem 8.25. Show that if a function is locally Lipschitz on a compact set, then it is Lipschitz on the set (see Definition 6.18).

Problem 8.26. Compactness of the product space. Let $\left(X, d_{1}\right)$ and $\left(Y, d_{2}\right)$ be metric spaces, and consider the product space $\left(Z=X \times Y, d_{\pi}\right)$, with the product metric $d_{\pi}$ defined by

$$
\begin{equation*}
d_{\pi}\left(z, z^{\prime}\right)=d_{\pi}\left[(x, y),\left(x^{\prime}, y^{\prime}\right)\right]=\sqrt{\left[d_{1}\left(x, x^{\prime}\right)\right]^{2}+\left[d_{2}\left(y, y^{\prime}\right)\right]^{2}} \tag{1}
\end{equation*}
$$

Show that the product space $\left(Z=X \times Y, d_{\pi}\right)$ is compact if and only if both $\left(X, d_{1}\right)$ and $\left(Y, d_{2}\right)$ are compact.

## 9. Connected Sets

A set is said to be connected if it consists of a single piece (i.e., if it is not made up of two or more "separate components"). The following definition makes this idea more precise.

Definition 9.1. Separated and connected sets. Two sets $A$ and $B$ in a metric space are said to be separated if both $A \cap \bar{B}$ and $\bar{A} \cap B$ are empty (i.e., if neither set has a point lying in the closure of the other). A set $C$ in a metric space is said to be connected if it is not the union of two nonempty separated sets.

Notice that the condition for two sets to be separated is stronger than disjointedness but weaker than the requirement that the distance between them be strictly positive. Thus, the intervals $(-1,0]$ and $(0,1)$ are disjoint but not separated, because 0 lies in one interval and in the closure of the other.

The intervals $(-1,0)$ and $(0,1)$, however, are separated, but the distance between them is zero.

Connected sets on the real line have a particularly simple structure. As shown in our next result, the connected sets in $\mathbb{R}$ are precisely the intervals.

Theorem 9.2. A set $\mathrm{S}$ of real numbers is connected if and only if is an interval.

Proof. Recall that a set $I$ of real numbers is an interval if whenever $x$ and $y$ are in $I$, any real number $z$, with $x<z<y$, also lies in $I$ (Problem 6.14 in Chapter 1).

- We first show that a set of real numbers that is not an interval is not connected. Let $S$ be such a set. Then there exist real numbers $x$ and $y$ in $S$ and $z \notin S$ such that $x<z<y$, and we can write $S$ as the union of two components, as follows:

$$
S=S_{1} \cup S_{2} \equiv[S \cap(-\infty, z)] \cup[S \cap(z, \infty)]
$$

Notice that neither of these sets is empty, because $S_{1}$ contains at least $x$, and $S_{2}$ contains at least $y$. Moreover, $S_{1}$ and $S_{2}$ are separated, because $S_{1} \subseteq(-\infty, z)$ and $S_{2} \subseteq(z, \infty)$, and these intervals are separated (neither of them contains the only common boundary point, $z$ ). Hence $S$ is not connected.

- To show that every interval is connected, we show that a nonconnected set cannot be an interval. Let $E$ be a nonconnected set of real numbers. Then there exist nonempty separated sets $A$ and $B$ such that $A \cup B=E$. Pick $a \in A$ and $b \in B$, and assume (relabeling the sets if necessary) that $a<b$, as in Figure 2.12. To establish that $E$ is not an interval, we will show that there is some real number $x \notin E$ with $a<x<b$.

We define

$$
x=\sup \{A \cap[a, b]\}
$$

Then (see Problem 4.15) we have $x \in \bar{A}$ and (because $A$ and $B$ are separated) $x \notin B$. Moreover, we have $a \leq x<b$. There are now two possibilities. If $x \notin A$, then we have found the desired number, for then $a<x<b$ and $x \notin E$. If $x \in A$, on the other hand, we have $x \notin \bar{B}$ (because $A$ and $B$ are separated), and it follows that $x$ lies in the open set $\mathbb{R} \sim \bar{B}$. Hence, we can find some other point $x^{\prime}$ in this set (and therefore not in $B$ ) such that $a \leq x<x^{\prime}<b$. This establishes the desired result.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-108.jpg?height=119&width=898&top_left_y=1998&top_left_x=289)

Figure 2.12.

Our next result says that continuous functions preserve connectedness. Hence, one way to establish the connectedness of a set is by showing that it is the continuous image of another set that is known to be connected.

Theorem 9.3. Let $\mathrm{f}: \mathrm{X} \longrightarrow \mathrm{Y}$ be a continuous mapping between two metric spaces. If $\mathrm{C}$ is a connected subset of $\mathrm{X}$, then $\mathrm{f}(\mathrm{C})$ is connected.

Proof. We will prove the contrapositive statement: If $f(C)$ is not connected, then neither is $C$. Suppose $f(C)$ is not connected. Then $f(C)=P \cup Q$, where $P$ and $Q$ are nonempty, separated subsets of $Y$, that is,

$$
\bar{P} \cap Q=\varnothing \text { and } \bar{Q} \cap P=\varnothing
$$

Let

$$
A=C \cap f^{-1}(P) \text { and } B=C \cap f^{-1}(Q)
$$

and notice that then

$$
C=A \cup B
$$

where neither $A$ nor $B$ is empty, and

$$
f(A)=P \quad \text { and } \quad f(B)=Q
$$

as illustrated in Figure 2.13.

Because $P \subseteq \bar{P}$ (where $\bar{P}$ is the closure of $P$ ), we have $A \subseteq f^{-1}[f(A)]=$ $f^{-1}(P) \subseteq f^{-1}(\bar{P})$. Because $f$ is continuous and $\bar{P}$ is closed, $f^{-1}(\bar{P})$ is closed, and it follows that $\bar{A} \subseteq f^{-1}(\bar{P})$. (Recall that the closure of $A$ is the smallest closed set containing $A$.) Then we have $f(\bar{A}) \subseteq f\left[f^{-1}(\bar{P})\right] \subseteq \bar{P}$ (see Problem 4.6 in Chapter 1).

Collecting our results so far, we have

$$
f(\bar{A}) \subseteq \bar{P}, f(B)=Q \text { and } \bar{P} \cap Q=\varnothing
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-109.jpg?height=414&width=669&top_left_y=1711&top_left_x=431)

Figure 2.13.

We can therefore write

$$
\varnothing=\bar{P} \cap Q=\bar{P} \cap f(B) \supseteq f(\bar{A}) \cap f(B)
$$

Hence, $f(\bar{A}) \cap f(B)=\varnothing$, and this implies that $\bar{A} \cap B=\varnothing$, for if the latter set were not empty, any point $z$ in $\bar{A} \cap B$ would have its image in $f(\bar{A}) \cap f(B)$, which could not therefore be empty.

A similar argument yields that $\bar{B} \cap A=\varnothing$. Hence $C=A \cup B$ is not connected, and the result follows.

Let $f$ be a continuous function from $\mathbb{R}$ to $\mathbb{R}$, and $I$ an interval in the real line. By Theorem 9.3, $f(I)$ is also an interval and therefore contains all points lying between its end points. Thus the intermediate-value theorem (Theorem 6.22) is a special case of this result.

A concept closely related to connectedness, and often easier to check, is that of arcwise connectedness. A set $C$ in a metric space is said to be arcwise-connected if any two points in it can be joined by a continuous curve lying entirely within the set. More formally, we have the following definition.

Definition 9.4. Arc and arcwise-connected set. A set $A$ in a metric space is an arc if it is the image of a closed interval of the real line under a homeomorphism (a continuous function with a continuous inverse). A set $B$ in a metric space is said to be arcwise-connected if given any two points $x$ and $y$ in $B$ there is an arc containing $x$ and $y$ that is contained entirely in the set $B$.

Notice that an arc is connected, for it is the continous image of a connected set.

Our preceding result shows that every arcwise-connected set is connected. The converse statement, however, does not hold. As an example, consider the set $A \cup B$, where $A$ is the graph of the function $y=\sin 1 / x$ for $x>0$, and $B$ is the interval $(-1,1)$ on the $y$ axis of the Cartesian plane (Figure 2.14). As $x \rightarrow 0$, the amplitude of the sine waves decreases, and given any point $b$ in $B$, we can find points in $A$ arbitrarily close to $b$. Hence, $A \cup B$ is connected. It can be shown, however, that $A \cup B$ is not arcwise-connected (Sutherland, 1993, pp. 99-101).

Theorem 9.5. An arcwise-connected set in a metric space is connected.

Proof. We will prove the contrapositive statement that a nonconnected set in a metric space cannot be arcwise-connected.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-111.jpg?height=529&width=984&top_left_y=186&top_left_x=246)

Figure 2.14.

Let $D$ be a nonconnected set. Then there exist nonempty sets $A$ and $B$ such that $A \cup B=D$ and

$$
\begin{equation*}
\bar{A} \cap B=\varnothing=A \cap \bar{B} \tag{1}
\end{equation*}
$$

Let $a$ and $b$ be arbitrary points of $A$ and $B$, respectively, and let $C$ be any subset of $D$ that contains both $a$ and $b$. We will show that $D$ is not connected and cannot therefore be an arc.

Notice that $C \cap A$ and $C \cap B$ are nonempty sets (one contains at least $a$, and the other at least $b$ ), and

$$
(C \cap A) \cup(C \cap B)=C \cap(A \cup B)=C \cap D=C
$$

It remains to show that $C \cap A$ and $C \cap B$ are separated. For this, notice that any closure point of $C \cap A$ is a closure point of both $C$ and $A$. Hence, $\operatorname{cl}(C \cap A) \subseteq \bar{C} \cap \bar{A}$. We can now write

$$
\operatorname{cl}(C \cap A) \cap(C \cap B) \subseteq(\bar{C} \cap \bar{A}) \cap(\bar{C} \cap B)=\bar{C} \cap(\bar{A} \cap B)=\bar{C} \cap \varnothing=\varnothing
$$

By the same argument, $(C \cap A) \cap \operatorname{cl}(C \cap B)=\varnothing$, and we conclude that $C$ is not connected and cannot therefore be an arc. Hence, there is no arc containing $a$ and $b$, and the set $D$ is not arcwise-connected.

## 10. Equivalent Metrics and Norms

We have already noted that it is possible (and often convenient) to define several different metrics or norms in a given set. The question then arises as to when alternative metrics can be considered equivalent. In Section 1 we introduced the concept of Lipschitz equivalence for metrics and norms. We
now introduce an alternative notion of equivalence (topological equivalence) and explore the relationship between these two concepts.

We will say that two metrics or norms are topologically equivalent if they preserve the basic topological properties of sets and functions. Formally, we will define topological equivalence in terms of the preservation of convergence and show that equivalent metrics also preserve continuity of functions and openness of sets.

Definition 10.1. Topologically equivalent metrics and norms. Let $X$ be a nonempty set, and $d_{1}$ and $d_{2}$ two metrics defined on it. We will say that $d_{1}$ and $d_{2}$ are topologically equivalent if they preserve the convergence of sequences. That is, $d_{1}$ and $d_{2}$ are topologically equivalent if and only if the following condition holds: For any $x \in X$ and any sequence $\left\{x_{n}\right\}$ in $X,\left\{x_{n}\right\}$ converges to $x$ in $\left(X, d_{1}\right)$ if and only if it converges to $x$ in $\left(X, d_{2}\right)$.

Given a vector space $X$, two norms $\|\cdot\|_{1}$ and $\|\cdot\|_{2}$ defined on it are said to be topologically equivalent if the metrics they generate are topologically equivalent.

Theorem 10.2. Equivalent metrics preserve continuity. Let ( $\mathrm{Y}, \rho)$ be a metric space, with $\mathrm{X}$ a nonempty set, and $\mathrm{d}_{1}$ and $\mathrm{d}_{2}$ two metrics defined on it. Then $\mathrm{d}_{1}$ and $\mathrm{d}_{2}$ are topologically equivalent if and only if given any two functions $\mathrm{f}: \mathrm{X} \longrightarrow \mathrm{Y}$ and $\mathrm{g}: \mathrm{Y} \longrightarrow \mathrm{X}$ we have that

(i) $\mathrm{f}$ is $\left(\mathrm{d}_{1}, \mathrm{\rho}\right)$-continuous if and only if is $\left(\mathrm{d}_{2}, \mathrm{\rho}\right)$-continuous, and

(ii) $\mathrm{g}$ is $\left(\rho, \mathrm{d}_{1}\right)$-continuous if and only if is $\left(\rho, \mathrm{d}_{2}\right)$-continuous.

## Proof

- $(\rightarrow)$ Assume that $d_{1}$ and $d_{2}$ are topologically equivalent metrics, and let $f: X \rightarrow Y$ be a $\left(d_{1}, \rho\right)$-continuous function. We want to show that $f$ is also $\left(d_{2 .} \rho\right.$ )-continuous. By Theorem 6.3 (sequential characterization of continuity), the $\left(d_{1}, \rho\right)$-continuity of $f$ implies that given any sequence $\left\{x_{n}\right\}$ convergent to $x^{0}$ in $\left(X, d_{1}\right)$, the sequence $\left\{f\left(x_{n}\right)\right\}$ converges to $f\left(x^{0}\right)$ in $(Y, \rho)$. By the equivalence of the metrics, any such sequence $\left\{x_{n}\right\}$ also converges to $x^{0}$ in $\left(X, d_{2}\right)$, and because the image sequence $\left\{f\left(x_{n}\right)\right\}$ converges to $f\left(x^{0}\right)$ by assumption, the function $f$ is continuous, again by Theorem 6.3. A similar argument can be made for functions $g: Y \longrightarrow X$.
- $(\leftarrow)$ Assume that condition (i) holds, and consider a $d_{1}$-convergent sequence $\left\{x_{n}\right\}$ in $X$ with limit $x$. We want to show that $\left\{x_{n}\right\}$ converges to $x$ in $\left(X, d_{2}\right\}$. Let $I: X \longrightarrow X$, with $I(x)=x$, be the identity mapping in $X$. Because this function is clearly $\left(d_{1}, d_{1}\right)$-continuous, condition (i) implies that it is also $\left(d_{1}, d_{2}\right)$-continuous. Hence, by Theorem 6.3, the image sequence $\left\{I\left(x_{n}\right)\right\}=\left\{x_{n}\right\}$ converges to $I(x)=x$ in $\left(X, d_{2}\right)$, which is the desired result.

Theorem 10.3. Equivalent metrics preserve open sets. Let $\mathrm{X}$ be a nonempty set, and $\mathrm{d}_{1}$ and $\mathrm{d}_{2}$ two metrics defined on it. Then a necessary and sufficient condition for $\mathrm{d}_{1}$ and $\mathrm{d}_{2}$ to be topologically equivalent is the following: $A$ subset A of $\mathrm{X}$ is $\mathrm{d}_{1}$-open if and only if it is $\mathrm{d}_{2}$-open.

## Problem 10.4. Prove Theorem 10.3. Hint: Use Theorem 10.2.

These results show that convergence and continuity do not really depend on the use of a specific metric per se, but rather on the topological equivalence class of metrics we are using or, equivalently, on the open-set structure of the space. As we have already noted, this property allows a more general treatment of many problems in a broad family of spaces (topological spaces) in which open sets are essentially the only primitive structures.

The next two results describe the relationship between topological equivalence and Lipschitz equivalence. The first theorem says that Lipschitz equivalence implies topological equivalence. The converse of this result does not hold in arbitrary metric spaces, but it does hold in normed vector spaces.

Theorem 10.5. Lipschitz equivalence implies topological equivalence. Let $\mathrm{X}$ be a nonempty set, and $\mathrm{d}_{1}$ and $\mathrm{d}_{2}$ two metrics defined on it. If $\mathrm{d}_{1}$ and $\mathrm{d}_{2}$ are Lipschitz-equivalent, that is, if there exist positive real numbers $\mathrm{m}$ and $\mathrm{M}$ such that

$$
\begin{equation*}
\operatorname{md}_{1}(\mathrm{x}, \mathrm{y}) \leq \mathrm{d}_{2}(\mathrm{x}, \mathrm{y}) \leq \operatorname{Md}_{1}(\mathrm{x}, \mathrm{y}) \quad \text { for any } \mathrm{x}, \mathrm{y} \in \mathrm{X} \tag{1}
\end{equation*}
$$

then $\mathrm{d}_{1}$ and $\mathrm{d}_{2}$ are topologically equivalent.

Problem 10.6. Prove Theorem 10.5.

Theorem 10.7. Topological equivalence implies Lipschitz equivalence in vector spaces. Let $\mathrm{X}$ be a vector space, and $\|\cdot\|_{1}$ and $\|\cdot\|_{2}$ two norms defined on it. If $\|\cdot\|_{1}$ and $\|\cdot\|_{2}$ are topologically equivalent, then they are also Lipschitz-equivalent; that is, there exist positive constants $\mathrm{m}$ and $\mathrm{M}$ such that

$$
\mathrm{m}\|\mathbf{x}\|_{1} \leq\|\mathbf{x}\|_{2} \leq \mathbf{M}\|\mathbf{x}\|_{1} \quad \text { for all } \mathbf{x} \in \mathbf{X}
$$

Proof. We will prove the contrapositive statement: If $\|\cdot\|_{1}$ and $\|\cdot\|_{2}$ are not Lipschitz-equivalent, then they cannot be topologically equivalent - that is, we can then find a sequence $\left\{x_{n}\right\}$ that will converge to some limit $x$ in the metric induced by $\|\cdot\|_{1}$ and will not converge to $x$ in the metric induced by $\|\cdot\|_{2}$.

Suppose there is no constant $M$ such that $\|x\|_{2} \leq M\|x\|_{1}$ for all $x$. Then for each positive integer $n$ we can find some $x_{n} \in X$ with the property that

$$
\begin{equation*}
\left\|x_{n}\right\|_{2}>n\left\|x_{n}\right\|_{1} \tag{1}
\end{equation*}
$$

Dividing both sides of (1) by $\left\|x_{n}\right\|_{2}$ and using the defining properties of the norm, we have

$$
\left\|\frac{x_{n}}{\left\|x_{n}\right\|_{2}}\right\|_{1}<\frac{1}{n} \text { for all } n
$$

which implies that the sequence $\left\{x_{n} /\left\|x_{n}\right\|_{2}\right\}$ converges to $\underline{0}$ in the metric induced by $\|\cdot\|_{1}$. On the other hand,

$$
\left\|\frac{x_{n}}{\left\|x_{n}\right\|_{2}}\right\|_{2}=\frac{\left\|x_{n}\right\|_{2}}{\left\|x_{n}\right\|_{2}}=1 \text { for all } n
$$

So $\left\{x_{n} /\left\|x_{n}\right\|_{2}\right\}$ does not converge to $\underline{0}$ in the metric induced by $\|\cdot\|_{2}$. The same argument will work with the roles of $\|\cdot\|_{1}$ and $\|\cdot\|_{2}$ reversed.

Our next theorem says that all norms are equivalent in finite-dimensional vector spaces. This result is often useful because it allows us to choose whichever norm is more convenient for the problem at hand without having to worry about the validity of the results.

Theorem 10.8. Equivalence of all norms in $\mathbb{R}^{n}$. Let $\mathrm{N}: \mathbb{R}^{n} \rightarrow \mathbb{R}$ be any norm. Then there exist constants $\mathrm{m}, \mathrm{M}>0$ such that

$$
\begin{equation*}
\mathrm{m}\|\mathrm{x}\|_{\mathrm{E}} \leq \mathrm{N}(\mathrm{x}) \leq \mathrm{M}\|\mathrm{x}\|_{\mathrm{E}} \quad \text { for all } \mathrm{x} \in \mathbb{R}^{\mathrm{n}} \tag{1}
\end{equation*}
$$

where $\|\cdot\|_{\mathrm{E}}$ is the Euclidean norm in $\mathbb{R}^{n}$.

Proof. Recall from Problem 6.8 that a norm is a continuous function. By the extreme-value theorem (Theorem 8.24) it follows that $N()$ achieves both a maximum $M$ and a minimum $m$ in the compact set

$$
C=\left\{x \in \mathbb{R}^{\mathbf{n}} ;\|x\|_{E} \leq 1\right\}
$$

Now let $x$ be an arbitrary vector in $\mathbb{R}^{\mathrm{n}}$. If $x=\underline{0}$, then $N(\underline{0})=\|\underline{0}\|_{E}=0$, and (1) holds trivially. If $x \neq 0$, then $\|x\|_{E}=\alpha>0$, and, using the defining properties of the norm, we can write

$$
N(x)=N\left(\alpha \alpha^{-1} x\right)=\alpha N\left(\alpha^{-1} x\right)
$$

Now, because $\left\|\alpha^{-1} x\right\|_{E}=\alpha^{-1}\|x\|_{E}=\|x\|_{E} /\|x\|_{E}=1$, we have that $\alpha^{-1} x \in \mathrm{C}$ and it follows that

$$
m \leq N\left(\alpha^{-1} x\right) \leq M
$$

from where

$$
m \leq \alpha^{-1} N(x) \leq M
$$

and, recalling that $\alpha=\|x\|_{E}$,

$$
m\|x\|_{E} \leq N(x) \leq M\|x\|_{E}
$$

## 11. Continuity of Correspondences in $\boldsymbol{E}^{\boldsymbol{n}}$

We saw in Chapter 1 that a correspondence $\Psi: X \rightarrow \rightarrow \mathrm{Y}$ is a set-valued mapping, that is, a mapping that assigns to each point $x$ in $X$ a subset $\Psi(x)$ of $Y$. Suppose $X$ and $Y$ are metric spaces. Then a correspondence is said to be closed-valued (compact-valued) at a point $x$ if the image set $\Psi(x)$ is closed (compact) in $Y$.

We would like to extend to the case of correspondences the standard notion of continuity for a single-valued mapping in a way that will preserve its intuitive interpretation. Hence, we would like to say that a correspondence $\Psi$ is continuous if a small change in the argument $x$ does not change the image set $\Psi(x)$ very much. To see how we can go about this, and to see the problems that arise, recall from Section 6 that a function is continuous if the inverse image of an open set is open. If we focus on a specific point in the domain of the function, this can be rephrased as follows: A function $f$ is continuous at a point $x$ if whenever $x$ lies in the inverse image of an open set $V$, so does every point sufficiently close to it. If we try to apply this definition to correspondences, we immediately run into a difficulty: What is the inverse image of a set under a correspondence? Notice that there are two natural possibilities: We can define $\Psi^{-1}(V)$ as the set of all points $x$ whose image set is totally contained in $V,\{x \in X ; \Psi(x) \subseteq V\}$, or as the set of points whose image set is partially contained in $V,\{x \in X ; \Psi(x) \cap V \neq \varnothing\}$. The first possibility is sometimes called the upper or strong inverse of $V$ under $\Psi$, and the second is the lower or weak inverse. Each of these concepts of inverse gives rise to a different notion of (hemi-) continuity for correspondences, and we reserve the term "continuous" for a set-valued function that is hemicontinuous in both senses. Notice that both types of hemicontinuity reduce to the standard notion of continuity if $\Psi$ is a singlevalued mapping.

Definition 11.1. Continuity for correspondences. ${ }^{10}$ Let $X$ and $Y$ be finitedimensional Euclidean spaces, and let $\Psi: X \rightarrow \rightarrow Y$ be a correspondence. Then we say the following:
(i) $\Psi$ is upper-hemicontinuous (uhc) at a point $x \in X$ if for every open set $V$ containing $\Psi(x)$ there exists a neighborhood $U$ of $x$ such that $\Psi\left(x^{\prime}\right) \subseteq V$ for every $x^{\prime} \in U$.

(ii) $\Psi$ is lower-hemicontinuous (lhc) at a point $x \in X$ if for every open set $V$ in $Y$ with $\Psi(x) \cap V \neq \varnothing$ there exists a neighborhood $U$ of $x$ such that $\Psi\left(x^{\prime}\right) \cap V \neq \varnothing$ for every $x^{\prime} \in U$.

(iii) $\Psi$ is continuous at $x$ if it is both uhe and lhe at this point.

A correspondence is continuous (uhc, lhc) if it is continuous (uhc, lhc) at each point in its domain.

Each type of hemicontinuity can be given a straightforward intuitive interpretation in terms of the restrictions placed on the "size" of the set $\Psi(x)$ as $x$ changes. First, suppose that $\Psi()$ is uhc at some point $x$, and fix an appropriate open set $V$ containing $\Psi(x)$. As we move from $x$ to a nearby point $x^{\prime}$, the set $V$ gives us an "upper bound" on the size of $\Psi\left(x^{\prime}\right)$, because we require that $\Psi\left(x^{\prime}\right)$ remain contained in $V$. Hence, upper hemicontinuity requires that the image set $\Psi(x)$ not "explode" (become suddenly much larger) with small changes in the argument, but allows this set to become suddenly much smaller. In the case of lower hemicontinuity, on the other hand, the set $V$ acts as a "lower bound" on $\Psi\left(x^{\prime}\right)$, because the intersection of the image set with $V$ cannot become empty. Hence, hemicontinuity rules out "implosions" of the image set (but not explosions).

Figure 2.15 may help clarify the meaning of these definitions. The correspondence $\Psi$ is not uhc at $x_{1}$ (but it is $\mathrm{lhc}$ ). To see this, fix an open set $V \supseteq \Psi\left(x_{1}\right)$ as in the figure, and notice that for any $x_{1}^{\prime}$ smaller than $x_{1}$ but arbitrarily close to it, the image set $\Psi\left(x_{1}^{\prime}\right)$ is not contained in $V$. Hence, $\Psi(x)$ "explodes" as we move away from $x_{1}$ to the left. On the other hand, $\varphi$ is uhc at $x_{2}$ but not lhc, because as we move from this point to the left, the image set $\varphi(x)$ suddenly becomes much smaller.

We now develop some alternative characterizations of upper and lower
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-116.jpg?height=410&width=1232&top_left_y=1723&top_left_x=106)

Figure 2.15. Failures of upper and lower hemicontinuity.
hemicontinuity that often are more convenient in applications than Definition 11.1. In all cases, the domain and range of the correspondence (the sets $X$ and $Y$ ) are assumed to be finite-dimensional Euclidean spaces.

Theorem 11.2. A sequential characterization of upper hemicontinuity. A compact-valued correspondence $\Psi: \mathrm{X} \rightarrow \rightarrow \mathrm{Y}$ is uhc at $\mathrm{x}$ if and only if for every sequence $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ converging to $\mathrm{x}$, every "companion sequence" $\left\{\mathrm{y}_{\mathrm{n}}\right\}$, with $\mathrm{y}_{\mathrm{n}} \in \Psi\left(\mathrm{x}_{\mathrm{n}}\right)$ for all $\mathrm{n}$, has a convergent subsequence $\left\{\mathrm{y}_{\mathrm{n}_{\mathrm{k}}}\right\}$ with limit in $\Psi(\mathrm{x})$.

## Proof

- Assume that $\Psi$ is uhc at $x$, and let $\left\{x_{n}\right\}$ be a sequence converging to $x$, and $\left\{y_{n}\right\}$, with $y_{n} \in \Psi\left(x_{n}\right)$ for each $n$, an arbitrary companion sequence. We will first show that $\left\{y_{n}\right\}$ is bounded. By Theorems 3.3 and 3.10, this implies that $\left\{y_{n}\right\}$ has a convergent subsequence. We will then show that the limit of this subsequence lies in $\Psi(x)$.

By assumption, $\Psi(x)$ is a compact and therefore bounded set. Hence there is a bounded and open set $B$ that contains $\Psi(x)$. By the upper hemicontinuity of $\Psi()$, there exists a neighborhood $U$ of $x$ such that $\Psi(z) \subseteq B$ for all $z \in U$. Now, because $\left\{x_{n}\right\} \rightarrow x$, there exists an integer $N$ such that $x_{n} \in U$ for all $n>N$, and it follows that $\Psi\left(x_{n}\right) \subseteq B$ for $n>N$. Hence, any companion sequence $\left\{y_{n} ; y_{n} \in \Psi\left(x_{n}\right)\right\}$ is bounded and therefore contains a convergent subsequence. Call this subsequence $\left\{y_{n_{k}}\right\}$, and let $y$ be its limit.

To show that $y \in \Psi(x)$, we will assume that such is not the case and obtain a contradiction. Suppose, then, that $y \notin \Psi(x)$. Because $\Psi(x)$ is (compact and therefore) closed, $y$ cannot be a boundary point of $\Psi(x)$, and it follows that the distance between $y$ and the set $\Psi(x)$ is strictly positive. Hence, we can construct a closed $\varepsilon$-ball around the set $\Psi(x)$.

$$
B_{\varepsilon}[\Psi(x)]=\underset{a \in \Psi(x)}{\cup} B_{\varepsilon}[a]
$$

that does not contain $y$ by choosing $\varepsilon$ such that

$$
0<\varepsilon<\inf _{a \in \Psi(x)} d(a, y)=d(\Psi(x), y)
$$

Notice that the interior of $B_{\varepsilon}[\Psi(x)]$ is an open set that contains $\Psi(x)$.

Now, because $\Psi$ is uhc at $x$, and $\left\{x_{n}\right\} \rightarrow x, \Psi\left(x_{n}\right)$ will be contained in $B_{\varepsilon}[\Psi(x)]$ (actually, in its interior) for $n$ sufficiently high. This, in turn, implies that the companion sequence $\left\{y_{n} ; y_{n} \in \Psi\left(x_{n}\right)\right\}$ will be contained in $B_{\varepsilon}[\Psi(x)]$ for $n$ high enough, and therefore so will the convergent subsequence $\left\{y_{n_{k}}\right\}$. Because $B_{\varepsilon}[\Psi(x)]$ is closed, it follows by Theorem 4.13 that $y$, which is the limit of $\left\{y_{n_{k}}\right\}$, will also belong to $B_{\varepsilon}[\Psi(x)]$. This contradicts the fact that $y \notin B_{\varepsilon}[\Psi(x)]$ by the construction of $B_{\varepsilon}[\Psi(x)]$.

- The second part of the theorem says that if a certain property concerning
sequences holds, then the correspondence is uhc. It will be convenient to establish the equivalent (contrapositive) assertion that if $\Psi$ is not uhc at $x$, then this property does not always hold.

For this, assume that $\Psi$ is not uhe at $x$, that is, that there exists an open set $V$ containing $\Psi(x)$ such that every neighborhood $U$ of $x$ contains a point $z_{u}$ with $\Psi\left(z_{u}\right)$ not contained in $V$. Then we can choose a decreasing sequence of such neighborhoods $\left\{U_{n}\right\}$, with $U_{n+1} \subseteq U_{n}$ (say $U_{n}=B_{1 / n}(x)$, an open ball with radius $1 / n$ and center at $x$ ), and for each of them there is some point $z_{n}$ with $\Psi\left(z_{n}\right)$ not contained in $V$. By construction, $\left\{z_{n}\right\} \rightarrow x$, but we can choose a companion sequence $\left\{y_{n}\right\}$, with $y_{n} \in \Psi\left(z_{n}\right)$, in such a way that $y_{n} \notin V$ (i.e., $y_{n} \in V^{c}$ for each $n$ ). Suppose now that $\left\{y_{n}\right\}$ has a convergent subsequence $\left\{y_{n_{k}}\right\}$, and call its limit $y$. Because $\left\{y_{n_{k}}\right\}$ is contained in the closed set $V^{c}$, its limit $y$ must also lie on this set (by Theorem 4.13). Hence, $y \notin V$, and because $V$ contains $\Psi(x)$, it follows that $y \notin \Psi(x)$. This establishes the desired result, for we have constructed a sequence $\left\{z_{n}\right\} \rightarrow x$ and a companion sequence $\left\{y_{n} \in \Psi\left(z_{n}\right)\right\}$ that can have no subsequence converging to a point in $\Psi(x)$.

Theorem 11.3. A sequential characterization of lower hemicontinuity. A correspondence $\Psi: X \rightarrow Y$ is lhc at $\mathrm{X}$ if and only if for every sequence $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ converging to $\mathrm{x}$ and every point $\mathrm{y} \in \Psi(\mathrm{x})$ there exists a companion sequence $\left\{\mathrm{y}_{\mathrm{n}}\right\}$, with $\mathrm{y}_{\mathrm{n}} \in \Psi\left(\mathrm{x}_{\mathrm{n}}\right)$ for all $\mathrm{n}$, that converges to $\mathrm{y}$.

## Proof

- Assume that $\Psi$ is lhc at $x$; let $\left\{x_{n}\right\}$ be a sequence converging to $x$, and fix an arbitrary point in $\Psi(x)$, say $y$. For each integer $k$, let $B_{1 / k}(y)$ be the open ball with radius $1 / k$ and center at $y$. Clearly, $B_{1 / k}(y) \cap \Psi(x)$ is nonempty, because it contains at least the point $y$. Because $\Psi$ is lhc at $x$, for each $k$ there exists a neighborhood $U_{k}$ of $x$ such that for each $z_{k} \in U_{k}$ we have $\Psi\left(z_{k}\right) \cap B_{1 / k}(y) \neq \varnothing$. Because $\left\{x_{n}\right\} \rightarrow x$, we can find, for each given $k$, an integer $n_{k}$ such that $x_{n} \in U_{k}$ for all $n \geq n_{k}$. These numbers, moreover, can be assigned so that $n_{k+1}>n_{k}$. Notice, moreover, that with $n \geq n_{k}$ we have $x_{n} \in U_{k}$, and this implies that $\Psi\left(x_{n}\right) \cap B_{1 / k}(y)$ is nonempty. Hence, we can construct a companion sequence $\left\{y_{n}\right\}$, with $y_{n}$ chosen from the set $\Psi\left(x_{n}\right) \cap B_{1 / k}(y)$, for each $n$ with $n_{k}<n_{k+1}$. As $k$, and hence $n$, increases, the radius of the balls $B_{1 / k}(y)$ shrinks down to zero, which implies that $\left\{y_{n}\right\}$ converges to $y$.
- As in the preceding theorem, we prove the contrapositive of the desired result. Assume that $\Psi$ is not lhc at $x$, that is, that there exists an open set $V$, with $\Psi(x) \cap V \neq \varnothing$, such that every neighborhood $U$ of $x$ contains a point $z_{u}$, with $\Psi\left(z_{u}\right) \cap V=\varnothing$. Taking a sequence of such neighborhoods, $U_{n}=B_{1 / n}(x)$, and an appropriate point $x_{n}$ in each of them, we obtain a sequence $\left\{x_{n}\right\}$ that converges to $x$ by construction and has the property that $\Psi\left(x_{n}\right) \cap V=\varnothing$ for all $n$.

Hence, every companion sequence $\left\{y_{n}\right\}$, with $y_{n} \in \Psi\left(x_{n}\right)$, is contained in the complement of $V$, and if $\left\{y_{n}\right\}$ is convergent, the same must be true of its limit, because the complement of $V$ is a closed set. It follows that no companion sequence of
$\left\{x_{n}\right\}$ can converge to a point in $V$. Hence, if we let $y$ be a point in $\Psi(x) \cap V$, no convergent companion sequence can exist.

We now introduce another concept of continuity for correspondences, essentially by extending the sequential characterization of continuity for functions (the image of a sequence under the function converges to the image of the limit of the sequence). Before we state the definition, recall that the graph of the correspondence $\Psi$ is the set

$$
G_{\Psi}=\{(x, y) \in X \times Y ; y \in \Psi(x)\}
$$

Definition 11.4. A correspondence $\Psi: X \rightarrow \rightarrow Y$ is said to be closed if its graph $G_{\Psi}$ is closed in $X \times Y$; that $\Psi$ is closed whenever

$$
\left(\begin{array}{c}
\left\{x_{n}\right\} \rightarrow x \\
y_{n} \in \Psi\left(x_{n}\right) \forall n \\
\left\{y_{n}\right\} \rightarrow y
\end{array}\right) \Rightarrow y \in \Psi(x)
$$

Problem 11.5. Show that a closed correspondence is closed-valued.

Our next result shows that closedness is closely related to upper hemicontinuity. Because closedness is also fairly easy to check in many cases, a convenient way to show that a given correspondence is uhc is to establish its closedness and then apply Theorem 11.6.

Theorem 11.6. Relationship between closedness and upper hemicontinuity. Let $\Psi: \mathrm{X} \rightarrow \rightarrow \mathrm{Y}$ be a nonempty valued and closed correspondence. If for any bounded set $\mathrm{B}$ in $\mathrm{X}$ the image set $\Psi(\mathrm{B})$ is bounded, then $\Psi$ is uhc.

Notice that if the range $Y$ of the correspondence is a compact space, the boundedness assumption is satisfied automatically.

Proof. Fix an arbitrary point $x$ in $X$. Then $\Psi(x)$ is a closed set (by Problem $11.5)$ that is bounded (by assumption) and therefore compact. Hence, $\Psi$ is compact-valued. Consider now a sequence $\left\{x_{n}\right\}$ converging to $x$ and an arbitrary companion sequence $\left\{y_{n}\right\}$, with $y_{n} \in \Psi\left(x_{n}\right)$ for each $n$. To establish the desired result, we have to show that $\left\{y_{n}\right\}$ has a convergent subsequence with limit in $\Psi(x)$.

Because $\left\{x_{n}\right\} \rightarrow x$, there is a bounded set, say $B$, that contains both $\left\{x_{n}\right\}$ and $x$ (Theorem 2.5). The image set $\Psi(B)$ contains the companion sequence and, by assumption, is bounded. Hence (by Theorems 3.3 and 3.10), $\left\{y_{n}\right\}$ has a
convergent subsequence, say $\left\{y_{n_{k}}\right\}$, with limit $y$. Then $\left\{\left(x_{n_{k}}, y_{n_{k}}\right)\right\}$ is a sequence in $G_{\Psi} \subseteq X \times Y$ converging to $(x, y)$, and it follows from the closedness of the graph of $\Psi$ that $(x, y) \in G_{\Psi}$ (i.e., that $\left.y \in \Psi(x)\right)$.

In the remainder of this section we list some useful properties of uhc correspondences.

Theorem 11.7. Let the correspondence $\Psi: \mathrm{X} \rightarrow \rightarrow \mathrm{Y}$ be compact-valued and uhc, let $\Gamma: \mathrm{X} \rightarrow \rightarrow \mathrm{Y}$ be closed, and assume that $\Psi(\mathrm{x}) \cap \Gamma(\mathrm{x}) \neq \varnothing$. Then the intersection correspondence $\Psi \cap \Gamma$, defined by $(\Psi \cap \Gamma)(\mathrm{x})=\Psi(\mathrm{x}) \cap \Gamma(\mathrm{x})$, is compact-valued and uhc.

Problem 11.8. Prove Theorem 11.7. Notice that $\Psi(x) \cap \Gamma(x)$ is compact, by Theorem 8.12.

Theorem 11.9. Let the correspondence $\Psi: \mathrm{X} \rightarrow \rightarrow \mathrm{Y}$ be compact-valued and $u$ hc. Then the image under $\Psi$ of a compact set $\mathrm{C}$,

$$
\Psi(\mathrm{C})=\cup_{\mathrm{x} \in \mathrm{C}} \Psi(\mathrm{x})
$$

is compact.

Problem 11.10. Prove Theorem 11.9. Hint: Use the sequential characterization of compactness and Theorem 11.2.

Theorem 11.11. Let the correspondences $\Psi_{\mathrm{i}}: \mathrm{X} \rightarrow \rightarrow \mathrm{Y}$, with $\mathrm{i}=1, \ldots, \mathrm{n}$, be compact-valued and uhc at $\mathrm{x}$. Then the sum correspondence $\Psi$, defined by $\Psi(\mathrm{x})=\sum_{\mathrm{i}=1}^{\mathrm{n}} \Psi_{\mathrm{i}}(\mathrm{x})$ for each $\mathrm{x}$, is compact-valued and uhc at $\mathrm{x}$.

Problem 11.12. Prove Theorem 11.11.

Let $\Psi: X \rightarrow \rightarrow$ and $\Gamma: Y \rightarrow \rightarrow$ be two correspondences. We define their composition, $\varphi=\Gamma \circ \Psi: X \rightarrow \rightarrow$ by

$$
\varphi(x)=\Gamma \circ \Psi(x)=\Gamma[\Psi(x)]=\bigcup_{y \in \Psi(x)}^{\bigcup} \Gamma(y)
$$

Theorem 11.13. Let $\Psi: \mathrm{X} \rightarrow \rightarrow \mathrm{Y}$ and $\Gamma: \mathrm{Y} \rightarrow \mathrm{Z}$ be uhc at $\mathrm{x}^{0}$. Then their composition $\varphi=\Gamma \circ \Psi$ is also uhc at $\mathrm{x}{ }^{\Gamma}$.

Proof. Let $W$ be an open set containing $\varphi\left(x^{0}\right)$, and let

$$
U=\{x \in X ; \varphi(x) \subseteq W\}
$$

To establish the upper hemicontinuity of $\varphi$, we need to show that $U$ is an open set. Let

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-121.jpg?height=414&width=1215&top_left_y=194&top_left_x=122)

Figure 2.16. Composition of two correspondences.

$$
V=\{y \in Y ; \Gamma(y) \subseteq W\}
$$

and observe that $\varphi(x)=\Gamma[\Psi(x)] \subseteq W$ if and only if $\Psi(x) \subseteq V$. Hence we have

$$
U=\{x \in X ; \Psi(x) \subseteq V\}
$$

Now, because $\Gamma$ is uhc, the openness of $W$ implies the openness of $V$. Similarly, because $V$ is open and $\Psi$ is uhc, it follows that $U$ is open, which establishes the desired result.

Theorem 11.14. Let $\Gamma: \mathrm{X} \rightarrow \mathrm{Y}$, with $\mathrm{i}=1, \ldots, \mathrm{n}$, be compact-valued and uhc correspondences. Then the product correspondence $\Gamma($ ), with $\Gamma(\mathrm{x})=$ $\Gamma^{I}(\mathrm{x}) \times \ldots \times \Gamma^{\mathrm{n}}(\mathrm{x})$ for each $\mathrm{x}$ in $\mathrm{X}$, is compact-valued and uhc.

Problem 11.15. Prove Theorem 11.14.

## Bibliography

Apostol, T. 1974. Mathematical Analysis, 2nd ed. Reading, MA: Addison-Wesley. Berge, C. 1966. Espace Topologiques. Fonctions Multivoques. Paris: Dunod.

Binmore, K. 1982. Mathematical Analysis: A Straightforward Approach, 2nd ed. Cambridge University Press.

Border, K. 1989. Fixed Point Theorems with Applications to Economics and Game Theory. Cambridge University Press.

Byrant, V. 1990. Yet Another Introduction to Analysis. Cambridge University. Press.

Clark, C. 1982. Elementary Mathematical Analysis, 2nd ed. Belmont, CA: Wadsworth.

Gemignani, M. 1972. Elementary Topology, 2nd ed. New York: Dover.

Giles, J. R. 1989. Introduction to the Analysis of Metric Spaces. Cambridge University Press.

Haaser, N., and Sullivan, J. 1991. Real Analysis. New York: Dover.

Hildenbrand, W. 1974. Core and Equilibria of a Large Economy. Princeton University Press.

Hildenbrand, W., and Kirman, A. 1976. Introduction to Equilibrium Analysis. Variations on Themes by Edgeworth and Walras. Amsterdam: North Holland. Kolmogorov, A. N., and Fomin, S. V. 1970. Introductory Real Analysis. New York: Dover.

Lang, S. 1989. Undergraduate Analysis. Berlin: Springer-Verlag.

Michel, P. 1984. Cours de Mathématiques pour Economistes. Paris: Economica.

Nikaido, H. 1972. Introduction to Sets and Mappings in Modern Economics. Amsterdam: North Holland.

Protter, M., and Morrey, C. 1991. A First Course in Real Analysis, 2nd ed. Berlin: Springer-Verlag.

Royden, H. L. 1988. Real Analysis, 3rd ed. New York: Macmillan.

Rudin, W. 1964. Principles of Mathematical Analysis, 2nd ed. New York: McGrawHill.

Stirling, D. 1990. Mathematical Analysis: A Fundamental and Straightforward Approach. New York: Ellis Horwood.

Sutherland, W. 1993. Introduction to Metric and Topological Spaces. Oxford: Clarendon Press.

## Notes

1 The choice of $x$ is arbitrary: Notice that if $S$ satisfies the definition of boundedness for some $x$, it will also satisfy it for any other point $x^{\prime}$ in $X$, with $B$ replaced by $B+d\left(x, x^{\prime}\right)$, because $d\left(s, x^{\prime}\right) \leq d(s, x)+d\left(x, x^{\prime}\right)$. It should be noted that a given set may be bounded or unbounded depending on what metric we are using.

2 To guarantee that $B_{\varepsilon}(x) \cap B_{\varepsilon}\left(x^{\prime}\right)=\varnothing$, it is enough to choose $\varepsilon, \varepsilon^{\prime}<d\left(x, x^{\prime}\right) / 2$.

3 Every nonempty set of real numbers that is bounded above has a least upper bound (see Chapter 1).

4 Note that openness is defined relative to a given metric space $(X, d)$. It may be important to keep that in mind if $X$ is itself embedded in a larger set. For example, let $A$ be an "open circle" in a plane $X$, which is itself a subset of three-dimensional space $Y$. Then $A$ is open in $X$, but not in $Y$, because any small movement in $Y$ away from the $X$ plane would take us out of $A$. However, any sufficiently small movement along the plane and away from a point in the circle will leave us inside $A$. If there is any possibility of ambiguity, we should say that a set $A$ is open (or not) in $X$.

5 Note that in fact both $X$ and $\varnothing$ satisfy the definition, but in a fairly strange way. It is true that around any point in $\varnothing$ we can construct an adequate open ball, or do anything we want, for that matter, because there is no such point. The same is true for $X$, for there is "nothing" outside it.

6 See Chapter 1.

7 Occasionally we may want to define the limit of $f$ as $x$ approaches $x^{0}$ through elements of a given set $\boldsymbol{A}$. Right-handed and left-handed limits for functions in $\mathbb{R}$, for example, are defined in this way by requiring $x$ to approach $x^{0}$ either from above or from below. More generally, we say that $f$ tends to $y^{0}$ as $x$ tends to $x^{0}$ for $x \in A$ if and only if $x^{0}$ is a limit point of $A$, and

$$
\forall \varepsilon>0, \exists \delta_{\varepsilon}>0 \text { s.th. } \rho\left[f(x), y^{0}\right]<\varepsilon \forall x \in A \text { s.th. } d\left(x, x^{0}\right)<\delta_{\varepsilon}
$$

8 As for limits, we may occasionally want to define continuity relative to a given set. We say that a function $f$ is continuous with respect to a set $A$ at a point $x^{0}$ if

$$
\forall \varepsilon>0, \exists \delta_{\varepsilon}>0 \text { s.th. } \rho\left[f(x), f\left(x^{0}\right)\right]<\varepsilon \forall x \in A \text { s.th. } d\left(x, x^{0}\right)<\delta_{\varepsilon}
$$

Right continuity and left continuity for real functions, for example, are defined in this way.

9 Given a contraction $T$ with modulus $\beta$, let $y$ be an arbitrary trial solution to the
equation $T x=x$. If the true solution is $x^{*}$, it is easy to see by the argument used in the existence proof that

$$
d\left(y, x^{*}\right) \leq \frac{1}{1-\beta} d(y, T y)
$$

10 The definition can be extended to the case of general metric spaces. Most of the results in this section continue to hold in this setting, but the proofs become more complicated. The interested reader is referred to Hildenbrand (1974) for a more general treatment.

## Vector Spaces and Linear Transformations

The concept of a vector space was defined in Chapter 1. We begin this chapter with a brief review of the structure of vector spaces, focusing on the concept of basis. Then we turn to the study of linear functions.

## 1. Linear Independence and Bases

Let $V$ be a vector space defined over the field $F$. A family of vectors in $V$, $\mathbb{x}=\left\{x_{s} \in V ; s \in S\right\}$, is the range of a function $f$ from an index set $S$ to $V$ such that $f(s)=x_{s}$. A subfamily of $\mathbb{x}$ is the range of the restriction of $f$ to a subset $S^{\prime}$ of $S$. If $S^{\prime}$ is a finite set, we speak of a finite subfamily of $x$.

Let $\mathbb{X}=\left\{x_{1}, \ldots, x_{n}\right\}$ be a finite family of vectors in $V$. A linear combination of $x_{1}, \ldots, x_{n}$ is a vector of the form

$$
y=\sum_{i=1}^{n} \alpha_{i} x_{i}
$$

where $\alpha_{1}, \ldots, \alpha_{n}$ are scalars, and $\alpha_{i}$ is called the coefficient of the vector $x_{i}$.

We say that a finite family of vectors $\mathbb{X}=\left\{x_{1}, \ldots, x_{n}\right\}$ is linearly dependent if at least one of the vectors can be written as a linear combination of the rest. Equivalently, we say that $x_{1}, \ldots, x_{n}$ are linearly dependent if there exist scalars $\alpha_{1}, \ldots, \alpha_{n}$, not all zero, such that

$$
\sum_{i=1}^{n} \alpha_{i} x_{i}=\underline{0}
$$

For an infinite family $\mathrm{x}=\left\{x_{s} \in V ; s \in S\right\}$, we say that $\mathrm{x}$ is linearly dependent if there exists at least one finite subfamily of $x$ that is linearly dependent.

A family of vectors $\mathrm{x}$ in $V$ is linearly independent if it is not linearly dependent; that is, if for every finite subfamily $\left\{x_{s} \in V ; s \in S^{\prime}\right\}$ of $\mathbb{x}$ we have that

$$
\sum_{s \in S^{\prime}} \alpha_{s} x_{s}=\underline{0} \Rightarrow \alpha_{s}=0 \forall s \in S^{\prime}
$$

A subset $W$ of $V$ spans or generates $V$ if every vector in $V$ can be written as a linear combination of a finite number of elements of $W$, that is, if for every $x \in V$ there exist scalars $\alpha_{1}, \ldots, \alpha_{n}$ and vectors $w_{1}, \ldots, w_{n}$ in $W$ such that

$$
x=\sum_{i=1}^{n} \alpha_{i} w_{i}
$$

We can now introduce a concept of "basis" that is valid for all vector spaces, even those of infinite dimension.

Definition 1.1. Hamel basis. A Hamel basis for a vector space $V$ is a linearly independent family of vectors that spans $V$.

A Hamel basis is a useful concept because it allows us to write every element of $V$ in a unique way as a linear combination of elements of the basis. Thus, once we have a basis, we "know" all the elements of $V$.

Theorem 1.2. Let $\mathbb{B}=\left\{\mathrm{v}_{\mathrm{s}} \in \mathrm{V} ; \mathrm{s} \in \mathrm{S}\right\}$ be a Hamel basis for $\mathrm{V}$. Then every nonzero vector $\mathrm{x} \in \mathrm{V}$ has a unique representation as a linear combination, with coefficients not all zero, of a finite number of vectors in $\mathbb{b}$.

Proof. Let $x$ be an arbitrary nonzero vector in $V$. Because (by definition of Hamel basis) $\mathbb{b}$ spans $V$, we know that $x$ has at least one representation of the form

$$
x=\sum_{s \in S_{1}} \alpha_{s} v_{s}
$$

where $S_{1}$ is a finite subset of $S$, and $\alpha_{s} \neq 0$ for $s \in S_{1}$. Let us assume that there exists a second such representation

$$
x=\sum_{s \in S_{2}} \beta_{s} v_{s}
$$

where $S_{2}$ is another finite subset of $S$, and $\beta_{s} \neq 0$ for $s \in S_{2}$. We will show that these two representations must be equal.

Let $S_{3}=S_{1} \cup S_{2}$, and let $\alpha_{s}=0$ for $s \in S_{3} \sim S_{1}$ and $\beta_{s}=0$ for $s \in S_{3} \sim S_{2}$. We can then write both representations in terms of the same finite subfamily of $\mathfrak{b}$ :

$$
x=\sum_{s \in S_{3}} \alpha_{s} v_{s}=\sum_{s \in S_{3}} \beta_{s} v_{s}
$$

from which

$$
\sum_{s \in S_{3}}\left(\alpha_{s}-\beta_{s}\right) v_{s}=\underline{0}
$$

Because $\left\{v_{s} \in V ; s \in S_{3}\right\}$ is a finite subfamily of a Hamel basis, it is linearly independent. Thus, the last expression implies that $\alpha_{s}-\beta_{s}=0$ for all $s$. Hence, $\alpha_{s}=\beta_{s}$, and the representation is unique.

It can be shown that every nontrivial vector space $(V \neq\{0\})$ has a Hamel basis, and that all Hamel bases of $V$ have the same cardinal number. This cardinal number is therefore a property of the space $V$ and is called its dimension (written $\operatorname{dim} V$ ). A finite-dimensional Hamel basis (i.e., one that contains a finite number of vectors) is called a basis.

Although we will work mostly with finite-dimensional vector spaces, it is important to observe that certain vector spaces of interest are infinitedimensional.

Example 1.3. Let $F$ be a field, and consider the set

$$
V_{n}(F)=\left\{v=\left(\alpha^{1}, \ldots, \alpha^{n}\right) ; \alpha^{i} \in F \forall i=1, \ldots, n\right\}
$$

Put

$$
\delta_{i k}=1 \text { if } i=k \quad \text { and } \quad \delta_{i k}=0 \text { if } i \neq k
$$

and define the vectors

$$
e_{p}^{n}=\left(\delta_{1 p}, \ldots, \delta_{p p}, \ldots, \delta_{n p}\right) \text { for } p \leq n
$$

(i.e., the $n$-vector $e_{p}^{n}$ has 1 as its $p$ th component, and the others are zeros). If $n$ is finite, it is easy to show that $V_{n}(F)$ is a vector space and the family $\left\{e_{p}^{n} ; p=1, \ldots, n\right\}$ is a basis (the canonical basis) for $V_{n}(F)$. If we go to the limit and put $n=\infty$, we obtain the infinite-dimensional vector space of the scalar sequences, $V_{\infty}(F)$. Observe that the infinite family $\left\{e_{p}^{\infty} ; p=1, \ldots, \infty\right\}$ of sequences with a single 1 and all the rest zeros is not a Hamel basis of $V_{\infty}(F)$, for it is impossible to write a sequence with an infinite number of terms different from zero as a linear combination of a finite number of sequences of the form $e_{p}^{\infty}$. It is possible to show, however, that there is an extension of this family that is a Hamel basis for $V_{\infty}(F)$.

In the case of finite-dimensional vector spaces, bases have a very simple structure. In particular, we shall show that if $V$ has dimension $n<\infty$, any collection of $n$ linearly independent vectors in $V$ is a basis for $V$.

Theorem 1.4. Let $\mathbb{v}=\left\{\mathrm{v}_{1}, \ldots, \mathrm{v}_{\mathrm{n}}\right\}$ be a basis of $\mathrm{V}$; then no set more than $\mathrm{n}$ vectors in $\mathrm{V}$ is linearly independent.

Proof. Let $\mathrm{x}=\left\{x_{1}, \ldots, x_{n+1}\right\}$ be a collection of $n+1$ vectors in $V$. We can always find scalars $\beta_{1}, \ldots, \beta_{n+1}$ such that

$$
\begin{equation*}
\sum_{k=1}^{n+1} \beta_{k} x_{k}=\underline{0} \tag{1}
\end{equation*}
$$

What we want to show is that there are $\beta_{k}$ 's that satisfy (1) and are not all zero.

Now, $\mathbb{V}=\left\{v_{1}, \ldots, v_{n}\right\}$ is a basis of $V$, and therefore each $x_{k}$ has a unique representation as a linear combination of elements of $\mathbb{v}$. That is, there exist scalars $\alpha_{i k}$, not all zero, such that for each $k=1, \ldots, n+1$,

$$
\begin{equation*}
x_{k}=\sum_{i=1}^{n} \alpha_{i k} v_{\imath} \tag{2}
\end{equation*}
$$

Substituting (2) into (1), we see that the $\beta_{k}$ 's must satisfy the following equality:

$$
\begin{equation*}
\underline{0}=\sum_{k=1}^{n+1} \beta_{k}\left(\sum_{i=1}^{n} \alpha_{i k} v_{i}\right)=\sum_{i=1}^{n}\left(\sum_{k=1}^{n+1} \beta_{k} \alpha_{i k}\right) v_{i} \tag{3}
\end{equation*}
$$

Because $v_{1}, \ldots, v_{n}$ are linearly independent, (3) implies

$$
\begin{equation*}
\sum_{k=1}^{n+1} \beta_{k} \alpha_{i k}=0 \forall i=1, \ldots, n \tag{4}
\end{equation*}
$$

Observe that (4) is a system of $n$ equations in $n+1$ unknowns (the $\beta_{k}$ 's). As we will prove later (and the reader should already know), every such system has nontrivial solutions. Hence, it is possible to find $\beta_{k}$ 's not all zero that satisfy (1), and we conclude that $x_{1}, \ldots, x_{n+1}$ are linearly dependent.

This theorem implies that every basis for a finite-dimensional vector space has the same number of elements, for if this were not so, a basis with more elements than another one could not be a linearly independent family. Another almost immediate corollary of Theorem 1.4 is the following result:

Theorem 1.5. Let $\mathrm{V}$ be a vector space of dimension $\mathrm{n}$. Then any linearly independent family of $\mathrm{n}$ vectors in $\mathrm{V}, \mathbb{v}=\left\{\mathrm{v}_{l}, \ldots, \mathrm{v}_{\mathrm{n}}\right\}$, is a basis for $\mathrm{V}$.

Problem 1.6. Prove Theorem 1.5.

Example 1.7. Let $F$ be a field. The set $F_{m \times n}$ of all matrices of dimension $m \times n, A=\left[a_{i k}\right](i=1, \ldots, m ; k=1, \ldots, n)$, with matrix addition and multiplication by a scalar defined component by component, is a vector space. Moreover, the $m n$ matrices $E_{i k}$ with a 1 in the position $i k$ and zeros in all other entries is a basis of $F_{m \times n}$ that therefore has dimension $m n$.

Problem 1.8. Prove the following result: Let $X$ be a finite-dimensional normed linear space over the real field with basis $\left\{v_{1}, \ldots, v_{m}\right\}$. A sequence $\left\{x_{n}\right\}$, in $X$, with $x_{n}=\sum_{i=1}^{\mathrm{m}} \alpha_{i}^{n} v_{i}\left(\alpha_{i}^{n}\right.$ real $)$, converges to $x=\sum_{i=1}^{\mathrm{m}} \alpha_{i} v_{i}$ if and only if each coordinate sequence $\left\{\alpha_{i}^{n}\right\}$ converges to $\alpha_{i}$ for each $i=1, \ldots, m$. (It is sufficient to consider the case where $x=\underline{0}$.)

(i) Show that if $\left\{\alpha_{i}^{n}\right\} \rightarrow 0$ for all $i$, then $\left\{x_{n}\right\} \rightarrow \underline{0}$.

(ii) To prove the converse implication, suppose $\left\{x_{n}\right\} \rightarrow \underline{0}$, but for some $k$ the coordinate sequence $\left\{\alpha_{k}^{n}\right\}$ does not converge to 0 . Then there exists a subsequence of $\left\{x_{n}\right\}$ (for convenience of notation, still referred to as $\left\{x_{n}\right\}$ and some $r>0$ such that $\left|\alpha_{k}^{n}\right|>r$ for all $n$. For each $n \in \mathbb{N}$, write

$$
M_{n}=\max _{i}\left\{\left|\alpha_{i}^{n}\right| ; 1 \leq i \leq m\right\}
$$

and consider the sequence $\left\{y_{n}\right\}$, with $y_{n}=\frac{x_{n}}{M_{n}}$. Show that $\left\{y_{n}\right\} \rightarrow \underline{0}$.

(iii) Use the Bolzano-Weierstrass theorem to show that from $\left\{y_{n}\right\}$ we can choose a subsequence that converges coordinate-wise, but to a nonzero element. By the first part of the theorem, we have a contradiction.

Problem 1.9. Using the foregoing result and the completeness of $\mathbb{R}$, we will show that every finite-dimensional normed vector space over $\mathbb{R}$ is complete.

(i) First, show that if $\left\{x_{n}\right\}$ is Cauchy, then every coordinate sequence $\left\{\alpha_{i}^{n}\right\}$ is Cauchy. (Prove the contrapositive statement: If some coordinate sequence $\left\{\alpha_{k}^{n}\right\}$ is not Cauchy, then neither is $\left\{x_{n}\right\}$. Use the result in Problem 1.8.)

(ii) Using (i), Problem 1.8 again, and the completeness of $\mathbb{R}$, show that the desired result holds.

## Affine Subspaces

Lex $X$ be a vector space, and $V$ a (vector) subspace of $X$. A set $A$ of the form

$$
A=x^{0}+V=\left\{x \in X ; x=x^{0}+v, \text { where } x^{0} \in X \text { and } v \in V\right\}
$$

is an affine subspace of $X$ "parallel" to $V$.

If $A=x^{0}+V$ is an affine subspace of $X$, and $a_{1}, \ldots, a_{n}$ are vectors in $A$, then every linear combination of $a_{1}, \ldots, a_{n}$ is a vector of the form

$$
x=\sum_{i=1}^{n} \alpha_{i} a_{i}=\sum_{i=1}^{n} \alpha_{i}\left(x^{0}+v_{i}\right)=\left(\sum_{i=1}^{n} \alpha_{i}\right) x^{0}+\sum_{i=1}^{n} \alpha_{i} v_{i}
$$

where $v_{i} \in V$ for all $i$. As $V$ is a vector space, we have $v=\Sigma_{i=1}^{n} \alpha_{i} v_{i} \in V$. If, in addition, we have $\Sigma_{i=1}^{n} \alpha_{i}=1$, then $x=x^{0}+v$, and therefore $x \in A$. That is, a linear combination $\Sigma_{i=1}^{n} \alpha_{i} a_{i}$ of vectors in an affine subspace of $A$ belongs to $A$ if and only if $\Sigma_{i=1}^{n} \alpha_{i}=1$. A linear combination with this property is called an affine combination.

## 2. Linear Transformations

A function between two vector spaces is sometimes called a transformation. We now introduce an important class of transformations that, loosely speaking, preserve the algebraic structure of the set on which they are defined.

Definition 2.1. Linear transformation. Let $X$ and $Y$ be two vector spaces defined over the same field $F$. We say that a transformation $T: X \longrightarrow Y$ is linear if for all $x_{1}, x_{2} \in X$ and any $\alpha, \beta \in F$, we have

$$
T\left(\alpha x_{1}+\beta x_{2}\right)=\alpha T\left(x_{1}\right)+\beta T\left(x_{2}\right)
$$

This implies, of course, that

$$
T\left(x_{1}+x_{2}\right)=T\left(x_{1}\right)+T\left(x_{2}\right) \text { and } T\left(\alpha x_{1}\right)=\alpha T\left(x_{1}\right)
$$

That is, given any two vectors, the image of their sum under a linear function is equal to the sum of their images, and the image of the product of a scalar and a vector is equal to the scalar times the image of the vector. It is in this sense that we can say that a linear function preserves the algebraic structure of the vector space on which it is defined.

Problem 2.2. Show that for any linear function $T$, we have $T(\underline{0})=\underline{0}$.

We will denote by $L(X, Y)$ the set of all linear transformations from $X$ to $Y$. This is a function space (i.e., a set whose elements are functions). However, we can still think of each linear function as a vector when we define addition and multiplication by a scalar in the usual way for functions.

Given two linear transformations $T_{1}, T_{2} \in L(X, Y)$ and arbitrary scalars $\eta$ and $\gamma$, the function $T=\left(\eta T_{1}+\gamma T_{2}\right)$, defined by

$$
T(x)=\left(\eta T_{1}+\gamma T_{2}\right)(x)=\eta T_{1}(x)=\gamma T_{2}(x) \text { for each } x \in X
$$

maps $X$ into $Y$. Moreover, $\left(\eta T_{1}+\gamma T_{2}\right)$ is a linear transformation, for, given any two scalars $\alpha$ and $\beta$ and vectors $x_{1}$ and $x_{2}$ in $X$, we have (using the linearity of $T_{1}$ and $T_{2}$ )

$$
\begin{aligned}
T\left(\alpha x_{1}+\beta x_{2}\right) & =\left(\eta T_{1}+\gamma T_{2}\right)\left(\alpha x_{1}+\beta x_{2}\right)=\eta T_{1}\left(\alpha x_{1}+\beta x_{2}\right)+\gamma T_{2}\left(\alpha x_{1}+\beta x_{2}\right) \\
& =\eta\left[\alpha T_{1}\left(x_{1}\right)+\beta T_{1}\left(x_{2}\right)\right]+\gamma\left[\alpha T_{2}\left(x_{1}\right)+\beta T_{2}\left(x_{2}\right)\right] \\
& =\alpha\left[\eta T_{1}\left(x_{1}\right)+\gamma T_{2}\left(x_{1}\right)\right]+\beta\left[\eta T_{1}\left(x_{2}\right)+\gamma T_{2}\left(x_{2}\right)\right] \\
& =\alpha\left(\eta T_{1}+\gamma T_{2}\right)\left(x_{1}\right)+\beta\left(\eta T_{1}+\gamma T_{2}\right)\left(x_{2}\right)=\alpha T\left(x_{1}\right)+\beta T\left(x_{2}\right)
\end{aligned}
$$

It follows that if $T_{1}, T_{2} \in L(X, Y)$, then $\eta T_{1}+\gamma T_{2} \in L(X, Y)$. It is also obvious that the rest of the vector-space axioms are satisfied by $L(X, Y)$. For
instance, the zero vector is the linear transformation that assigns to any $x$ in $X$ the zero vector in $Y$. We have, then, the following theorem.

Theorem 2.3. Lex $\mathrm{X}$ and $\mathrm{Y}$ be two vector spaces defined over the same field. The set $\mathrm{L}(\mathrm{X}, \mathrm{Y})$ of linear transformations from $\mathrm{X}$ to $\mathrm{Y}$ is a vector space.

Hence, every linear combination of linear functions is a linear function. It is also easy to see that the composition of linear functions is linear.

The composition of two linear functions is defined in the standard way. Let $R: X \longrightarrow Y$ and $S: Y \longrightarrow Z$ be two linear transformations. Then the composite mapping $S \circ R=T: X \longrightarrow Z$ is defined, as for any two functions, by $T(x)=S[R(x)]$.

Problem 2.4. Show that the composition of two linear functions is linear.

## (a) Image and Kernel of a Linear Function

Definition 2.5. Given a linear function $T: X \longrightarrow Y$, its image (im) or range is the subset of $Y$ given by

$$
\operatorname{im} T=T(X)=\{y \in Y ; y=T(x) \text { for some } x \in X\}
$$

and its kernel or null space is the subset of $X$ given by

$$
\operatorname{ker} T=T^{-1}(\underline{0})=\{x \in X ; T(x)=\underline{0}\}
$$

In other words, $\operatorname{ker} T$ is the set of solutions to the homogeneous linear system $T(x)=\underline{0}$, and im $T$ is the set of vectors $y \in Y$ for which the system $T(x)$ $=y$ has at least one solution. We will now show that both $\operatorname{im} T$ and $\operatorname{ker} T$ are vector spaces, and we will prove an important result that relates the dimension of these two spaces to that of the vector space $X$ on which $T$ is defined.

Theorem 2.6. Given a linear transformation $\mathrm{T}: \mathrm{X} \longrightarrow \mathrm{Y}$, im $\mathrm{T}$ is a vector subspace of $\mathrm{Y}$. If $\mathrm{x}=\left\{\mathrm{x}_{1}, \ldots, \mathrm{x}_{\mathrm{n}}\right\}$ is a basis for $\mathrm{X}$, then $\left[\mathrm{T}\left(\mathrm{x}_{1}\right), \ldots, \mathrm{T}\left(\mathrm{x}_{\mathrm{n}}\right)\right\}$ spans im T.

Proof. Let $y_{1}$ and $y_{2}$ be vectors in $T(X)$. We want to show that $\alpha y_{1}+\beta y_{2} \in$ $T(X)$ for any scalars $\alpha$ and $\beta$. Because $y_{1}, y_{2} \in T(X)$, there exist $x_{1}, x_{2} \in X$ such that $T\left(x_{1}\right)=y_{1}$ and $T\left(x_{2}\right)=y_{2}$. As $X$ is a vector space, $\alpha x_{1}+\beta x_{2} \in X$, and by the linearity of $T$,

$$
T\left(\alpha x_{1}+\beta x_{2}\right)=\alpha T\left(x_{1}\right)+\beta T\left(x_{2}\right)=\alpha y_{1}+\beta y_{2}
$$

Hence, $\alpha y_{1}+\beta x_{2} \in T(X)$, and therefore $T(X)$ is a vector subspace of $Y$.

Consider an arbitrary vector $y=T(x)$ in $T(X)$, and let $\mathrm{x}=\left\{x_{1}, \ldots, x_{n}\right\}$ be a basis for $X$. Then $x \in X$ has a unique representation of the form $x=\sum_{i=1}^{n} \alpha_{i} x_{i}$. Using the linearity of $T$, we have

$$
y=T(x)=T\left(\sum_{i=1}^{n} \alpha_{i} x_{i}\right)=\sum_{i=1}^{n} \alpha_{i} T\left(x_{i}\right)
$$

Hence, any $T(x) \in \operatorname{im} T$ can be written as a linear combination of the images of the elements of a basis of $X$.

The rank of a family of vectors $\mathbb{V}=\left\{v_{1}, \ldots, v_{n}\right\}$ in a vector space $V$ is the size of the largest independent family of vectors contained in $\mathbb{v}$. If there are $r$ independent vectors in $\mathbb{v}$, they span a vector space of dimension $r$. Hence, the rank of $\left\{v_{1}, \ldots, v_{n}\right\}$ is also the dimension of the vector subspace formed by all the linear combinations of the vectors in $v$.

Given a linear transformation $T: X \longrightarrow Y$ and a basis for $X,\left\{x_{1}, \ldots, x_{n}\right\}$, the rank of $T$ is the dimension of its image space, im $T$. By Theorem 2.6, the rank of $T$ is equal to the number of linearly independent vectors in $\left\{T\left(x_{1}\right)\right.$, $\left.\ldots, T\left(x_{n}\right)\right\}$.

Theorem 2.7. Given a linear transformation $\mathrm{T}: \mathrm{X} \longrightarrow \mathrm{Y}$, ker $\mathrm{T}$ is a vector subspace of $\mathrm{X}$.

## Problem 2.8. Prove Theorem 2.7.

We conclude this section with a theorem which shows that there is a simple relationship among the dimensions of im $T$, ker $T$, and $X$ (the space on which $T$ is defined). In a later section we will consider the implications of this result for the dimension of the space of solutions to a system of linear equations.

Theorem 2.9. Let $\mathrm{X}$ be a finite-dimensional vector space, and $\mathrm{T}: \mathrm{X} \rightarrow \mathrm{Y}$ a linear transformation. Then $\operatorname{dim} \mathrm{X}=\operatorname{dim}(\operatorname{ker} \mathrm{T})+\operatorname{rank} \mathrm{T}$.

Proof. Put $\operatorname{dim} X=n, \operatorname{dim}(\operatorname{ker} T)=k$, and $\operatorname{rank} T=\operatorname{dim}(\operatorname{im} T)=r$. The theorem says, then, that $n=k+r$. Let $\left\{w_{1}, \ldots, w_{r}\right\}$ be a basis for im $T$, and $\left\{u_{1}, \ldots, u_{k}\right\}$ a basis for $\operatorname{ker} T$ (if the kernel is not equal to $\{\underline{0}\}$ ). Now, $w_{i} \in T(X)$, and therefore for each $w_{i}$ there exists some $v_{i} \in X$ such that $T\left(v_{i}\right)=w_{i}$. We will show that

$$
\mathbb{b}=\left\{v_{1}, \ldots, v_{r} ; u_{1}, \ldots, u_{k}\right\}
$$

is a basis for $X$, which establishes the theorem.

- First we show that $\mathbb{b}$ generates $X$. Let $x$ be an arbitrary vector in $X$. Because $\left\{w_{1}, \ldots, w_{r}\right\}$ is a basis for $T(X)$, there exist unique scalars $\alpha_{1}, \ldots, \alpha_{r}$ such that

$$
T(x)=\sum_{i=1}^{r} \alpha_{i} w_{i}=\sum_{i=1}^{r} \alpha_{i} T\left(v_{t}\right)
$$

By the linearity of $T$,

$$
T(x)=T\left(\sum_{i=1}^{r} \alpha_{i} v_{i}\right)
$$

and, again by linearity, subtracting the right- from the left-hand side in the preceding expression,

$$
T\left(x-\sum_{i=1}^{r} \alpha_{i} v_{i}\right)=\underline{0}
$$

Thus, $x-\Sigma_{i=1}^{r} \alpha_{i} v_{i} \in$ ker $T$, and because $\left\{u_{1}, \ldots, u_{k}\right\}$ is a basis for $\operatorname{ker} T$, there exist scalars $\beta_{1}, \ldots, \beta_{k}$ such that

$$
x-\sum_{i=1}^{r} \alpha_{i} v_{i}=\sum_{m=1}^{k} \beta_{m} u_{m} \Rightarrow x=\sum_{i=1}^{r} \alpha_{i} v_{i}+\sum_{m=1}^{k} \beta_{m} u_{m}
$$

In conclusion, any $x$ in $X$ has a representation as a linear combination of elements of $\mathbb{b}$; hence $\mathbb{b}$ spans $X$.

- To prove that $\mathrm{b}$ is a basis for $X$, it remains to show that it is a linearly independent family. Whether or not that is the case, there exist scalars $\gamma_{i}(i=1, \ldots, r)$ and $\eta_{m}(m=1, \ldots, k)$ such that

$$
\begin{equation*}
\sum_{i=1}^{r} \gamma_{i} v_{i}+\sum_{m=1}^{k} \eta_{m} u_{m}=\underline{0} \tag{1}
\end{equation*}
$$

What we want to show is that they must all be zero.

Applying $T$ to both sides of (1), we have

$$
\begin{equation*}
T\left(\sum_{i=1}^{r} \gamma_{i} v_{i}+\sum_{m=1}^{k} \eta_{m} u_{m}\right)=\sum_{t=1}^{r} \gamma_{t} T\left(v_{t}\right)+\sum_{m=1}^{k} \eta_{m} T\left(u_{m}\right)=\underline{0} \tag{2}
\end{equation*}
$$

Now, $u_{m} \in \operatorname{ker} T$, implying $T\left(u_{m}\right)=\underline{0}$ for all $m$, leaving us with

$$
\begin{equation*}
\sum_{i=1}^{r} \gamma_{i} T\left(v_{i}\right)=\sum_{i=1}^{r} \gamma_{i} w_{i}=\underline{0} \tag{3}
\end{equation*}
$$

But the $w_{i}$ 's are linearly independent by assumption, so $\gamma_{i}=0$ for all $i$, and (1) reduces to

$$
\begin{equation*}
\sum_{m=1}^{k} \eta_{m} u_{m}=\underline{0} \tag{4}
\end{equation*}
$$

Finally, the $u_{m}$ 's are also linearly independent by assumption. Hence, $\eta_{m}=0$ for all $m$, and we conclude that $\mathbb{b}=\left\{v_{1}, \ldots, v_{r} ; u_{1}, \ldots, u_{k}\right\}$ is a linearly independent family.

## (b) Inverse of a Linear Transformation

Definition 2.10. Inverse of a linear mapping. Let $T: X \longrightarrow Y$ be a linear mapping. We say that $T$ is invertible if there exists a mapping $S$ from $Y$ to $X$ such that

$$
\begin{aligned}
& \forall x \in X, S[T(x)]=x \Leftrightarrow S \circ T=I_{x} \quad \text { and } \\
& \forall y \in Y, T[S(y)]=y \Leftrightarrow T \circ S=I_{y}
\end{aligned}
$$

where $I_{x}$ and $I_{y}$ are the identity mappings in $X$ and $Y$, respectively (i.e., the functions that map each element in the corresponding space into itself).

The transformation $S$ is called the inverse of $T$ and is denoted $T^{-1}$. Clearly, if $T^{-1}$ is the inverse of $T$, then $T$ is the inverse of $T^{-1}$, and the relationships in the definition can be written

$$
T^{-1}[T(x)]=x \quad \text { and } \quad T\left[T^{-1}(y)\right]=y
$$

The following theorem shows that the inverse of a linear transformation is also a linear transformation.

Theorem 2.11. Let $\mathrm{T} \in \mathrm{L}(\mathrm{X}, \mathrm{Y})$ be an invertible linear function. Then the inverse map $\mathrm{T}^{-1}: \mathrm{Y} \longrightarrow \mathrm{X}$ is linear; that is, $\mathrm{T}^{-1} \in \mathrm{L}(\mathrm{Y}, \mathrm{X})$.

Problem 2.12. Prove Theorem 2.11.

Recall that a transformation $T: X \longrightarrow Y$ is said to be injective or one-toone if it does not map distinct elements of $X$ into the same vector in $Y$, that is, $T$ is one-to-one if

$$
\forall x, x^{\prime} \in X, x \neq x^{\prime} \Rightarrow T(x) \neq T\left(x^{\prime}\right)
$$

$T$ is said to be surjective or "onto" if $T(X)=Y$ (i.e., if its range is the entire set $Y$ ).

Clearly, a linear transformation $T: X \longrightarrow Y$ is invertible if and only if it is both injective and surjective, for the inverse mapping is a well-defined function if and only if for each $y$ in $Y$ there exists a unique $x$ in $X$ such that $T(x)=y$.

We conclude with a useful necessary and sufficient condition for a linear mapping to be one-to-one.

Theorem 2.13. A linear transformation $\mathrm{T}: \mathrm{X} \longrightarrow \mathrm{Y}$ is one-to-one if and only if $\mathrm{T}(\mathrm{x})=\underline{0} \Rightarrow \mathrm{x}=\underline{0}$, that is, if $\operatorname{ker} \mathrm{T}=\{\underline{0}\}$.

Problem 2.14. Prove Theorem 2.13. Hint: Recall that for any linear mapping $T$, we have $T(\underline{0})=\underline{0}$.

## 3. Isomorphisms

We will now show that two vector spaces of the same dimension are "equivalent" from an algebraic point of view. Two particular cases of this result are of special interest in practice:

(i) Every vector space of finite dimension $n$ defined over a field $F$, is equivalent to the space $V_{n}(F)$ defined in Example 1.3.

(ii) If $X$ and $Y$ are vector spaces defined over a field $F$, of finite dimensions $n$ and $m$, respectively, the vector space of linear transformations from $X$ to $Y$, $L(X, Y)$, is "equivalent" to the set of matrices of dimension $m \times n$ formed with elements of $F$.

Before getting into details, we need to make precise the notion of "equivalent" vector spaces.

Definition 3.1. Isomorphism and isomorphic vector spaces. Two vector spaces $X$ and $Y$ are isomorphic if there exists an invertible linear function (one-to-one and onto) from $X$ to $Y$.A function with these properties is called an isomorphism.

Two isomorphic vector spaces are practically the same for algebraic purposes, for there exists an invertible function from $X$ to $Y$ that preserves algebraic operations in both directions. In particular, if $T$ is an isomorphism from $X$ onto $Y$, given any two vectors $x_{1}$ and $x_{2}$ in $X$, there exist unique vectors $y_{1}$ and $y_{2}$ in $Y$ such that $y_{1}=T\left(x_{1}\right)$ and $y_{2}=T\left(x_{2}\right)$, and, vice versa, given any $y_{1}$, $y_{2} \in Y$, there exist unique elements of $X, x_{1}$ and $x_{2}$, such that $x_{1}=T^{-1}\left(y_{1}\right)$ and $x_{2}=T^{-1}\left(y_{2}\right)$. Because both $T$ and $T^{-1}$ are linear functions, we have, moreover,

$$
\begin{gathered}
T\left(\alpha x_{1}+\beta x_{2}\right)=\alpha T\left(x_{1}\right)+\beta T\left(x_{2}\right)=\alpha y_{1}+\beta y_{2} \\
T^{-1}\left(\alpha y_{1}+\beta y_{2}\right)=\alpha T^{-1}\left(y_{1}\right)+\beta T^{-1}\left(y_{2}\right)=\alpha x_{1}+\beta x_{2}
\end{gathered}
$$

and therefore $x=\alpha x_{1}+\beta x_{2}$ if and only if $T(x)=y=\alpha y_{1}+\beta y_{2}$.

We begin with a preliminary result.

Theorem 3.2. Let $\mathrm{X}$ and $\mathrm{Y}$ be two vector spaces defined over the same field $\mathrm{F}$, and let $\mathrm{X}=\left\{\mathrm{x}_{\mathrm{s}} \in \mathrm{X} ; \mathrm{s} \in \mathrm{S}\right\}$ be a Hamel basis for $\mathrm{X}$. Then a linear transformation $\mathrm{T}: \mathrm{X} \rightarrow \mathrm{Y}$ is completely defined by its value on $\mathrm{X}$, that is:

(i) Given an arbitrary family $\mathbb{y}=\left\{\mathrm{y}_{\mathrm{s}} \in \mathrm{Y} ; \mathrm{s} \in \mathrm{S}\right\}$ in $\mathrm{Y}$ with the same cardinal number as $\mathrm{X}$, there exists a linear transformation $\mathrm{T}: \mathrm{X} \longrightarrow \mathrm{Y}$ such that $\mathrm{T}\left(\mathrm{x}_{\mathrm{s}}\right)=$ $\mathrm{y}_{\mathrm{s}}$ for each $\mathrm{s}$.
(ii) This transformation is unique. That is, if two linear transformations from $\mathrm{X}$ to $\mathrm{Y}$, $\mathrm{T}$ and $\mathrm{R}$, coincide in $\mathbb{X}$ (i.e., $\mathrm{T}\left(\mathrm{x}_{\mathrm{s}}\right)=\mathrm{R}\left(\mathrm{x}_{\mathrm{s}}\right) \forall \mathrm{s} \in \mathrm{S}$ ), then they coincide for all $\mathbf{x} \in \mathbf{X}$.

## Proof

- Let $\mathrm{x}=\left\{x_{s} \in X ; s \in S\right\}$ be a Hamel basis for $X$, and $\mathbb{y}=\left\{y_{s} \in Y ; s \in S\right\}$ a family of vectors in $Y$ with the same cardinality as $\mathrm{x}$. We define the function $T$ from $\mathrm{x}$ onto y by

$$
T\left(x_{s}\right)=y_{s} \forall s \in S
$$

and extend it to the whole of $X$ in the following way: Given an arbitrary $x \in X$ with representation

$$
x=\sum_{s \in S^{\prime}} \alpha_{x} x_{s}
$$

(where the $\alpha_{s}^{\prime}$ s are scalars and $S^{\prime}$ is a finite subset of $S$ ), we define

$$
T(x)=\sum_{s \in S^{\prime}} \alpha_{s} T\left(x_{s}\right)=\sum_{s \in S^{\prime}} \alpha_{s} y_{s}
$$

The function $T: X \longrightarrow Y$ thus defined is linear. Given two vectors $x, y \in X$, with representations ${ }^{1}$

$$
x=\sum_{s \in S^{\prime}} \alpha_{s} x_{s} \quad \text { and } \quad y=\sum_{s \in S^{\prime}} \beta_{s} x_{s}
$$

and any two scalars $\delta$ and $\gamma$, we have

$$
\begin{aligned}
T(\gamma x+\delta y) & =T\left(\gamma \sum_{s \in S^{\prime}} \alpha_{s} x_{s}+\delta \sum_{s \in S^{\prime}} \beta_{s} x_{s}\right)=T\left(\sum_{s \in S^{\prime}}\left(\gamma \alpha_{s}+\delta \beta_{s}\right) x_{s}\right) \\
& =\sum_{s \in S^{\prime}}\left(\gamma \alpha_{s}+\delta \beta_{s}\right) T\left(x_{s}\right)=\gamma \sum_{s \in S^{\prime}} \alpha_{s} T\left(x_{s}\right)+\delta \sum_{s \in S^{\prime}} \beta_{s} T\left(x_{s}\right) \\
& =\gamma T(x)+\delta T(y)
\end{aligned}
$$

- Suppose $R$ and $T$ are two linear transformations such that

$$
T\left(x_{s}\right)=R\left(x_{s}\right) \forall s \in S
$$

Given an arbitrary $x \in X$, with representation $x=\Sigma_{s \in s} \alpha_{s} x_{s}$, we have, using the linearity of $T$ and $S$,

$$
T(x)=\sum_{s \in S^{\prime}} \alpha_{s} T\left(x_{s}\right)=\sum_{s \in S^{\prime}} \alpha_{s} R\left(x_{s}\right)=R(x)
$$

Theorem 3.3. Two vector spaces $\mathrm{X}$ and $\mathrm{Y}$ defined over the same field are isomorphic if and only if they have the same dimension.

## Proof

- Assume $T$ is an isomorphism from $X$ onto $Y$, and let $\mathrm{X}=\left\{x_{s} \in X ; s \in S\right\}$ be a Hamel basis for $X$. We will prove that $X$ and $Y$ have the same dimension by showing that $T(\mathrm{x})=\left\{T\left(x_{s}\right) \in Y ; x_{s} \in \mathrm{x}\right\}$ is a Hamel basis for $Y$.

For any finite subset $S^{\prime}$ of $S$, we have

$$
\sum_{s \in S^{\prime}} \alpha_{s} T\left(x_{s}\right)=\underline{0} \Rightarrow T\left(\sum_{s \in S^{\prime}} \alpha_{s} x_{s}\right)=\underline{0}
$$

by the linearity of $T$, and given that $T$ is invertible and therefore one-to-one and that $T(\underline{0})=\underline{0}, T(x)=\underline{0}$ implies $x=\underline{0}$; hence $\Sigma_{s \in S^{\prime}} \alpha_{s} x_{s}=\underline{0}$, and by the assumption that $\mathrm{x}$ is a linearly independent family,

$$
\sum_{s \in S^{\prime}} \alpha_{s} x_{s}=\underline{0} \Rightarrow \alpha_{s}=0 \forall s \in S^{\prime}
$$

implying that $T(\mathrm{x})=\left\{T\left(x_{s}\right) \in Y ; x_{s} \in \mathrm{x}\right\}$ is a linearly independent family of vectors in $Y$.

Next, we show that $T(\mathrm{x})$ spans $Y$. Let $y$ be an arbitrary vector in $Y$. Because $T$ maps $X$ onto $Y$, there exists some $x \in X$ such that $T(x)=y$. The vector $x$ has a representation of the form

$$
x=\sum_{s \in S^{\prime}} \alpha_{s} x_{s}
$$

where $S^{\prime}$ is a finite subset of $S$. By the linearity of $T$, we can write $y$ as

$$
y=T(x)=T\left(\sum_{s \in S^{\prime}} \alpha_{s} x_{s}\right)=\sum_{s \in S^{\prime}} \alpha_{s} T\left(x_{s}\right)
$$

and it follows that every $y \in Y$ can be written as a linear combination of a finite number of elements of $T(\mathrm{x})$, which is therefore a Hamel basis for $Y$.

- Conversely, suppose that $X$ and $Y$ have the same dimension, and let $\mathbb{X}=\left\{x_{s} \in X\right.$; $s \in S\}$ and $\mathrm{y}=\left\{y_{s} \in Y ; s \in S\right\}$ be Hamel bases for the two spaces. ${ }^{2}$ Define the function $T$ from $\mathrm{x}$ onto $y$ by $T\left(x_{s}\right)=y_{s}$ for each $x_{s} \in \mathrm{x}$, and by $T(x)=\Sigma_{s \in s} \alpha_{s} T\left(x_{s}\right)$ for an arbitrary $x=\Sigma_{s \in S} \alpha_{s} x_{s}$ in $X$. By the preceding theorem, this function is linear, so we only have to establish its invertibility.

Suppose two vectors $x^{\prime}=\Sigma_{s \in S^{\prime}} \alpha_{s} x_{s}$ and $x^{\prime \prime}=\Sigma_{s \in S^{\prime}} \beta_{s} x_{s}$ have the same image under $T$. Then

$$
T\left(x^{\prime}\right)=T\left(x^{\prime}\right) \Rightarrow \sum_{s \in S^{\prime}} \alpha_{s} T\left(x_{s}\right)=\sum_{s \in S^{\prime}} \beta_{s} T\left(x_{s}\right) \Rightarrow \sum_{s \in S^{\prime}}\left(\alpha_{s}-\beta_{s}\right) y_{s}=\underline{0}
$$

from which $\alpha_{s}-\beta_{\mathrm{s}}=0$ for all $s \in S^{\prime}$, by the linear independence of the family $\mathbb{y}$. Hence, $T\left(x^{\prime}\right)=T\left(x^{\prime \prime}\right)$ implies $x^{\prime}=x^{\prime \prime}$, and $T$ is one-to-one. Finally, we know that $T(X)$ is a vector subspace of $Y$ spanned by $T(\mathrm{x})$ (Theorem 2.6). Because $T(\mathrm{x})=$ y, which is a Hamel basis for $Y$, we have $T(X)=Y$, that is, $T$ maps $X$ onto $Y$. In conclusion, $T$ is an isomorphism.

Let $X$ be a vector space of finite dimension $n$ defined over a field $F$. The simplest $n$-dimensional vector space defined over $F$ is $V_{n}(F)$. The preceding result assures us that $X$ and $V_{n}(F)$ are isomorphic. We will now verify directly that this is true. Along the way we will see what the isomorphism looks like and introduce the concept of coordinates.

If $X$ is an $n$-dimensional vector space, then it has a basis formed by $n$ vectors, $\mathbb{V}=\left\{v_{1}, \ldots, v_{n}\right\}$, and every $x \in X$ has a unique representation as a linear combination of the elements of $v$; that is, there exist unique scalars $\alpha_{1}, \ldots, \alpha_{n}$ such that

$$
x=\sum_{i=1}^{n} \alpha_{i} v_{i}
$$

We say that $\alpha_{i}$ is the $i$ th coordinate of $x$ in basis $\mathrm{v}$. We can now define a function, $\operatorname{crd}_{v}: X \rightarrow V_{n}(F)$, that assigns to each $x \in X$ its vector of coordinates in basis $\mathbb{v}$ :

$$
\operatorname{crd}_{\mathrm{v}}(x)=\underline{\alpha}=\left(\alpha_{1}, \ldots, \alpha_{n}\right)
$$

The function $\mathrm{crd}_{\mathrm{v}}$ is one-to-one because two vectors are equal if and only if they have the same coordinates, and it is onto because, given any $\underline{\alpha}=\left(\alpha_{1}, \ldots, \alpha_{n}\right)$ in $V_{n}(F)$, the linear combination $\Sigma_{i=1}^{n} \alpha_{i} v_{i}$ is a vector in $X$. Finally, $\operatorname{crd}_{v}$ is a linear function because, given arbitrary vectors $x, y \in X$, with coordinates $\underline{\alpha}$ and $\underline{\beta}$, respectively, and scalars $\gamma$ and $\eta$, we have

$$
\gamma x+\eta y=\gamma\left(\sum_{i=1}^{n} \alpha_{i} v_{i}\right)+\eta\left(\sum_{i=1}^{n} \beta_{i} v_{i}\right)=\sum_{i=1}^{n}\left(\gamma \alpha_{i}+\eta \beta_{i}\right) v_{i}
$$

and therefore

$$
\operatorname{crd}_{v}(\gamma x+\eta y)=\gamma \underline{\alpha}+\eta \underline{\beta}=\gamma \operatorname{crd}_{v}(x)+\eta \operatorname{cdr}_{\mathrm{v}}(y)
$$

We have proved the following theorem.

Theorem 3.4. Every vector space of dimension $\mathrm{n}<\infty$ defined over a field $\mathrm{F}$ is isomorphic to $\mathrm{V}_{\mathrm{n}}(\mathrm{F})$.

## Matrix Representation of a Linear Function

We have seen that the set $L(X, Y)$ of linear transformations between vector spaces is itself a vector space. We have also seen that the space $F_{m \times n}$ of $m \times n$ matrices defined over a field $F$ is also a vector space. It is easy to show that if $M$ is a matrix in $F_{m \times n}$, the function $L_{M}: V_{n}(F) \longrightarrow V_{m}(F)$, defined for all $x$ in $V_{n}(F)$ by $L_{M}(x)=M x$, is linear. We will now prove the converse result: With every linear transformation $T$ between finite-dimensional vector spaces we can associate a matrix that, given bases for $X$ and $Y$, represents $T$ in a natural sense and is unique. We will also see that the function $M t x_{\mathrm{w}, \mathrm{v}}: L(X, Y) \longrightarrow F_{m \times n}$ that assigns to a linear transformation in $L(X, Y)$ its matrix representation, given bases $v$ and $w$ for $X$ and $Y$, respectively, is an isomorphism. This implies that, for many purposes, the theory of linear mappings between finite-dimensional spaces reduces to the study of matrices.

Let $T: X \longrightarrow Y$ be a linear transformation between finite-dimensional vector spaces $(\operatorname{dim} X=n, \operatorname{dim} Y=m)$ defined over a field $F$. We fix bases $\mathbb{v}=\left\{v_{1}, \ldots, v_{n}\right\}$ for $X$ and $\mathbb{w}=\left\{w_{1}, \ldots, w_{m}\right\}$ for $Y$ and form the matrix $M_{T}$, with

$$
\operatorname{col}_{i}\left(M_{T}\right)=\operatorname{crd}_{\mathrm{w}}\left(T\left(v_{i}\right)\right)
$$

Let $x$ be a vector in $X$, with $\operatorname{crd}_{\mathrm{v}}(x)=\underline{\alpha}$. Using the linearity of $\operatorname{crd}()$ and $T$, we have

$$
\begin{aligned}
M_{T} \operatorname{crd}_{\mathrm{v}}(x) & =\left[\operatorname{crd}_{\mathrm{w}}\left(T\left(v_{1}\right)\right), \ldots, \operatorname{crd}_{\mathrm{w}}\left(T\left(v_{n}\right)\right)\right]\left[\begin{array}{l}
\alpha_{1} \\
\ldots \\
\alpha_{n}
\end{array}\right]=\sum_{i=1}^{n} \alpha_{i} \operatorname{crd}_{\mathrm{w}}\left(T\left(v_{i}\right)\right) \\
& =\operatorname{crd}_{\mathrm{w}}\left(\sum_{i=1}^{n} \alpha_{i} T\left(v_{i}\right)\right)=\operatorname{crd}_{\mathrm{w}}\left(T\left(\sum_{i=1}^{n} \alpha_{i} v_{l}\right)\right)=\operatorname{crd}_{\mathrm{w}}(T(x))
\end{aligned}
$$

Hence, the matrix $M_{T}$ is such that for each $x$ in $X$,

$$
\operatorname{crd}_{\mathrm{w}}(T(x))=M_{T} \operatorname{crd}_{v}(x)
$$

That is, given bases for $X$ and $Y$, the (coordinate vector in basis $w$ of the) image of $x$ under $T$ is simply the product of the matrix $M_{T}$ and (the coordinate vector in basis $\mathbb{v}$ of) the vector $x$. Thus, we say that $M_{T}$ is the matrix representation of $T$ given bases $\mathbb{v}$ and $\mathbb{w}$ for $X$ and $Y$, respectively.

We now define a function $M t x_{w, v}: L(X, Y) \longrightarrow F_{m \times n}$ by

$$
\operatorname{Mtx}_{\mathrm{w}, \mathrm{v}}(T)=M_{T} \text { s.th. } \operatorname{col}_{i}\left(M_{T}\right)=\operatorname{crd}_{w}\left(T\left(v_{i}\right)\right)
$$

where $v_{i}$ is the $i$ th element of $\mathbb{v}$ (a basis for $X$ ).

It is easy to see that $M t x_{\mathrm{w}, \mathrm{Y}}(T)$ is a linear function. Let $S$ and $T$ be two linear transformations, and $M_{T}$ and $M_{S}$ their matrix representations. For each $x \in X$ we have, then,

$$
\begin{equation*}
\operatorname{crd}_{\mathrm{w}}(T(x))=M_{T} \operatorname{crd}_{\mathrm{v}}(x) \text { and } \operatorname{crd}_{\mathrm{w}}(S(x))=M_{S} \operatorname{crd}_{\mathrm{v}}(x) \tag{1}
\end{equation*}
$$

Using the linearity of $\operatorname{crd}($ ) and (1),

$$
\begin{aligned}
& \operatorname{crd}_{\mathrm{w}}((\alpha T+\beta S)(x))=\operatorname{crd}_{\mathrm{w}}(\alpha T(x)+\beta S(x))=\alpha \operatorname{crd}_{\mathrm{w}}(T(x))+\beta \operatorname{crd}_{\mathrm{w}}(S(x)) \\
& \quad=\alpha M_{T} \operatorname{crd}_{\mathrm{v}}(x)+\beta M_{S} \operatorname{crd}_{\mathrm{v}}(x)=\left(\alpha M_{T}+\beta M_{S}\right) \operatorname{crd}_{\mathrm{v}}(x)
\end{aligned}
$$

which shows that $\alpha M_{T}+\beta M_{S}$ is the matrix representation of $\alpha T+\beta S$ for the given bases; that is,

$$
M t x_{\mathrm{w}, \mathrm{v}}(\alpha T+\beta S)=\alpha M t x_{\mathrm{w}, \mathrm{v}}(T)+\beta M t x_{\mathrm{w}, \mathrm{v}}(S)
$$

Two linear transformations $S$ and $T$ have the same matrix representation if and only if they coincide in $\mathbb{v}$, that is, $S\left(v_{i}\right)=T\left(v_{i}\right)$ for all $v_{i} \in \mathbb{V}$. But then $S=T$ (Theorem 3.2), so $M t x_{\mathrm{w}, \mathrm{v}} T=M t x_{\mathrm{w}, \mathrm{v}} S$ implies $S=T$, and therefore $M t x$ is oneto-one. Finally, given an arbitrary matrix $M \in F_{m \times n}$ and bases $\mathbb{V}=\left\{v_{1}, \ldots, v_{n}\right\}$ for $X$ and $\mathbb{w}=\left\{w_{1}, \ldots, w_{m}\right\}$ for $Y$, there exists a linear transformation $L_{M}$ from $X$ to $Y$ such that $\operatorname{crd}_{\mathrm{w}}\left(L_{M}\left(v_{i}\right)\right)=\operatorname{col}_{i}(M)$ (Theorem 3.2). Hence, with each matrix in $F_{m \times n}$ we can associate a linear function from $X$ to $Y$; that is, $M t x$ maps $F_{m \times n}$ onto $L(X, Y)$. In conclusion, we have the following theorem.

Theorem 3.5. Let $\mathrm{X}$ and $\mathrm{Y}$ be vector spaces defined over the same field $\mathrm{F}$, with dimensions $\mathrm{n}$ and $\mathrm{m}$, respectively (both finite). Then $\mathrm{L}(\mathrm{X}, \mathrm{Y})$ is isomorphic to $\mathrm{F}_{\mathrm{m} \times \mathrm{n}}$.

## 4. Linear Mappings between Normed Spaces

We now consider linear transformations between normed linear spaces. As may be expected, the algebraic properties of linear maps simplify the study of their continuity. Our first result says that a linear function is either always continuous or always discontinuous. Hence, to check its global continuity, it is sufficient to check local continuity at some convenient point, usually the zero vector. The reason for this is that given a linear transformation $T: X \longrightarrow Y$ and two points $x$ and $y \in X$, linearity implies that $T(x)-T(y)=$ $T(x-y)$. It follows that if $X$ and $Y$ are normed spaces, the distance between $T(x)$ and $T(y)$ depends only on the distance between $x$ and $y$, not on the locations of these points.

Theorem 4.1. Let $\mathrm{X}$ and $\mathrm{Y}$ be normed vector spaces, and $\mathrm{T}$ a linear mapping $\mathrm{X} \longrightarrow \mathrm{Y}$. If $\mathrm{T}$ is continuous at some point $\mathrm{x}^{\prime} \in \mathrm{X}$, then it is (uniformly) continuous everywhere on $\mathrm{X}$.

Proof. Suppose $T$ is continuous at some $x^{\prime} \in X$, and fix some $\varepsilon>0$. By continuity at $x^{\prime}$, there exists some $\delta>0$ such that

$$
\left\|T\left(y^{\prime}\right)-T\left(x^{\prime}\right)\right\|<\varepsilon \forall y^{\prime} \in \beta_{\delta}\left(x^{\prime}\right)
$$

Now consider some other point $x^{\prime \prime}=x^{\prime}+\Delta \in X$. Then $y^{\prime \prime}=y^{\prime}+\Delta \in B_{\delta}\left(x^{\prime \prime}\right)$ if and only if $y^{\prime} \in B_{\delta}\left(x^{\prime}\right)$ and

$$
T\left(y^{\prime \prime}\right)-T\left(x^{\prime \prime}\right)=T\left(y^{\prime}+\Delta\right)-T\left(x^{\prime}+\Delta\right)=T\left(y^{\prime}-x^{\prime}\right)=T\left(y^{\prime}\right)-T\left(x^{\prime}\right)
$$

Hence, for any $y^{\prime \prime} \in B_{\delta}\left(x^{\prime \prime}\right)$ we have $\left\|T\left(y^{\prime \prime}\right)-T\left(x^{\prime \prime}\right)\right\|<\varepsilon$, and we conclude that $T$ is continuous at $x^{\prime \prime}$.

Note that for give $\varepsilon$, the same $\delta$ will work everywhere. Hence, a continuous linear function is uniformly continuous.

We shall now establish a useful characterization of continuity for linear functions.

Definition 4.2. Bounded linear transformation. Let $T$ be a linear transformation between two normed linear spaces, $X$ and $Y$. We say that $T$ is bounded if there exists some real number $B$ such that

$$
\forall x \in X,\|T x\| \leq B\|x\|
$$

that is, if $T$ maps bounded sets in $X$ into bounded sets in $Y$.

For linear functions, boundedness turns out to be equivalent to continuity.

Theorem 4.3. Let $\mathrm{X}$ and $\mathrm{Y}$ be normed vector spaces. A linear function $\mathrm{T}: \mathrm{X}$ $\longrightarrow \mathrm{Y}$ is continuous if and only if is bounded.

## Proof

- First, we show that a bounded mapping is continuous at 0 and therefore everywhere. If $T$ is bounded, then there exists some $B>0$ such that $\|T x\| \leq B\|x\|$ for all $x \in X$. Fix an arbitrary $\varepsilon>0$, and put $\delta=\varepsilon / B$ in the definition of continuity. Then, for any $x$ with $\|x\|<\delta$, we have

$$
\|T x\| \leq B\|x\|<B \delta=\varepsilon
$$

- To prove the second part of the theorem, we will show that if $T$ is not bounded, then it cannot be continuous. If $T$ is not bounded, then for each $n \in \mathbb{N}$ we can find some $x_{n} \in X$ such that

$$
\left\|T x_{n}\right\|>n\left\|x_{n}\right\|
$$

By the linearity of $T$ and the defining properties of the norm, this implies

$$
\frac{1}{n\left\|x_{n}\right\|}\left\|T\left(x_{n}\right)\right\|=\left\|\frac{1}{n\left\|x_{n}\right\|} T\left(x_{n}\right)\right\|=\left\|T\left(\frac{x_{n}}{n\left\|x_{n}\right\|}\right)\right\|>1
$$

Now, the normalized vectors $x_{n} /\left\|x_{n}\right\|$ all have norm 1, implying that the sequence $\left\{x_{n} /\left(n\left\|x_{n}\right\|\right)\right\}$ converges to $\underline{0}$. By the preceding expression, however, the sequence $\left\{T\left(x_{n} /\left(n\left\|x_{n}\right\|\right)\right)\right\}$ does not converge to $T(\underline{0})=\underline{0}$, implying that $T$ is not continuous. $\square$

The second part of the proof suggests a method for establishing that a given linear function $T$ is discontinuous: We can try to find a sequence $\left\{x_{n}\right\}$ converging to $\underline{0}$, with $\left\{T\left(x_{n}\right)\right\} \nrightarrow \underline{0}$.

Problem 4.4. We will prove the following theorem: Given normed linear spaces $X$ and $Y$ and a linear function $T: X \longrightarrow Y$, the inverse function $T^{-1}$
exists and is a continuous linear mapping on $T(X)$ if and only if there exists some $m>0$ such that $m\|x\| \leq\|T x\|$.

(i) Using Theorem 2.13, show that if there exists some $m>0$ such that $m\|x\| \leq\|T x\|$, then $T$ is one-to-one (and therefore invertible on $T(X)$ ).

(ii) Use Theorem 4.3 to show that $T^{-1}$ is continuous on $T(X)$.

(iii) Using Theorem 4.3, show that if $T^{-1}$ is continuous on $T(X)$, then there exists some $m>0$ such that $m\|x\| \leq\|T x\|$.

Theorem 4.5. A linear function from a finite-dimensional normed vector space into a normed vector space is continuous.

Proof. Let $T$ be a linear function from a finite-dimensional normed vector space $X$, with basis $\mathbb{V}=\left\{v_{1}, \ldots, v_{m}\right\}$, into a normed vector space $Y$. We will prove that $T$ is continuous at $\underline{0}$ by showing that given any sequence $\left\{x_{n}\right\}$ of vectors in $X$ with limit $\underline{0}$, the image sequence $\left\{T x_{n}\right\}$ converges to $T(\underline{0})=\underline{0}$ in $Y$. Each $x_{n}$ has a representation of the form

$$
x_{n}=\sum_{i=1}^{m} \alpha_{i}^{n} v_{i}
$$

where $\alpha_{i}^{n}$ is a scalar. We know that in any finite-dimensional normed linear space, convergence is equivalent to coordinate-wise convergence, that is, $\left\{x_{n}\right\} \rightarrow \underline{0}$ if and only if $\left\{\alpha_{i}^{n}\right\} \rightarrow 0$ for all $i=1, \ldots, m$ (see Problem 1.8). Now, for each $n$ we have

$$
0 \leq\left\|T\left(x_{n}\right)\right\|=\left\|T\left(\sum_{i=1}^{m} \alpha_{i}^{n} v_{i}\right)\right\|=\left\|\sum_{i=1}^{m} \alpha_{i}^{n} T\left(v_{i}\right)\right\| \leq \sum_{i=1}^{m} \mid \alpha_{i}^{n}\|\| T\left(v_{i}\right) \|
$$

And because $\left|\alpha_{i}^{n}\right| \rightarrow 0$ for all $i$, we have $\left\|T\left(x_{n}\right)\right\| \rightarrow 0$ or, equivalently, $\left\{T x_{n}\right\} \rightarrow \underline{0}$.

(a) Linear Homeomorphisms

Given normed linear spaces $X$ and $Y$, a linear mapping $T: X \longrightarrow Y$ is a topological isomorphism (or linear homeomorphism) if it is also a homeomorphism, that is, if it is continuous and invertible and has a continuous inverse. If there exists such a mapping between $X$ and $Y$, we say that these two spaces are topologically isomorphic.

A linear homeomorphism is both a homeomorphism and an isomorphism. Hence, topologically isomorphic spaces are "equivalent" both in a topological sense and in an algebraic sense, because the mapping preserves closed and open sets and the convergence of sequences, as well as algebraic operations in both directions.

Given an $m$-dimensional normed linear space $X$ defined over $\mathbb{R}$ with basis
$\mathbb{v}$, we have seen that the coordinate mapping $\operatorname{crd}_{\mathrm{v}}: X \rightarrow \mathbb{R}^{\mathrm{m}}$ that assigns to each $x \in X$ its vector of coordinates in basis $\mathrm{v}$ is an isomorphism (i.e., a linear and invertible function). Because $X$ and $V_{n}(F)$ are finite-dimensional spaces, both the coordinate mapping and its inverse are continuous. It follows that $\mathrm{crd}_{\mathrm{v}}$ is a linear homeomorphism, and we have the following theorem.

Theorem 4.6. All $\mathrm{m}$-dimensional normed linear spaces over $\mathbb{R}$ are topologically isomorphic to $\mathrm{E}^{\mathrm{m}}=\left(\mathbb{R}^{\mathrm{m}},\|\cdot\|_{\mathrm{E}}\right)$.

Hence, for most purposes, the study of finite-dimensional vector spaces reduces to the study of $\mathbb{R}^{\mathrm{m}}$.

## (b) The Norm of a Linear Mapping

Let $X$ and $Y$ be two vector spaces. We have seen that the set $L(X, Y)$ of linear transformations from $X$ to $Y$ is a vector space. If $X$ and $Y$ are normed spaces, it seems natural to ask whether or not we can define a norm over $L(X, Y)$, that is, whether or not we can make $L(X, Y)$ into a normed space. While there is no "natural" way to define the "size" of a mapping, we can try defining the norm of a linear transformation $T$ in terms of what it does to the norm of vectors. Thus, we write

$$
\begin{equation*}
\|T\|=\sup \left\{\frac{\|T(x)\|}{\|x\|} ; x \in X \text { and } x \neq \underline{0}\right\} \tag{1}
\end{equation*}
$$

Note that the symbol $\|\cdot\|$ has three different meanings in this expression: $\|x\|$ is the norm of a vector in $X,\|T(x)\|$ is the norm of a vector in $Y$, and $\|T\|$ is the "norm" (we still have to prove that it is really a norm) of a linear mapping. Intuitively, the ratio $\|T(x)\| /\|x\|$ tells us by how much the application of $T$ to a vector $x$ will increase or decrease its length, and we define the norm of $T$ as the largest such ratio we can find.

To make sure that the supremum in (1) exists, we have to restrict $\|\cdot\|$ to a subset of $L(X, Y)$. Recall that a linear function $T$ is bounded if there exists some $B>0$ such that $\|T x\| \leq B\|x\|$ for all $x$. If $T$ is bounded, the smallest such $B$ is its norm. Hence, we will define $\|\cdot\|$ on the set $B(X, Y)$ of bounded (i.e., continuous) linear functions from $X$ to $Y$.

From the definition of $\|\cdot\|$, we see immediately that for any $T$ in $B(X, Y)$ and any vector $x$ in $X$, we have

$$
\begin{equation*}
\|T\| \geq \frac{\|T x\|}{\|x\|} \Rightarrow\|T x\| \leq\|T\|\|x\| \tag{2}
\end{equation*}
$$

Theorem 4.7. Let $\mathrm{T}: \mathrm{X} \longrightarrow \mathrm{Y}$ be a bounded linear mapping, and $\mathrm{x}$ an arbitrary vector in $\mathrm{X}$. Then $\|\mathrm{T}(\mathrm{x})\| \leq\|\mathrm{T}\|\|\mathrm{x}\|$.

Using the defining properties of the norm (in $Y$ ) and the linearity of $T$, we see that

$$
\frac{1}{\|x\|}\|T(x)\|=\left\|\frac{1}{\|x\|} T(x)\right\|=\left\|T\left(\frac{x}{\|x\|}\right)\right\|
$$

Hence, we can write (note that $x /\|x\|$ has norm 1)

$$
\begin{aligned}
\|T\| & =\sup \left\{\frac{\|T x\|}{\|x\|} ; x \in X, x \neq \underline{0}\right\}=\sup \{\|T x\| ; x \in X,\|x\|=1\} \\
& ={ }^{3} \sup \{\|T x\| ; x \in X,\|x\| \leq 1\}
\end{aligned}
$$

We want to show that $(B(X, Y),\|\cdot\|)$ is a normed vector space. The first part of the proof is immediate: Because any linear combination of continuous linear functions is linear and continuous, $B(X, Y)$ is a vector subspace of $L(X, Y)$. It remains only to show that $\|\cdot\|$ is a norm in $B(X, Y)$. Clearly, $\|T\| \geq 0$ for any $T \in B(X, Y)$, because it is defined as the supremum of a set of nonnegative numbers. Moreover, for any scalar $\alpha$,

$$
\begin{aligned}
\|\alpha T\| & =\sup \{\|\alpha T(x)\| ;\|x\|=1\}=\sup \{\mid \alpha\|T(x)\| ;\|x\|=1\} \\
& =|\alpha| \sup \{\|T(x)\| ;\|x\|=1\}=|\alpha|\|T\|
\end{aligned}
$$

Next, we check that the triangle inequality holds. For any $T_{1}$ and $T_{2}$ in $B(X, Y)$,

$$
\begin{aligned}
\left\|T_{1}+T_{2}\right\| & =\sup \left\{\left\|T_{1}(x)+T_{2}(x)\right\| ;\|x\|=1\right\} \leq \sup \left\{\left\|T_{1}(x)\right\|+\left\|T_{2}(x)\right\| ;\|\mathrm{x}\|=1\right\} \\
& \leq \sup \left\{\left\|T_{1}(x)\right\| ;\|x\|=1\right\}+\sup \left\{\left\|T_{2}(x)\right\| ;\|x\|=1\right\}=\left\|T_{1}\right\|+\left\|T_{2}\right\|
\end{aligned}
$$

Finally, suppose $\|T\|=0$; by (2), we have

$$
\|T(x)\| \leq\|T\|\|x\|=0 \text { for any } x
$$

and so $T(x)=\underline{0}$ for all $x$. Thus $\|T\|=0$ only for the function $T_{0}$ that maps every $x$ in $X$ into the zero element of $Y$ - that is, for the zero vector in $L(X$, $Y)$. With this, we have verified that $\|\cdot\|$ satisfies all the defining properties of a norm, proving the following result:

Theorem 4.8. Let $\mathrm{X}$ and $\mathrm{Y}$ be normed vector spaces. Then the set $\mathrm{B}(\mathrm{X}, \mathrm{Y})$ of bounded linear mappings from $\mathrm{X}$ into $\mathrm{Y}$, with the norm defined earlier, is a normed vector space.

Given two finite-dimensional vector spaces $X$ and $Y$ over $\mathbb{R}$, with bases $\mathrm{v}$ and $\mathrm{w}$, we have seen that $L(X, Y)$ and $B(X, Y)$ coincide and that the function $M t x_{\mathrm{w}, \mathrm{v}}: L(X, Y) \longrightarrow \mathbb{R}_{m \times n}$ is an isomorphism. Next, we define a norm on $\mathbb{R}_{m \times n}$ by thinking of a matrix as an $m n$ vector and using the Euclidean norm; that is, for $A=\left[a_{i k}\right]$ with $i=1, \ldots, m$ and $k=1, \ldots, n$, we write

$$
\|A\|=\sqrt{\sum_{i=1}^{m} \sum_{k=1}^{n} \alpha_{i k}^{2}}
$$

Then Theorem 4.5 implies that $\operatorname{Mtx}(\mathrm{)}$ is also a homeomorphism. Hence the theory of linear transformations between finite-dimensional vector spaces reduces, for most purposes, to the study of matrices.

(c) The Normed Vector Space $\mathbf{L}\left(\mathbb{R}^{m}, \mathbb{R}^{m}\right)$

Because $\mathbb{R}^{\mathrm{n}}$ and $\mathbb{R}^{\mathrm{m}}$ (equipped with the Euclidean norm) are finitedimensional normed vector spaces, linear transformations in $L\left(\mathbb{R}^{\mathrm{n}}, \mathbb{R}^{\mathrm{m}}\right)$ are continuous (Theorem 4.5) and therefore bounded (Theorem 4.3). It follows that $L\left(\mathbb{R}^{\mathbf{n}}, \mathbb{R}^{\mathrm{m}}\right)$, equipped with the norm defined in the preceding section, is a normed vector space. In the remainder of this section we will study some properties of this space, concentrating on some results that will be needed in connection with the development of differential calculus in the next chapter.

In general, there is no practical way to compute the norm of a linear mapping. The following result, however, gives us some useful bounds for linear transformations in $L\left(\mathbb{R}^{\mathbf{n}}, \mathbb{R}^{\mathbf{m}}\right)$.

Theorem 4.9. Let $\mathrm{T} \in \mathrm{L}\left(\mathbb{R}^{n}, \mathbb{R}^{m}\right)$ be a linear mapping, with standard matrix representation (i.e., relative to the canonical bases) $\mathrm{A}=\left[\mathrm{a}_{\mathrm{ik}}\right]$, with $\mathrm{i}=1, \ldots, \mathrm{m}$ and $\mathrm{k}=1, \ldots, \mathrm{n}$. Let $\mu$ be the absolute value of the dominant element of $\mathrm{A}$,

$$
\begin{equation*}
\mu=\max _{\mathrm{ik}}\left\{\left|\mathrm{a}_{\mathrm{ik}}\right| ; \mathrm{i}=1, \ldots \mathrm{m}, \mathrm{k}=1, \ldots \mathrm{n}\right\} \tag{1}
\end{equation*}
$$

We have, then,

$$
\mu \leq\|\mathrm{T}\| \leq \mu \sqrt{\mathrm{mn}}
$$

## Proof

- Given the standard bases in $\mathbb{R}^{\mathrm{n}}$ and $\mathbb{R}^{\mathrm{m}}, T$ is represented by an $m \times n$ matrix, $A=\left[a_{i k}\right]$. The image of a vector $x, T(x) \in \mathbb{R}^{\mathrm{m}}$, is the vector $y=A x$ whose $i$ th component is given by

$$
y_{i}=\sum_{k=1}^{n} a_{i k} x_{k}
$$

By the Cauchy-Schwarz inequality and the definition of $\mu$ in (1), we have

$$
\begin{equation*}
\left|y_{i}\right|=\left|\sum_{k=1}^{n} a_{i k} x_{k}\right| \leq \sqrt{\sum_{k=1}^{n} a_{i k}^{2}} \sqrt{\sum_{k=1}^{n} x_{k}^{2}}=\sqrt{\sum_{k=1}^{n} a_{i k}^{2}}\|x\| \leq \sqrt{n \mu^{2}}\|x\|=\mu \sqrt{n}\|x\| \tag{2}
\end{equation*}
$$

for each $i$. Then

$$
\|T(x)\|=\|y\|=\sqrt{\sum_{i=1}^{m} y_{i}^{2}} \leq \sqrt{m n \mu^{2}\|x\|^{2}}=\mu \sqrt{m n}\|x\|
$$

Finally, using the definition of the norm of a linear mapping, we observe that because $\mu \sqrt{m n}$ is an upper bound of $\|T(x)\|$ for any $x$ with $\|x\|=1$, we have

$$
\|T\|=\sup \left\{\|T(x)\| ; x \in \mathbb{R}^{\mathrm{n}},\|x\|=1\right\} \leq \mu \sqrt{m n}
$$

- To get the lower bound on $\|T\|$, we consider what $T$ does to the standard coordinate vectors in $\mathbb{R}^{\mathrm{n}}$. Let $e^{k}=(0,0, \ldots, 1, \ldots, 0)$ be the $k$ th unit vector (with a single 1 in the $k$ th component, and zeros elsewhere) and observe that (with $A$ the standard representation of $T$ ) we have

$$
\sigma_{k}=\left\|T\left(e^{k}\right)\right\|=\left\|A e^{k}\right\|=\left\|\left(a_{1 k}, \ldots, a_{m k}\right)\right\|=\sqrt{\sum_{i=1}^{m} a_{i k}^{2}}
$$

Hence $\sigma_{k}$ is the norm of the vector corresponding to the $k$ th column of $A$. Let

$$
\sigma=\max _{k} \sigma_{k}
$$

be the norm of the largest column vector of $A$. Because $\|T(x)\|=\sigma$ for some unit vector $e^{k}$ (with norm 1 ), it follows that

$$
\begin{equation*}
\|T\|=\sup \left\{\|T x\| ; x \in \mathbb{R}^{\mathbb{m},},\|x\|=1\right\} \geq \sigma \tag{3}
\end{equation*}
$$

Moreover,

$$
\sigma_{k}=\sqrt{\sum_{i=1}^{n} a_{i k}^{2}} \geq \max _{i}\left|a_{i k}\right|
$$

and therefore

$$
\sigma=\max _{k} \sigma_{k} \geq \max _{k}\left[\max _{i}\left|a_{i k}\right|\right]=\mu
$$

From this last inequality and (3), we obtain

$$
\mu \leq \sigma \leq\|T\|
$$

Given two functions $R \in L\left(\mathbb{R}^{\mathrm{n}}, \mathbb{R}^{\mathrm{m}}\right)$ and $S \in L\left(\mathbb{R}^{\mathrm{m}}, \mathbb{R}^{\mathrm{p}}\right)$, their composition $T=S \circ R$ is a linear function in $L\left(\mathbb{R}^{\mathrm{n}}, \mathbb{R}^{\mathrm{p}}\right)$, by Problem 2.4. In terms of their matrix representation, the composition of two linear mappings translates into a product. (In fact, the product of two matrices is defined so as to correspond to the composition of the corresponding linear operators.) Let $A_{R}, A_{S}$, and $A_{T}$ be the standard matrices associated with $R, S$, and $T$; then

$$
T(x)=S[R(x)]=A_{S}\left(A_{R} x\right)=\left(A_{S} A_{R}\right) x, \quad \text { so } A_{T}=A_{S} A_{R}
$$

Using Theorem 4.7 we can get a bound on the norm of the composition of two linear mappings in terms of their respective norms. Observe that

$$
\|T(x)\|=\|S(R(x))\| \leq\|S\|\|R(x)\| \leq\|S\|\|R\|\|x\|
$$

for any $x$. Hence, $\|S\|\|R\|$ is an upper bound for $\|T(x)\|$ when $\|x\|=1$, and it follows that

$$
\|T\|=\|S \circ R\| \leq\|S\|\|R\|
$$

We have proved the following result:

Theorem 4.10. Let $\mathrm{R} \in \mathrm{L}\left(\mathbb{R}^{n}, \mathbb{R}^{m}\right)$ and $\mathrm{S} \in \mathrm{L}\left(\mathbb{R}^{m}, \mathbb{R}^{p}\right)$. Then $T=\mathrm{S} \circ \mathrm{R} \in$ $\mathrm{L}\left(\mathbb{R}^{n}, \mathbb{R}^{p}\right)$, and $\|\mathrm{T}\|=\|\mathrm{S} \circ \mathrm{R}\| \leq\|\mathrm{S}\|\|\mathrm{R}\|$.

## Linear Operators in $\mathbb{R}^{n}$

A mapping from a space $X$ into itself is often called an operator. In this section we will study some properties of linear operators in $\mathbb{R}^{n}$. The set of all such operators will be denoted by $L\left(\mathbb{R}^{\mathrm{n}}\right)$. Because $L\left(\mathbb{R}^{\mathrm{n}}\right)$ is just the vector space $L\left(\mathbb{R}^{\mathbf{n}}, \mathbb{R}^{\mathbf{n}}\right)$, earlier results apply. Certain additional properties follow from the fact that the domain and range spaces are the same.

If a linear operator $T \in L\left(\mathbb{R}^{\mathrm{n}}\right)$ is invertible, then its inverse $T^{-1}$ is also an element of $L\left(\mathbb{R}^{\mathrm{n}}\right)$. Hence

$$
\begin{equation*}
T \circ T^{-1}=T^{-1} \circ T=I_{n} \tag{1}
\end{equation*}
$$

that is, each invertible operator commutes with its inverse, and their composition is the identity operator in $\mathbb{R}^{\mathrm{n}}$. Moreover, because $\left\|I_{n}\right\|=1$, (1) yields (using Theorem 4.10)

$$
\left\|I_{n}\right\|=1=\left\|T^{-1} \circ T\right\| \leq\|T\|\left\|T^{-1}\right\| \Rightarrow\left\|T^{-1}\right\| \geq \frac{1}{\|T\|}
$$

so the norm of the inverse of a linear operator is (weakly) larger than the inverse of the norm of the operator itself.

Each linear operator $T$ in $\mathbb{R}^{\mathrm{n}}$ is associated with a square $n$-matrix $A$. Hence the operator $T$ is invertible if and only if the equation $y=A x$ can be solved for a unique value of $x$ for any given $y$. From elementary linear algebra we know that this is true if and only if the determinant $|A|$ does not vanish. In that case, the matrix $A$ is nonsingular, and the solution of the system is given by $x=A^{-1} y$. Hence, invertible operators are those that are represented by invertible matrices.

If we let $y$ be the zero vector in $\mathbb{R}^{\mathrm{n}}\left(\underline{0}_{n}\right)$, the system $A x=\underline{0}_{n}$ has always the trivial solution $x=\underline{0}_{n}$. If $|A| \neq 0$, then the trivial solution is unique, but if the determinant vanishes, then there are other solutions, and therefore $T$ cannot be invertible, because it maps distinct vectors into zero. Recall also the relation

$$
n=\operatorname{dim} \operatorname{ker} T+\operatorname{rank} T
$$

If $T$ is invertible, then $\operatorname{rank} T=n$, and therefore $\operatorname{dim} \operatorname{ker} T$ must be zero; that is, the kernel must be a subspace of dimension zero of $\mathbb{R}^{\mathbf{n}}$, and hence $\operatorname{ker} T$ $=\left\{\underline{0}_{n}\right\}$. In conclusion, we have the following result:

Theorem 4.11. A necessary and sufficient condition for a linear operator $\mathrm{T}: \mathbb{R}^{n} \longrightarrow \mathbb{R}^{n}$ to be invertible is that $\mathrm{T}$ map only the zero vector into the zero vector.

If $S$ and $T$ are linear operators in $\mathbb{R}^{\mathrm{n}}$, their composition $S \circ T$ is also a linear operator in $\mathbb{R}^{\mathrm{n}}$, by Theorem 2.11. Moreover, the composition of two invertible operators is itself invertible. To show this is so, let $T$ and $S$ be invertible operators, and $x$ any vector in $\mathbb{R}^{\mathrm{n}}$ other than the zero vector $\underline{0}_{n}$. Because $T$ is invertible and therefore one-to-one, $x \neq \underline{0}_{n}$ implies $T(x) \neq$ $\underline{0}_{n}$, by Theorem 2.13; and because $S$ is invertible, this implies in turn that $S(T x) \neq \underline{0}_{n}$, and it follows that $S \circ T$ is invertible, by Theorem 4.11. Moreover,

$$
(S \circ T) \circ\left(T^{-1} \circ S^{-1}\right)=S \circ\left(T \circ T^{-1}\right) \circ S^{-1}=S \circ I \circ S^{-1}=S \circ S^{-1}=I
$$

so $(S \circ T)^{-1}=T^{-1} \circ S^{-1}$, that is, the inverse of the composition of two linear operators is the composition of their inverses in reverse order. We have, then, the following theorem.

Theorem 4.12. Let $\mathrm{S}$ and $\mathrm{T}$ be invertible operators in $\mathrm{L}\left(\mathbb{R}^{n}\right)$. Then the composition $\mathrm{S} \circ \mathrm{T}$ is also an invertible operator in $\mathrm{L}\left(\mathbb{R}^{n}\right)$, and $(\mathrm{S} \circ \mathrm{T})^{-1}=$ $\mathbf{T}^{-1} \circ \mathrm{S}^{-1}$.

The set of all invertible operators in $L\left(\mathbb{R}^{n}\right)$ is denoted by $\Omega\left(\mathbb{R}^{n}\right)$. Because $L\left(\mathbb{R}^{\mathrm{n}}\right)$ is a normed space, the concepts of open and closed sets are defined, as is the notion of continuity for functions mapping $L\left(\mathbb{R}^{\mathrm{n}}\right)$ into itself. In the remainder of this section we will show that $\Omega\left(\mathbb{R}^{n}\right)$ is an open subset of $L\left(\mathbb{R}^{\mathrm{n}}\right)$ and that the function that assigns its inverse to each invertible linear operator in $\mathbb{R}^{\mathrm{n}}$ is continuous. These results will be needed in Chapter 4 in the proof of the inverse-function theorem. We begin with a preliminary result.

Lemma 4.13. Let $\mathrm{T}$ be an operator in $\mathrm{L}\left(\mathbb{R}^{n}\right)$, and $\mathrm{I}$ the identity mapping in $\mathbb{R}^{n}$.
(i) If $\|\mathrm{T}\|<1$, then $(\mathrm{I}-T)$ is invertible, and $\left\|(\mathrm{I}-\mathrm{T})^{-1}\right\| \leq 1 /(1-\|\mathrm{T}\|)$.

(ii) If $\|\mathrm{I}-\mathrm{T}\|<1$, then $\mathrm{T}$ is invertible.

## Proof

(i) Let $x \neq \underline{0}$ be an otherwise arbitrary vector in $\mathbb{R}^{\mathrm{n}}$. We will show that if $\|T\|<1$, then $(I-T)(x) \neq \underline{0}$. By Theorem 4.11, this implies that $(I-T)$ is invertible.

First, note that for arbitrary vectors $x$ and $y$,

$$
\|x\|-\|y\|=\|(x-y)+y\|-\|y\| \leq\|x-y\|+\|y\|-\|y\| \Rightarrow\|x-y\| \geq\|x\|-\|y\|
$$

Also, recall that

$$
\|T(x)\| \leq\|T\|\|x\|
$$

Hence we have

$$
\begin{equation*}
\|(I-T)(x)\|=\|x-T(x)\| \geq\|x\|-\|T(x)\| \geq\|x\|(1-\|T\|)>0 \tag{1}
\end{equation*}
$$

because $\|T\|<1$ by assumption. Hence, $\|(I-T)(x)\| \neq 0$, and it follows that $(I-T)$ is invertible.

To get the bound on the norm of $(I-T)^{-1}$, replace $x$ in (1) by $(I-T)^{-1}(y)$, where $y$ is an arbitrary vector in $\mathbb{R}^{\mathrm{n}}$. The left-hand side of this expression then becomes

$$
\left\|(I-T) \circ(I-T)^{-1}(y)\right\|=\|I(y)\|=\|y\|
$$

Hence, (1) yields

$$
\|y\| \geq\left\|(I-T)^{-1}(y)\right\|(1-\|T\|)
$$

from which

$$
\left\|(I-T)^{-1}(y)\right\| \leq \frac{\|y\|}{1-\|T\|}
$$

Hence, $1 /(1-\|T\|)$ is an upper bound of $\left\|(I-T)^{-1}(y)\right\|$ for any $y$ with $\|y\|=1$, and it follows that

$$
\left\|(I-T)^{-1}\right\| \leq \frac{1}{1-\|T\|}
$$

as was to be shown.

(ii) Put $S=I-T$. Because $\|S\|=\|I-T\|<1,(I-S)$ is invertible, by (i), but $I-S=$ $I-(I-T)=T$.

Theorem 4.14. Let $\mathrm{T}$ and $\mathrm{S}$ be linear operators in $\mathbb{R}^{n}$. If $\mathrm{T}$ is invertible and S satisfies

$$
\|\mathrm{T}-\mathrm{S}\|<1 /\left\|\mathrm{T}^{-1}\right\|
$$

then $\mathrm{S}$ is also invertible. This implies that the set $\Omega\left(\mathbb{R}^{n}\right)$ is open in $\mathrm{L}\left(\mathbb{R}^{n}\right)$. Moreover,

$$
\left\|\mathrm{S}^{-1}\right\| \leq \frac{\left\|\mathrm{T}^{-1}\right\|}{1-\left\|\mathrm{T}^{-1} \circ(\mathrm{T}-\mathrm{S})\right\|}
$$

Notice that the theorem says that if $T$ is invertible, then every operator $S$ within an open ball with center at $T$ and radius $1 /\left\|T^{-1}\right\|$ is invertible. Hence the set of invertible operators is open. Although the reader may find it strange at first to think in these terms, the intuition should be clear. The openness of $\Omega\left(\mathbb{R}^{n}\right)$ means that if $T$ is invertible, then any other linear operator $S$ that is sufficiently close to $T$, in the sense that $\|S-T\|$ is "small," is also invertible. At this point, it may help to think in terms of the matrix representations of $S$ and $T: T$ is invertible if and only if det $M_{T} \neq 0$; because the determinant is a continuous function of the entries of a matrix, any matrix $M_{S}$ sufficiently similar to $M_{T}$ has a nonzero determinant and is therefore invertible.

Proof. Because $T$ is invertible, we can write

$$
\begin{equation*}
S=T-I \circ(T-S)=T \circ\left[I-T^{-1} \circ(T-S)\right] \tag{1}
\end{equation*}
$$

By Theorem 4.10 and the assumptions of this theorem, we have

$$
\begin{equation*}
\left\|T^{-1} \circ(T-S)\right\| \leq\left\|T^{-1}\right\|\|T-S\|<1 \tag{2}
\end{equation*}
$$

By Lemma 4.13, with $T^{-1} \circ(T-S)$ in place of $T$, this implies that $I-T^{-1} \circ$ $(T-S)$ is invertible. But then (1) shows that $S$ is the composition of two invertible operators and therefore is invertible itself, by Theorem 4.12.

Moreover, from (1) we have, by Theorem 4.12,

$$
S^{-1}=\left[I-T^{-1} \circ(T-S)\right]^{-1} \circ T^{-1}
$$

and hence

$$
\begin{equation*}
\left\|S^{-1}\right\| \leq\left\|\left[I-T^{-1} \circ(T-S)\right]^{-1}\right\|\left\|T^{-1}\right\| \tag{3}
\end{equation*}
$$

Using (2) and the inequality in part (i) of Lemma 4.13, with $T^{-1} \circ(T-S)$ in place of $T$, we have

$$
\left\|\left[I-T^{-1} \circ(T-S)\right]^{-1}\right\| \leq \frac{1}{1-\left\|T^{-1} \circ(T-S)\right\|}
$$

Substituting this expression into (3), we obtain the desired result:

$$
\left\|S^{-1}\right\| \leq\left\|\left[I-T^{-1}(T-S)\right]^{-1}\right\| \mid T^{-1} \| \leq \frac{\left\|T^{-1}\right\|}{1-\left\|T^{-1} \circ(T-S)\right\|}
$$

Thinking of an invertible operator as a point in the set $\Omega\left(\mathbb{R}^{n}\right)$, we can construct a function ()$^{-1}: \Omega\left(\mathbb{R}^{n}\right) \longrightarrow \Omega\left(\mathbb{R}^{n}\right)$ that assigns to each $T$ in $\Omega\left(\mathbb{R}^{\mathrm{n}}\right)$ its inverse $T^{-1}$. The next theorem tells us that this function is continuous; that is, for any $\varepsilon>0$ we can find some $\delta>0$ such that for $S$ and $T$ in $\Omega\left(\mathbb{R}^{\mathrm{n}}\right)$,

$$
\|S-T\|<\delta \Rightarrow\left\|S^{-1}-T^{-1}\right\|<\varepsilon
$$

Intuitively, the continuity of the inversion mapping means that similar operators have similar inverses.

Theorem 4.15. The function ( $)^{-1}: \Omega\left(\mathbb{R}^{n}\right) \longrightarrow \Omega\left(\mathbb{R}^{n}\right)$ that assigns to each invertible operator $\mathrm{T}$ its inverse $\mathrm{T}^{-1}$ is continuous.

Proof. Fix some $T$ in $\Omega\left(\mathbb{R}^{\mathrm{n}}\right)$, and observe that if we pick $S$ so that

$$
\begin{equation*}
\|T-S\|<1 /\left\|T^{-1}\right\| \tag{1}
\end{equation*}
$$

then, by Theorem $4.14, S$ is invertible, and

$$
\begin{equation*}
\left\|S^{-1}\right\| \leq \frac{\left\|T^{-1}\right\|}{1-\left\|T^{-1} \circ(T-S)\right\|} \tag{2}
\end{equation*}
$$

If we strengthen (1) and require $\|T-S\|<1 /\left(2\left\|T^{-1}\right\|\right)$, then it can be seen from the proof of the preceding theorem that $\left\|T^{-1} \circ(T-S)\right\|<1 / 2$, so (2), which still holds, becomes

$$
\left\|S^{-1}\right\| \leq \frac{\left\|T^{-1}\right\|}{1-\left\|T^{-1} \circ(T-S)\right\|} \leq 2\left\|T^{-1}\right\|
$$

Next, note that

$$
T^{-1} \circ(T-S) \circ S^{-1}=\left(I-T^{-1} \circ S\right) \circ S^{-1}=S^{-1}-T^{-1}
$$

and hence, by $\left(2^{\prime}\right)$,

$$
\begin{equation*}
\left\|S^{-1}-T^{-1}\right\|=\left\|T^{-1} \circ(T-S) \circ S^{-1}\right\| \leq\left\|T^{-1}\right\|\|T-S\|\left\|S^{-1}\right\|<2\left\|T^{-1}\right\|^{2}\|T-S\| \tag{3}
\end{equation*}
$$

Finally, fix some arbitrary $\varepsilon>0$. If we choose

$$
\delta=\frac{\varepsilon}{2\left\|T^{-1}\right\|^{2}}
$$

then $\|S-T\|<\delta$ implies, using (3),

$$
\left\|S^{-1}-T^{-1}\right\|<2\left\|T^{-1}\right\|^{2}\|T-S\|<\varepsilon
$$

and we conclude that ()$^{-1}$ is continuous.

## 5. Change of Basis and Similarity

Let $T$ be a linear mapping from a finite-dimensional vector space $V$ into itself. We have seen that given a basis for $V$, the mapping $T$ is represented by a square matrix. A change of basis, of course, yields a different matrix representation. In this section we investigate the relationships between different representations of a given linear mapping. This material will be useful in applications, as it is often convenient to change basis so as to obtain a simple representation of a given mapping.

We begin by exploring the effect of a change of basis on the coordinates of a vector. Let

$$
\mathfrak{a}=\left\{a_{1}, \ldots, a_{n}\right\} \quad \text { and } \quad \mathrm{b}=\left\{b_{1}, \ldots, b_{n}\right\}
$$

be two bases for an $n$-dimensional vector space $V$. Because a is a basis, we can write each vector $b_{i}$ of $\mathbb{b}$ as a linear combination of the elements of $a$, that is, there exist scalars $q_{i 1}, \ldots, q_{i n}$ such that

$$
b_{i}=\sum_{k=1}^{n} q_{i k} a_{k}
$$

Because this is true for each $i=1, \ldots, n$, there exists a matrix $Q=\left[q_{i k}\right]$ such that

$$
\left[\begin{array}{c}
b_{i}  \tag{1}\\
\cdots \\
b_{n}
\end{array}\right]=\left[\begin{array}{ccc}
q_{11} & \cdots \cdots & q_{1 n} \\
\cdots & \cdots \cdots & \cdots \\
q_{n 1} & \cdots \cdots & q_{n n}
\end{array}\right]\left[\begin{array}{l}
a_{1} \\
\cdots \\
a_{n}
\end{array}\right]=Q\left[\begin{array}{l}
a_{1} \\
\cdots \\
a_{n}
\end{array}\right]
$$

Next, let $x$ be an arbitrary vector in $V$, with coordinate vector $\alpha=$ $\left(\alpha_{1}, \ldots, \alpha_{n}\right)^{T}$ in basis $\mathfrak{a}$, and $\beta=\left(\beta_{1}, \ldots, \beta_{n}\right)^{T}$ in basis $\mathbb{b}$. Then

$$
x=\sum_{k=1}^{n} \alpha_{k} a_{k}=\left(\alpha_{1}, \ldots, \alpha_{n}\right)\left[\begin{array}{l}
a_{1} \\
\cdots \\
a_{n}
\end{array}\right]=\alpha^{T}\left[\begin{array}{l}
a_{1} \\
\ldots \\
a_{n}
\end{array}\right]
$$

Similarly, using (1),

$$
x=\sum_{k=1}^{n} \beta_{k} b_{k}=\beta^{T}\left[\begin{array}{l}
b_{1} \\
\cdots \\
b
\end{array}\right]=\beta^{T} Q\left[\begin{array}{l}
a_{1} \\
\cdots \\
a_{n}
\end{array}\right]
$$

Because $A=\left[a_{1}, \ldots, a_{n}\right]^{T}$ is an invertible matrix by the linear independence of the elements of the basis, $\alpha^{T} A=\beta^{T} Q A$ implies $\alpha^{T} A A^{-1}=\beta^{T} Q A A^{-1}$, and therefore

$$
\beta^{T} Q=\alpha^{T}
$$

Taking transposes of both sides of this expression, and letting $Q^{T}=P$, we see that

$$
\begin{equation*}
\alpha=P \beta \tag{2}
\end{equation*}
$$

Hence, the effect of a change of basis on the coordinates of a vector is to multiply the original coordinate vector by the transpose of the matrix $Q$ that summarizes the relationship between the two bases. The following problem shows that the matrix $P$ is invertible.

Problem 5.1. Show that the matrix $P$ that represents a coordinate change is invertible. Hint: By the same argument we have used, there is a matrix $Z$ such that $\beta=Z \alpha$.

Now, let $T: V \longrightarrow V$ be a linear mapping with matrix representation $M_{a}$ in basis $\mathfrak{a}$ and $M_{b}$ in basis $\mathbb{b}$. Then, given an arbitrary vector $x$ in $V$, its image $T(x)$ has coordinates $M_{a} \alpha$ in basis a and $M_{b} \beta$ in basis $\mathbb{b}$. By the previous discussion, these two coordinate vectors are related by

$$
M_{a} \alpha=P M_{b} \beta
$$

Substituting (2) in this expression,

$$
M_{a} P \beta=P M_{b} \beta
$$

and premultiplying both sides by $P^{-1}$,

$$
P^{-1} M_{a} P \beta=P^{-1} P M_{b} \beta=M_{b} \beta
$$

Because this expression must hold for all vectors $\beta$, it follows that

$$
\begin{equation*}
P^{-1} M_{\mathrm{a}} P=M_{b} \tag{3}
\end{equation*}
$$

Hence, any two representations of the same linear mapping are related in a simple way: We can write one of them as the result of premultiplying and postmultiplying the other one by a matrix and its inverse.

Two matrices that satisfy relation (3) are said to be similar.

Definition 5.2. Two matrices $A$ and $B$ are said to be similar if there exists an invertible matrix $P$ such that $P^{-1} A P=B$.

Hence, a change of basis alters the matrix representation of a linear mapping by a similarity transformation. In a later section we will see that it is often possible to find invertible matrices $P$ that yield particularly convenient representations of a given linear mapping.

Problem 5.3. Show that similar matrices have the same determinant. (Recall that the determinant of the product of two matrices is the product of their determinants.)

## 6. Eigenvalues and Eigenvectors

Definition 6.1. Eigenvalues and eigenvectors. Let $A$ be an $n \times n$ matrix, with $e$ a nonzero $n$-vector, and $\lambda$ a scalar (real or complex), such that

$$
\begin{equation*}
A e=\lambda e \tag{1}
\end{equation*}
$$

We then say that $\lambda$ is an eigenvalue or characteristic root of $A$, and $e$ an eigenvector or characteristic vector of $A$ corresponding (or belonging) to the eigenvalue $\lambda$.

Rearranging (1), we see that the pair $(\lambda, e)$ must satisfy the homogeneous system of equations

$$
\begin{equation*}
(A-\lambda I) e=\underline{0} \tag{2}
\end{equation*}
$$

where $I$ is the identity matrix. Notice that (2) is a homogeneous system of $n$ equations in $n$ unknowns (the components of $e$ ) and will therefore have nontrivial solutions only if $\lambda$ is such that the coefficient matrix of the system is noninvertible, that is, if

$$
\begin{equation*}
|A-\lambda I|=0 \tag{3}
\end{equation*}
$$

for otherwise, $e=(A-\lambda I)^{-1} \underline{0}=\underline{0}$. Expanding the determinant $|A-\lambda I|$ in this expression, we obtain an $n$ th-degree polynomial $p(\lambda)$, called the characteristic polynomial of $A$. Equation (3) (the characteristic equation) is therefore an $n$ th-degree polynomial equation in $\lambda$, and, as such, it has $n$ solutions, not necessarily all real or all distinct. Each of these solutions $\left(\lambda_{i}, i=1, \ldots, n\right)$ is an eigenvalue of $A$. If an eigenvalue is repeated $m$ times, we say that it has multiplicity $m$. The set of eigenvalues of $A$, $\left\{\lambda_{i} ; i=1, \ldots, n\right\}$, is sometimes called the spectrum of the matrix, denoted by $\sigma(A)$.

Having solved (3) for the eigenvalues of $A$, we can calculate the corresponding eigenvectors by solving the system

$$
\begin{equation*}
A e_{i}=\lambda_{i} e_{i} \Leftrightarrow\left(A-\lambda_{i} I\right) e_{i}=\underline{0} \tag{4}
\end{equation*}
$$

for each $i=1, \ldots, n$. Observe that the characteristic vectors of a matrix are not uniquely defined. If $e_{i}$ is an eigenvector of $A$ associated with the eigenvalue $\lambda_{i}$, any vector of the form $\alpha e_{i}$, where $\alpha$ is an arbitrary scalar, will also be a characteristic vector of $A$, for if we multiply $A$ by $\alpha e_{i}$, we obtain

$$
A\left(\alpha e_{i}\right)=\alpha\left(A e_{i}\right)=\alpha\left(\lambda_{i} e_{i}\right)=\lambda_{i}\left(\alpha e_{i}\right)
$$

Hence, if $e_{i}$ is an eigenvector of $A$, so is $\alpha e_{i}$. The space of solutions of (4) corresponding to a given eigenvalue $\lambda_{i}$ is called the eigenspace of $A$ belonging to $\lambda_{i}$.

Problem 6.2. Show that the eigenspace of $A$ corresponding to an eigenvalue $\lambda$ is a vector space.

Problem 6.3. Show that if $\lambda$ is an eigenvalue of $A$, then (i) $\lambda^{n}$ is an eigenvalue of $A^{n}$, and (ii) $\lambda^{-1}$ is an eigenvalue of $A^{-1}$.

The case of a $2 \times 2$ matrix is particularly simple and often useful in applications. Given the matrix

$$
A=\left[\begin{array}{l}
a_{11} a_{12} \\
a_{21} a_{22}
\end{array}\right]
$$

its characteristic equation is

$$
\begin{aligned}
p(\lambda) & =|A-\lambda I|=\left|\begin{array}{cc}
a_{11}-\lambda & a_{12} \\
a_{21} & a_{22}-\lambda
\end{array}\right|=\left(a_{11}-\lambda\right)\left(a_{22}-\lambda\right)-a_{12} a_{21} \\
& =a_{11} a_{22}-\lambda a_{11}-\lambda a_{22}+\lambda^{2}-a_{12} a_{21}-\lambda^{2}-\left(a_{11}+a_{22}\right) \lambda+\left(a_{11} a_{22}-a_{12} a_{21}\right) \\
& =\lambda^{2}-(\operatorname{tr} A) \lambda+\operatorname{det} A=0
\end{aligned}
$$

Using the quadratic formula, the eigenvalues of $A$ are given by

$$
\lambda_{1}, \lambda_{2}=\frac{\operatorname{tr} \pm \sqrt{(\mathrm{tr})^{2}-4(\mathrm{det})}}{2}
$$

Given an eigenvalue $\lambda_{i}$, we now seek the corresponding eigenvectors $e_{i}$. To simplify things a bit, we can take advantage of the fact that eigenvectors are defined, at most, up to a multiplicative constant to normalize the second
component of $e_{i}$ to $1\left(e_{i 2}=1\right)$. Hence, we want a vector $e_{i}=\left(e_{i 1}, 1\right)$ such that $A e_{i}=\lambda_{i} e_{i}$, that is, a solution of the system

$$
\left[\begin{array}{l}
a_{11} a_{12} \\
a_{21} a_{22}
\end{array}\right]\left[\begin{array}{l}
e_{i 1} \\
1
\end{array}\right]=\lambda_{i}\left[\begin{array}{l}
e_{i 1} \\
1
\end{array}\right]
$$

or

$$
\begin{aligned}
& a_{11} e_{i 1}+a_{12}=\lambda_{i} e_{i 1} \\
& a_{21} e_{i 1}+a_{22}=\lambda_{i}
\end{aligned}
$$

Notice that there is only one unknown $\left(e_{i 1}\right)$. However, we know that the system must be consistent; hence, both equations have the same solutions, and we can solve whichever one is more convenient.

Problem 6.4. Find the eigenvalues and eigenvectors of the matrix

$$
A=\left[\begin{array}{ccc}
3 & -2 & 0 \\
-2 & 3 & 0 \\
0 & 0 & 5
\end{array}\right]
$$

The following theorems list some properties of eigenvalues and eigenvectors that will be useful in the study of linear dynamical systems.

Theorem 6.5. Let A be a square matrix with real entries. Then, complex eigenvalues of $\mathrm{A}$, if they exist, come in conjugate pairs. Moreover, the corresponding eigenvectors also come in conjugate pairs.

Theorem 6.6. Let $\mathrm{A}=\left[\mathrm{a}_{\mathrm{ij}}\right]$ be an $\mathrm{n} \times \mathrm{n}$ matrix. Then

(i) the product of the eigenvalues of $\mathrm{A}$ is equal to its determinant, that is,

$$
|\mathrm{A}|=\Pi_{\mathrm{i}=1}^{\mathrm{n}} \lambda_{\mathrm{i}}
$$

(ii) the sum of the eigenvalues of $\mathrm{A}$ is equal to its trace, that is,

$$
\operatorname{tr} \mathrm{A} \equiv \sum_{\mathrm{i}=1}^{\mathrm{n}} a_{i i}=\sum_{\mathrm{i}=1}^{\mathrm{n}} \lambda_{\mathrm{i}}
$$

(iii) if $\mathrm{A}$ is a triangular matrix, then its eigenvalues are the coefficients in the principal diagonal of the matrix (i.e., $\lambda_{\mathrm{i}}=\mathrm{a}_{\mathrm{ij}}$ ).

Proof. Let $A$ be an $n \times n$ matrix. Then its characteristic polynomial is an $n$ thdegree polynomial,

$$
p(\lambda)=c_{n} \lambda^{n}+c_{n-1} \lambda^{n-1}+\ldots+c_{1} \lambda+c_{0}
$$

To prove (i) and (ii), we will write down two equivalent expressions for $p(\lambda)$ and compare their coefficients.

(i) First, let $\lambda_{1}, \ldots, \lambda_{n}$ be the eigenvalues of $A$. Because these numbers are, by definition, zeros of $p(\lambda)$, we can write

$$
\begin{equation*}
p(\lambda)=a\left(\lambda_{1}-\lambda\right)\left(\lambda_{2}-\lambda\right) \ldots\left(\lambda_{n}-\lambda\right) \tag{1}
\end{equation*}
$$

for some number $a$. Using this expression, we see that

$$
\begin{align*}
& c_{n}=a(-1)^{n}  \tag{2}\\
& c_{0}=p(0)=a \lambda_{1} \lambda_{2} \ldots \lambda_{n} \tag{3}
\end{align*}
$$

Alternatively, we can also write

$$
p(\lambda)=|A-\lambda I|=\left[\begin{array}{cccc}
a_{11}-\lambda & a_{12} & \cdots & a_{1 n}  \tag{4}\\
a_{21} & a_{22}-\lambda & \cdots & a_{2 n} \\
\cdots & \cdots & \cdots & \cdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}-\lambda
\end{array}\right]
$$

from which

$$
\begin{equation*}
c_{0}=p(0)=\operatorname{det} A \tag{5}
\end{equation*}
$$

Moreover, it can be shown by induction that this polynomial is of the form

$$
\begin{equation*}
p(\lambda)=\left(a_{11}-\lambda\right)\left(a_{22}-\lambda\right) \ldots\left(a_{n n}-\lambda\right)+\text { terms of order } n-2 \text { or lower in } \lambda \tag{6}
\end{equation*}
$$

Inspection of this expression shows that

$$
\begin{equation*}
c_{n}=(-1)^{n} \tag{7}
\end{equation*}
$$

Comparing (2) and (7), we see that

$$
\begin{equation*}
a=1 \tag{8}
\end{equation*}
$$

Equations (3) and (5) then imply, using (8), that

$$
\begin{equation*}
\lambda_{1} \lambda_{2} \ldots \lambda_{n}=\operatorname{det} A \tag{9}
\end{equation*}
$$

(ii) Next, consider the coefficient of $\lambda^{n-1}, c_{n-1}$. Comparing equations (1) and (6), we see that both expansions of the polynomial should yield similar expressions for $c_{n-1}$, with $\lambda_{i}$ taking the role of $a_{i i}$. Using (1) with $a=1$, we will show by induction that $c_{n-1}=(-1)^{n-1}\left(\Sigma_{i=1}^{n} \lambda_{i}\right)$. By the same argument, it can be shown that $c_{n-1}=(-1)^{n-1}\left(\sum_{i=1}^{n} a_{i i}\right)$. Hence, it follows that $\operatorname{tr} A=\sum_{i=1}^{n} \lambda_{i}$, as was to be shown.

For each $k=1, \ldots, n$, let

$$
p_{k}(\lambda)=\left(\lambda_{1}-\lambda\right)\left(\lambda_{2}-\lambda\right) \ldots\left(\lambda_{k}-\lambda\right)
$$

and observe that

$$
p_{k+1}(\lambda)=p_{k}(\lambda)\left(\lambda_{k+1}-\lambda\right)
$$

First, we verify that the desired result holds for $k=2$. In this case, $p_{k}(\lambda)$ is of the form

$$
p_{2}(\lambda)=\left(\lambda_{1}-\lambda\right)\left(\lambda_{2}-\lambda\right)=\lambda_{1} \lambda_{2}-\lambda_{1} \lambda-\lambda \lambda_{2}+\lambda^{2}=\lambda^{2}-\left(\lambda_{1}+\lambda_{2}\right) \lambda+\lambda_{1} \lambda_{2}
$$

and $c_{n-1}=c_{1}$ (the coefficient of $\lambda$ ) is indeed of the form

$$
(-1)^{n-1}\left(\sum_{i=1}^{n} \lambda_{i}\right)=(-1)\left(\lambda_{1}+\lambda_{2}\right)
$$

Next we will assume that this result holds for $k$ and show that this implies that it holds also for $k+1$. Under our assumptions we have

$$
p_{k}(\lambda)=(-1)^{k} \lambda^{k}+(-1)^{k-1}\left(\sum_{i=1}^{k} \lambda_{i}\right) \lambda^{k-1}+c_{k-2} \lambda^{k-2}+\ldots+c_{1} \lambda+c_{0}
$$

Hence,

$$
\begin{aligned}
p_{k+1}(\lambda) & =p_{k}(\lambda)\left(\lambda_{k+1}-\lambda\right) \\
& =\left[(-1)^{k} \lambda^{k}+(-1)^{k-1}\left(\sum_{i=1}^{k} \lambda_{i}\right) \lambda^{k-1}+c_{k-2} \lambda^{k-2} \ldots+c_{1} \lambda+c_{0}\right]\left(\lambda_{k+1}-\lambda\right) \\
& =(-1)^{k+1} \lambda^{k+1}+\lambda_{k+1}(-1)^{k} \lambda^{k}+(-1)^{k}\left(\sum_{i=1}^{k} \lambda_{i}\right) \lambda^{k}+\ldots \\
& =(-1)^{k+1} \lambda^{k+1}+(-1)^{k}\left(\sum_{i=1}^{k} \lambda_{i}+\lambda_{k+1}\right) \lambda^{k} \ldots
\end{aligned}
$$

which shows that the coefficient of $\lambda^{k}$ is of the required form. This completes the proof.

(iii) Notice that in this case the characteristic equation reduces to $\prod_{i=1}^{n}\left(a_{i i}-\lambda_{i}\right)$ $=0$.

So far, we have talked about the eigenvalues and eigenvectors of a matrix, but in fact these concepts can be defined directly in terms of the underlying linear mapping. Let $T$ be a linear function mapping an $n$-dimensional vector space $V$ into itself. Given two bases of $V$, $\mathfrak{a}$ and $\mathbb{b}$, let $M_{a}$ and $M_{b}$ be the corresponding matrix representations of $T$. We have seen that $M_{a}$ and $M_{b}$ are similar matrices; that is, there exists an invertible matrix $P$ (which is the transpose of the "change-of-basis" matrix) such that $M_{b}=P^{-1} M_{a} P$. Using this expression, it is easy to show that the two matrices have the same characteristic polynomial and therefore the same eigenvalues:

$$
\begin{aligned}
\left|M_{b}-\lambda I\right| & =\left|P^{-1} M_{a} P-\lambda I\right|=\left|P^{-1}\left(M_{a}-\lambda I\right) P\right|=\left|P^{-1}\right|\left|M_{a}-\lambda I\right||P| \\
& =\left|M_{a}-\lambda I\right|\left|P^{-1}\right||P|=\left|M_{a} \lambda I\right|
\end{aligned}
$$

Moreover, the eigenvectors of $M_{a}$ and $M_{b}$ represent the same element of $V$ in the two bases we are considering. To see this, let $x$ and $y$ be eigenvectors
of $M_{a}$ and $M_{b}$ belonging to the same eigenvalue, $\lambda$, that is, vectors such that

$$
M_{a} x=\lambda x \text { and } M_{b} y=\lambda y
$$

Then, because $M_{b}=P^{-1} M_{a} P$, we have

$$
P^{-1} M_{a} P y=\lambda y \quad \text { and therefore } \quad M_{a} P y=\lambda P y
$$

Hence, $x=P y$, and we conclude (see the previous section) that $x$ and $y$ represent the same vector under different bases.

## Diagonalization of a Square Matrix

A matrix $A$ is said to be diagonalizable if it is similar to a diagonal matrix, that is, if there exists an invertible matrix $P$ such that $P^{-1} A P$ is diagonal.

Theorem 6.7. Let $\mathrm{A}$ be an $\mathrm{n} \times \mathrm{n}$ matrix with $\mathrm{n}$ linearly independent eigenvectors. Then $\mathrm{A}$ is diagonalizable. Moreover, the diagonalizing matrix is the matrix $\mathrm{E}=\left[\mathrm{e}_{l}, \ldots, \mathrm{e}_{\mathrm{n}}\right]$ whose columns are the eigenvectors of $\mathrm{A}$, and the resulting diagonal matrix is the matrix $\Lambda=\operatorname{diag}\left(\lambda_{1}, \ldots, \lambda_{n}\right)$, with the eigenvalues of $\mathrm{A}$ in the principal diagonal, and zeros elsewhere. That is, $\mathrm{E}^{-1} \mathrm{AE}=\Lambda$.

Proof. Because the eigenvectors of $A$ are linearly independent by assumption, $E=\left[e_{1}, \ldots, e_{n}\right]$ is an invertible matrix, and therefore $E^{-1} A E=\Lambda$ is equivalent to $A E=E \Lambda$. We now verify that this expression holds. Using the definition of eigenvectors and eigenvalues,

$$
\begin{aligned}
A E & =A\left[e_{1}, \ldots, e_{n}\right]=\left[A e_{1}, \ldots, A e_{n}\right]=\left[\lambda_{1} e_{1}, \ldots, \lambda_{n} e_{n}\right] \\
& =\left[e_{1}, \ldots, e_{n}\right]\left[\begin{array}{ccc}
\lambda_{1} & \cdots & 0 \\
\cdots & \cdots & \cdots \\
0 & \cdots & \lambda_{n}
\end{array}\right]=E \Lambda
\end{aligned}
$$

Theorem 6.8. Let $\mathrm{A}$ be an $\mathrm{n} \times \mathrm{n}$ matrix. If the $\mathrm{n}$ eigenvalues of $\mathrm{A}$ are all distinct, then its eigenvectors $\mathrm{e}_{1}, \ldots, \mathrm{e}_{\mathrm{n}}$ are linearly independent, and therefore $\mathrm{A}$ is diagonalizable.

Proof. Recall that a set of vectors $e_{1}, \ldots, e_{n}$ is said to be linearly dependent if there exist scalars $\alpha_{1}, \ldots, \alpha_{n}$ not all zero, such that

$$
\sum_{i=1}^{n} \alpha_{i} e_{i}=\underline{0}
$$

and to be linearly independent if this expression holds only when all the scalars are zero.

For simplicity, let $n=2$. There exist scalars $\alpha_{1}$ and $\alpha_{2}$ (possibly both zero) such that

$$
\begin{equation*}
\alpha_{1} e_{1}+\alpha_{2} e_{2}=\underline{0} \tag{1}
\end{equation*}
$$

Multiplying both sides of (1) by $A$,

$$
\begin{equation*}
\alpha_{1} A e_{1}+\alpha_{2} A e_{2}=\underline{0} \Rightarrow \alpha_{1} \lambda_{1} e_{1}+\alpha_{2} \lambda_{2} e_{2}=\underline{0} \tag{2}
\end{equation*}
$$

where $\lambda_{1}$ and $\lambda_{2}$ are the corresponding eigenvalues. Next, we multiply both sides of (1) by $\lambda_{2}$ and subtract the resulting equation from (2), obtaining

$$
\alpha_{1} \lambda_{1} e_{1}+\alpha_{2} \lambda_{2} e_{2}-\alpha_{1} \lambda_{2} e_{1}-\alpha_{2} \lambda_{2} e_{2}=\alpha_{1}\left(\lambda_{1}-\lambda_{2}\right) e_{1}=\underline{0}
$$

Because $\lambda_{1} \neq \lambda_{2}$ by assumption, and $e_{1} \neq \underline{0}$, we must have $\alpha_{1}=0$. By the same argument, $\alpha_{2}$ is also zero. Hence, the eigenvectors $e_{1}$ and $e_{2}$ belonging to different eigenvalues must be linearly independent.

A similar argument will work for any $n$ : Assume that some linear combination of the $n$ eigenvectors, $e_{1}, \ldots, e_{n}$, is equal to zero, multiply this combination by $A$, and subtract $\lambda_{n}$ times the original linear combination from the resulting expression. This will leave a linear combination of $e_{1}, \ldots, e_{n-1}$ that is equal to zero. By repeating the process, we end up with the result that a multiple of $e_{1}$ is the zero vector, forcing $\alpha_{1}=0$ and, eventually, $\alpha_{i}=0$ for all $i$. Hence, eigenvectors associated with distinct eigenvalues must be linearly independent.

## Appendix: Polynomial Equations

A polynomial of degree $n$ in $x$ is a real or complex-valued function

$$
\begin{equation*}
p(x)=a_{0} x^{n}+a_{1} x^{n-1}+\ldots+a_{n-1} x+a_{n} \quad\left(\text { with } a_{0} \neq 0\right) \tag{1}
\end{equation*}
$$

where the coefficients $a_{i}$ are real or complex numbers. An equation of the form

$$
\begin{equation*}
p(x)=a_{0} x^{n}+a_{1} x^{n-1}+\ldots+a_{n-1} x+a_{n}=0 \tag{2}
\end{equation*}
$$

is called a polynomial or algebraic equation. The solutions or roots of the equation $p(x)=0$ are the zeros of the polynomial $p(x)$.

Polynomial equations arise in the computation of the eigenvalues of a matrix and in other applications. A first question that arises in connection with such equations has to do with the existence of solutions to (2). It can be shown that a polynomial equation of degree $n$ will always have $n$ solutions, provided we allow for complex and repeated roots. In fact, complex numbers were "invented" to make sure that algebraic equations always have
a solution. If the coefficients of $p(x)$ are real, moreover, any complex roots will come in conjugate pairs.

The solutions of the second-degree algebraic equation

$$
a x^{2}+b x+c=0
$$

can be obtained directly using the quadratic formula:

$$
\begin{equation*}
x_{1}, x_{2}=\frac{-b \pm \sqrt{b^{2}-4 a c}}{2 a} \tag{3}
\end{equation*}
$$

For the case of the third-degree equation,

$$
z^{3}+A z^{2}+B z+c=0
$$

there is a similar result. Observe first that by letting $z=x-(A / 3)$, this equation can be written in the form

$$
\begin{equation*}
x^{3}+a x+b=0 \tag{4}
\end{equation*}
$$

The roots of (4), then, must satisfy the Cardano formula:

$$
\begin{equation*}
x=\left(\frac{-b+\sqrt{\frac{4 a^{3}+27 b^{2}}{27}}}{2}\right)^{1 / 3}+\left(\frac{-b-\sqrt{\frac{4 a^{3}+27 b^{2}}{27}}}{2}\right)^{1 / 3} \tag{5}
\end{equation*}
$$

Notice that there may be more than three numbers that satisfy this expression. Only three of them, however, will solve the original equation.

A more complicated formula exists for fourth-degree polynomial equations. For equations of a higher order, however, no explicit formulas are available.

Integer roots of a polynomial with integer coefficients are relatively easy to find. Observe that we can rewrite the equation

$$
\begin{equation*}
p(x)=a_{0} x^{n}+a_{1} x^{n-1}+\ldots+a_{n-1} x+a_{n}=0 \tag{2}
\end{equation*}
$$

in the form

$$
x\left(a_{0} x^{n-1}+a_{1} x^{n-2}+\ldots+a_{n-1}\right)=-a_{n}
$$

Assume that the coefficients of $p(x)$ are all integers and that $x^{*}$ is an integer solution of (2). Then the expression inside the parentheses is an integer, and $x^{*}$ must be a factor of the constant term $a_{n}$. It follows that in order to find the integer solutions of (2) (if they exist), it suffices to find all the integer factors of $a_{n}$. We can then insert each factor $f_{n}$ in $p(x)$ to check whether
or not it is indeed a zero of the polynomial. If it is, we can use this fact to simplify $p(x)$ by dividing it by $\left(x-f_{n}\right)$. In this manner, we can rewrite the original equation in the form

$$
p(x)=q(x)\left(x-f_{n}\right)
$$

where $q(x)$ is a polynomial of degree $n-1$. If $p(x)=0$ has enough integer roots, we may be able to write it as a product of a number of binomials of the form $\left(x-f_{n}\right)$ and a second- or third-degree polynomial $q(x)$. We can then use the quadratic formula or the Cardano formula to solve the equation $q(x)=0$, thus finding the remaining solutions of the original equation.

We conclude this section with an algorithm that simplifies the task of dividing a polynomial $p(x)$ by a binomial of the form $(x-c)$. In general, the division of $p(x)$ by $(x-c)$ yields a quotient polynomial $q(x)$ of degree $n-1$ and a constant remainder $r$, according to the formula

$$
p(x)=q(x)(x-c)+r
$$

Given $p(x)$ and $c$, we seek $q(x)$ and $r$. To illustrate the algorithm, let $p(x)$ be a third-degree polynomial. Then $p$ and $q$ are of the form

$$
p(x)=a_{0} x^{3}+a_{1} x^{2}+a_{2} x^{2}+a_{3} \text { and } q(x)=b_{0} x^{2}+b_{1} x+b_{2}
$$

To compute the values of $r$ and the coefficients of $q(x)$, we construct the following table. The top row contains the coefficients of $p$. The first element of the third row is $a_{0}$. Then each element of the second row is obtained by multiplying the previous element of the third row by $c$. Each element of the third row is the sum of the corresponding elements of the first and second rows. The elements of the third row are the coefficients of $q(x)$, except for the last one, which is the remainder.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-161.jpg?height=254&width=1085&top_left_y=1597&top_left_x=101)

## Bibliography

Anton, H. 1981. Elementary Linear Algebra, 3rd ed. New York: Wiley. Apostol, T. 1984. Calculus, 2nd ed. Barcelona: Editorial Reverté. Cullen, C. 1990. Matrices and Linear Transformations, 2nd ed. New York: Dover. Giles, J. 1987. Introduction to the Analysis of Metric Spaces. Cambridge University Press.

Lang, S. 1986. Introduction to Linear Algebra, 2nd ed. Berlin: Springer-Verlag. Maddox, I. 1988. Elements of Functional Analysis, 2nd ed. Cambridge University Press.

Michel, P. 1984. Cours de Mathématiques pour Economistes. Paris: Economica.

Schneider, H., and Barker, G. P. 1973. Matrices and Linear Algebra. New York: Dover.

Shilov, G. 1977. Linear Algebra. New York: Dover.

Sydsaeter, K. 1981. Topics in Mathematical Analyis for Economists. Orlando, FL: Academic Press.

Taylor, A., and Mann, R. Advanced Calculus. New York: Wiley.

## Notes

1 We can assume, without loss of generality, that $S^{\prime}$ is the same set in both cases. If it were not so, we would have

$$
x=\sum_{s \in S_{1}} \alpha_{s} x_{s} \quad \text { and } \quad y=\sum_{s \in S_{2}} \beta_{s} x_{s}
$$

We could then define $S^{\prime}=S_{1} \cup S_{2}$ and put $\alpha_{s}=0$ for $s \in S^{\prime} \sim S_{1}$ and $\beta_{s}=0$ for $s \in S^{\prime} \sim S_{2}$.

2 Because $X$ and $Y$ have the same dimension, we can assume that the index set is the same for the Hamel bases of the two spaces.

3 Recall that for any scalar $\alpha,\|\alpha x\|=|\alpha|\|x\|$; hence $\|T(\alpha x)\|=|\alpha|\|T(x)\|$. If $\|x\| \leq 1$, we can write $x=\alpha y$, where $|\alpha| \leq 1$ and $\|y\|=1$ and therefore $\|T(x)\| \leq\|T(y)\|$. This is why we can replace the equality $\|x\|=1$ by the inequality $\|x\| \leq 1$.

## 4

## Differential Calculus

This chapter introduces the concept of differentiability and discusses some of its implications. After dealing briefly with the familiar case of univariate real functions, we extend the concept of differentiability to functions of $\mathbb{R}^{n}$ into $\mathbb{R}^{\mathrm{m}}$. The key to the extension lies in the interpretation of differentiability in terms of the existence of a "good" linear approximation to a function at a point. We also show that important aspects of the local behavior of "sufficiently differentiable" functions are captured accurately by linear or quadratic approximations. This material has important applications to comparative statics and optimization.

## 1. Differentiable Univariate Real Functions

Let $g$ be a univariate function, $g: \mathbb{R} \longrightarrow \mathbb{R}$. We want to make precise the notion of the slope of the function at a given point $x$. Given a second point $y$ in the domain of $g$, the difference quotient $(g(y)-g(x)) /(y-x)$ gives the slope of the secant to the function through the points $(x, g(x))$ and $(y, g(y))$. As we take points $y$ closer and closer to $x$, the secant becomes a better approximation to the tangent to the graph of $g$ at the point $(x, g(x))$, and in the limit the two coincide. Thus, we can define the derivative of $g$ at $x$ as the limit

$$
g^{\prime}(x)=\lim _{y \rightarrow x} \frac{g(y)-g(x)}{y-x}=\lim _{h \rightarrow 0} \frac{g(x+h)-g(x)}{h} \quad(h \in \mathbb{R})
$$

whenever it exists, and we can interpret it as the slope of the function at this point.

Definition 1.1. Derivative of a univariate function. Let $g: \mathbb{R} \longrightarrow \mathbb{R}$ be defined on an open interval $I$. We say that $g$ is differentiable at a point $x$ in $I$ if the following limit exists:

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-164.jpg?height=642&width=876&top_left_y=183&top_left_x=298)

Figure 4.1. The derivative as the limit of the secant.

$$
\lim _{h \rightarrow 0} \frac{g(x+h)-g(x)}{h} \quad(h \in \mathbb{R})
$$

When it does, we say that the value of the limit is the derivative of $g$ at $x$, written $g^{\prime}(x)$. If $g$ is differentiable at each point in its domain, we say that the function is differentiable (on $I$ ).

Problem 1.2. Let $f$ and $g$ be functions $\mathbb{R} \longrightarrow \mathbb{R}$, and assume that they are both differentiable at some point $x^{0}$. Using the elementary properties of limits and the continuity of $f$ and $g$ at $x$, show that the product function $p$, defined by $p(x)=f(x) g(x)$, is differentiable at $x^{0}$ and that

$$
p^{\prime}\left(x^{0}\right)=f\left(x^{0}\right) g^{\prime}\left(x^{0}\right)+f^{\prime}\left(x^{0}\right) g\left(x^{0}\right)
$$

Hint: $f(x) g(x)-f\left(x^{0}\right) g\left(x^{0}\right)=f(x) g(x)-f\left(x^{0}\right) g(x)+f\left(x^{0}\right) g(x)-f\left(x^{0}\right) g\left(x^{0}\right)$.

Problem 1.3. Let $f(x)=x^{n}$. Show by induction that $f^{\prime}(x)=n x^{n-1}$. (First, prove it directly for $n=2$.)

We will now establish some important properties of differentiable functions.

Theorem 1.4. Let $\mathrm{f}$ be a function $\mathrm{f}: \mathbb{R} \supseteq \mathrm{I} \rightarrow \mathbb{R}$ (I open). If $\mathrm{f}$ is differentiable at a point $\mathrm{x} \in \mathrm{I}$, then it is continuous at $\mathrm{x}$.

Proof. Given two points $x$ and $x+h$ in $I$, we can write

$$
f(x+h)-f(x)=\frac{f(x+h)-f(x)}{h} h
$$

Taking limits as $h \rightarrow 0$, and applying earlier results on the algebra of limits, we have

$$
\lim _{h \rightarrow 0} f(x+h)-f(x)=\left(\lim _{h \rightarrow 0} \frac{f(x+h)-f(x)}{h}\right) 0=f^{\prime}(x) 0=0
$$

and therefore

$$
\lim _{h \rightarrow 0} f(x+h)=f(x)
$$

which establishes the continuity of $f$ at $x$.

A point $x^{0}$ is a local maximizer of $f$ if there exists some $\delta>0$ such that $f\left(x^{0}\right) \geq f(x)$ for all $x \in B_{\delta}\left(x^{0}\right)$. The following result tells us that a zero derivative is a necessary condition for an interior maximum (minimum) of a differentiable function. (Notice that we exclude the end points of the interval, to avoid the possibility of corner maxima.)

Theorem 1.5. Necessary condition for an interior maximum. Let $\mathrm{f}$ be a differentiable function ( $\mathrm{a}, \mathrm{b}) \longrightarrow \mathbb{R}$, and $\mathrm{x}^{0}$ a local maximizer (minimizer) of $\mathrm{f}$. Then $\mathrm{f}^{\prime}\left(\mathrm{x}^{0}\right)=0$.

Proof. Suppose, for concreteness, that $f$ has a local maximum at $x^{0}$. Then we have

$$
f\left(x^{0}+h\right)-f\left(x^{0}\right) \leq 0 \forall h \text { with }|h|<\delta
$$

and therefore

$$
\begin{aligned}
\frac{f\left(x^{0}+h\right)-f\left(x^{0}\right)}{h} & \leq 0 \quad \text { for } h \in(0, \delta) \\
& \geq 0 \quad \text { for } h \in(-\delta, 0)
\end{aligned}
$$

Taking limits as $h$ approaches zero from above and from below, we have

$$
\lim _{h \rightarrow 0^{+}} \frac{f\left(x^{0}+h\right)-f\left(x^{0}\right)}{h} \leq 0 \text { and } \lim _{h \rightarrow 0^{-}} \frac{f\left(x^{0}+h\right)-f\left(x^{0}\right)}{h} \geq 0
$$

Now, because the function is differentiable, the limit of the difference quotient as $h \rightarrow 0$ exists and is given by the common value of the two one-sided limits. Hence,

$$
0 \leq f^{\prime}\left(x^{0}\right)=\lim _{h \rightarrow 0} \frac{f\left(x^{0}+h\right)-f\left(x^{0}\right)}{h} \leq 0 \Rightarrow f^{\prime}\left(x^{0}\right)=0
$$

Theorem 1.6. Rolle's theorem. Let $\mathrm{f}:[\mathrm{a}, \mathrm{b}] \longrightarrow \mathbb{R}$ be continuous and differentiable on (a, b). Assume $\mathrm{f}(\mathrm{a})=\mathrm{f}(\mathrm{b})=0$; then there is some number $\theta \in(\mathrm{a}, \mathrm{b})$ such that $\mathrm{f}^{\prime}(\theta)=0$.

Proof. Because $f$ is continuous on the compact set $I=[a, b]$, it attains both a maximum $M$ and a minimum $m$ on this interval. That is, there exist points $x_{m}$ and $x_{M}$ in $[a, b]$ with $f\left(x_{m}\right)=m$ and $f\left(x_{M}\right)=M$. If $f\left(x_{m}\right)=f\left(x_{M}\right)=0$, then the function is constant on the interval, and $f^{\prime}(x)=0$ for all $x$ in $I$. Otherwise, either $f\left(x_{m}\right)<0$ for $x_{m} \in(a, b)$ and $f^{\prime}\left(x_{m}\right)=0$ (because $x_{m}$ is a local minimizer) or $f\left(x_{M}\right)>0$ for $x_{M} \in(a, b)$ and $f^{\prime}\left(x_{M}\right)=0$ (by Theorem 1.5), or both.

Using Rolle's theorem, it is easy to prove the following important result.

Theorem 1.7. Mean-value theorem. Let $\mathrm{f}: \mathbb{R} \longrightarrow \mathbb{R}$ be a differentiable function. If $\mathrm{a}$ and $\mathrm{b}$ are two points in $\mathbb{R}$, with $\mathrm{a}<\mathrm{b}$, then there is some number $\theta$ $\in(\mathrm{a}, \mathrm{b})$ such that $\mathrm{f}^{\prime}(\theta)=(\mathrm{f}(\mathrm{b})-\mathrm{f}(\mathrm{a})) /(\mathrm{b}-\mathrm{a})$.

Proof. Define the function $\phi()$ by

$$
\phi(x)=f(x)-f(a)-\frac{f(b)-f(a)}{b-a}(x-a)
$$

Because $\phi($ ) satisfies the assumptions of Rolle's theorem, there exists some point $\theta$ in $(a, b)$ such that $\phi^{\prime}(\theta)=0$, that is,

$$
\phi^{\prime}(\theta)=f^{\prime}(\theta)-\frac{f(b)-f(a)}{b-a}=0 \Rightarrow f^{\prime}(\theta)=\frac{f(b)-f(a)}{b-a}
$$

The mean-value theorem gives us a way to relate the properties of a function to those of its derivative. The following problem provides an example of how this can be useful.

Problem 1.8. Let $f: \mathbb{R} \longrightarrow \mathbb{R}$ be a differentiable function on an interval $I$. Show that

(i) if $f^{\prime}(x)=0$ for each $x \in I$, then $f$ is constant on the interval. Hint: Let $x$ and $y$, with $x<y$, be two arbitrary points in $I$. Use the mean-value theorem to show that $f(x)=f(y)$,

(ii) if $f^{\prime}(\mathrm{x})>0$ on $(a, b)$, then $f$ is strictly increasing on $(a, b)$.

Figure 4.2 gives a geometrical interpretation of the mean-value theorem. Putting $b=a+h$ in the formula given in the statement of the theorem, and rearranging terms, we have

$$
f(b)=f(a)+f^{\prime}(a+\lambda h) h
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-167.jpg?height=612&width=817&top_left_y=196&top_left_x=337)

Figure 4.2. The mean-value theorem.

for some $\lambda \in(0,1)$. The following theorem may be seen as an extension of this result.

Theorem 1.9. Taylor's formula for univariate functions. Let $\mathrm{f}: \mathbb{R} \longrightarrow \mathbb{R}$ be $\mathrm{n}$ times differentiable on an open interval $\mathrm{I}$. For all $\mathrm{x}$ and $\mathrm{x}+\mathrm{h} \in \mathrm{I}$ we have

$$
\begin{equation*}
f(x+h)=f(x)+\sum_{x=1}^{n-1} \frac{f^{(k)}(x)}{k !} h^{k}+E_{n} \tag{1}
\end{equation*}
$$

where $\mathrm{f}^{(\mathrm{x})}(\mathrm{x})$ is the $\mathrm{k}$ th derivative of $\mathrm{f}$ evaluated at $\mathrm{x}$, and the remainder or error term $\mathrm{E}_{\mathrm{n}}$ is of the form

$$
E_{n}=\frac{f^{(n)}(x+\lambda h)}{n !} h^{n}
$$

for some $\lambda \in(0,1)$.

That is, the remainder has the same form as the other terms, except that the $n$th derivative is evaluated at some point between $x$ and $x+h$.

Proof. Put $y=x+h$ and define the function $F(z)$ for $z$ between $x$ and $y$ by

$$
\begin{equation*}
F(z)=f(y)-f(z)-\sum_{k=1}^{n-1} \frac{f^{(k)}(z)}{k !}(y-z)^{k} \tag{2}
\end{equation*}
$$

Then the theorem says that for some point $x+\lambda(y-x)$ between $x$ and $y$,

$$
\begin{equation*}
F(x)=\frac{f^{(n)}(x+\lambda(y-x))}{n !}(y-x)^{n} \tag{3}
\end{equation*}
$$

First, observe that $F(y)=0$ and that most terms in

$$
\begin{aligned}
& F^{\prime}(z)=-f^{\prime}(z)-\sum_{k=1}^{n-1}\left(\frac{f^{(k)}(z)}{k !} k(y-z)^{k-1}(-1)+\frac{f^{(k+1)}(z)}{k !}(y-z)^{k}\right) \\
& =-f^{\prime}(z)+\sum_{k=1}^{n-1}\left(\frac{f^{(k)}(z)}{(k-1) !}(y-z)^{k-1}-\frac{f^{(k+1)}(z)}{k !}(y-z)^{k}\right) \\
& =-f^{\prime}(z)+\left(\frac{f^{\prime}(z)}{1} 1-\frac{f^{\prime \prime}(z)}{1 !}(y-z)\right)+\left(\frac{f^{\prime \prime}(z)}{1 !}(y-z)-\frac{f^{(3)} /(z)}{/ 2 !}(y-z)^{2}\right) \\
& +\left(\frac{f^{(3)}(z)}{2 !} /(y-z)^{2}-\frac{f^{(4)}(z)}{3 !} /(y-z)^{3}\right)+\ldots+\left(\frac{f^{(n-2)} /(z)}{(\not n-3) !}(y-z)^{n-3}\right. \\
& \left.-\frac{\left.f^{(n-1)}\right)(z)}{(n-2) !}(y-z)^{n-2}\right)+\left(\frac{f^{(n-1)}(z)}{(n-2) !}(y-z)^{n-2}-\frac{f^{(n)}(z)}{(n-1) !}(y-z)^{n-1}\right)
\end{aligned}
$$

cancel, leaving us with:

$$
\begin{equation*}
F^{\prime}(z)=-\frac{f^{(n)}(z)}{(n-1) !}(y-z)^{n-1} \tag{4}
\end{equation*}
$$

Next, define the function

$$
\begin{equation*}
G(z)=F(z)-\left(\frac{y-z}{y-x}\right)^{n} F(x) \tag{5}
\end{equation*}
$$

and observe that $G$ is a continuous function on $(x, y)$, with

$$
G(y)=F(y)-0=0=F(x)-F(x)=G(x)
$$

and

$$
\begin{equation*}
G^{\prime}(z)=F^{\prime}(z)-n\left(\frac{y-z}{y-x}\right)^{n-1} \frac{-1}{y-x} F(x) \tag{6}
\end{equation*}
$$

By Rolle's theorem, there exists some $\lambda \in(0,1)$ such that

$$
G^{\prime}(x+\lambda(y-x))=0
$$

Expanding that expression using (4) and (6),

$$
\begin{aligned}
& 0=G^{\prime}(x+\lambda(y-x))=F^{\prime}(x+\lambda(y-x))+n\left(\frac{y-x-\lambda(y-x)}{y-x}\right)^{n-1} \frac{1}{y-x} F(x) \\
& \Rightarrow \frac{f^{(n)}(x+\lambda(y-x))}{(n-1) !}[y-x-\lambda(y-x)]^{n-1}=n\left(\frac{(1-\lambda)(y-x)}{y-x}\right)^{n-1} \frac{1}{y-x} F(x) \\
& \Rightarrow \frac{f^{(n)}(x+\lambda(y-x))}{(n-1) !}[(1-\lambda)(y-x)]^{n-1}=n(1-\lambda)^{n-1} \frac{1}{y-x} F(x) \\
& \Rightarrow \frac{f^{(n)}(x+\lambda(y-x))}{n !}(y-x)^{n}=F(x)
\end{aligned}
$$

which is the desired result.

Taylor's theorem gives us a formula for constructing a polynomial approximation to a differentiable function. With $n=2$, and omitting the remainder, we get

$$
\begin{equation*}
f(x+h) \cong f(x)+f^{\prime}(x) h \tag{1}
\end{equation*}
$$

The differentiability of $f$ implies that the error term $E_{2}$ will be small. Hence the linear function in the right-hand side of (1) is guaranteed to be a decent approximation to $f($ ) near $x$. Higher-order approximations that use several derivatives will be even better.

Problem 1.10. A sufficient condition for a local maximum. Let $f: \mathbb{R} \longrightarrow \mathbb{R}$ be twice differentiable on some interval containing $x^{0}$. Assume, moreover, that $f^{\prime}\left(x^{0}\right)=0, f^{\prime \prime}\left(x^{0}\right)<0$, and $f^{\prime \prime}$ is continuous at $x^{0}$. Use Problem 1.8 to show that $x^{0}$ is a local maximizer of $f$.

Problem 1.11. Let $f: \mathbb{R} \longrightarrow \mathbb{R}$ be $m+1$ times differentiable on an interval around the point $x^{0}$. Assume that for some $m>1, f^{(m)}\left(x^{0}\right)$ is the first nonzero derivative of $f$ at $x^{0}$, that is,

$$
f^{\prime}\left(x^{0}\right)=f^{\prime \prime}\left(x^{0}\right)=f^{(3)}\left(x^{0}\right)=\ldots=f^{(m-1)}\left(x^{0}\right)=0 \quad \text { and } \quad f^{(m)}\left(x^{0}\right) \neq 0
$$

Use Taylor's theorem to show that

(i) if $m$ is even and $f^{(m)}\left(x^{0}\right)<0$, then $f$ has a local maximum at $x^{0}$,

(ii) if $m$ is even and $f^{(m)}\left(x^{0}\right)>0$, then $f$ has a local minimum at $x^{0}$,

(iii) if $m$ is odd, then $f$ has neither a local maximum nor a local minimum at $x^{0}$.

Problem 1.12. Cauchy's mean-value theorem. Prove the following result: Let $f$ and $g:[a, b] \rightarrow \mathbb{R}$ be differentiable on $(a, b)$, and suppose that $g^{\prime}(x) \neq 0$ for all $x$ in $(a, b)$. Then there is a point $z$ in $(a, b)$ such that

$$
\frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f^{\prime}(z)}{g^{\prime}(z)}
$$

Hint: How do you have to modify the function $\phi()$ in the proof of Theorem 1.7?

Problem 1.13. L'Hôpital's rule. Suppose $f$ and $g$ are continuous real-valued functions defined and differentiable on some open interval containing the point $a$ and such that $f(a)=g(a)=0$. Show that if $f^{\prime}(x) / g^{\prime}(x)$ tends to a limit as $x \rightarrow a$, so does $f(x) / g(x)$, and

$$
\lim _{x \rightarrow a} \frac{f(x)}{g(x)}=\lim _{x \rightarrow a} \frac{f^{\prime}(x)}{g^{\prime}(x)}
$$

Hint: Use Cauchy's mean-value theorem (Problem 1.12).

## 2. Partial and Directional Derivatives

We now want to extend the concept of differentiability at a point $x$ from univariate functions to real-valued functions of $n$ variables. One complication we immediately run into is that we now have to specify the direction along which we are approaching $x$. The problem does not arise in the real line because there we can approach $x$ only from the left or from the right, and the derivative of the univariate function $g()$ at $x$ is defined as the common value of both one-sided limits whenever they coincide. In $\mathbb{R}^{\mathrm{m}}$, however, we can approach a point from an infinite number of directions, and therefore we have to specify which one we are considering. This observation leads us to the concept of directional derivative, which we now define.

Let $f$ be a function $\mathbb{R}^{\mathrm{n}} \rightarrow \mathbb{R}$, and fix two vectors $x^{0}$ and $u$ in $\mathbb{R}^{\mathrm{n}}$ with $\|u\|=1$. We will interpret $x^{0}$ as a "point" in space, and $u$ as a vector (an "arrow") describing a direction of movement in $n$-space, as illustrated in Figure 4.3. The set of points

$$
L\left(x^{0}, u\right)=\left\{x(\alpha) \in \mathbb{R}^{\mathbf{n}} ; x(\alpha)=x^{0}+\alpha u, \alpha \in \mathbb{R}\right\}
$$

corresponds to the straight line through $x^{0}$ with direction $u$. Because $u$ has norm 1, the parameter $\alpha$ measures the distance between a point $x(\alpha)$ in the line and $x^{0}$.

We will define the directional derivative of $f$ at $x^{0}$ in the direction of $u$ with the help of an auxiliary univariate function $g$ whose derivative at zero gives us the slope of $f$ as we move away from $x^{0}$ in the direction of $u$. We define $g: \mathbb{R} \longrightarrow \mathbb{R}$ by

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-170.jpg?height=470&width=781&top_left_y=1602&top_left_x=352)

$\underline{0}$

Figure 4.3.

$$
g(\alpha)=f\left(x^{0}+\alpha u\right)
$$

When $n=2$, the geometric interpretation is straightforward: The graph of $f$ is a three-dimensional surface that we suppose to be oriented in such a way that the value of the function is measured vertically. The function $g$ is the restriction of $f$ to the line $L\left(x^{0}, u\right)$, and its graph is the curve obtained by cutting this surface with a vertical plane through $x^{0}$ and "parallel" to $u$. Then $g^{\prime}(0)$ gives the slope of this curve at $x^{0}$ or, equivalently, the slope of the surface $\left\{\left(x_{1}, x_{2}, y\right) ; y=f\left(x_{1}, x_{2}\right)\right\}$ at the point $\left(x_{1}, x_{2}, f\left(x_{1}, x_{2}\right)\right)$ when we move in the direction of $u$. We say that $g^{\prime}(0)$ is the directional derivative of $f$ at the point $x^{0}$ in the direction of $u$, and write $D f\left(x^{0} ; u\right)$. More formally, we have the following:

Definition 2.1. Directional derivative. The directional derivative of $f: \mathbb{R}^{\mathrm{n}}$ $\longrightarrow \mathbb{R}$ in the direction of $u$ at the point $x^{0}$ is defined by

$$
D f\left(x^{0} ; u\right)=\lim _{\alpha \rightarrow 0} \frac{f\left(x^{0}+\alpha u\right)-f\left(x^{0}\right)}{\alpha}, \quad \text { where } \alpha \in \mathbb{R} \text { and }\|u\|=1
$$

whenever this limit exists.

Because the only function of the vector $u$ is that of indicating the direction of motion, we can assume that its norm is 1 . This is not necessary for the definition per se, but it is a convenient way to normalize directional derivatives.

Problem 2.2. Let $f\left(x_{1}, x_{2}\right)=x_{1} x_{2}, u=(3 / 5,4 / 5)$, and $x^{0}=(1,2)$. Compute $D f\left(x^{0} ; u\right)$ directly by taking the appropriate limits, and verify that the result is the same if you use the formula

$$
D f\left(x^{0} ; u\right)=\nabla f\left(x^{0}\right) u
$$

(The definition of the gradient $\nabla f\left(x^{0}\right)$ follows after Problem 2.5.)

Directional derivatives in the direction of the coordinate axes are of special interest. The partial derivative of $f$ with respect to its $i$ th argument is defined as $D f\left(x ; e^{i}\right)$, where $e^{i}$ is a vector whose components are all zero except for the $i$ th one, which is 1 .

Definition 2.3. Partial derivative. Let $f$ be a multivariate function $\mathbb{R}^{\mathrm{n}} \rightarrow$ $\mathbb{R}$. The partial derivative of $f$ with respect to its $i$ th argument, $x_{i}$, at a point $x=\left(x_{i}, x_{-i}\right)$, is the limit ${ }^{1}$

$$
D_{x_{i}} f(x)=\lim _{\alpha \rightarrow 0} \frac{f\left(x_{i}+\alpha, x_{-i}\right)-f\left(x_{i}, x_{-i}\right)}{\alpha}
$$

whenever it exists.

There are several standard ways to write the partial derivative of $f$ with respect to $x_{i}$. One of the most common notations uses subindices to indicate the variable with respect to which we are differentiating: $D_{x_{1}} f(x), f_{x_{i}}(x)$, or $f_{i}(x)$. Another possibility is to write $\partial f(x) / \partial x_{i}$. In each case, we explicitly indicate the argument vector $x$ to emphasize that the partial derivative is also a function of $x$. As it is not normally necessary to insist on this, the arguments are often omitted, and we write $D_{x_{i}} f, f_{x_{i}}$, or $\partial f / \partial x_{i}$.

Conceptually there is no difference between a partial derivative and the ordinary derivative of a univariate function. For given values of the other arguments $x_{-i}, f\left(x_{i}, x_{-i}\right)$ is a function of a single variable, $x_{i}$. Fixing $x_{-i}$ at a constant value $\bar{x}_{-i}$, and defining a new function $g$ by $g\left(x_{i}\right)=f\left(x_{i}, \bar{x}_{-i}\right)$, we have $g^{\prime}\left(x_{i}\right)=f_{i}\left(x_{i}, \bar{x}_{-i}\right)$. Hence the standard rules of differentiation for "normal" derivatives apply, without change, to partial derivatives, treating the other variables as constants. For example, if $f(x, y)=3 x^{2} y+4 y^{3}$, then $f_{x}(x, y)=6 x y$, and $f_{y}(x, y)=3 x^{2}+12 y^{2}$.

Problem 2.4. Given the functions

$$
\begin{aligned}
& y=f\left(x_{1}, x_{2}\right)=\sin \left(x_{1} x_{2}+x_{2}^{2}\right), \quad y=f\left(x_{1}, x_{2}\right)=x_{1}^{2} x_{2}+x_{2}^{3} \ln x_{1}, \\
& y=f\left(x_{1}, x_{2}\right)=\ln \left(x_{2}+e^{x_{1}} x_{2}\right)
\end{aligned}
$$

calculate, for each of them, the partial derivatives $\partial y / \partial x_{1}$ and $\partial y / \partial x_{2}$.

Problem 2.5. Find the points where all the partial derivatives of the function

$$
f\left(x_{1}, x_{2}\right)=x_{1}^{4} x_{2}-x_{1}^{2} x_{2}^{3}
$$

are zero.

If all the partial derivatives of $f$ exist and are continuous in some neighborhood of a point $x^{0}$, then the directional derivative at $x^{0}$ exists for all directions $u$ and can be written as a linear combination of the partial derivatives. To see this, let

$$
g(\alpha)=f\left(x^{0}+\alpha u\right)=f\left(x_{1}^{0}+\alpha u_{1}, \ldots, x_{n}^{0}+\alpha u_{n}\right)
$$

If the partial derivatives of $f$ are continuous, then $f$ is differentiable at $x^{0}$, and the chain rule yields

$$
g^{\prime}(\alpha)=f_{1}\left(x^{0}+\alpha u\right) u_{1}+\ldots+f_{n}\left(x^{0}+\alpha u\right) u_{n}=\sum_{i=1}^{n} f_{i}\left(x^{0}+\alpha u\right) u_{i}
$$

(see Theorems 3.4 and 3.5 in Section 3). Hence,

$$
\begin{equation*}
D f\left(x^{0} ; u\right)=g^{\prime}(0)=\sum_{i=1}^{n} f_{i}\left(x^{0}\right) u_{i} \tag{1}
\end{equation*}
$$

If we define the gradient vector of $f$ at $x$ by

$$
\nabla f(x)=\left(f_{1}(x), \ldots, f_{n}(x)\right)
$$

then (1) can be written as the scalar product of the gradient and the direction vector:

$$
\begin{equation*}
D f\left(x^{0} ; u\right)=\nabla f(x) u \tag{2}
\end{equation*}
$$

Using expression (2), we see that the gradient is the vector that points in the direction of steepest ascent or descent along the graph of the function. Given (2), the Cauchy-Schwarz inequality implies (using the convention that $\|u\|=1)$

$$
\begin{equation*}
|D f(x ; u)|=|\nabla f(x) u| \leq\|\nabla f(x)\|\|u\|=\|\nabla f(x)\| \tag{3}
\end{equation*}
$$

Hence, the absolute value of the directional derivative cannot exceed the norm of the gradient. Moreover, if we consider the direction of the gradient, given by the normalized vector $g=\nabla f(x) /\|\nabla f(x)\|$, we have

$$
|D f(x ; g)|=|\nabla f(x) g|=\frac{\nabla f(x) \nabla f(x)}{\|\nabla f(x)\|}=\frac{\|\nabla f(x)\|^{2}}{\|\nabla f(x)\|}=\|\nabla f(x)\|
$$

In this particular direction, therefore, the weak inequality in (3) holds as an equality. Thus, the gradient of $f$ at $x$ points in the direction in which the slope of $f$ at $x$ is largest in absolute value, and its norm is the absolute value of this slope.

## Higher-Order Partials

Let $f$ be a function $\mathbb{R}^{\mathrm{n}} \longrightarrow \mathbb{R}$; then each one of its partial derivatives $f_{i}(x)$ is also a real-valued function of $n$ variables, and the partials of $f_{i}()$ can be defined exactly as for $f()$. The partials of the $f_{i}()$ 's are the second partial derivatives of $f$, and we write $f_{i k}(x)$ or $\partial^{2} f(x) / \partial x_{i} \partial x_{k}$ for $\partial f_{i}(x) / \partial x_{k}$.

In many cases of interest, symmetric cross-partials coincide, that is $f_{i k}(x)=f_{k i}(x)$, so the order of differentiation does not matter. The following result, a weak version of Schwarz's theorem, gives sufficient conditions for this property to hold.

Theorem 2.6. Let $\mathrm{f}: \mathbb{R}^{n} \longrightarrow \mathbb{R}$ be a function defined in an open neighborhood of a point $\mathrm{x}^{0}$. Assume that the partial derivatives $\mathrm{f}_{\mathrm{i}}(\mathrm{x}), \mathrm{f}_{\mathrm{k}}(\mathrm{x}), \mathrm{f}_{\mathrm{ki}}(\mathrm{x})$, and $\mathrm{f}_{\mathrm{ik}}(\mathrm{x})$ are also defined in this neighborhood and that $\mathrm{f}_{\mathrm{ki}}(\mathrm{x})$ and $\mathrm{f}_{\mathrm{ik}}(\mathrm{x})$ are continuous at $\mathrm{x}^{0}$. Then $\mathrm{f}_{\mathrm{ik}}\left(\mathrm{x}^{0}\right)=\mathrm{f}_{\mathrm{ki}}\left(\mathrm{x}^{0}\right)$.

Proof. Because we will consider only two partials at a time, we can assume, with no loss of generality, that $f$ is a function of two variables, say $f(x, y)$. We
will work on a square of side $h$ contained in the neighborhood of $\left(x^{0}, y^{0}\right)$ mentioned in the statement of the theorem.

Consider the expression

$$
D=f\left(x^{0}+h, y^{0}+h\right)-f\left(x^{0}+h, y^{0}\right)-f\left(x^{0}, y^{0}+h\right)+f\left(x^{0}, y^{0}\right)
$$

To prove the theorem, we will use the mean-value theorem for univariate functions to derive two equivalent expressions for $D$ in terms of symmetric cross-partials and conclude from their equality that $f_{x y}\left(x^{0}, y^{0}\right)=f_{y x}\left(x^{0}, y^{0}\right)$.

- If we define the function

$$
\phi(x)=f\left(x, y^{0}+h\right)-f\left(x, y^{0}\right)
$$

we can write $D$ in the form

$$
\begin{equation*}
D=\phi\left(x^{0}+h\right)-\phi\left(x^{0}\right) \tag{1}
\end{equation*}
$$

By assumption, $\phi$ is differentiable in the region in which we are working, with

$$
\phi^{\prime}(x)=f_{x}\left(x, y^{0}+h\right)-f_{x}\left(x, y^{0}\right)
$$

and applying the mean-value theorem for univariate functions, we have, for some $\lambda_{1} \in(0,1)$,

$$
\begin{equation*}
D=h \phi^{\prime}\left(x^{0}+\lambda_{1} h\right)=h\left[f_{x}\left(x^{0}+\lambda_{1} h, y^{0}+h\right)-f_{x}\left(x^{0}+\lambda_{1} h, y^{0}\right)\right] \tag{2}
\end{equation*}
$$

Next, put

$$
g(y)=f_{x}\left(x^{0}+\lambda_{1} h, y\right)
$$

with derivative

$$
g^{\prime}(y)=f_{x y}\left(x^{0}+\lambda_{1} h, y\right)
$$

and write (2) in the form

$$
\begin{equation*}
D=h\left[g\left(y^{0}+h\right)-g\left(y^{0}\right)\right] \tag{3}
\end{equation*}
$$

By the mean-value theorem, there is some $\lambda_{2} \in(0,1)$ for which we have

$$
\begin{equation*}
D=h^{2} g^{\prime}\left(y^{0}+\lambda_{2} h\right)=h^{2} f_{x y}\left(x^{0}+\lambda_{1} h, y^{0}+\lambda_{2} h\right) \tag{4}
\end{equation*}
$$

- In a similar manner, if we define $\gamma()$ by

$$
\gamma(y)=f\left(x^{0}+h, y\right)-f\left(x^{0}, y\right)
$$

we have $D=\gamma\left(y^{0}+h\right)-\gamma\left(y^{0}\right)$, and by the same procedure used earlier we see that there exist $\lambda_{3}, \lambda_{4} \in(0,1)$ such that

$$
\begin{equation*}
D=h^{2} f_{y x}\left(x^{0}+\lambda_{3} h, y^{0}+\lambda_{4} h\right) \tag{5}
\end{equation*}
$$

Hence,

$$
h^{2} f_{x y}\left(x^{0}+\lambda_{1} h, y^{0}+\lambda_{2} h\right)=D=h^{2} f_{y x}\left(x^{0}+\lambda_{3} h, y^{0}+\lambda_{4} h\right)
$$

- Finally, we take limits for the preceding expression as $h \rightarrow 0$. Then the points at which we are evaluating the partials both approach $\left(x^{0}, y^{0}\right)$, and because $f_{x y}()$ and $f_{y x}()$ are continuous by assumption, we have

$$
f_{x y}\left(x^{0}, y^{0}\right)=\lim _{h \rightarrow 0} f_{x y}\left(x^{0}+\lambda_{1} h, y^{0}+\lambda_{2} h\right)=\lim _{h \rightarrow 0} f_{y x}\left(x^{0}+\lambda_{3} h, y^{0}+\lambda_{4} h\right)=f_{y x}\left(x^{0}, y^{0}\right)
$$

Thus, symmetric cross-partials coincide at $\left(x^{0}, y^{0}\right)$.

## Directional Derivatives and Continuity

We began this section emphasizing the conceptual similarity between the directional derivatives of a multivariate function and the "normal" derivatives of univariate functions. The similarities end, however, when it comes to the connection between the existence of a derivative and continuity. We know that a function from $\mathbb{R}$ to $\mathbb{R}$ that is differentiable at a point $x^{0}$ is also continuous at $x^{0}$. For a function $\mathbb{R}^{n} \rightarrow \mathbb{R}$, however, the existence of all partial derivatives, or even the existence of all directional derivatives at a point, is not sufficient to guarantee continuity, as shown by the following example.

Example 2.7. Consider the function

$$
\begin{aligned}
f(x, y) & =\frac{x y^{2}}{x^{2}+y^{4}} & & \text { for } x \neq 0 \\
& =0 & & \text { for } x=0
\end{aligned}
$$

For any $u=\left(u_{1}, u_{2}\right)$ in $R^{2}$, the directional derivative of $f$ at $(0,0)$ is given by

$$
\begin{array}{rlrl}
\lim _{\alpha \rightarrow 0} \frac{f\left(\alpha u_{1}, \alpha u_{2}\right)-f(0,0)}{\alpha} & =\lim _{\alpha \rightarrow 0} \frac{\left(\alpha u_{1}\right)\left(\alpha u_{2}\right)^{2}}{\alpha\left[\left(\alpha u_{1}\right)^{2}+\left(\alpha u_{2}\right)^{4}\right]} & \\
& =\lim _{\alpha \rightarrow 0} \frac{u_{1} u_{2}^{2}}{u_{1}^{2}+\alpha^{2} u_{2}^{4}}=u_{2}^{2} / u_{1} & & \text { if } u_{1} \neq 0 \\
& =0 & & \text { if } u_{1}=0
\end{array}
$$

Hence, $D f(0,0 ; u)$ exists for all $u$. On the other hand, $f$ has value $\frac{1}{2}$ at all points on the curve $x=y^{2}$ except at the origin, where it is zero. Hence, $f$ is not continuous at $(0,0)$.

It is possible to guarantee the continuity of $f$ at a point by imposing additional conditions on the directional derivatives. For example, it can be shown, using an argument similar to that in the proof of Theorem 2.6, that
a sufficient condition for the continuity of $f$ at $x^{0}$ is that all its partial derivatives exist and be bounded on a neighborhood of $x$. It follows easily from this result that the continuity of the partial derivatives of $f$ on some neighborhood of $x^{0}$ is sufficient for $f$ to be continuous at $x^{0}$. Soon we will prove a stronger result.

The foregoing discussion suggests that it might be interesting to define a stronger concept of differentiability for multivariate functions. This will be done in the following section. For the moment, we observe that the existence of partial derivatives at a point $x^{0}$, or even of directional derivatives in all directions, is not sufficient for us to say that the function is differentiable at $x^{0}$.

## 3. Differentiability

We now turn to the general case where $f: \mathbb{R}^{n} \longrightarrow \mathbb{R}^{m}$ is a function of $n$ variables whose value is an $m$-vector. We can think of the mapping $f$ as a vector of component functions $f^{\prime}$, each of which is a real-valued function of $n$ variables:

$$
f=\left(f^{1}, \ldots, f^{m}\right)^{T}, \quad \text { where } \quad f^{i}: \mathbb{R}^{n} \longrightarrow \mathbb{R} \quad \text { for } i=1, \ldots, m
$$

We would like to define a concept of differentiability for functions $\mathbb{R}^{\mathrm{n}} \longrightarrow \mathbb{R}^{\mathrm{m}}$ that can be seen as a natural generalization of the derivative of a univariate function and that will preserve the implication of continuity without additional assumptions. As we will see, the key lies in defining differentiability in terms of the possibility of approximating the local behavior of $f$ through a "linear" function. We will then relate the resulting concept of derivative to the partial derivatives of the components of $f$.

Let us return for a moment to the definition of the derivative for a function $g: \mathbb{R} \longrightarrow \mathbb{R}$ and see if we can reinterpret it in a way that can be naturally extended to the multivariate case. A univariate real-valued function $g$ is differentiable at a point $x$ in its domain if the limit

$$
\lim _{h \rightarrow 0} \frac{g(x+h)-g(x)}{h} \quad(h \in \mathbb{R})
$$

exists, that is, if it is equal to some real number $a$. This condition may be rephrased as follows: $g$ is differentiable at $x$ if there exists a real number $a$ such that

$$
\begin{equation*}
\lim _{h \rightarrow 0} \frac{g(x+h)-[g(x)+a h]}{h}=0 \tag{1}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-177.jpg?height=516&width=891&top_left_y=183&top_left_x=286)

Figure 4.4. The derivative as a linear approximation.

To interpret this expression, fix some $x$, and suppose that we want to approximate the value of $g(x+h)$ by an affine function. One possibility is to use $g(x)+a h=g(x)+g^{\prime}(x) h$ to approximate $g(x+h)$, as shown in Figure 4.4.

Expression (1) guarantees that the approximation will be good whenever $h$ is small. If we denote the approximation error by

$$
E_{g}(h) \equiv g(x+h)-[g(x)+a h]
$$

then (1) can be written

$$
\begin{equation*}
\lim _{h \rightarrow 0} \frac{E_{g}(h)}{h}=0 \tag{2}
\end{equation*}
$$

which tells us that the approximation error goes to zero with $h$. Indeed, $E_{g}(h)$ goes to zero "faster" than $h$ itself, a fact we sometimes indicate by writing $E_{g}(h)=o(h)$ (which reads " $E_{g}(h)$ is little-oh of $h$ ").

In summary, a function $g$ is differentiable at $x$ if for points close to $x, g()$ admits a "good" approximation by an affine function or, equivalently, if the difference $g(x+h)-g(x)$ can be approximated by a linear function $a h$ with an error that is of a smaller order of magnitude than $h$ as $h \rightarrow 0$.

There is no difficulty in extending this notion of differentiability to mappings from $\mathbb{R}^{\mathrm{m}}$ to $\mathbb{R}^{\mathrm{m}}$. Before giving a formal definition, we want to emphasize the importance of the concept of differentiability for our purposes. Because differentiable functions admit good linear approximations, so do differentiable models. This gives us a tractable way to analyze them: When we use the calculus to study a nonlinear model, we are in fact constructing a linear approximation to it in some neighborhood of an equilibrium. The assumption that the behavioral functions in the model are differentiable means that the approximation error is small. The obvious limitation of the
method is that it generally yields only local results, valid only in some small neighborhood of the initial solution.

Definition 3.1. Differentiability. A function $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}^{\mathrm{m}}$, where $X$ is an open set, is differentiable at a point $x \in X$ if there exists a matrix $A_{x}$ such that

$$
\begin{equation*}
\lim _{\|h\| \rightarrow 0} \frac{\left\|f(x+h)-f(x)-A_{x} h\right\|}{\|h\|}=0 \tag{3}
\end{equation*}
$$

where $h \in \mathbb{R}^{\mathrm{n}}$ and $\|\cdot\|$ is the Euclidean norm of a vector, $\|x\|=\sqrt{\sum_{i=1}^{n}\left(x_{i}\right)^{2}}$. If $f$ is differentiable at every point in its domain, we say that $f$ is differentiable (on $X$ ).

There are two slightly different ways to think about the derivative of a mapping. Perhaps the most natural one is as a function whose value at each point is a matrix. If $f$ is differentiable on $X$, we can define its derivative as the function

$$
D f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}_{m \times n}
$$

such that for each $x \in X, D f(x)=A_{x}$, where $A_{x}$ is the matrix that satisfies (3) in Definition 3.1. In this interpretation, therefore, the derivative of a function at a point is a matrix, and $D f$ is a function $X \rightarrow \mathbb{R}_{\mathrm{mxn}}$.

As we know, every matrix defines a linear transformation. We refer to the linear mapping defined by the derivative of $f$ at $x$ as the differential of $f$ at $x$, written $d f_{x}$. Hence, the differential of $f$ at $x$ is the function

$$
d f_{x}: \mathbb{R}^{\mathrm{n}} \longrightarrow \mathbb{R}^{\mathrm{m}}, \quad \text { with } d f_{x}(h)=D f(x) h=A_{x} h
$$

and its value at a point is a vector in $\mathbb{R}^{\mathrm{m}}$. Thus, we can also think of the derivative as a mapping that to each $x$ in $X$ assigns the linear transformation $d f_{x}$, represented by the matrix $D f(x)$. In this interpretation, the derivative $D f$ is a mapping from $X$ to the space $L\left(\mathbb{R}^{\mathbf{n}}, \mathbb{R}^{\mathbf{m}}\right)$ of linear functions from $\mathbb{R}^{\mathbf{n}}$ into $\mathbb{R}^{\mathrm{m}}$, with $x \longrightarrow d f_{x}{ }^{3}$

We can, as in the case of a univariate real function, interpret the differential as a linear approximation to the difference $f(x+h)-f(x)$. Expression (3) then guarantees that the approximation is good for "small" $h$. As before, if we denote the approximation error by

$$
E_{f}(h)=f(x+h)-f(x)-d f_{x}(h)
$$

we can rewrite (3) in the form

$$
\begin{equation*}
\lim _{\|h\| \rightarrow 0} \frac{\left\|E_{f}(h)\right\|}{\|h\|}=0 \tag{4}
\end{equation*}
$$

That is, the (norm of the) error vector approaches zero faster than (the norm of) $h$.

It is now easy to check that differentiability implies continuity. We have

$$
f(x+h)=f(x)+d f_{x}(h)+E_{f}(h)
$$

Taking the limit of this expression as $h \rightarrow \underline{0}$, we have that $E_{f}(h) \rightarrow \underline{0}$ by the differentiability of $f$, and $d f_{x}(h) \rightarrow \underline{0}$ by the continuity of the linear mapping $d f_{x}$ and the fact that $d f_{x}(\underline{0})=\underline{0}$. Hence,

$$
\lim _{h \rightarrow \underline{0}} f(x+h)=f(x)
$$

and $f$ is continuous at $x$. We have, then, the following theorem.

Theorem 3.2. Differentiability implies continuity. Let $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \rightarrow \mathbb{R}^{m}$ (X open) be differentiable at a point $\mathrm{x} \in \mathrm{X}$. Then $\mathrm{f}$ is continuous at $\mathrm{x}$.

The following theorem relates the derivative of the mapping $f$ to the partial derivatives of its component functions $f^{1}, \ldots, f^{m}$. An immediate implication of the theorem is that the matrix $A_{x}$ that appears in the definition of differentiability is unique, and therefore the functions $D f$ and $d f_{x}$ are well defined.

Theorem 3.3. Let $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}^{m}$, ( $\mathrm{X}$ open) be a mapping, with component functions $\mathrm{f}^{\mathrm{I}}, \ldots, \mathrm{f}^{\mathrm{m}}$. Then $\mathrm{f}$ is differentiable at a point $\mathrm{x} \in \mathrm{X}$ if and only if each of these component functions is differentiable at $\mathbf{x}$. Moreover, if $\mathrm{f}$ is differentiable at $\mathrm{x}$, then the partial derivatives of the component functions exist at $\mathrm{x}$, and the derivative of $\mathrm{f}$ at $\mathrm{x}$ is the matrix of first partial derivatives of the component functions evaluated at $\mathrm{x}$, that is,

$$
\operatorname{Df}(\mathrm{x})=\left[\begin{array}{c}
\mathrm{Df}^{\mathrm{I}}(\mathrm{x}) \\
\ldots . \\
\mathrm{Df}^{\mathrm{m}}(\mathrm{x})
\end{array}\right]=\left[\begin{array}{c}
\nabla \mathrm{f}^{1}(\mathrm{x}) \\
\ldots \\
\nabla \mathrm{f}^{\mathrm{m}}(\mathrm{x})
\end{array}\right] \equiv\left[\begin{array}{ccc}
\mathrm{f}_{\mathrm{x}_{\mathrm{I}}}^{I}(\mathrm{x}) & \ldots \ldots . \mathrm{f}_{\mathrm{x}_{\mathrm{n}}}^{l}(\mathrm{x}) \\
\ldots . & \ldots \ldots . & \ldots . \\
\mathrm{f}_{\mathrm{x}_{2}}^{\mathrm{m}}(\mathrm{x}) & \ldots \ldots . \mathrm{f}_{\mathrm{x}_{\mathrm{n}}}^{\mathrm{m}}(\mathrm{x})
\end{array}\right]
$$

Note carefully what this expression says. Each row of the matrix $D f(x)$ is the vector $D f^{j}(x)$. This vector, thought of as a $1 \times n$ matrix, is the derivative of the function $f^{j}: \mathbb{R}^{\mathrm{n}} \rightarrow \mathbb{R}$. Moreover, the components of this vector are the partial derivatives of $f^{j}$.

The matrix of first partial derivatives of the component functions of $f$ is known as the Jacobian of $f^{4}$ The following symbols are sometimes used to refer to this matrix:

$$
D f(x)=J^{f}(x)=\left[\frac{\partial\left(f^{1}, \ldots, f^{m}\right)}{\partial\left(x_{1}, \ldots, x_{n}\right)}\right]
$$

When we are interested in a submatrix of $D f(x)$, we will use subindices to indicate the variables with respect to which we are differentiating. For example, if we partition $x=(y, z)$, the matrix of partial derivatives of $f^{1}, \ldots$, $f^{m}$ with respect to the components of $z$ will be written $D_{z}^{f}(y, z)$ or $J_{z}^{f}(y, z)$.

Proof. Assume that $f$ is differentiable at $x$. Then there exists a matrix $D f(x)$ such that

$$
\begin{equation*}
\lim _{\|h\| \rightarrow 0} \frac{\|f(x+h)-f(x)-D f(x) h\|}{\|h\|}=0 \tag{1}
\end{equation*}
$$

Denote the entries of $D f(x)$ by $a_{i k}(i=1, \ldots, m ; k=1, \ldots, n)$, and let $h=\left(h_{1}, \ldots, h_{n}\right)$. Then we have

$$
D f(x) h=\left(\sum_{k=1}^{n} a_{1 k} h_{k}, \ldots, \sum_{k=1}^{n} a_{m k} h_{k}\right)^{T}
$$

and the $i$ th component of the vector $f(x+h)-f(x)-D f(x) h$ is given by

$$
f^{i}(x+h)-f^{i}(x)-\sum_{k=1}^{n} a_{i k} h_{k}
$$

Observe that the absolute value of a component of a vector cannot exceed the Euclidean norm of the vector. Hence, (1) implies

$$
\begin{equation*}
\lim _{\|h\| \rightarrow 0} \frac{\left|f^{i}(x+h)-f^{i}(x)-\sum_{k=1}^{n} a_{i k} h_{k}\right|}{\|h\|}=0 \tag{2}
\end{equation*}
$$

which is precisely the definition of differentiability for the function $f^{i}$ : $\mathbb{R}^{\mathrm{n}} \rightarrow \mathbb{R}$. Therefore, the component functions of $f$ are differentiable.

To show that the coefficients $a_{i k}$ of the matrix $D f(x)$ are the corresponding partial derivatives, we let $h$ approach $\underline{0}$ along the $s$ th coordinate axis (i.e., put $h_{k}=0$ for all $k \neq s$ ). Then (2) implies

$$
\begin{equation*}
a_{i s}=\lim _{h_{s} \rightarrow 0} \frac{f^{i}\left(x_{s}+h_{s}, x_{-s}\right)-f^{i}\left(x_{s}, x_{-s}\right)}{h_{s}} \equiv f_{x_{s}}^{i}(x) \tag{3}
\end{equation*}
$$

To establish sufficiency, note that the same logic will work in reverse. If all the component functions are differentiable, (2) holds, with $a_{i s}=f_{x_{s}}^{i}(x)$; then (1) follows from (2) and from the observation that the Euclidean norm of a vector cannot be larger than the sum of the absolute values of its components. $^{5}$

By Theorem 3.3, differentiability at a point implies the existence of all partial derivatives at that point. As we have seen, the converse statement is not true. However, the continuity of the partial derivatives is sufficient to guarantee differentiability, as shown in the following theorem.

Theorem 3.4. Let $\mathrm{f}: \mathbb{R}^{\mathrm{n}} \supseteq \mathrm{X} \longrightarrow \mathbb{R}^{\mathrm{m}}$, ( $\mathrm{X}$ open) be a mapping with component functions $\mathrm{f}^{l}, \ldots, \mathrm{f}^{\mathrm{m}}$. If the partial derivatives of the component functions exist and are continuous on $\mathrm{X}$, then $\mathrm{f}$ is differentiable on $\mathrm{X}$.

Proof. By the preceding theorem, a vector-valued function is differentiable at a point $x^{0}$ if and only if all its component functions are differentiable at $x^{0}$. Hence, it is sufficient to prove the theorem for the case of a real-valued function of $n$ variables, $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}$.

Fix some arbitrary $x$ in $X$ and some $\varepsilon>0$. Because $X$ is open and the partials of $f$ are continuous, we can find some $r$ such that the open ball $B_{r}(x)$ is contained in $X$ and

$$
\begin{equation*}
\left|f_{i}(x+h)-f_{i}(x)\right|<\frac{\varepsilon}{n} \text { for } i=1, \ldots, n \tag{1}
\end{equation*}
$$

for all $x+h \in B_{r}(x)$ (or, equivalently, for all $h$ such that $\|h\|<r$ ).

Now, if $f$ is differentiable, its derivative at $x$ will be the gradient vector

$$
\nabla f(x)=\left(f_{1}(x), \ldots, f_{n}(x)\right)
$$

Hence, what we want to prove is that

$$
\begin{equation*}
\lim _{\|h\| \rightarrow 0} \frac{|f(x+h)-f(x)-\nabla f(x) h|}{\|h\|}=0 \tag{2}
\end{equation*}
$$

We will work with the expression in the numerator. Let $h=\left(\alpha_{1}, \ldots, \alpha_{n}\right)$ $=\sum_{i=1}^{n} \alpha_{i} e^{i}$, where $e^{i}$ is the $i$ th-unit coordinate vector in $\mathbb{R}^{\mathbf{n}}$ (a vector with all zeros except for a 1 in the $i$ th coordinate), and assume $\|h\|<r$. Next, define the $n$-vectors $v_{0}, \ldots, v_{n}$ by

$$
v_{0}=\underline{0} \quad \text { and } \quad v_{k}=\left(\alpha_{1}, \ldots, \alpha_{k}, 0, \ldots, 0\right)=\sum_{i=1}^{k} \alpha_{i} e^{i} \quad \text { for } k=1, \ldots, n
$$

Then, we can write ${ }^{6}$

$$
\begin{equation*}
f(x+h)-f(x)=\sum_{i=1}^{n}\left[f\left(x+v_{i}\right)-f\left(x+v_{i-1}\right)\right] \tag{3}
\end{equation*}
$$

Because $\left\|v_{k}\right\| \leq\|h\|<r$ for all $r$ and $B_{r}(x)$ is a convex set, the segments with end points $x+v_{k}$ all lie in $B_{r}(x)$, and therefore each partial $f_{i}()$ of $f$ exists and is continuous on the line segment connecting $x+v_{i}$ and $x+v_{i-1}$. Moreover, because along this segment of length $\alpha_{i}$ only the $i$ th argument of $f$ changes, we can use the one-dimensional mean-value theorem to conclude that for each $i=1, \ldots, n$, there exists some $\theta_{i} \in(0,1)$ such that

$$
\begin{equation*}
f\left(x+v_{i}\right)-f\left(x+v_{i-1}\right)=\alpha_{i} f_{i}\left(x+v_{i-1}+\theta_{i} \alpha_{i} v_{i}\right) \tag{4}
\end{equation*}
$$

Using (3), (4), and (1) in the numerator of (2), we have, for $\|h\|<r$,

$$
\begin{aligned}
& |f(x+h)-f(x)-\nabla f(x) h|=\left|\sum_{i=1}^{n}\left[f\left(x+v_{i}\right)-f\left(x+v_{i-1}\right)\right]-\sum_{i=1}^{n} \alpha_{i} f_{i}(x)\right| \\
& \quad=\left|\sum_{i=1}^{n} \alpha_{i}\left[f_{i}\left(x+v_{i-1}+\theta_{i} \alpha_{i} v_{i}\right)-f_{i}(x)\right]\right| \\
& \left.\quad \leq \sum_{i=1}^{n}\left|\alpha_{i}\right| f_{i}\left(x+v_{i-1}+\theta_{i} \alpha_{i} v_{i}\right)-f_{i}(x)\right]\left|<\sum_{i=1}^{n}\right| \alpha_{i} \left\lvert\, \frac{\varepsilon}{n} \leq \varepsilon\|h\|\right.
\end{aligned}
$$

Hence,

$$
\frac{|f(x+h)-f(x)-\nabla f(x) h|}{\|h\|}<\varepsilon \text { for }\|h\|<r
$$

which is what we wanted to show.

We conclude this section with some terminology and a few results for differentiable functions.

## Critical and Regular Points and Values of a Function

As we will see later, some important results require assumptions concerning the rank of the Jacobian of a function, or, equivalently, that of its differential. In particular, it can be shown that if a function $f: \mathbb{R}^{\mathrm{n}} \rightarrow \mathbb{R}^{\mathrm{m}}$ is differentiable at a point $x$ and has a derivative matrix $D f(x)$ of rank $m$, then its local behavior is (loosely speaking) fully determined by that of its differential.

We now introduce some terms that will be useful later. Let $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow$ $\mathbb{R}^{\mathrm{m}}$ ( $X$ open) be a differentiable function. A vector $x \in X$ is a regular point of $f$ if the differential of $f$ at $x$ (i.e., the linear mapping $d f_{x} \in L\left(\mathbb{R}^{\mathbf{n}}, \mathbb{R}^{m}\right)$ ), is surjective (onto). If $x$ is not a regular point of $f$ (i.e., if $d f_{x}$ is not onto), then $x$ is a critical point of $f$. A point $y \in \mathbb{R}^{\mathrm{m}}$ is a critical value of $f$ if it is the image of a critical point, and a regular value otherwise.

Recall that $d f_{x}$ is surjective (and therefore $x$ is a regular point of $f$ ) if and only if the derivative $D f(x)$ has rank $m$. Hence the set of critical points of $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}^{\mathrm{m}}$ is given by

$$
C_{f}=\{x \in X ; \operatorname{rank} D f(x)<m\}
$$

The set of critical values of $f$ is $f\left(C_{f}\right)$, and the set of regular values is its complement, $\mathbb{R}^{\mathrm{m}} \sim f\left(C_{f}\right)$. Note that if $y$ is not the image of any point in $X$, then $y$ is by definition a regular value of $f$, because a regular value is any point that is not a critical value, and $y$ is a critical value of $f$ if and only if $f^{-1}(y)$ contains at least one critical point, which is impossible if $f^{-1}(y)$ is the empty set.

This definition generalizes the standard concept of critical point used in the elementary calculus. If $f$ is a multivariate real-valued function, the definition we have just given is equivalent to the condition that the gradient $\nabla f(x)$ be the zero vector, because this is the only case in which the components of $\nabla f(x)$ do not generate $\mathbb{R}$; if $f$ is a univariate function, the condition
reduces to $f^{\prime}(x)=0$. Note also that if $f$ is a function from $\mathbb{R}^{\mathbf{n}}$ into itself, then $D f(x)$ is a square matrix, and $x$ is a critical point if $|D f(x)|=0$.

## The Chain Rule

In many cases we are interested in the derivatives of composite functions. The following result says that the composition of differentiable functions is differentiable, and its derivative is the product of the derivatives of the original functions.

Theorem 3.5. Let $\mathrm{f}$ and $\mathrm{g}$ be two functions, with

$$
\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}^{m} \quad \text { and } \mathrm{g}: \mathbb{R}^{m} \supseteq \mathrm{Y} \longrightarrow \mathbb{R}^{p}
$$

where $\mathrm{X}$ and $\mathrm{Y}$ are open sets, and $\mathrm{Y} \supseteq \mathrm{f}(\mathrm{X})$. Let $\mathrm{x}^{0}$ be a point in $\mathrm{X}$, put $\mathrm{y}^{0}=\mathrm{f}\left(\mathrm{x}^{0}\right)$, and define the composite function

$$
\mathrm{F}=\mathrm{g} \circ \mathrm{f} \text { by } \mathrm{F}(\mathrm{x})=\mathrm{g}[\mathrm{f}(\mathrm{x})] \text { for each } \mathrm{x} \in \mathrm{X}
$$

If $\mathrm{f}$ is differentiable at $\mathrm{x}^{0}$, and $\mathrm{g}$ at $\mathrm{y}^{0}$, then $\mathrm{F}=\mathrm{g} \circ \mathrm{f}$ is differentiable at $\mathrm{x}^{0}$, and its derivative is given by

$$
\operatorname{DF}\left(\mathrm{x}^{0}\right)=\operatorname{Dg}\left(\mathrm{y}^{0}\right) \operatorname{Df}\left(\mathrm{x}^{0}\right)
$$

Proof. We want to show that

$$
\begin{equation*}
\lim _{\|h\| \rightarrow 0} \frac{\left\|E_{F}(h)\right\|}{\|h\|}=\lim _{\|h\| \rightarrow 0} \frac{\left\|F\left(x^{0}+h\right)-F\left(x^{0}\right)-D g\left(y^{0}\right) D f\left(x^{0}\right) h\right\|}{\|h\|}=0 \tag{0}
\end{equation*}
$$

for if this expression holds, $F$ is differentiable at $x^{0}$, and its derivative is $D g\left(y^{0}\right) D f\left(x^{0}\right)$. The basic idea is to show that the error $E_{F}(h)$ is "small" by relating it to the analogous terms for $f$ and $g$, which are small by assumption.

For arbitrary $h \in \mathbb{R}^{\mathrm{n}}$ and $k \in \mathbb{R}^{\mathrm{m}}$, define

$$
\begin{align*}
& E_{f}(h)=f\left(x^{0}+h\right)-f\left(x^{0}\right)-D f\left(x^{0}\right) h  \tag{1}\\
& E_{g}(k)=g\left(y^{0}+k\right)-g\left(y^{0}\right)-D g\left(y^{0}\right) k \tag{2}
\end{align*}
$$

The vectors $E_{f}(h)$ and $E_{g}(h)$ are the errors committed when we approximate $f$ and $g$ by their respective differentials. Because $f$ and $g$ are by assumption differentiable at $x^{0}$ and $y^{0}$, respectively, we know that these terms are small for $h$ and $k$ close to zero; in particular,

$$
\begin{equation*}
\varepsilon(h)=\frac{\left\|E_{f}(h)\right\|}{\|h\|} \rightarrow 0 \quad \text { as }\|h\| \rightarrow 0 \tag{3}
\end{equation*}
$$

$$
\begin{equation*}
\eta(k)=\frac{\left\|E_{g}(k)\right\|}{\|k\|} \rightarrow 0 \quad \text { as }\|k\| \rightarrow 0 \tag{4}
\end{equation*}
$$

Fix $h$ and let

$$
\begin{equation*}
k=f\left(x^{0}+h\right)-f\left(x^{0}\right)=f\left(x^{0}+h\right)-y^{0} \tag{5}
\end{equation*}
$$

Then

$$
\begin{array}{rlrl}
\|k\|= & \left\|f\left(x^{0}+h\right)-f\left(x^{0}\right)\right\| & & (\text { by }(1)) \\
& =\left\|E_{f}(h)+D f\left(x^{0}\right) h\right\| & & \text { (by the triangle inequality) } \\
& \leq\left\|E_{f}(h)\right\|+\left\|D f\left(x^{0}\right) h\right\| & & (\text { by }(3))^{7} \\
& \leq \varepsilon(h)\|h\|+\left\|D f\left(x^{0}\right)\right\|\|h\| & \\
= & \|h\|\left(\varepsilon(h)+\left\|D f\left(x^{0}\right)\right\|\right) & \tag{6}
\end{array}
$$

Consider now the expression in the numerator of (0). We can write

$$
\begin{array}{rlr}
E_{F}(h) & =F\left(x^{0}+h\right)-F\left(x^{0}\right)-D g\left(y^{0}\right) D f\left(x^{0}\right) h \\
& =g\left[f\left(x^{0}+h\right)\right]-g\left[f\left(x^{0}\right)\right]-D g\left(y^{0}\right) D f\left(x^{0}\right) h \\
& =g\left(y^{0}+k\right)-g\left(y^{0}\right)-D g\left(y^{0}\right) D f\left(x^{0}\right) h \\
& =E_{g}(k)+D g\left(y^{0}\right) k-D g\left(y^{0}\right) D f\left(x^{0}\right) h \\
& =E_{g}(k)+D g\left(y^{0}\right)\left[f\left(x^{0}+h\right)-f\left(x^{0}\right)-D f\left(x^{0}\right) h\right] \quad \text { (by (2)) } \tag{5}
\end{array}
$$

from which

$$
\begin{equation*}
E_{F}(h)=E_{g}(k)+D g\left(y^{0}\right) E_{f}(h) \tag{7}
\end{equation*}
$$

This expression relates the approximation error for $F$ to the analogous terms for $f$ and $g$. Because each of the latter is small, so will be $E_{F}(h)$, which establishes the desired result. More formally, returning to (0) and using (7), we have

$$
\begin{align*}
\frac{\left\|E_{f}(h)\right\|}{\|h\|} & =\frac{\left\|E_{g}(k)+D g\left(y^{0}\right) E_{f}(h)\right\|}{\|h\|}  \tag{7}\\
& \leq \frac{\left\|E_{g}(k)\right\|+\left\|D g\left(y^{0}\right)\right\|\left\|E_{f}(h)\right\|}{\|h\|} \quad(\text { by (3) and (4)) } \\
& =\frac{\eta(k)\|k\|}{\|h\|}+\varepsilon(h)\left\|D_{g}\left(y^{0}\right)\right\|  \tag{6}\\
& =\eta(k)\left\{\varepsilon(h)+\left\|D f\left(x^{0}\right)\right\|\right\}+\varepsilon(h)\left\|D g\left(y^{0}\right)\right\|
\end{align*}
$$

Finally, suppose $\|h\| \rightarrow 0$. Then $\varepsilon(h) \rightarrow 0$, and, by (6), so does $\|k\|$, implying $\eta(k) \rightarrow 0$. Hence,

$$
\lim _{\|h\| \rightarrow 0} \frac{\left\|E_{F}(h)\right\|}{\|h\|}=0
$$

which is what we wanted to show.

Problem 3.6. Let $w=f(x, y, z)=x y^{2} z$, with

$$
x=r+2 s+t, \quad y=2 r+3 s+t, \quad z=3 r+s+t
$$

Use the chain rule to calculate $\partial w / \partial r, \partial w / \partial s$, and $\partial w / \partial t$.

The Mean-Value Theorem

Given a function $g: \mathbb{R} \longrightarrow \mathbb{R}$ differentiable on an open interval $I$, the mean-value theorem says that for any $x$ and $y$ in $I$ there exists some number $z$ between $x$ and $y$ such that

$$
\begin{equation*}
f(y)-f(x)=f^{\prime}(z)(y-x) \tag{1}
\end{equation*}
$$

This formula continues to be valid for real functions of several variables, but it may not hold for mappings from $\mathbb{R}^{\mathrm{n}}$ into $\mathbb{R}^{\mathrm{m}}$. The following result tells us how (1) has to be modified in this case.

We will use the notation $L(x, y)$ to refer to the straight line segment that joins points $x$ and $y$. That is, if $x, y \in \mathbb{R}^{\mathbf{n}}$, then

$$
L(x, y)=\left\{z \in \mathbb{R}^{\mathrm{n}} ; z=\lambda x+(1-\lambda) y, \lambda \in[0,1]\right\}
$$

Theorem 3.7. Mean-value theorem. Let $\mathrm{f}: \mathbb{R}^{n} \longrightarrow \mathbb{R}^{m}$ be differentiable on an open subset $\mathrm{X}$ of $\mathbb{R}^{\mathrm{n}}$, and let $\mathrm{x}$ and $\mathrm{y}$ be two points in $\mathrm{X}$ such that $\mathrm{L}(\mathrm{x}, \mathrm{y})$ is contained in $\mathrm{X}$. Then for each vector a in $\mathbb{R}^{\mathrm{m}}$ there exists a vector $\mathrm{z}$ in $\mathrm{L}(\mathrm{x}$, y) such that

$$
\begin{equation*}
\mathrm{a}[\mathrm{f}(\mathrm{y})-\mathrm{f}(\mathrm{x})]=\mathrm{a}[\mathrm{Df}(\mathrm{z})(\mathrm{y}-\mathrm{x})] \tag{2}
\end{equation*}
$$

Of course, if $\mathrm{X}$ is a convex set, then $\mathrm{X} \supseteq \mathrm{L}(\mathrm{x}, \mathrm{y})$ for all $\mathrm{x}, \mathrm{y}$ in $\mathrm{X}$.

Problem 3.8. Complete the following proof of Theorem 3.7. Put $h=y-x$. As $X$ is open and contains $L(x, y)$, there exists some $\delta>0$ such that $x+\lambda h \in X$ for $\lambda \in(-\delta, 1+\delta)$. Fix an arbitrary vector $a \in \mathbb{R}^{\mathrm{m}}$, and define a real-valued function $\phi_{a}$ on the interval $(-\delta, 1+\delta)$ by

$$
\phi_{a}(\lambda)=a f(x+\lambda h)=\sum_{i=1}^{m} a_{i} f^{i}(x+\lambda h)
$$

By construction, $\phi_{a}()$ is differentiable on $(-\delta, 1+\delta)$. Compute its derivative, and apply the mean-value theorem for univariate functions to conclude that there exists some vector $z=x+\theta h$ for which (2) holds.

Theorem 3.9. Let $\mathrm{f}: \mathbb{R}^{n} \longrightarrow \mathbb{R}^{m}$ be a differentiable function on an open subset $\mathrm{X}$ of $\mathbb{R}^{\mathrm{n}}$, and let $\mathrm{x}$ and $\mathrm{y}$ be two points in $\mathrm{X}$ such that $\mathrm{L}(\mathrm{x}, \mathrm{y})$ is contained in $\mathrm{X}$. Then there exists a vector $\mathrm{z}$ in $\mathrm{L}(\mathrm{x}, \mathrm{y})$ such that

$$
\begin{gather*}
\text { Continuous Differentiability } \\
\|\mathrm{f}(\mathrm{y})-\mathrm{f}(\mathrm{x})\| \leq\|\mathrm{Df}(\mathrm{z})(\mathrm{y}-\mathrm{x})\| \leq\|\mathrm{Df}(\mathrm{z})\|\|\mathrm{y}-\mathrm{x}\| \tag{3}
\end{gather*}
$$

Proof. If $f(x)=f(y)$, the result holds trivially. Otherwise, the mean-value theorem guarantees that for each vector $a \in \mathbb{R}^{\mathrm{m}}$ there exists some vector $z \in L(x, y)$ such that

$$
a[f(y)-f(x)]=a[D f(z)(y-x)]
$$

Taking the absolute value of each side of this expression and using the Cauchy-Schwarz inequality, we have

$$
\begin{equation*}
|a(f(y)-f(x))|=|a(D f(z)(y-x))| \leq\|a\|\|D f(z)(y-x)\| \tag{4}
\end{equation*}
$$

Now, let $a$ be the unit vector

$$
a=\frac{(f(y)-f(x))^{T}}{\|f(y)-f(x)\|}
$$

and observe that in this case

$$
\begin{aligned}
|a(f(y)-f(x))| & =\frac{1}{\|f(y)-f(x)\|^{2}}\left|(f(y)-f(x))^{T}(f(y)-f(x))\right| \\
& =\frac{\|f(y)-f(x)\|^{2}}{\|f(y)-f(x)\|}=\|f(y)-f(x)\|
\end{aligned}
$$

Using (4) and the preceding expression,

$$
\|f(y)-f(x)\|=|a(f(y)-f(x))| \leq 1\|D f(z)(y-x)\| \leq\|D f(z)\|\|y-x\|
$$

where we have made use of the fact that for any linear transformation $A$ and any vector $x,\|A x\| \leq\|A \mid\| x \|$ (see Chapter 3 ).

## 4. Continuous Differentiability

We now introduce a stronger concept of differentiability that will be useful later. Let $f$ be differentiable on an open region $X$ - that is, we assume that the derivative $D f(x)$ exists at all points in $X$. We then say that $f$ is continuously differentiable on $X$ if its derivative is a continuous function. In this statement, we think of the derivative of $f$ as a function $D f$ from $X$ to the set $L\left(\mathbb{R}^{\mathrm{n}}, \mathbb{R}^{\mathrm{m}}\right)$ of linear transformations from $\mathbb{R}^{\mathrm{n}}$ to $\mathbb{R}^{\mathrm{m}}$ equipped with the norm defined in Chapter 3. ${ }^{8}$ With this in mind, the definition of continuity is the usual one: $f$ is continuously differentiable if it is differentiable and any two nearby points, $x$ and $y$, in its domain have as differentials linear transformations $d f_{x}$ and $d f_{y}$, which are similar.

Definition 4.1. Continuously differentiable function. The function $f: \mathbb{R}^{\mathrm{n}} \supseteq X$ $\rightarrow \mathbb{R}^{\mathfrak{m}}(X$ open $)$ is continuously differentiable on $X$ if it is differentiable on $X$ and the derivative $D f$ is a continuous function from $X$ to $L\left(\mathbb{R}^{\mathbf{n}}, \mathbb{R}^{\mathbf{m}}\right)$. That is, given any $x$ in $X$ and an arbitrary $\varepsilon>0$, there exists some $\delta>0$ such that

$$
\left\|d f_{x}-d f_{y}\right\|<\varepsilon \forall y \in B_{\delta}(x)
$$

where the symbol $\|\cdot\|$ denotes the norm of a linear transformation.

This definition may appear a little strange, because it is difficult to visualize what we mean by continuity for a function whose value at each point is a linear mapping. The next definition and the theorem that follows it will give us a characterization of continuous differentiability in more familiar terms.

Definition 4.2. Function of class $C^{k}$. The function $f: \mathbb{R}^{\mathrm{n}} \supseteq X \rightarrow \mathbb{R}^{\mathrm{m}}$ ( $X$ open) is (of class) $C^{k}$ in $X$, written $f \in C^{k}(X)$, if the first $k$ partial derivatives of the component functions of $f$ exist and are continuous on $X$.

By convention, a continuous function is of class $C^{0}$. If $f \in C^{k}$, where $k \geq 1$, we say that $f$ is a smooth function, although this term is sometimes reserved for functions of class $\mathrm{C}^{\infty}$.

The following result tells us that the continuity of the first partial derivatives of the components of $f$ is a necessary and sufficient condition for $f$ to be continuously differentiable. Intuitively, this equivalence should not be surprising: A function is continuously differentiable if two nearby points, $x$ and $y$ in $X$, have as differentials linear functions $d f_{x}$ and $d f_{y}$ that are "close," that is, represented by similar matrices $D f(x)$ and $D f(y)$. Because the coefficients of these matrices are the partial derivatives of the components of $f$ and, provided $f$ is $C^{1}$, the partials are continuous functions, small changes in $x$ will result in small changes in each of these coefficients and will therefore yield similar differentials.

Theorem 4.3. The function $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}^{m}$ ( $\mathrm{X}$ open) is continuously differentiable in $\mathrm{X}$ if and only if it of class $\mathrm{C}^{1}$ in $\mathrm{X}$.

Proof. Let $x$ and $x+h$ be two points in X. Under our assumptions, $f$ is differentiable in both parts of the theorem (by assumption for the necessity part, and by Theorem 3.4 for the sufficiency implication), so $d f_{x+h}$ and $d f_{x}$ exist, and their difference $d f_{x+h}-d f_{x}$ is a linear transformation in $L\left(\mathbb{R}^{\mathbf{n}}, \mathbb{R}^{\mathrm{m}}\right)$ with matrix representation $\left[a_{i k}\right]=D f(x+h)-D f(x)$, where

$$
\begin{equation*}
a_{i k}(h)=f_{k}^{i}(x+h)-f_{k}^{i}(x) \tag{1}
\end{equation*}
$$

Fix $x$ and define

$$
\kappa(h)=\max _{i k}\left|a_{i k}(h)\right|=\max _{i k}\left|f_{k}^{i}(x+h)-f_{k}^{i}(x)\right|
$$

By Theorem 4.9 in Chapter 3, we have

$$
\begin{equation*}
0 \leq \kappa(h) \leq\left\|d f_{x+h}-d f_{x}\right\| \leq \kappa(h) \sqrt{m n} \tag{2}
\end{equation*}
$$

from which we obtain the equivalence

$$
\begin{equation*}
[\kappa(h) \rightarrow 0 \text { as } h \rightarrow \underline{0}] \text { if and only if } \quad\left[\left\|d f_{x+h}-d f_{x}\right\| \rightarrow 0 \text { as } h \rightarrow \underline{0}\right] \tag{3}
\end{equation*}
$$

If $f \in C^{1}$, the continuity of the partials implies that for each $i$ and $k$, $a_{i k}(h) \rightarrow 0$ as $h \rightarrow \underline{0}$ (see (1)). It follows that $\kappa(h)=\max _{i k}\left|a_{i k}(h)\right|$ also goes to zero, implying $\left\|d f_{x+h}-d f_{x}\right\| \rightarrow 0$, and hence the continuity of the derivative mapping. Conversely, the continuity of $D f$ implies $\left\|d f_{x+h}-d f_{x}\right\| \rightarrow 0$; then $\kappa(h) \rightarrow 0$, and because $0 \leq\left|a_{i k}(h)\right| \leq \kappa(h)$ for all $a_{i k}$, we have $a_{i k}(h) \rightarrow 0$ for all $i$ and $k$, that is,

$$
\lim _{h \rightarrow 0} f_{k}^{i}(x+h)=f_{k}^{i}(x)
$$

so the partial derivatives are indeed continuous.

## Taylor's Theorem

Taylor's formula can be generalized for the case of a real-valued function of $n$ variables. Because the notation gets rather messy, and we need only the simplest case, we shall state the following theorem for the case of a firstorder approximation with a quadratic-form remainder. This result will be useful later in connection with the characterization of concavity for smooth functions and the derivation of necessary and sufficient conditions for local maxima.

Theorem 4.4. Taylor's formula for multivariate functions with second-order remainder. Let $\mathrm{f}: \mathbb{R}^{n} \longrightarrow \mathbb{R}$ be a $\mathrm{C}^{2}$ function defined on an open and convex set $\mathrm{X}$. If $\mathrm{x}, \mathrm{x}+\mathrm{h} \in \mathrm{X}$, then

$$
\begin{equation*}
\mathrm{f}(\mathrm{x}+\mathrm{h})=\mathrm{f}(\mathrm{x})+\mathrm{Df}(\mathrm{x}) \mathrm{h}+(1 / 2) \mathrm{h}^{\mathrm{T}} \mathrm{D}^{2} \mathrm{f}(\mathrm{x}+\lambda \mathrm{h}) \mathrm{h} \tag{1}
\end{equation*}
$$

for some $\lambda \in(0,1)$.

Problem 4.5. Prove Theorem 4.4. Hint: Apply the univariate version of Taylor's formula to the function $g(\alpha)=f(x+\alpha h)$.

## The Inverse-Function Theorem

Let $f$ be a function from $\mathbb{R}^{\mathrm{n}}$ to itself. Each vector $x \in \mathbb{R}^{\mathrm{n}}$ is mapped by $f$ into another vector $y$ in $\mathbb{R}^{n}$, that is

$$
\begin{equation*}
f(x)=y \tag{1}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-189.jpg?height=566&width=1284&top_left_y=192&top_left_x=101)

Figure 4.5.

We can also turn this expression around: Given a vector $y$, (1) is a system of $n$ equations in $n$ unknowns (the components of $x$ ). We would like to know under what conditions it is true that given a vector $y$, equation (1) can be solved for a value of $x$ that is, at least locally, unique.

If $f$ is a linear operator, (1) is equivalent to a system of the form

$$
\begin{equation*}
A x=y \tag{2}
\end{equation*}
$$

where $A$ is a square matrix. Then $A$ is invertible if and only if its determinant is not zero, and therefore equation (2) has a unique solution $x^{*}=A^{-1} y$ for each given y whener $|A| \neq 0$ - that is, provided all the equations in the system are linearly independent.

If $f$ is not linear, the question of its invertibility is more complicated, but in many cases it is possible to determine whether or not a function is locally invertible simply by calculating the determinant of its derivative matrix. Consider first the case of a function from $\mathbb{R}$ to $\mathbb{R}$. If $f$ is continuously differentiable on some interval $I$ and $f^{\prime}(x) \neq 0$ for all $x \in I$, then the function is monotonic and therefore one-to-one. It follows that the inverse relation $f^{-1}$ is a well-defined function on $f(I)$. Given any $y$ in $f(I)$, the equation $f(x)=y$ will have a unique solution, $x^{*}=f^{-1}(y)$.

If $f$ is not monotonic, the inverse relation $f^{-1}$ is not a function, and there could be several solutions to the equation $f(x)=y$, as suggested in Figure 4.5. On the other hand, these solutions will be locally unique provided $f$ is strictly monotonic in some neighborhood of the solution. Hence, $f^{\prime}\left(x^{*}\right) \neq 0$ and $f \in C^{1}$ in some open neighborhood of a solution $x^{*}$ are sufficient conditions for the local invertibility of $f$ close to $x^{*}$. If we restrict ourselves to a sufficiently small neighborhood of $x^{*}, f^{-1}$ is a well-defined function under these assumptions.

We now ask if it is possible to extend this result for functions of $\mathbb{R}^{\mathrm{n}}$ into itself. For this purpose it will be convenient to reinterpret the preceding discussion in terms of the invertibility of the differential of $f$, rather than the monotonicity of the function. If $f^{\prime}(x)=a \neq 0$, then $d f_{x}(h)=a h$ is an invertible linear function. Hence, we can rephrase our earlier conclusion by saying that a sufficient condition for a continuously differentiable function to be locally invertible in a neighborhood of a point $x$ is that its differential at $x$ be invertible. $^{9}$ Because the differential of a function is the best linear approximation to it, it seems reasonable to conjecture that the result is true in general, and the following theorem confirms that this is indeed the case. We may even suspect that the invertibility of its differential is necessary, as well as sufficient, for the local invertibility of a function, but the second panel of Figure 4.5 shows that this is not true: The function $g$ is strictly monotonic and therefore globally invertible, but its derivative at the inflection point $x^{*}$ is zero, and therefore its differential is not invertible.

Theorem 4.6. Inverse-function theorem. Let $\mathrm{f}: \mathbb{R}^{\mathrm{n}} \supseteq \mathrm{X} \longrightarrow \mathbb{R}^{n}$ (X open) be a continuously differentiable function, and $\mathrm{x}^{0}$ a point on its domain. Assume that the determinant of the Jacobian of $\mathrm{f}$ is not zero at $\mathrm{x}^{0}$ (i.e., $\left|\mathrm{Df}\left(\mathrm{x}^{0}\right)\right|$ $\neq 0$ ). Then there exists an open neighborhood of $\mathrm{x}^{0}, U$, such that

(i) $\mathrm{f}$ is one-to-one in $\mathrm{U}$; hence the inverse relation $\mathrm{f}^{-1}$ is a well-defined function from $\mathrm{V}=\mathrm{f}(\mathrm{U})$ to $\mathrm{U}$,

(ii) $\mathrm{V}=\mathrm{f}(\mathrm{U})$ is an open set containing $\mathrm{y}^{0}=\mathrm{f}\left(\mathrm{x}^{0}\right)$,

(iii) the inverse function $\mathrm{f}^{-1}$ is of class $\mathrm{C}^{1}$, with derivative $\mathrm{Df}^{-1}\left(\mathrm{y}^{0}\right)=\left[\mathrm{Df}\left(\mathrm{x}^{0}\right)\right]^{-1}$,

(iv) if $\mathrm{f}$ is $\mathrm{C}^{\mathrm{k}}$, with $\mathrm{k}>1$, so is $\mathrm{f}^{-1}$.

A diffeomorphism is an invertible smooth function ( $C^{k}$ with $k \geq 1$ ) with a smooth inverse. The inverse-function theorem says that a sufficient condition for $f$ to be locally a diffeomorphism near a point $x^{0}$ is that $x^{0}$ be a regular point of $f$.

Proof. Before getting into the details, which are rather complicated, let us sketch the logic of the proof. We begin by defining $U$ as an open ball with center at $x^{0}$ and sufficiently small radius. (What we mean by this will become clear later.) To establish the local invertibility of $f$, we make use of an auxiliary function $\phi_{y}(x)$, defined for each vector $y$ in $\mathbb{R}^{\mathrm{n}}$ by

$$
\phi_{y}(x)=x+\left[D f\left(x^{0}\right)\right]^{-1}[y-f(x)]
$$

Observe that by construction, $y=f(x)$ if and only if $x$ is a fixed point of $\phi_{y}($ ). Given a point $x$ in $U$, let $y$ be its image. Then it can be shown that $\phi_{y}()$ is a contraction that maps a closed ball $B$ with center at $x$ into itself. By the contraction mapping theorem, for each $y \in f(U), \phi_{y}()$ has a unique
fixed point in $U$ that lies inside $B$. This implies that there is a unique point in $U$ with image $y$ ( $x$ itself); $f$ is therefore one-to-one in $U$, and the restriction of the inverse relation $f^{-1}$ to $f(U)$ is a well-defined function.

The second step is to establish the differentiability of $f^{-1}$. By assumption, the differential of $f$ at $x^{0}$ is an invertible linear operator in $L\left(\mathbb{R}^{n}\right)$. The radius of $U$ has been chosen small enough that $d f_{x}$ is invertible for all $x$ in $U$. This is possible because the set $\Omega\left(\mathbb{R}^{n}\right)$ of invertible linear operators on $\mathbb{R}^{n}$ is open, as we saw in Chapter 3 (Theorem 4.14), and because $f$ is continuously differentiable. ${ }^{10}$

We know, therefore, that $[D f(x)]^{-1}$ exists for all $x \in U$. Inserting this matrix into the expression that defines the derivative of the inverse function, we verify that it works, thus establishing that for $x=f^{-1}(y)$,

$$
D f^{-1}(y)=\left\{D f\left[f^{-1}(y)\right]\right\}^{-1}
$$

This expression shows also that $D f^{-1}$ is the composition of three continuous functions and is therefore continuous; that is, $f^{-1}$ is $C^{1}$. Now for the details.

(i) $f$ is one-to-one in $U$. Put $D f\left(x^{0}\right)=A$ (which is an invertible matrix by assumption) and define $\lambda$ by

$$
\begin{equation*}
2 \lambda\left\|A^{-1}\right\|=1 \tag{1}
\end{equation*}
$$

where, to avoid complicating the notation further, $\|A\|$ is the norm of the linear operator associated with the matrix $A$.

Because $X$ is open, there exists some $\delta>0$ such that the open ball $U=\mathrm{B}_{\delta}\left(x^{0}\right)$ is contained in $X$. Further, by the continuous differentiability of $f, D f$ is a continuous function from $X$ to $L\left(\mathbb{R}^{n}\right)$, so we can choose $\delta$ in such a way that for every $x \in U$ the derivative $D f(x)$ is not very different from $A$; in particular, there is some $\delta>0$ such that

$$
\begin{equation*}
\|D f(x)-A\|<\lambda \forall x \in U=B_{\delta}\left(x^{0}\right) \tag{2}
\end{equation*}
$$

With each $y \in \mathbb{R}^{\mathrm{n}}$ we associate a function $\phi_{y}()$ defined for $x$ in $X$ by

$$
\begin{equation*}
\phi_{y}(x)=x+A^{-1}[y-f(x)] \tag{3}
\end{equation*}
$$

and observe that $y=f(x)$ if and only if $x$ is a fixed point of $\phi_{y}()$.

To show that $f$ is one-to-one in $U$, we have to prove that given a vector $y$, there exists at most one $x$ in $U$ such that $f(x)=y$-or, equivalently, that for each $y, \phi_{y}()$ has at most one fixed point in $U$. This will be true if $\phi_{y}()$ is a contraction in $U$, as we now show.

The derivative of $\phi_{y}()$ is

$$
D \phi_{y}(x)=I-A^{-1} D f(x)=A^{-1}[A-D f(x)]
$$

Expressions (1) and (2) and the properties of the norm in $L\left(\mathbb{R}^{\mathrm{n}}\right)$ imply that for any $x \in U$,

$$
\begin{equation*}
\left\|D \phi_{y}(x)\right\|=\left\|A^{-1}[A-D f(x)]\right\| \leq\left\|A^{-1}\right\|\|A-D f(x)\|<\frac{1}{2 \lambda} \lambda=\frac{1}{2} \tag{4}
\end{equation*}
$$

from which we have (by Theorem 3.9) that for any $x^{\prime}$ and $x^{\prime \prime}$ in $U$,

$$
\begin{equation*}
\left\|\phi_{y}\left(x^{\prime}\right)-\phi_{y}\left(x^{\prime \prime}\right)\right\| \leq \frac{1}{2}\left\|x^{\prime}-x^{\prime \prime}\right\| \tag{5}
\end{equation*}
$$

establishing that the restriction of $\phi_{y}$ to $U$ is a contraction. As $U$ is not complete, $\phi_{y}$ may not have a fixed point in it, but it is still true that there can be no more than one such point. Hence, given $y$, there is at most one $x$ in $U$ with $f(x)$ $=y ; f$ is one-to-one in $U$.

(ii) $f(U)$ is an open set and contains $y^{0}=f\left(x^{0}\right)$. Put $V=f(U)$ and take an arbitrary $y^{\prime}$ in $V$; then $y^{\prime}=f\left(x^{\prime}\right)$ for some $x^{\prime} \in U$. Let $B=B_{r}\left[x^{\prime}\right]$ be a closed ball contained in $U$, with center at $x^{\prime}$ and radius $r$. (Observe that it is always possible to construct such a ball, because $U$ is open.) To show that $V$ is open, we will prove that $\left\|y-y^{\prime}\right\|<\lambda r$ implies $y \in V$.

Take some y such that $\left\|y-y^{\prime}\right\|<\lambda r$ and observe that by (1), $2 \lambda\left\|A^{-1}\right\|=1$,

$$
\begin{equation*}
\left\|\phi_{y}\left(x^{\prime}\right)-x^{\prime}\right\|=\left\|A^{-1}\left(y-y^{\prime}\right)\right\| \leq\left\|A^{-1}\right\|\left\|y-y^{\prime}\right\|<\left\|A^{-1}\right\| \lambda r=r / 2 \tag{6}
\end{equation*}
$$

For $x \in B$ we have, by the triangle inequality and using (5) and (6),

$$
\left\|\phi_{y}(x)-x^{\prime}\right\| \leq\left\|\phi_{y}(x)-\phi_{y}\left(x^{\prime}\right)\right\|+\left\|\phi_{y}\left(x^{\prime}\right)-x^{\prime}\right\|<(1 / 2)\left\|x-x^{\prime}\right\|+(r / 2) \leq r
$$

and therefore $\phi_{y}(x) \in B$ for $x \in B$ and $y$ close to $y^{\prime}$.

It follows that for an appropriate $y, \phi_{y}()$ is a contraction that maps $B$ into itself. Moreover, $B$, being a closed subset of $\mathbb{R}^{\mathrm{n}}$, is complete. By the contraction mapping theorem (see Chapter 3), $\phi_{y}()$ has a fixed point $x^{*}$ in $B$. For this $x^{*} \in B=B_{r}\left[x^{\prime}\right] \subseteq U, f\left(x^{*}\right)=y$, implying $y \in f(B) \subseteq f(U)=V$ whenever $\left\|y-y^{\prime}\right\|<$ $\lambda r$. In words, given an arbitrary point $y^{\prime}$ in $V$, we can construct an open ball around it that is still contained in $V$, that is, $V$ is open.

(iii) The inverse function $f^{-1}$ is differentiable, with $D f^{-1}\left(y^{0}\right)=\left[D f\left(x^{0}\right)\right]^{-1}$. Take two points $y$ and $y+k$ in $V=f(U)$. Then there exist vectors $x$ and $x+h$ in $U$ such that

$$
y=f(x) \text { and } y+k=f(x+h)
$$

With $\phi_{z}($ ) defined as in (3), we have

$$
\phi_{z}(x+h)-\phi_{z}(x)=h+A^{-1}[f(x)-f(x+h)]=h-A^{-1} k
$$

Because $x, x+h \in U$, we have, by (5),

$$
\left\|\phi_{z}(x+h)-\phi_{z}(x)\right\|=\left\|h-A^{-1} k\right\| \leq(1 / 2)\|h\|
$$

implying

$$
\|h\|-\left\|A^{-1} k\right\| \leq\left\|h-A^{-1} k\right\| \leq(1 / 2)\|h\| \Rightarrow\left\|A^{-1} k\right\| \geq(1 / 2)\|h\|
$$

and therefore, using (1),

$$
\begin{equation*}
\|h\| \leq 2\left\|A^{-1} k\right\| \leq 2\left\|A^{-1}\right\|\|k\|=(1 / \lambda)\|k\| \tag{7}
\end{equation*}
$$

Hence, if $y$ and $y+k$ are close in $V$, then the distance between their preimages $x$ and $x+h$ is also small. This expression directly implies the continuity of the inverse function $f^{-1}$, but we want to establish the stronger result that $f^{-1}$ is differentiable.

Observe that (1) and (2) imply that for every $x$ in $U$ we have

$$
\|D f(x)-A\|<\frac{1}{2\left\|A^{-1}\right\|}
$$

where $A=D f\left(x^{0}\right)$ is by assumption invertible. By Theorem 4.14 in Chapter 4, $D f(x)$ is also invertible for every $x$ in $U$; denote its inverse $[D f(x)]^{-1}$ by $T$. To show that $f^{-1}$ is differentiable, we insert $T$ in the expression that defines the derivative of $f^{-1}$ and verify that it holds. We have

$$
\begin{aligned}
f^{-1}(y+k)-f^{-1}(y)-T k & =(x+h)-x-T k=h I-T k \\
& =h T D f(x)-T[(y+k)-y] \\
& =-T[f(x+h)-f(x)-D f(x) h]
\end{aligned}
$$

from which

$$
\left\|f^{-1}(y+k)-f^{-1}(y)-T k\right\| \leq\|T\|\|f(x+h)-f(x)-D f(x) h\|
$$

which, together with (7), implies

$$
\begin{equation*}
0 \leq \frac{\left\|f^{-1}(y+k)-f^{-1}(y)-T k\right\|}{\|k\|} \leq\|T\| \frac{\|f(x+h)-f(x)-D f(x) h\|}{\lambda\|h\|} \tag{8}
\end{equation*}
$$

Now, (7) implies that $\|h\| \rightarrow 0$ as $\|k\| \rightarrow 0$. Because $f$ is differentiable at $x$ and $(1 / \lambda)\|T\|$ is a constant, the right-hand side of the inequality goes to zero, and therefore so does the middle term as $\|h\|$ (and hence $\|k\|$ ) goes to zero. In conclusion, $f$ is differentiable, and its derivative is given by

$$
\begin{equation*}
D f^{-1}(y)=T=\left(D f\left[f^{-1}(y)\right]\right)^{-1} \tag{9}
\end{equation*}
$$

(iv) It remains to show that $f^{-1}$ is continuously differentiable, that is, that its derivative

$$
D f^{-1}: V \rightarrow L\left(\mathbb{R}^{\mathrm{n}}\right)
$$

is a continuous function. By (9), we see that $D f^{-1}$ is the composition of the following three continuous functions:

- $f^{-1}$, which is a differentiable and therefore continuous function from $V$ to $U$, as we have just shown,
- $D f\left(\right.$ ), a continuous function (by assumption) from $U$ to $L\left(\mathbb{R}^{\mathrm{n}}\right)$, and in particular to the subset $\Omega\left(\mathbb{R}^{n}\right)$ of invertible operators in $L\left(\mathbb{R}^{n}\right)$ (because $U$ is defined in such a way that $D f(x)$ is invertible for all $x$ in $U$ ), and
- the inversion operator, ()$^{-1}: \Omega\left(\mathbb{R}^{\mathrm{n}}\right) \longrightarrow \Omega\left(\mathbb{R}^{\mathrm{n}}\right)$, which assigns to each invertible operator in $L\left(\mathbb{R}^{\mathrm{n}}\right)$ its inverse. (This function is continuous by Theorem 4.15 in Chapter 3.)

Hence, the composite function $D f^{-1}: U \longrightarrow \Omega\left(\mathbb{R}^{\mathrm{n}}\right)$ is continuous.

Problem 4.7. Let $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}^{\mathrm{n}}$ be a continuously differentiable function on the open set $X$. Show that $f$ is locally Lipschitz on $X$. (See Section 6 in Chapter 2.)

## 5. Homogeneous Functions

A set $X$ in $\mathbb{R}^{\mathrm{n}}$ is called a cone if given any $x \in X$ the point $\lambda x$ belongs to $X$ for any $\lambda>0$. A function defined on a cone is said to be homogeneous of degree $k$ if, when we multiply all its arguments by a positive real number $\lambda$, the value of the function increases in the proportion $\lambda^{k}$.

Definition 5.1. Homogeneous functions. A function $f: \mathbb{R}^{\mathbf{n}} \supseteq X \longrightarrow \mathbb{R}$, where $X$ is a cone, is homogeneous of degree $k$ in $X$ if

$$
f(\lambda x)=\lambda^{k} f(x) \forall \lambda>0
$$

Homogeneous functions often arise naturally in economics. For example, consider the response of a consumer to an equiproportional increase in income and the prices of all goods in the market. Because this change would not change the budget set (i.e., the set of consumption bundles the agent can afford), consumption choices should not be affected. Hence, the demand function $x(p, y)$ that gives the optimal consumption bundle as a function of the vector of prices $p$ and income $y$ will be homogeneous of degree zero. In production theory, it often makes sense to assume that a doubling of all inputs will lead to a doubling in output. If this assumption, known as constant returns to scale, holds, the production function will be linearly homogeneous (i.e., homogeneous of degree 1).

The following theorem provides a useful characterization of homogeneous functions with continuous partial derivatives.

Theorem 5.2. Euler's theorem. Let $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$ be a function with continuous partial derivatives defined on an open cone $\mathrm{X}$. Then $\mathrm{f}$ is homogeneous of degree $\mathrm{k}$ in $\mathrm{X}$ if and only if

$$
\begin{equation*}
\sum_{\mathrm{i}=1}^{\mathrm{n}} \mathrm{f}_{\mathrm{i}}(\mathrm{x}) \mathrm{x}_{\mathrm{i}}=\mathrm{kf}(\mathrm{x}) \forall \mathrm{x} \text { in } \mathrm{X} \tag{1}
\end{equation*}
$$

## Proof

- Assume that $f$ is homogeneous of degree $k$, and fix an arbitrary $x$ in $X$. Then we have

$$
f(\lambda x)=\lambda^{k} f(x)
$$

for all $\lambda>0$. The continuity of the partial derivatives of $f$ guarantees the differentiability of the function. Hence, we can differentiate this expression with respect to $\lambda$. Using the chain rule, we have

$$
\sum_{i=1}^{n} f_{i}(\lambda x) x_{i}=k \lambda^{k-1} f(x)
$$

Putting $\lambda=1$, we obtain (1).

- Conversely, suppose that (1) holds for all $x$. Fix an arbitrary $x$ in $X$, and define the function $\phi$ for all $\lambda>0$ by

$$
\phi(\lambda)=f(\lambda x)
$$

Then

$$
\phi^{\prime}(\lambda)=\sum_{i=1}^{n} f_{i}(\lambda x) x_{i}
$$

and multiplying both sides of this expression by $\lambda$,

$$
\begin{equation*}
\lambda \phi^{\prime}(\lambda)=\sum_{i=1}^{n} f_{i}(\lambda x) \lambda x_{i}=k f(\lambda x)=k \phi(\lambda) \tag{2}
\end{equation*}
$$

where the second equality follows by applying (1) to the point $\lambda x$.

Next, define the function $F$ for $\lambda>0$ by

$$
\begin{equation*}
F(\lambda)=\frac{\phi(\lambda)}{\lambda^{k}} \tag{3}
\end{equation*}
$$

and observe that, using (2),

$$
F^{\prime}(\lambda)=\frac{\lambda^{k} \phi^{\prime}(\lambda)-k \lambda^{k-1} \phi(\lambda)}{\left(\lambda^{k}\right)^{2}}=\frac{\lambda^{k-1}}{\left(\lambda^{k}\right)^{2}}\left[\lambda \phi^{\prime}(\lambda)-k \phi(\lambda)\right]=0
$$

Hence, $F$ is a constant function. Putting $\lambda=1$ in (3), we have $F(1)=\phi(1)$, and therefore

$$
F(\lambda)=\frac{\phi(\lambda)}{\lambda^{k}}=\phi(1) \Rightarrow \phi(\lambda)=\lambda^{k} \phi(1)
$$

Finally, recalling that $\phi(\lambda) \equiv f(\lambda x)$, we have

$$
f(\lambda x)=\lambda^{k} f(x)
$$

as was to be shown.

Problem 5.3. Show that if $f$ is homogeneous of degree $k$ and "sufficiently differentiable," then its first partial derivatives are homogeneous of degree $k-1$.

## Problem 5.4

(i) Show that the Cobb-Douglas function

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-196.jpg?height=567&width=761&top_left_y=189&top_left_x=335)

Figure 4.6. Level sets of a homogeneous function.

$$
f(x)=A \prod_{i=1}^{n} x_{l}^{\alpha_{i}} \text { is homogeneous of degree } \sum_{i=1}^{n} \alpha_{i}
$$

(ii) Show that the constant-elasticity-of-substitution (CES) function,

$$
\begin{aligned}
g(x) & =A\left(\sum_{i=1}^{n} \delta_{i} x_{i}^{-\rho}\right)^{-v / \rho}, \text { where } A>0, v>0, \rho>-1 \text { and } \rho \neq 0 \\
\delta_{i} & >0 \text { for all } i, \text { and } \sum_{i=1}^{n} \delta_{i}=1
\end{aligned}
$$

is homogeneous of degree $v$.

Homogeneous functions have some interesting geometric properties. Let $X$ be a cone in $\mathbb{R}^{\mathrm{n}}$, with $f: X \longrightarrow \mathbb{R}$ a homogeneous function of degree $k$, and

$$
L(\alpha)=\{x \in X ; f(x)=\alpha\}
$$

the $\alpha$-level set of $f$. Let $x_{\alpha}$ be a point in $L(\alpha)$, and consider the point $\lambda x_{\alpha}$ (with $\lambda>0$ ) obtained by moving along the ray going through the origin and $x_{\alpha}$. Then $f\left(x_{\alpha}\right)=\alpha$ and by the homogeneity of $f()$, we have

$$
f\left(\lambda x_{\alpha}\right)=\lambda^{k} f\left(x_{\alpha}\right)=\lambda^{k} \alpha
$$

Hence, $\lambda x_{\alpha} \in L\left(\lambda^{k} \alpha\right)$ if $x_{\alpha} \in L(\alpha)$. Conversely, if $y \in L\left(\lambda^{k} \alpha\right)$, then $(1 / \lambda) y$ lies in $L(\alpha)$, by the same argument. Hence, the level sets of homogeneous functions are radial expansions and contractions of each other, as illustrated in Figure 4.6.

The tangent planes to the different level sets of a $C^{1}$ homogeneous function, moreover, have constant slope along each ray from the origin. To see this, let $x_{0}$ and $x_{1}=\lambda x_{0}$ be two points lying on the same ray through the origin, and let $f$ be $C^{1}$ and homogeneous of degree $k$. Using Problem 5.3, we have, for any $i$ and $q$,

$$
\frac{f_{i}\left(x_{1}\right)}{f_{q}\left(x_{1}\right)}=\frac{f_{i}\left(\lambda x_{0}\right)}{f_{q}\left(\lambda x_{0}\right)}=\frac{\lambda^{k-1} f_{i}\left(x_{0}\right)}{\lambda^{k-1} f_{q}\left(x_{0}\right)}=\frac{f_{i}\left(x_{0}\right)}{f_{q}\left(x_{0}\right)}
$$

If $f$ is a utility function, for example, this expression says that the marginal rate of substitution between any two goods, $i$ and $q$, is constant along each ray from the origin.

A function is said to be homothetic if it is an increasing transformation of a homogeneous function. That is, $g()$ is homothetic if it can be written in the form $g()=h[f()]$, where $f$ is homogeneous of some degree and $h: \mathbb{R} \rightarrow \mathbb{R}$ is an increasing function. Notice that, because the family of level sets of $g()$ is the same as that of $f()$, homothetic functions inherit the geometric properties of homogeneous functions. In particular, their level sets are radial expansions or contractions of each other, and the slope of their level sets is the same along each ray from the origin.

## Bibliography

Apostol, T. 1989. Calculus, 2nd ed. Barcelona: Editorial Reverté. Apostol, T. 1974. Mathematical Analysis, 2nd ed. Reading, MA: Addison-Wesley.

Binmore, K. 1982. Mathematical Analysis, A Straightforward Approach. Cambridge University Press.

Buck, R. 1978. Advanced Calculus, 3rd ed. New York: McGraw-Hill.

Clark, C. 1982. Elementary Mathematical Analysis, 2nd ed. Belmont, CA: Wadsworth.

Lang, S. 1989. Undergraduate Analysis. Berlin: Springer-Verlag.

Luenberger, D. 1973. Introduction to Linear and Non-linear Programming. Reading, MA: Addison-Wesley.

Rudin, W. 1976. Principles of Mathematical Analysis, 3rd ed. New York: McGrawHill.

Sydsæter, K. 1981. Topics in Mathematical Analysis for Economists. Orlando, FL: Academic Press.

Taylor, A., and Mann, W. 1983. Advanced Calculus, 3rd ed. New York: Wiley.

Weintraub, E. 1982. Mathematics of Economists, An Integrated Approach.

Cambridge University Press.

## Notes

1 To avoid writing out all the components of a vector when we are interested in just one of them, we will use the following notation. Let $x_{i}$ be an arbitrary component of the vector $x$, and define the vector

$$
x_{-i}=\left(x_{1}, \ldots, x_{i-1}, x_{i+1}, \ldots, x_{n}\right)
$$

which contains all the components of $x$ except for $x_{i}$. We can then write $x=\left(x_{i}, x_{-i}\right)$.

2 As a matter of fact, we should say an affine function. A function is affine if it is the sum of a linear function and a constant.

3 In fact, we could define differentiability directly in terms of the existence of a linear mapping $T_{x}$ such that

$$
\lim _{\| h \rightarrow \rightarrow 0} \frac{\left\|f(x+h)-f(x)-T_{x}(h)\right\|}{\|h\|}=0
$$

We know, however, that given bases for $\mathbb{R}^{\mathrm{n}}$ and $\mathbb{R}^{m}$, there exists a bijective linear function between $L\left(\mathbb{R}^{\mathrm{n}}, \mathbb{R}^{\mathrm{m}}\right)$ and $\mathbb{R}_{m \times n}$, so that, for all practical purposes, it makes little difference which definition we use. The one we give in the text is probably easier to visualize, but we will occasionally ask the reader to think of the derivative of $f$ as a function $X \rightarrow L\left(\mathbb{R}^{\mathrm{n}}, \mathbb{R}^{\mathbf{m}}\right)$.

4 The term "Jacobian" is sometimes used to refer to the determinant of a matrix of partial derivatives, rather than to the matrix itself. The meaning should be clear from the context.

5 This is easily verified by induction.

6 Notice what we are doing. For $n=2$, we have

$$
\begin{aligned}
f(x+h)-f(x) & =f\left(x_{1}+\alpha_{1}, x_{2}+\alpha_{2}\right)-f\left(x_{1}, x_{2}\right) \\
& =\left[f\left(x_{1}+\alpha_{1}, x_{2}+\alpha_{2}\right)-f\left(x_{1}+\alpha_{1}, x_{2}\right)\right]+\left[f\left(x_{1}+\alpha_{1}, x_{2}\right)-f\left(x_{1}, x_{2}\right)\right]
\end{aligned}
$$

We decompose the change in $f$ from $x$ to $x+h$ into the sum of $n$ changes, each between two points that differ only in one coordinate. This is done so that we can use the onedimensional mean-value theorem.

7 Here, $\left\|D f\left(x^{0}\right)\right\|$ is the norm of the linear transformation associated with the matrix $D f\left(x^{0}\right)$. Recall from Chapter 3 that if $A$ is a linear transformation, and $x$ a vector, then $\|A x\| \leq\|A\|\|x\|$.

8 Let $T$ be a continuous linear transformation defined between two normed vector spaces $X$ and $Y$. As discussed in Section 4(b) of Chapter 3, its norm is defined by $\|T\|=$ $\sup _{x}\{\|T x\| ; x \in X,\|x\| \leq 1\}$.

9 Another intuitive way to interpret this result is as follows. Suppose $x^{0}$ solves the system $f(x)=y$ for some value $y^{0}$ of $y$, and linearize the system around $x^{0}$ to get $f(x) \equiv f\left(x^{0}\right)+$ $D f\left(x^{0}\right)\left(x-x^{0}\right)=y$. If the equations of the linearized system are all linearly independent, then $f(x)=y$ has a locally unique solution for any $y$ sufficiently close to $y^{0}$.

10 The inverse image of an open set under a continuous function is open. Therefore, $\left(D f^{-1}\left(\Omega\left(\mathbb{R}^{\mathrm{n}}\right)\right)\right.$ is open, and given a point in this set there is an open ball around it that is still contained in the set. We take $U$ to be a subset of this ball.

$$
\square
$$

## Static Models and Comparative Statics

A great many economic models into which time does not enter explicitly can be reduced to a parameterized system of equations of the form

$$
\begin{equation*}
F(x ; \alpha)=\underline{0} \tag{M}
\end{equation*}
$$

where $F$ is a function $F: \mathbb{R}^{\mathrm{n}} \times \mathbb{R}^{\mathrm{p}} \supseteq X \times \Omega \longrightarrow \mathbb{R}^{\mathrm{m}}$ and typically $m=n$. We interpret $\alpha$ as a vector of parameters that summarizes the "environment" in which the system described by the model is embedded, and $x$ as the vector of endogenous variables whose equilibrium values we seek. Many of the questions we ask when we analyze such a model can be formulated in terms of the properties of the solution correspondence,

$$
S: \Omega \rightarrow \rightarrow X, \text { where } S(\alpha)=\{x \in X ; F(x ; \alpha)=\underline{0}\}
$$

which assigns to each vector of parameters the corresponding set of equilibrium values of the endogenous variables. In this chapter we will focus on two types of questions that arise naturally in connection with this correspondence:

(i) For a given value of $\alpha$, what does the solution set of the model look like? Is it empty? If not, what is its dimension? Under this heading we have questions concerning the existence and uniqueness (local and global) of equilibrium.

(ii) How does $S(\alpha)$ change with changes in the parameters? On a practical level, we are interested in questions of comparative statics. That is, in what direction does the equilibrium change as a result of a change in the "environment" or in some control variable? Before we can begin to answer this question, we have to deal with the previous issue of continuity: Under what conditions is it true that the equilibrium moves in a continuous and therefore (at least in principle) predictable manner with changes in parameter values?

We will begin with a review of linear models. If $F()$ is a linear function, then the questions we have just raised have rather simple answers in terms of rank conditions and the values of certain determinants. If $F()$ is not linear,
things are more complicated, but given some regularity conditions, we can use the calculus to analyze the local behavior of the model by constructing a linear approximation to it in a neighborhood of a known solution point. The basic tool for this kind of analysis is the implicit-function theorem, which will be discussed in depth in Section 2, building on the theory of differentiability for functions from $\mathbb{R}^{\mathrm{n}}$ into $\mathbb{R}^{\mathrm{m}}$ developed in Chapter 4. We conclude in Section 3 with a brief discussion of some results that are often used to prove the existence of solutions to nonlinear models: the intermediate-value theorem and various fixed-point theorems for functions and correspondences.

## 1. Linear Models

Models that can be written as linear systems of equations are particularly easy to solve and analyze. In this section we will apply some of the results on linear functions obtained in Chapter 3 to the solution of linear systems of equations.

Suppose we are given a model

$$
\begin{equation*}
T(x ; \alpha)=T_{\alpha}(x)=\underline{0} \tag{M}
\end{equation*}
$$

where $T: \mathbb{R}^{\mathrm{n}} \times \mathbb{R}^{\mathrm{p}} \supseteq X \times \Omega \longrightarrow \mathbb{R}^{\mathrm{m}}$ is a linear function (and therefore so is $T_{\alpha}$ ). Given bases for $\mathbb{R}^{m}, \mathbb{R}^{n}$, and $\mathbb{R}^{\mathrm{p}}$, we can write $(\mathrm{M})$ in the form

$$
\begin{equation*}
A x+B \alpha=\underline{0} \tag{1}
\end{equation*}
$$

where $A$ and $B$ are real matrices of dimensions $m \times n$ and $m \times p$, respectively. Putting $y=-B \alpha$, we can write (1) in the form

$$
\begin{equation*}
A x=y \tag{2}
\end{equation*}
$$

which will be more convenient when we work with fixed parameter values. We will interpret (2) as a system of $m$ equations in $n$ unknowns (the coordinates of $x$ ). In what follows, we will freely use the equivalence (for given bases) between matrices and linear mappings.

We saw in Chapter 3 that given a linear transformation $T: X \rightarrow Y$, the sets

$$
\begin{gathered}
\operatorname{ker} T=T^{-1}(\underline{0})=\{x \in X ; T(x)=\underline{0}\} \quad \text { and } \\
\operatorname{im} T=T(X)=\{y \in Y ; y=T(x) \text { for some } x \in X\}
\end{gathered}
$$

are vector subspaces of $X$ and $Y$, respectively, and that their dimensions satisfy the following equality:

$$
\begin{equation*}
\operatorname{dim}(\operatorname{ker} T)=\operatorname{dim} X-\operatorname{dim}(\operatorname{im} T)=\operatorname{dim} X-\operatorname{rank} T \tag{3}
\end{equation*}
$$

Thus, the kernel of $T$ is the set of solutions to the homogeneous linear system

$$
\begin{equation*}
T(x)=\underline{0} \tag{H}
\end{equation*}
$$

or, equivalently,

$$
A x=\underline{0}
$$

Let $S^{\mathrm{H}}$ denote the set of solutions to (H). We know that $S^{\mathrm{H}}$ always contains the zero vector and is a linear subspace of $X$. Therefore, in order to construct the "general solution" to $(\mathrm{H})$ (i.e., to find all the elements of $S^{\mathrm{H}}$ ), it suffices to find enough linearly independent solutions to construct a basis; that is, we need $m-\operatorname{rank} A$ such solutions.

Next, we observe that because im $T$ is a subspace of $\mathbb{R}^{m}$, the dimension of im $T$ cannot exceed $m$. Hence, (3) implies

$$
\operatorname{dim} S^{\mathrm{H}}=n-\operatorname{rank} A \geq n-m
$$

That is, the dimension of the set of solutions to $(\mathrm{H})$ is equal to the number of unknowns $(n)$ minus the number of linearly independent equations (rank $A$ ); and because the second of these numbers cannot exceed the total number of equations, we have $\operatorname{dim} S^{\mathrm{H}} \geq n-m$. Hence, if the system has more unknowns than equations $(n>m)$, we have $S^{\mathrm{H}} \geq 1$, and it follows that $(\mathrm{H})$ has nontrivial solutions.

We now turn to the nonhomogeneous system of linear equations

$$
\begin{equation*}
T(x)=y \tag{N}
\end{equation*}
$$

or

$$
A x=y
$$

where $y \in \mathbb{R}^{\mathrm{m}}$ is a known vector. Let $S^{\mathrm{N}}$ denote the solution set of (N). The following result says that $S^{N}$ is an affine subspace of $\mathbb{R}^{\mathrm{n}}$ parallel to $S^{\mathrm{H}}$.

Theorem 1.1. Given a linear transformation $\mathrm{T}: \mathrm{X} \longrightarrow \mathrm{Y}$, let $\mathrm{x}^{\mathrm{p}}$ be any ("particular") solution to the nonhomogeneous system of equations $(N): \mathrm{T}(\mathrm{x})=\mathrm{y}$. Then the set $\mathrm{S}^{N}$ of solutions to $(N)$ is the set

$$
\mathbf{S}^{N}=\mathbf{x}^{\mathrm{p}}+\mathbf{S}^{H}=\left\{\mathbf{x}^{N} \in \mathbf{X} ; \mathbf{x}^{N}=\mathbf{x}^{\mathrm{p}}+\mathbf{x}^{H} \quad \text { for some } \mathbf{x}^{H} \in \mathrm{S}^{H}\right\}
$$

Proof. Let $x^{\mathrm{H}}$ be an arbitrary solution of (H). We want to show (i) that all vectors of the form $x^{p}+x^{\mathrm{H}}$ are solutions of (N) and (ii) that only vectors of this form can solve $(\mathrm{N})$, that is, every $x^{\mathrm{N}} \in S^{\mathrm{N}}$ can be written $x^{\mathrm{N}}=x^{p}+x^{\mathrm{H}}$ or, equivalently, that given any two solutions $x^{\mathrm{N}}$ and $x^{p}$ to $(\mathrm{N})$, their difference is a solution to $(\mathrm{H})$. Both statements are easy to verify:
(i) If $x^{p} \in S^{\mathrm{N}}$ and $x^{\mathrm{H}} \in S^{\mathrm{H}}$, then $x^{p}+x^{\mathrm{H}}$ solves (N), because

$$
T\left(x^{p}+x^{\mathrm{H}}\right)=T\left(x^{p}\right)+T\left(x^{\mathrm{H}}\right)=y+\underline{0}=y
$$

(ii) If $x^{p}, x^{\mathrm{N}} \in S^{\mathrm{N}}$, then $x^{p}-x^{\mathrm{N}}$ solves (H), as

$$
T\left(x^{p}-x^{\mathrm{N}}\right)=T\left(x^{p}\right)-T\left(x^{\mathrm{N}}\right)=y-y=\underline{0}
$$

Hence, if the nonhomogeneous system has a solution (and it may not), $S^{N}$ has the same dimension as $S^{\mathrm{H}}$. Moreover, the first of these sets is easy to construct once we know the second: It is sufficient to find any particular solution to $(\mathrm{N})$ in order to know them all, once we have the solutions to $(\mathrm{H})$.

Recall that im $T$ is the set of vectors $y$ in $\mathbb{R}^{\mathrm{nn}}$ for which the system $T(x)=$ $y$ has a solution. We also know that im $T$ is a vector subspace of $\mathbb{R}^{\mathrm{m}}$ generated by the columns of the matrix representation of $T$, and therefore its dimension (the rank of $T$ ) is equal to the rank of its associated matrix $A$, that is, the number of linearly independent equations in the system.

It follows that for a given vector $y$, the system $T(x)=y$ will have a solution if and only if $y \in \operatorname{im} T$, the space generated by the columns of the coefficient matrix. In order to obtain a more "operational" condition, observe that we can write $(\mathrm{N})$ in the form

$$
x_{1}\left[\begin{array}{c}
a_{11} \\
\ldots \\
a_{m 1}
\end{array}\right]+\ldots+x_{n}\left[\begin{array}{c}
a_{1 n} \\
\ldots \\
a_{m n}
\end{array}\right]=\left[\begin{array}{c}
y_{1} \\
\ldots \\
y_{m}
\end{array}\right]
$$

or

$$
\begin{equation*}
\sum_{i=1}^{n} x_{i} \operatorname{col}_{i}(A)=y \tag{4}
\end{equation*}
$$

Looking at things this way, it is clear that a solution $x^{*}=\left(x_{1}^{*}, \ldots, x_{n}^{*}\right)$ of (N) exists if and only if it is possible to write $y$ as a linear combination of column vectors of the coefficient matrix $A$, that is, if $y$ is in the column space of $A$.

Next, consider the coefficient matrix $A=\left[\operatorname{col}_{1}(A), \ldots, \operatorname{col}_{n}(A)\right]$ and the matrix formed by adding to $A$ a new column equal to the vector $y, A_{y}=$ $\left[\operatorname{col}_{1}(A), \ldots, \operatorname{col}_{n}(A), y\right]$. Recall that the rank of a matrix is the number of linearly independent columns (or rows) in it. Because $A_{y}$ is $A$ augmented by a new column, the rank of $A$ cannot exceed that of $A_{y}$. There are, then, only two possibilities:

(i) $\operatorname{rank} A=\operatorname{rank} A_{y}$ : When we add the new column $y$ to $A$, the rank of the matrix does not increase. This implies that $y$ is a linear combination of the column vectors of $A$, and therefore the system has at least one solution.
(ii) rank $A<\operatorname{rank} A_{y}$ : If the rank increases when we form the augmented matrix, $y$ must be linearly independent of the column vectors of $A$; that is, there are no scalars $x_{1}^{*}, \ldots, x_{n}^{*}$ such that (4) holds.

The same logic will work in reverse. If there is a solution to the system, then $y$ can be written as a linear combination of the columns of $A$, and the addition of $y$ to the coefficient matrix will not increase its rank. Hence, we have proved the following result:

Theorem 1.2. Existence of solutions for linear systems. The linear system Ax $=\mathrm{y}$ has (at least) one solution if and only if $\operatorname{rank} \mathrm{A}=\operatorname{rank} \mathrm{A}_{\mathrm{y}}$.

Assume that there exists a solution to $(\mathrm{N})$. Given that $\operatorname{dim}(\operatorname{ker} A)=n-$ rank $A$, this solution will be unique (i.e., $S^{\mathrm{N}}$ will have dimension zero) if and only if rank $A=n$, that is, if we have as many linearly independent equations as unknowns. ${ }^{1}$

Theorem 1.3. Uniqueness of solutions for linear systems. The system of $\mathrm{m}$ equations in $\mathrm{n}$ unknowns, $\mathrm{Ax}=\mathrm{y}\left(\mathrm{x} \in \mathbb{R}^{n}, \mathrm{y} \in \mathbb{R}^{m}\right)$ has a unique solution if and only if

$$
\operatorname{rank} \mathrm{A}=\mathrm{n}=\operatorname{rank} \mathrm{A}_{\mathrm{y}}
$$

Observe that we could have $m>n$, that is, more equations than unknowns, but in that case not all the equations would be linearly independent. In fact, $m-n$ of them would be redundant and would add no information to the others. Hence, we can ignore them and work with the $n$ independent equations. If we have as many equations as unknowns, $A$ is a square matrix, and a unique solution exists if and only if $A$ is invertible or, equivalently, if its determinant is different from zero. In this case, the unique solution to the system is given by

$$
x^{*}=A^{-1} y
$$

and we can use Cramer's rule to obtain each of the components of the solution vector as the ratio of two determinants:

$$
x_{i}^{*}=\frac{\left|A_{i}\right|}{|A|}
$$

where $A_{i}$ is the matrix obtained by replacing the $i$ th column of $A$ by the vector $y$ (the right-hand side of the system).

A nonhomogeneous system $T(x)=y$ may have solutions for certain vectors $y$ and no solutions for others. Clearly, $T(x)=y$ will have a solution for every $y \in \mathbb{R}^{\mathrm{m}}$ if and only if im $T=T\left(\mathbb{R}^{\mathrm{n}}\right)=\mathbb{R}^{\mathrm{n}}$. For this, it is sufficient
that the rank of $T$ be equal to $m$ (it cannot be larger). If, on the other hand, we have rank $T<m$, then the set of $y$ 's for which $(\mathrm{N})$ has a solution is a subspace of $\mathbb{R}^{m}$ of dimension less than $m$ (e.g., a straight line on the plane, or a plane in three-dimensional space). Hence, if we pick a vector $y$ randomly, the system $A x=y$ will have a solution only by chance, and if we start with some $y=-B \alpha$ for which there is a solution, almost any small change in the parameters will leave the system with no solutions.

Let us now reintroduce the parameters $\alpha$ explicitly into the model. Assume that the system

$$
\begin{equation*}
A x+B \alpha=\underline{0} \tag{L.1}
\end{equation*}
$$

has $n$ independent equations (that is, $A$ is an $n \times n$ matrix and has full rank). Then $A$ is invertible, and we can solve (L.1) to obtain a solution that will be unique for given parameter values:

$$
x=-A^{-1} B \alpha
$$

The solution function for the model is therefore

$$
x^{*}=x(\alpha) C \alpha, \quad \text { where } C=-A^{-1} B
$$

Given the matrices $A$ and $B$, explicit solutions for the model can be computed using Cramer's rule or, more efficiently, some algorithm for the inversion of matrices. In any case, the solution of linear models does not pose difficulties, at least in principle.

In this case, dealing with comparative statics is easy. Because we know the solution function, we can differentiate it directly to obtain

$$
\frac{\partial x_{i}^{*}}{\partial \alpha_{k}}=c_{i k} \quad(\text { the } i k \text { element of } C)
$$

We can also handle discrete parameter changes quite easily. Let $\alpha^{\prime}$ and $\alpha^{\prime \prime}$ be two different parameter vectors. The corresponding equilibrium values of the endogenous variables will be given by

$$
x^{\prime \prime}=C \alpha^{\prime \prime} \text { and } \quad x^{\prime}=C \alpha^{\prime}
$$

Hence the displacement of the equilibrium as a result of the parameter change will be

$$
x^{\prime \prime}-x^{\prime}=C \alpha^{\prime \prime}-C \alpha^{\prime}=C\left(\alpha^{\prime \prime}-\alpha^{\prime}\right) \Rightarrow \Delta x^{*}=C \Delta \alpha
$$

## 2. Comparative Statics and the Implicit-Function Theorem

Let us now return to nonlinear models. Let $F$ be a function $\mathbb{R}^{\mathrm{n}+\mathrm{p}} \supseteq X \times \Omega$ $\longrightarrow \mathbb{R}^{\mathrm{m}}$, with $X \times \Omega$ open, and consider the model

$$
\begin{equation*}
F(x ; \alpha)=\underline{0} \tag{M}
\end{equation*}
$$

where $\alpha$ is a vector of parameters, and $x$ is the vector of endogenous variables whose solution values we seek. For a given value of $\alpha$, we define a function of $x$ alone by $f_{\alpha}(x)=F(x ; \alpha)$. Then $x^{*}$ is a solution of the model for the given $\alpha$ if and only if it is a zero of $f_{\alpha}$. Hence, the equilibrium or solution correspondence

$$
S: \mathbb{R}^{\mathrm{p}} \supseteq \Omega \longrightarrow X \subseteq \mathbb{R}^{\mathrm{n}}
$$

that assigns to each parameter vector $\alpha$ the corresponding set $S(\alpha)$ of equilibrium values of the endogenous variables is given by

$$
S(\alpha)=f_{\alpha}^{-1}(\underline{0})=\left\{x \in X ; f_{\alpha}(x)=\underline{0}\right\}
$$

As we have already indicated, we are interested in two types of questions: (i) For a given value of $\alpha$, what does the solution set $S(\alpha)$ look like? (ii) How does it change if we change the parameters? We have seen that the answers to these questions are straightforward in the case of linear models. For nonlinear models, things are more complicated, but if we are willing to assume that $F$ is differentiable, we can proceed by constructing a linear approximation to the model in a neighborhood of a solution point and then analyze the resulting linear model. This approach yields a tractable method for doing comparative statics and some valuable information on the local structure and dimensionality of the solution set of the model.

In what follows, we will assume that $F$ is a $C^{1}$ function and focus on the case in which $m=n$, that is, we assume that the model $(\mathrm{M})$ has as many equations as unknowns. The central result is the implicit-function theorem (IFT). This theorem gives sufficient conditions for the solution correspondence $S(\alpha)$ to be a well-defined and nicely behaved function in some neighborhood of a known solution point. The IFT also provides a tractable method for doing comparative statics, that is, for determining in what direction the equilibrium moves as a result of changes in the parameters of the system.

The IFT is a close relative of the inverse-function theorem. Assume that the number of equations and the number of unknowns in $(M)$ are the same; then $f_{\alpha}$ maps $\mathbb{R}^{\mathbf{n}}$ into itself, and we can apply the inverse-function theorem. Hence, if for a given value of the parameter vector $\alpha^{0}$ the pair $\left(x^{0}, \alpha^{0}\right)$ satisfies (M), $F\left(\right.$ ) (and therefore $f_{\alpha}$ ) is continuously differentiable, and the Jacobian of $f_{\alpha} 0$, given by $\left|D f_{\alpha^{0}}\left(x^{0}\right)\right|=\left|D_{x} F\left(x^{0}, \alpha^{0}\right)\right|$, is not zero at $x^{0}$, then $f_{\alpha^{0}}$ is one-to-one in some neighborhood of $x^{0}$, and therefore $x^{0} \in f_{\alpha^{0}}^{-1}(\underline{0})$ is a locally unique solution of the system $F\left(x ; \alpha^{0}\right)=\underline{0}$.

To see what the IFT adds to this, imagine that there are changes in the
parameters. For each $\alpha$ we obtain a new system of equations $f_{\alpha}(x)=\underline{0}$ and a different solution set $f_{\alpha}^{-1}(\underline{0})$ (possibly empty). Now, if $F$ is a continuously differentiable function of the parameters and we restrict ourselves to a sufficiently small neighborhood of $\alpha^{0}$, then all the $f_{\alpha}$ 's will be sufficiently similar to $f_{\alpha^{0}}$ that each one of the systems $f_{\alpha}(x)=\underline{0}$ will have a solution close to $x^{0}$. Moreover, because each of the $f_{\alpha}^{\prime}$ 's is locally invertible, each of these solutions will be locally unique.

## (a) Derivatives of Implicit Functions and Comparative Statics

We will begin by deriving a very useful formula for doing comparative statics in differentiable models. We will then specify under what conditions the use of this formula is legitimate. Given a parameterized system of equations (M), which we can write in more detailed notation as

$$
\begin{gather*}
F^{1}\left(x_{1}, \ldots, x_{n} ; \alpha_{1}, \ldots, \alpha_{p}\right)=0 \\
\vdots \\
F^{n}\left(x_{1}, \ldots, x_{n} ; \alpha_{1}, \ldots, \alpha_{p}\right)=0
\end{gather*}
$$

we would like to know in what direction the solution of the system $x^{*}=\left(x_{1}^{*}\right.$, $\left.\ldots, \mathbf{x}_{n}^{*}\right)$ moves when there is a small change in the value of some parameter, say $\alpha_{k}$. Suppose, for the time being, that the solution correspondence for this model is a differentiable function, that is, that we can write the equilibrium value $x_{i}^{*}$ for each of the endogenous variables as a differentiable function of the form

$$
x_{1}^{*}=x_{i}(\alpha)=x_{i}\left(\alpha_{1}, \ldots, \alpha_{p}\right)
$$

We would like to determine the sign of the partial derivatives $\partial x_{i}^{*} / \partial \alpha_{k}$. If the model can be solved explicitly, the problem is simple. In general, however, closed forms for the solution functions of $(\mathbf{M})$ will not be available, so we will have to resort to less direct methods to "extract" the properties of $x_{i}(\alpha)$ from those of $F()$. The most straightforward approach is the following.

Substituting the solution function $x($ ) back into (M), we obtain the identity

$$
\begin{equation*}
F[x(\alpha), \alpha] \equiv \underline{0} \tag{1}
\end{equation*}
$$

or, in more detailed notation,

$$
\begin{align*}
& F^{i}\left[x_{1}\left(\alpha_{1}, \ldots, \alpha_{p}\right), \ldots, x_{n}\left(\alpha_{1}, \ldots, \alpha_{p}\right) ; \alpha_{1}, \ldots, \alpha_{p}\right] \equiv 0 \\
& \quad \text { for each } i=1, \ldots, n
\end{align*}
$$

We emphasize that (1) is an identity - in the sense that, unlike (M), it holds for all values of $\alpha$ - and in fact (1) defines the function $x(\alpha)$. Hence we can differentiate both sides of (1) with respect to any parameter and the equality will continue to hold. Differentiating $\left(1^{\prime}\right)$ with respect to $\alpha_{k}$, we have

$$
\frac{d F^{i}}{d \alpha_{k}}=F_{x_{1}}^{i} \frac{\partial x_{1}^{*}}{\partial \alpha_{k}}+\ldots+F_{x_{n}}^{i} \frac{\partial x_{n}^{*}}{\partial \alpha_{k}}+F_{\alpha_{k}}^{i}=0
$$

for the $i$ th equation. Repeating the operation for each equation, we obtain the following expression for the whole system:

$$
\left[\begin{array}{ccc}
F_{x_{1}}^{1} & \ldots & F_{x_{n}}^{1}  \tag{2}\\
\ldots & \ldots & \ldots \\
F_{x_{1}}^{n} & \ldots & F_{x_{n}}^{n}
\end{array}\right]\left[\begin{array}{c}
\frac{\partial x_{1}^{*}}{\partial \alpha_{k}} \\
\ldots \\
\frac{\partial x_{n}^{*}}{\partial \alpha_{k}}
\end{array}\right]=-\left[\begin{array}{c}
F_{\alpha_{k}}^{1} \\
\cdots \\
F_{\alpha_{k}}^{n}
\end{array}\right]
$$

If the Jacobian matrix $J=D_{x} F(x ; \alpha)$ of first partial derivatives of $F$ with respect to the endogenous variables is invertible (i.e., if $|J| \neq 0$ ), then (2) can be solved for the partial derivatives of the solution functions, $\partial x_{i}^{*} / \partial \alpha_{k}$. Using Cramer's rule, we have

$$
\begin{equation*}
\frac{\partial x_{i}^{*}}{\partial \alpha_{k}}=\frac{-\left|J_{i}\right|}{|J|} \tag{3}
\end{equation*}
$$

where $J_{i}$ is the matrix obtained by replacing the $i$ th column of the Jacobian $J$ with the vector $\left(F_{\alpha_{k}}^{1}, \ldots, F_{\alpha_{k}}^{n}\right)^{T}$ that appears on the right-hand side of (2).

The same conclusion can be obtained in much more compact form using vector notation. Differentiating (1) with respect to the parameter vector, we obtain

$$
D_{x} F(x ; \alpha) D x(\alpha)+D_{\alpha} F(x ; \alpha)=\underline{0}
$$

from where

$$
\begin{equation*}
D x(\alpha)=-\left[D_{x} F(x ; \alpha)\right]^{-1} D_{\alpha} F(x ; \alpha) \tag{4}
\end{equation*}
$$

Equation (3) then gives us the $i$ th component of the vector $D x(\alpha)$.

The formula we have just derived is an extremely useful tool for the analysis of static, differentiable models. But we still have to see when it is legitimate to use it. To obtain it, we have assumed that the solution correspondence is a well-defined and differentiable function, which is not
necessarily true. In the following section we will derive sufficient conditions for this to be locally true in some neighborhood of a known solution point. In particular, it suffices that $F$ be a $C^{1}$ function and that its derivative with respect to the vector of endogenous variables, evaluated at the solution of the system, be invertible. The necessity of this second condition is apparent from (4). Before turning to this problem, we pause to observe that the procedure described earlier is equivalent to working with the linearization of (M) in some neighborhood of a given solution.

## A Reinterpretation

Given a nonlinear model

$$
\begin{equation*}
F(x ; \alpha)=\underline{0} \tag{M}
\end{equation*}
$$

where $F$ is a smooth function, and $x^{0}$ a solution of the system for given values $\alpha^{0}$ of the parameters, we can construct a linear approximation to $F$ in some neighborhood of $\left(x^{0}, \alpha^{0}\right)$ :

$$
\begin{aligned}
F(x ; \alpha) & \cong F\left(x^{0}, \alpha^{0}\right)+\left[D F_{x}\left(x^{0}, \alpha^{0}\right), D_{\alpha} F\left(x^{0}, \alpha^{0}\right)\right]\left[\begin{array}{l}
x-x^{0} \\
\alpha-\alpha^{0}
\end{array}\right] \\
& =\underline{0}+D_{x} F\left(x^{0}, \alpha^{0}\right)\left(x-x^{0}\right)+D_{\alpha} F\left(x^{0}, \alpha^{0}\right)\left(\alpha-\alpha^{0}\right)
\end{aligned}
$$

Hence, we can approximate (M) by the linear model

$$
\begin{equation*}
D_{x} F\left(x^{0}, \alpha^{0}\right)\left(x-x^{0}\right)=-D_{\alpha} F\left(x^{0}, \alpha^{0}\right)\left(\alpha-\alpha^{0}\right) \tag{L}
\end{equation*}
$$

where $D_{x} F\left(x^{0}, \alpha^{0}\right)$ and $D_{\alpha} F\left(x^{0}, \alpha^{0}\right)$ are "constant" matrices. We have, then, a system of $n$ linear equations in $n$ unknowns $(x)$, and if $\left|D_{x} F\left(x^{0}, \alpha^{0}\right)\right| \neq 0$, we can solve it to find the solution function for $(\mathrm{L})$ :

$$
x_{L}^{*}=\phi(\alpha)=x^{0}-\left[D_{x} F\left(x^{0}, \alpha^{0}\right)\right]^{-1} D_{\alpha} F\left(x^{0}, \alpha^{0}\right)\left(\alpha-\alpha^{0}\right)
$$

Alternatively, we can use the procedure described earlier to calculate the derivative of the solution function for the original model, $x(\alpha)$. Constructing a linear approximation to this function, and using (4), we find that, close to $x^{0}$,

$$
x^{*} \cong x^{0}+D x\left(\alpha^{0}\right)\left(\alpha-\alpha^{0}\right)=x^{0}-\left[D_{x} F\left(x^{0}, \alpha^{0}\right)\right]^{-1} D_{\alpha} F\left(x^{0}, \alpha^{0}\right)\left(\alpha-\alpha^{0}\right)=\phi(\alpha)
$$

Thus, the two approaches are equivalent: They yield the same linear approximation to the solution function for $(\mathbf{M})$.

## (b) The Implicit-Function Theorem

We begin the discussion of this important result by considering a simple case in which we can rely on graphical intuition. Let $F$ be a $C^{1}$ function from $\mathbb{R}^{2}$ to $\mathbb{R}$, and consider the "system" formed by a single equation in one unknown and one parameter:

$$
\begin{equation*}
F(x ; \alpha)=0 \tag{5}
\end{equation*}
$$

Graphically, the graph of $F$ corresponds to a surface in three-dimensional space, with the values of the function measured along the vertical axis. The set of pairs $(x, \alpha)$ that satisfy equation (5) (the zero level set of $F$ ) corresponds to the intersection of this surface with the horizontal plane. If $F$ satisfies certain regularity conditions, this locus will describe a curve on the plane, as illustrated in Figure 5.1.

The following question then arises: Can we interpret the curve $F(x, \alpha)=$ 0 as the graph of a function $x(\alpha)$ giving the solution to (5) as a function of the parameter? We see that, in general, the answer is no: As the figure suggests, there is no guarantee that for each value of $\alpha$ there will exist precisely one solution to the equation $F(x, \alpha)=0$. In the foregoing example, $x(\alpha)$ is a function on the interval $\left(-\infty, \alpha^{\prime}\right)$, but not on the rest of the real line, because equation (5) has two solutions in the interval $\left(\alpha^{\prime}, \alpha^{\prime \prime}\right)$, and none for $\alpha>\alpha^{\prime \prime}$.

On the other hand, the figure also suggests that in many cases $x(\alpha)$ will

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-210.jpg?height=736&width=1141&top_left_y=1392&top_left_x=177)

Figure 5.1.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-211.jpg?height=770&width=1090&top_left_y=189&top_left_x=191)

Figure 5.2.

indeed be a function locally. If we restrict ourselves to a sufficiently small rectangle $R$ around a point $\left(x^{0}, \alpha^{0}\right)$ on the curve, it will be true that, for almost all points, the restriction of the curve to the rectangle is the graph of a function. The only exception in Figure 5.1 is the point $\left(\alpha^{\prime \prime}, x^{\prime \prime}\right)$, at which the curve is locally vertical (i.e., where $F_{x}\left(x^{\prime \prime}, \alpha^{\prime \prime}\right)=0$ ). ${ }^{2}$ No matter how small we draw the rectangle around this point, it will always include some values of $\alpha$ for which there are two solutions of the system, and others for which there is none. Hence, in this case equation (5) does not define the solution value of the endogenous variable $x^{*}$ as a function of the parameter $\alpha$, even locally. However, inspection of Figure 5.1 reveals that this is the only point at which we run into this problem.

Consider now the same problem from a slightly different point of view. If we fix the value of $\alpha$ at $\alpha^{0}$ and plot $F$ as a function of $x$, the solutions of the system correspond to the points at which the graph of $F\left(x, \alpha^{0}\right)$ touches the horizontal axis. Figure 5.2 suggests that two types of solutions are possible: In one case (e.g., $x^{\prime \prime}$ ), $F($ ) crosses the axis transversally, whereas in the other (e.g., $\left.x^{\prime}\right), F()$ is only tangent to it. In the first case, the partial derivative of $F($ ) with respect to $x$ will be either strictly positive or strictly negative; in the second case, we have $F_{x}()=0$.

Intuitively, it is clear that the two types of equilibria will behave very differently in response to a small change in the value of the parameter. "Transversal" (or regular) equilibria will survive small perturbations and remain
locally unique, whereas "tangency" (or critical) solutions will be fragile, tending to disappear with some perturbations, or to unfold into two different equilibria. Once more, we conclude that if $F_{x}(x, \alpha) \neq 0$ at a solution of the system, then the solution correspondence will be, at least locally, a welldefined function. On the other hand, if $F_{x}(x, \alpha)=0$, we have a tangency equilibrium, and strange things may happen.

The following result formalizes the preceding discussion: If we rule out tangency equilibria, $x(\alpha)$ is locally a well-defined function and inherits the differentiability of $F$.

Theorem 2.1. Implicit-function theorem (simplest case). Suppose $\mathrm{F}: \mathbb{R}^{2} \longrightarrow$ $\mathbb{R}$ is $\mathrm{C}^{l}$ on an open neighborhood $\mathrm{A}$ of a point $\left(\mathrm{x}^{0}, \alpha^{0}\right)$ such that $\mathrm{F}\left(\mathrm{x}^{0}, \alpha^{0}\right)=$ 0 and $\mathrm{F}_{\mathrm{x}}\left(\mathrm{x}^{0}, \alpha^{0}\right) \neq 0$. Then there exist open intervals $\mathrm{I}_{\mathrm{x}}$ and $\mathrm{I}_{\alpha}$ centered at $\mathrm{x}^{0}$ and $\alpha^{0}$, respectively, such that the following hold:

(i) For each $\alpha \subseteq \mathrm{I}_{\alpha}$ there exists a unique $\mathrm{x}_{\alpha} \in \mathrm{I}_{\mathrm{x}}$ such that $\mathrm{F}\left(\mathrm{x}_{\alpha}, \alpha\right)=0$. That is, the restriction of the zero-level curve of $\mathrm{F}$ to the rectangle $\mathrm{I}_{\mathrm{x}} \times \mathrm{I}_{\alpha}$ defines a function

$$
x: I_{\alpha} \longrightarrow I_{x}, \text { with } x(\alpha)=x_{\alpha}
$$

(ii) The function $\mathrm{x}()$ is differentiable, and its derivative is a continuous function given by

$$
\mathrm{x}^{\prime}(\alpha)=\frac{-\mathrm{F}_{\alpha}(\mathrm{x}, \alpha)}{\mathrm{F}_{\mathrm{x}}(\mathrm{x}, \alpha)}
$$

Although the simplest way to prove the implicit-function theorem is by applying the inverse-function theorem, we will give a direct proof for this special case of the theorem that probably will illustrate the logic of the result better than will the general proof given later.

## Proof

(i) $x(\alpha)$ is a well-defined function from $I_{\alpha}$ to $I_{x}$; that is, for each $\alpha$ in $I_{\alpha}$ there exists a unique $x_{\alpha}$ in $I_{x}$ such that $F\left(x_{\alpha}, \alpha\right)=0$.

By assumption, $F_{x}\left(x^{0}, \alpha^{0}\right) \neq 0$; for concreteness, suppose $F_{x}\left(x^{0}, \alpha^{0}\right)=a>0$. Because $F_{x}(x, \alpha)$ is continuous on $A$, there exists an open rectangular neighborhood $R^{\prime}$ of $\left(x^{0}, \alpha^{0}\right)$ such that for all $(x, \alpha)$ in $R^{\prime}, F_{x}>a / 2$; that is, there exist $\eta, \delta>0$ such that

$$
\begin{equation*}
\forall(x, \alpha) \in R^{\prime}=B_{\delta}\left(x^{0}\right) \times B_{\eta}\left(\alpha^{0}\right), F_{x}(x, \alpha)>a / 2>0 \tag{1}
\end{equation*}
$$

(refer to Figure 5.3). That is, $F$ is a strictly increasing function of $x$ for given $\alpha$ and $(x, \alpha) \in R^{\prime}$. Moreover, because $F$ has value zero at $\left(x^{0}, \alpha^{0}\right)$, we have

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-213.jpg?height=813&width=1103&top_left_y=197&top_left_x=194)

Figure 5.3.

$$
\begin{equation*}
F\left(x^{0}+\delta, \alpha^{0}\right)>0 \quad \text { and } \quad F\left(x^{0}-\delta, \alpha^{0}\right)<0 \tag{2}
\end{equation*}
$$

Next, fix $\bar{x}=x^{0}+\delta$; then $F(\bar{x}, \alpha)$ is a continuous function of $\alpha$, with $F\left(\bar{x}, \alpha^{0}\right)>$ 0 . By continuity, this inequality continues to hold for $\alpha$ sufficiently close to $\alpha^{0}$; that is, there exists some $\varepsilon \in(0, \eta)$ such that $F(\bar{x}, \alpha)>0$ for all $\alpha \in B_{\varepsilon}\left(\alpha^{0}\right)$. Similarly, if we fix $\underline{x}=x^{0}-\delta, F$ will be strictly negative for $\alpha$ sufficiently close to $\alpha^{0}$. Hence, we can choose $\varepsilon$ in such a way that

$$
\begin{equation*}
F\left(x^{0}+\delta, \alpha\right)>0 \quad \text { and } \quad F\left(x^{0}-\delta, \alpha\right)<0 \quad \text { for all } \alpha \in B_{\varepsilon}\left(\alpha^{0}\right) \tag{3}
\end{equation*}
$$

Fix some $\alpha$ in $B_{\varepsilon}\left(\alpha^{0}\right)$. The function $f_{\alpha}(x) \equiv F(x, \alpha)$ is continuous in $x$, and, by (3), we have

$$
f_{\alpha}\left(x^{0}+\delta\right)>0 \text { and } f_{\alpha}\left(x^{0}-\delta\right)<0
$$

By the intermediate-value theorem, it follows that there exists some $x_{\alpha} \in$ $\left(x^{0}-\delta, x^{0}+\delta\right)$ such that

$$
f_{\alpha}\left(x_{\alpha}\right)=F\left(x_{\alpha}, \alpha\right)=0
$$

Moreover, this $x_{\alpha}$ will be unique, for $f_{\alpha}()$ is strictly increasing in $B_{\delta}\left(x^{0}\right)$ and therefore can cut the horizontal axis only once in this interval, as suggested in Figure 5.4.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-214.jpg?height=695&width=995&top_left_y=195&top_left_x=234)

Figure 5.4.

In conclusion, we have shown that given any $\alpha$ in a sufficiently small neighborhood of $\alpha^{0}$, there exists one, and only one, value of $x$ (namely $x_{\alpha}$ ) such that $\left(x_{\alpha}, \alpha\right)$ satisfies the given equation. Hence, the solution correspondence $\alpha \rightarrow \rightarrow x(\alpha)=x_{\alpha}$ is a well-defined function from $B_{\varepsilon}\left(\alpha^{0}\right)$ to $B_{\delta}\left(x^{0}\right)$.

(ii) The function $x(): B_{\varepsilon}\left(\alpha^{0}\right) \longrightarrow B_{\delta}\left(x^{0}\right)$ is continuously differentiable.

Take two points $\alpha^{\prime}$ and $\alpha^{\prime \prime}$ in $B_{\varepsilon}\left(\alpha^{0}\right)$ and put $x^{\prime}=x\left(\alpha^{\prime}\right)$ and $x^{\prime \prime}=x\left(\alpha^{\prime \prime}\right)$; by construction, we have $x^{\prime}, x^{\prime \prime} \in B_{\delta}\left(x^{0}\right)$ and

$$
\begin{equation*}
F\left(x^{\prime}, \alpha^{\prime}\right)=F\left(x^{\prime \prime}, \alpha^{\prime \prime}\right)=0 \tag{4}
\end{equation*}
$$

By the mean-value theorem, there exists some point $\left(x^{\lambda}, \alpha^{\lambda}\right)$ on the straight line segment connecting $\left(x^{\prime}, \alpha^{\prime}\right)$ and $\left(x^{\prime \prime}, \alpha^{\prime \prime}\right)$ (and therefore in $R=B_{\delta}\left(x^{0}\right) \times B_{\varepsilon}\left(\alpha^{0}\right)$ ) such that

$$
\begin{equation*}
0=F\left(x^{\prime}, \alpha^{\prime}\right)-F\left(x^{\prime \prime}, \alpha^{\prime \prime}\right)=F_{x}\left(x^{\lambda}, \alpha^{\lambda}\right)\left(x^{\prime}-x^{\prime \prime}\right)+F_{\alpha}\left(x^{\lambda}, \alpha^{\lambda}\right)\left(\alpha^{\prime}-\alpha^{\prime \prime}\right) \tag{5}
\end{equation*}
$$

Regrouping terms in (5),

$$
\begin{equation*}
x\left(\alpha^{\prime}\right)-x\left(\alpha^{\prime \prime}\right)=\frac{-F_{\alpha}\left(x^{\lambda}, \alpha^{\lambda}\right)}{F_{x}\left(x^{\lambda}, \alpha^{\lambda}\right)}\left(\alpha^{\prime}-\alpha^{\prime \prime}\right) \tag{6}
\end{equation*}
$$

and because $\left(x^{\lambda}, \alpha^{\lambda}\right) \in R^{\prime}$, we have

$$
\begin{equation*}
F_{x}\left(x^{\lambda}, \alpha^{\lambda}\right)>a / 2>0 \tag{7}
\end{equation*}
$$

by (1). Moreover, $F_{\alpha}(x, \alpha)$ is a continuous function on the closure of $R^{\prime}$, which
is a compact set, and therefore attains a maximum on this set. Hence we can write

$$
\begin{equation*}
F_{\alpha}\left(x^{\lambda}, \alpha^{\lambda}\right) \leq M \equiv \max \left\{F_{\alpha}(x, \alpha) ;(x, \alpha) \in \operatorname{cl} R^{\prime}\right\} \tag{8}
\end{equation*}
$$

Expressions (6), (7), and (8) imply that

$$
\begin{equation*}
\left|x\left(\alpha^{\prime}\right)-x\left(\alpha^{\prime \prime}\right)\right|=\left|\frac{-F_{\alpha}\left(x^{\lambda}, \alpha^{\lambda}\right)}{F_{x}\left(x^{\lambda}, \alpha^{\lambda}\right)}\right|\left|\alpha^{\prime}-\alpha^{\prime \prime}\right| \leq \frac{2 M}{a}\left|\alpha^{\prime}-\alpha^{\prime \prime}\right| \tag{9}
\end{equation*}
$$

where we see that $x()$ is continuous, for $x\left(\alpha^{\prime}\right) \rightarrow x\left(\alpha^{\prime \prime}\right)$ as $\alpha^{\prime} \rightarrow \alpha^{\prime \prime}$.

In fact, $x()$ is not only continuous but also differentiable. To see this, recall that $\left(x^{\lambda}, \alpha^{\lambda}\right)$ lies on the straight line segment between $\left(x^{\prime}, \alpha^{\prime}\right)$ and $\left(x^{\prime \prime}, \alpha^{\prime \prime}\right)$. As $\alpha^{\prime} \rightarrow \alpha^{\prime \prime}$, we have $x\left(\alpha^{\prime}\right) \rightarrow x\left(\alpha^{\prime \prime}\right)$, by (9), and therefore $\left(x^{\prime}, \alpha^{\prime}\right) \rightarrow$ $\left(x^{\prime \prime}, \alpha^{\prime \prime}\right)$. Because $\left(x^{\lambda}, \alpha^{\lambda}\right)$ lies between these two points, it follows also that $\left(x^{\lambda}, \alpha^{\lambda}\right) \rightarrow\left(x^{\prime \prime}, \alpha^{\prime \prime}\right)$. Regrouping terms in (6), and taking the limits of both sides as $\alpha^{\prime} \rightarrow \alpha^{\prime}$, we have (making use of the differentiability of $F_{x}$ and $\left.F_{\alpha}\right)$

$$
x^{\prime}\left(\alpha^{\prime \prime}\right)=\lim _{\alpha^{\prime} \rightarrow \alpha^{\prime \prime}} \frac{x\left(\alpha^{\prime}\right)-x\left(\alpha^{\prime \prime}\right)}{\alpha^{\prime}-\alpha^{\prime \prime}}=\lim _{\alpha^{\prime} \rightarrow \alpha^{\prime \prime}} \frac{-F_{\alpha}\left(x^{\lambda}, \alpha^{\lambda}\right)}{F_{x}\left(x^{\lambda}, \alpha^{\lambda}\right)}=\frac{-F_{\alpha}\left(x^{\prime \prime}, \alpha^{\prime \prime}\right)}{F_{x}\left(x^{\prime \prime}, \alpha^{\prime \prime}\right)}
$$

which establishes the differentiability of $x()$ and the formula given for its value in the theorem. Finally, because $F_{x}()$ and $F_{\alpha}()$ are continuous functions, so is $x^{\prime}()$ at all points where $F_{x}() \neq 0$, and in particular in $B_{\delta}\left(x^{0}\right)$.

We now turn to the general case of this result. Given a parameterized system of $n$ equations in $n$ unknowns,

$$
\begin{equation*}
F(x ; \alpha)=\underline{0} \tag{M}
\end{equation*}
$$

the implicit-function theorem gives us sufficient conditions for (M) to implicitly define a differentiable function that assigns to each $\alpha$ the corresponding equilibrium value of the vector of endogenous variables.

Theorem 2.2. Implicit-function theorem (general case). Let $\mathrm{F}: \mathbb{R}^{\mathrm{n}+p} \supseteq \mathrm{X} \times \Omega$ $\longrightarrow \mathbb{R}^{n}$ be a continuously differentiable function on an open set $\mathrm{X} \times \Omega$. Consider the system of equations $\mathrm{F}(\mathrm{x} ; \alpha)=\underline{0}$, and assume that has a solution $\mathrm{x}^{0}$ $\in \mathrm{X}$ for given parameter values $\alpha^{0} \in \Omega$. If the determinant of the Jacobian of endogenous variables is not zero at $\left(\mathrm{x}^{0} ; \alpha^{0}\right)$, that is, if

$$
\left|\mathrm{J}\left(\mathrm{x}^{0} ; \alpha^{0}\right)\right|=\left|\mathrm{D}_{\mathrm{x}} \mathrm{F}\left(\mathrm{x}^{0} ; \alpha^{0}\right)\right| \neq 0
$$

then we have the following:
(i) There exist open sets $\mathrm{U}$ in $\mathbb{R}^{n+p}$ and $\mathrm{U}_{\alpha}$ in $\mathbb{R}^{p}$, with $\left(\mathrm{x}^{0}, \alpha^{0}\right) \subseteq \mathrm{U}$ and $\alpha^{0} \subseteq \mathrm{U}_{\alpha}$, such that for each $\alpha$ in $\mathrm{U}_{\alpha}$ there exists a unique $\mathrm{x}_{\alpha}$ such that

$$
\left(\mathrm{x}_{\alpha}, \alpha\right) \in \mathrm{U} \text { and } \mathrm{F}\left(\mathrm{x}_{\alpha} ; \alpha\right)=\underline{0}
$$

That is, the correspondence from $\mathrm{U}_{\alpha}$ to $\mathrm{X}$ defined by $\mathrm{x}(\alpha)=\mathrm{x}_{\alpha}$ is a well-defined function when restricted to $\mathrm{U}$.

(ii) The solution function $\mathrm{x}(): \mathrm{U}_{\alpha} \longrightarrow \mathbb{R}^{n}$ is continuously differentiable, and its derivative is given by $\mathrm{D}_{\mathrm{x}}(\alpha)=-\left[\mathrm{D}_{\mathrm{x}} \mathrm{F}\left(\mathrm{x}_{\alpha} ; \alpha\right)\right]^{-1} \mathrm{D}_{\alpha} \mathrm{F}\left(\mathrm{x}_{\alpha} ; \alpha\right)$.

(iii) If $\mathrm{F}()$ is $\mathrm{C}^{\mathrm{k}}$, so is $\mathrm{x}($ ).

That is, given some parameter vector $\alpha^{0}$, suppose that $x^{0}$ solves the system (M), and the remaining assumptions of the theorem hold. Then for every $\alpha$ close to $\alpha^{0}$ there exists a solution $x(\alpha)$ close to $x^{0}$ that is locally unique. Hence, $x(\alpha)$ is locally a well-defined function, and, moreover, it inherits the differentiability of $F$.

Proof. We will apply the inverse-function theorem to the function $G: \mathbb{R}^{\mathrm{n}+p}$ $\longrightarrow \mathbb{R}^{\mathrm{n}+\mathrm{p}}$ defined by

$$
\begin{equation*}
G(x ; \alpha)=[F(x ; \alpha), \alpha]^{T} \tag{1}
\end{equation*}
$$

that is,

$$
\begin{array}{ll}
G^{t}(x ; \alpha)=F^{i}(x ; \alpha) & \text { for } i=1, \ldots, n \\
G^{n+j}(x ; \alpha)=\alpha_{j} & \text { for } j=1, \ldots, p
\end{array}
$$

Observe that

$$
\begin{equation*}
G\left(x^{0} ; \alpha^{0}\right)=\left[F\left(x^{0}, \alpha^{0}\right), \alpha^{0}\right]^{T}=\left(\underline{0}, \alpha^{0}\right)^{T} \tag{2}
\end{equation*}
$$

and the Jacobian of $G$ can be written

$$
D G(x ; \alpha)=\left[\begin{array}{cc}
D_{x} F\left(x^{0}, \alpha^{0}\right) & D_{\alpha} F\left(x^{0}, \alpha^{0}\right) \\
\frac{0}{4} & I
\end{array}\right]
$$

where $I$ is the identity matrix, and $\underline{0}$ a matrix of zeros. Expanding the determinant of $D G\left(x^{0} ; \alpha^{0}\right)$ by cofactors, starting from the lower right-hand-side corner, we find that

$$
\left|D G\left(x^{0} ; \alpha^{0}\right)\right|=\left|D_{x} F\left(x^{0} ; \alpha^{0}\right)\right| \neq 0
$$

so we can apply the inverse-function theorem to $G$ at $\left(x^{0} ; \alpha^{0}\right)$.

By the inverse-function theorem, there exist open sets $U$ and $V=G(U)$ in $\mathbb{R}^{\mathrm{n}+\mathrm{p}}$, with $\left(x^{0}, \alpha^{0}\right) \in U,\left(\underline{0}, \alpha^{0}\right) \in V$, and the property that $G$ is a one-to-one function from $U$ onto $V$. Hence, $G^{-1}: V \longrightarrow U$ is a well-defined function.

Because $\left(\underline{0}, \alpha^{0}\right) \in V$ and $V$ is open, we have $(\underline{0}, \alpha) \in V$ for all $\alpha$ sufficiently close to $\alpha^{0}$, which we write $\alpha \in U_{\alpha}$. Given that $G$ is invertible, for each $\alpha \in U_{\alpha}$ there exists a unique point $\left(x_{\alpha}, \alpha\right) \in U$ such that

$$
\left(x_{\alpha}, \alpha\right)=G^{-1}(\underline{0}, \alpha)
$$

which is equivalent to

$$
G\left(x_{\alpha}, \alpha\right)=(\underline{0}, \alpha)^{T}
$$

and therefore implies, by definition of $G$,

$$
F\left(x_{\alpha}, \alpha\right)=\underline{0}
$$

In fact, we can put

$$
U_{\alpha}=\left\{\alpha \in \mathbb{R}^{\mathrm{n}+\mathrm{p}} ;(\underline{0}, \alpha) \in V\right\}
$$

where $U_{\alpha}$ is open (in $\mathbb{R}^{\mathrm{p}}$ ) because $U$ is open (in $\mathbb{R}^{\mathrm{n}+\mathrm{p}}$ ). In summary, for each $\alpha \in U_{\alpha}$ there exists a unique solution $x_{\alpha}$ of the system such that $\left(x_{\alpha}, \alpha\right) \in U$. It follows that the solution correspondence is locally a function, defined on $U_{\alpha}$ by

$$
x(\alpha)=x_{\alpha} \quad \text { such that }\left(x_{\alpha}, \alpha\right) \in U \quad \text { and } \quad F\left(x_{\alpha}, \alpha\right)=\underline{0}
$$

It remains to show that this function is $C^{1}$. By the inverse function theorem, $G^{-1}: V \longrightarrow U$ is $C^{1}$, and because

$$
G[x(\alpha), \alpha]=(\underline{0}, \alpha)^{T} \Leftrightarrow[x(\alpha), \alpha]^{T}=G^{-1}(\underline{0}, \alpha)
$$

by definition, we have that $x(\alpha)$ is a component of a $C^{1}$ function and therefore is itself $C^{1}$ (or as smooth as $G^{-1}$ ).

## Degrees of Freedom and the Regular-Value Theorem

In stating the implicit-function theorem, we have made an a priori distinction between endogenous variables and parameters. It is clear, however, that the logic of the result does not depend in any way on whether or not we choose to make this distinction. Let $F$, then, be a $C^{1}$ function from $\mathbb{R}^{\mathrm{n}+\mathrm{p}}$ to $\mathbb{R}^{\mathrm{n}}$, and consider the system of $n$ equations in $n+p$ variables, equations $(\mathrm{M})$ : $F(x)=\underline{0}$. If the Jacobian $D F(x)$ has rank $n$ at a solution point $x^{0}$, then we can always find at least one partition of $x$ into two vectors, $x=(y, z)$, with $y \in \mathbb{R}^{\mathrm{n}}$ and $z \in \mathbb{R}^{\mathrm{p}}$, such that the square submatrix $D_{y} F(y, z)$ has a nonzero determinant. By the implicit-function theorem, it follows that in some neighborhood of $x^{0}$ it is possible to solve the system for the $n$ variables $y$ as functions of the $p$ variables $z$.

In other words, the system has $p$ degrees of freedom: We can freely assign values to $p$ of the variables, and the rest will then be determined by the condition $F(y, z)=\underline{0}$. This gives us some information about the local dimensionality of the set $F^{-1}(\underline{0})$ of solutions of the system.

If, in addition, $\underline{0}$ is a regular value of $F$, then every element $x^{*}$ of $F^{-1}(\underline{0})$ is a regular point of $F$ and therefore satisfies the assumptions of the implicitfunction theorem. ${ }^{3}$ Hence, the implicit-function theorem guarantees that the solution set always has the "right" dimension (equal to the number of unknowns minus the number of equations). The following theorem tells us that in that case, $F^{-1}(\underline{0})$ will be a geometric object with "nice" properties. To state the theorem precisely, we need some definitions.

Recall that a diffeomorphism is a smooth homeomorphism, that is, an invertible $C^{k}$ function with $k \geq 1$ and a $C^{k}$ inverse. Two sets are diffeomorphic if there exists a diffeomorphism that maps one onto the other, that is, if the sets are identical except for a smooth change of coordinates. A subset $M$ of $\mathbb{R}^{\mathrm{n}}$ is a smooth manifold of dimension $k$ if every point in $M$ has a neighborhood $U$ (in $\mathbb{R}^{\mathrm{n}}$ ) such that $U \cap M$ is diffeomorphic to an open set in $\mathbb{R}^{\mathbf{k} 4}$

That is, a smooth manifold is an object that looks locally like an open set in a Euclidean space. For example, a smooth surface in $\mathbb{R}^{3}$ is a manifold of dimension 2 , because it looks locally like a plane - in the sense that there is a smooth change of coordinates that will map any region on the surface into a neighborhood of a point on the plane (e.g., imagine that we project a neighborhood of a point in the surface onto the horizontal plane). A manifold of dimension zero is a set of isolated points. By convention, the empty set can be considered a manifold of any dimension.

The following result tells us that the inverse image of a regular value is a nice geometrical object of precisely the dimension we would expect.

Theorem 2.3. Regular-value theorem. Let $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}^{m}$, with $\mathrm{X}$ open, be a $\mathrm{C}^{1}$ function. If $\mathrm{y}$ is a regular value of $\mathrm{f}$, then $\mathrm{f}^{-1}(\mathrm{y})$ is a smooth manifold of dimension $\mathrm{n}-\mathrm{m}$ (in the ambient space $\mathbb{R}^{n}$ ).

Note that $f^{-1}(y)$ may be empty, as $\varnothing$ may be considered a manifold of any dimension. For a proof of the theorem, see Guillemin and Pollack (1974, pp. 20ff.) or Milnor (1965, p. 11). At any rate, this is an almost immediate implication of the implicit-function theorem.

Intuitively, the theorem tells us that the dimension of the solution set of the system $f(x)=y$ is equal to the number of unknowns minus the number of equations in the system, provided these are linearly independent in some neighborhood of each solution point. In fact, if $m=n$, we have as many equations as unknowns, and, as we may expect, the set of solutions is a manifold
of dimension zero (i.e., a set of isolated points). If $n>m$, we have more equations than unknowns, leaving us with $n-m$ degrees of freedom and a solution set of dimension $n-m$.

## Regular and Critical Equilibria and the Sard and Transversality-Density Theorems

An equilibrium of the model

$$
\begin{equation*}
F(x ; \alpha)=f_{\alpha}(x)=\underline{0}, \quad \text { where } F: \mathbb{R}^{\mathrm{n}+\mathrm{p}} \supseteq X \times \Omega \rightarrow \mathbb{R}^{\mathrm{m}} \quad(X \times \Omega \text { open }) \tag{M}
\end{equation*}
$$

is a point $x^{*} \in f_{\alpha}^{-1}(\underline{0})$. An equilibrium is critical if it is a critical point of $f_{\alpha}$, and regular otherwise. If $x_{\alpha}$ is a regular equilibrium for some $\alpha$, then the assumptions of the implicit-function theorem hold at $\left(x_{\alpha}, \alpha\right)$. Hence, regular equilibria are locally isolated and robust to small perturbations, and they change continuously with small parameter changes. Critical equilibria, on the other hand, may not behave so nicely: They may not be locally unique, and they have a tendency to disappear or unfold into several distinct equilibria with small parameter changes. The implicit-function theorem tells us that the graphical intuition developed earlier around the distinction between transversal and tangency equilibria remains valid for models with more than one endogenous variable and several parameters.

We have seen that a full-rank condition on the Jacobian of $F$ guarantees that the solution of a system of equations has certain nice properties. Because the equilibrium of a model is determined endogenously, however, it is not legitimate simply to assume that we start out with a regular equilibrium. This suggests the following question: Is it possible to say a priori that the "probability" that we shall find ourselves at a critical equilibrium is low in some well-defined sense?

The answer is yes. We will now review two results that, loosely speaking, say that problematic (critical or tangency) equilibria are exceptions, rather than the rule, so that, in general, differentiable models will be nicely behaved. The first result, known as Sard's theorem, says that a sufficiently smooth function can have only "a few" critical values, although it may have any number of critical points. Hence, the property "being a regular point" is typical or generic. In some sense, therefore, it may be expected that given a system of equations $f_{\alpha}(x)=\underline{0}$, the zero vector will be a regular value of $f_{\alpha}$, implying that the solution set $f_{\alpha}^{-1}(\underline{0})$ will contain only regular, and thus nicely behaved, equilibria. The second result (the transversality-density theorem) reinforces this conclusion: If, by chance, the zero vector turns out to be a critical value of $f_{\alpha}$, then, under reasonable assumptions, almost any small change in any of the parameters will turn the zero vector into a regular value of the new $f_{\alpha}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-220.jpg?height=783&width=1051&top_left_y=194&top_left_x=213)

Figure 5.5.

Both theorems make use of the concept of a set of measure zero. Let $A$ be a set in $\mathbb{R}^{\mathrm{n}}$; we say that $A$ has Lebesgue measure zero if given an arbitrarily small positive number $\varepsilon$, we can always find a countable collection of closed cubes $u_{1}, u_{2}, \ldots$ such that their union contains the set $A$, and the sum of their volumes (the product of the lengths of their sides) is smaller than $\varepsilon$.

Figure 5.5 suggests that a function may have "many" critical points, but only a few critical values. The function $f$ has an infinite number of critical points (two isolated ones at $x^{a}$ and $x^{b}$, and a continuum of them in the interval $\left[x^{c}, x^{d}\right]$ ), but has only three critical values, because all points in $\left[x^{c}, x^{d}\right]$ have the same image (that is, $f^{\prime}(x)=0$ on an interval implies that the function is constant in it).

Sard's theorem tells us that the figure gives the correct intuition: The property "being a regular value of a function" is generic.

Theorem 2.4. Sard's theorem. Let $\mathrm{f}: \mathbb{R}^{\mathrm{n}} \supseteq \mathrm{X} \longrightarrow \mathbb{R}^{\mathrm{m}}$ (X open) be a $\mathrm{C}^{\mathrm{r}}$ function with $\mathrm{r}>\max \{0, \mathrm{n}-\mathrm{m}\}$, and let $\mathrm{C}_{\mathrm{f}}$ be the set of critical points of $\mathrm{f}$. Then $\mathrm{f}\left(\mathrm{C}_{\mathrm{f}}\right)$ has Lebesgue measure zero.

If $n<m$, then $C_{f}=X$ (see note 5), and the theorem simply says that $f(X)$ has Lebesgue measure zero, implying that the equation $f(x)=y$ has no solutions for most of the vectors $y$ in $\mathbb{R}^{\mathrm{m}}$. Note that the theorem requires an assumption concerning the degree of smoothness of the function. In the

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-221.jpg?height=772&width=1074&top_left_y=195&top_left_x=210)

Figure 5.6.

case of greatest interest for us $(m=n)$, however, it is sufficient to have $f \in C^{1}$.

For parameterized functions, we have the following generalization of Sard's theorem, sometimes called the transversality-density theorem.

Theorem 2.5. Let, $\mathrm{F}: \mathbb{R}^{n+p} \supseteq \mathrm{X} \times \Omega \longrightarrow \mathbb{R}^{m}\left(\mathrm{X} \times \Omega\right.$ open) be a $\mathrm{C}^{\mathrm{r}}$ function with $\mathrm{r}>\max \{0, \mathrm{n}-\mathrm{m}\}$. If $\mathrm{y} \in \mathbb{R}^{m}$ is a regular value of $\mathrm{F}$, then the set of vectors $\alpha \in \mathbb{R}^{p}$ such that $\mathrm{y}$ is a critical value for $\mathrm{f}_{\alpha}(\mathrm{x})=\mathrm{F}(\mathrm{x} ; \alpha)$ has Lebesgue measure zero.

In other words, if $y$ is a regular value for the "whole $F$," then it is a regular value of $f_{\alpha}($ ) for almost all values of $\alpha$. Observe that because $D F(x ; \alpha)=$ $\left[D_{x} F(x ; \alpha), D_{\alpha} F(x ; \alpha)\right]$, the rank condition for a regular value is easier to satisfy for the "whole $F$ " - that is, it is easier to be a regular point of $F$ than one of $f_{\alpha}$. In fact, if we have a sufficient number of parameters, it is possible to have rank $D_{\alpha} F(x ; \alpha)=m$, which is sufficient to satisfy the assumptions of the theorem.

Figure 5.6 tries to capture the intuition of the result. For $\alpha=\alpha^{0}$, the function $f_{0^{0}}()$ has a critical value at zero. However, if $F$ is sensitive to changes in $\alpha$ (and this is the intuitive meaning of the assumption of the theorem), any small perturbation will shift the graph of $F$ in such a way that the tangency point will disappear.

In summary, because critical equilibria are problematic, we may wonder if it is possible to find some reasonable excuse for ignoring them. The answer is a qualified yes. Given some vector of parameters $\alpha$, a model may have any number of critical equilibria, any number of regular equilibria, and any combination of the two. Graphical intuition, however, suggests that critical equilibria are fragile in the sense that they tend to disappear with small perturbations to the parameters. The preceding two theorems make this intuition precise: If $\underline{0}$ is a regular value of the "whole $F$," then it is also a regular value of $f_{\alpha}$ for almost all $\alpha$, and this implies that $f_{\alpha}^{-1}(\underline{0})$ contains only regular equilibria. For most environments, therefore, many models will have no critical equilibria. $^{6}$

## Genericity

In many cases it is not possible to exclude completely the possibility of pathological phenomena, but it is sometimes possible to show that they are unlikely in a well-defined sense. Let $X$ be a set, and consider some property $P$ that elements of $X$ may or may not have. We say that $P$ is a generic property if it holds for almost all elements of this set.

There are two notions of genericity. The first, based on the concept of measure, is the one we have used here: $P$ is generic in $X$ if it holds for all $X$ except possibly for a subset of measure zero. Sometimes, however, we cannot use Lebesgue measure to make precise the idea that a given set is small. This is the case, for example, in infinite-dimensional spaces. In such situations, we can resort to another notion of genericity (not as satisfactory as the first one) that is defined in topological terms.

In this second sense of the term, a property is generic in $X$ if it holds in a subset of $X$ that is open and dense in $X$. A subset $D$ of a metric space $X$ is dense in $X$ if given any element $x$ of $X$ and an arbitrarily small number $\varepsilon$ $>0$, there exists some $y \in D$ such that $d(x, y)<\varepsilon$. That is, $D$ is dense in $X$ if given any point $x$ in $X$ there always exists some point in $D$ arbitrarily close to $x$. In other words, $D$ is dense in $X$ if any element of $X$ may be well approximated by some element of $D$.

Intuitively, a subset $D$ of $X$ that is both open and dense in $X$ constitutes most of $X$. By the density of $D$, any point in $X$ is close to some point in $D$. In principle, a dense subset could be a collection of isolated points (e.g., the set of rational numbers in the real line), but the requirement that $D$ also be open eliminates that possibility. Openness also implies robustness or persistence, because small perturbations must leave us inside $D$.

Finally, note that genericity defined in terms of measure implies topological genericity (whenever both are defined), but the converse statement is not generally true. In fact, an open and dense subset of a Euclidean space could have arbitrarily small Lebesgue measure, although not zero.

## Conclusion

The implicit-function theorem is a fundamental result for the analysis of nonlinear models. On a practical level, the theorem tells us when we can use implicit differentiation to do comparative statics and gives us a formula for computing the derivatives of the solution function given the partials of $F$ with respect to $x$ and $\alpha$. This is very helpful, because most of the models with which we work in economic theory are not specified at a sufficient level of detail to allow calculation of numerical solutions. Hence, the implicit-function theorem gives us an indispensable tool for extracting qualitative information about the solution function from qualitative assumptions incorporated into the behavioral equations of the model.

On a more basic level, the implicit-function theorem gives us sufficient conditions for the solution correspondence $S(\alpha)$ to be, at least locally, a differentiable function. This takes care of the continuity problem: Under the assumptions of the theorem, the equilibrium $x^{*}$ depends continuously on the parameters, and therefore qualitative predictions concerning the effects of small changes in $\alpha$ are possible, at least in principle. Moreover, the conclusion that the solution correspondence is locally a continuous function also provides partial answers to the existence and uniqueness questions. It is important to emphasize, however, that such an answer has two important limitations. First, it is a conditional answer, because the theorem assumes the existence of a solution for some parameter vector $\alpha^{0}$. Second, it is a local answer, as the conclusions hold only in a neighborhood of the value $\alpha^{0}$ of the parameter vector for which a solution is known to exist. What the theorem says, therefore, is that if a solution $x^{0}$ exists for $\alpha^{0}$ and the function $F$ satisfies certain regularity conditions at $\left(x^{0}, \alpha^{0}\right)$, then locally unique solutions will also exist for parameter values close to $\alpha^{0}$. But note that nothing is said about the existence of solutions per se.

## 3. Existence of Equilibrium

Nothing that we have seen thus far guarantees that the system $F(x ; \alpha)=\underline{0}$ will have a solution for a given value of $\alpha$. This section reviews some results that are sometimes useful in establishing the existence of equilibrium in nonlinear models. The first method, based on the intermediate-value theorem, can be used only in "small" models, with two endogenous variables at most. On the other hand, it has the advantage that it is based on an obvious geometric intuition: The graph of a continuous function whose value is positive at some point and negative at another must cross the horizontal axis at some intermediate point.

For models with more than two variables, graphical methods are not, in
general, very useful. In this case, fixed-point theorems are the most commonly used tools for dealing with existence problems. We will discuss a number of such results. In Chapter 8 we will see how some of them can be used to establish the existence of equilibrium in a number of important economic applications.

## (a) The Intermediate-Value Theorem

We saw in Chapter 2 that a continuous function of $\mathbb{R}$ into itself maps intervals into intervals. Hence, if $f$ takes on values $y^{\prime}$ and $y^{\prime \prime}$ in $I$, it must also take on all values in between these two numbers. The formal result, reproduced here for convenience, is the following:

Theorem 3.1. Intermediate-value theorem. Let $\mathrm{f}: \mathbb{R} \longrightarrow \mathbb{R}$ be a continuous function on the interval $\mathrm{I}$. Given two points in $\mathrm{I}, \mathrm{x}^{\prime}$ and $\mathrm{x}^{\prime \prime}$, with images $\mathrm{y}^{\prime}$ and $\mathrm{y}^{\prime \prime}$, for each number $\mathrm{y}$ between $\mathrm{y}^{\prime}$ and $\mathrm{y}^{\prime \prime}$ there exists some point $\mathrm{x}$ in $\mathrm{I}$, lying between $\mathrm{x}^{\prime}$ and $\mathrm{x}^{\prime \prime}$, such that $\mathrm{f}(\mathrm{x})=\mathrm{y}$.

It is easy to see how this result can be useful in establishing the existence of solutions. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function, and consider the equation $f(x)=0$. If we can find two points $x^{\prime}$ and $x^{\prime \prime}$ such that $f\left(x^{\prime}\right)>0$ and $f\left(x^{\prime \prime}\right)<0$, then there will exist at least one point $x^{*}$ lying between $x^{\prime}$ and $x^{\prime \prime}$ such that $f\left(x^{*}\right)=0$. Figure 5.7 illustrates this geometrically obvious fact.

In many economic models, appropriate points $x^{\prime}$ and $x^{\prime \prime}$ can be found by asking what agents would do in "extreme situations." It is difficult to be more

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-224.jpg?height=631&width=824&top_left_y=1492&top_left_x=333)

Figure 5.7. The intermediate-value theorem.
specific without a concrete example in mind, but some will turn up in the problems posed later in this chapter.

This procedure can sometimes be used to establish uniqueness. For example, if $f$ is a strictly monotonic function, it is clear that it can cross the horizontal axis at most once. In fact, it is not necessary that $f$ be globally monotonic. It is enough that the function be strictly monotonic in some neighborhood of any solution to the equation. If $f$ is differentiable, that can at times be shown by evaluating $f^{\prime}\left(x^{*}\right)$, that is, by inspecting the expression for the value of the function's derivative evaluated at an arbitrary solution point. Even if $x^{*}$ is not explicitly known, the information that at such a point $f$ has value zero may be sufficient to determine the sign of $f^{\prime}\left(x^{*}\right)$. If $f^{\prime}\left(x^{*}\right)>$ $0($ or $<0)$ at all solution points, then the solution is unique, for $f$ can cut the horizontal axis only in one direction.

For systems of two equations it is sometimes possible to use this approach repeatedly to establish existence. Suppose we are given a system of the form

$$
\begin{equation*}
F(x, y)=0 \text { and } G(x, y)=0 \tag{1}
\end{equation*}
$$

We first consider each equation separately and see if it is possible to solve them for functions of the form

$$
\begin{equation*}
y=f(x) \text { and } y=g(x) \tag{2}
\end{equation*}
$$

The slopes of these functions can be calculated by implicit differentiation, but we first have to establish existence. This can be done by the method discussed earlier. For example, if we fix $x=x^{0}$, then

$$
\begin{equation*}
F\left(x^{0}, y\right)=0 \tag{3}
\end{equation*}
$$

is an equation in a single unknown, and we can use the intermediate-value theorem to show that there is some $y$ that solves (3) for the given $x^{0}$ (see Figure 5.8). Note that we may have to restrict the domain of $f($ ), for (3) may have solutions only for certain values of $x^{0}$. To prove that $f$ is a well-defined function, we have to show that the solution of (3) is unique for each given $x^{0}$. This will be true, for example, if $F_{y}$ is always positive or always negative, or if its sign is constant at any solution of (3).

If it is true that the two equations define functions of the form (2), the original system can be reduced to a single equation:

$$
\begin{equation*}
f(x)-g(x)=0 \tag{4}
\end{equation*}
$$

Graphically, we have two curves on the plane $(x, y)$, as shown in the second panel of Figure 5.8, and we can apply the intermediate-value theorem once more. If one curve starts out above the other and ends up below, there must
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-226.jpg?height=450&width=1212&top_left_y=196&top_left_x=140)

Figure 5.8.

be some point at which the two curves cross. And if we can determine that at an arbitrary intersection the slope of one is larger than that of the other, there will be at most one solution of (4).

## (b) Fixed-Point Theorems

For problems in more than two dimensions, where the geometry of the plane is not very helpful, we have to resort to the more abstract methods of fixedpoint theory. Two of the results of this theory most commonly used in economic analysis are the theorems due to Brouwer and Kakutani. The first one gives sufficient conditions for the existence of a fixed point of a function; the second gives similar conditions for correspondences.

A function $f$ has a fixed point at $x^{*}$ if the image of $x^{*}$ is $x^{*}$ itself, that is, if $f\left(x^{*}\right)=x^{*}$. It is easy to see the connection between equilibria and fixed points. Given a system of equations

$$
\begin{equation*}
f(x)=\underline{0} \tag{5}
\end{equation*}
$$

define the function $g$ by

$$
g(x)=f(x)+x
$$

Observe that if $x^{*}$ is a fixed point of $g$, then

$$
g\left(x^{*}\right)=f\left(x^{*}\right)+x^{*}=x^{*} \Leftrightarrow f\left(x^{*}\right)=\underline{0}
$$

Hence, $x^{*}$ solves the system (5) if and only if it is a fixed point of $g$.

Our first two results deal with the existence of fixed points for functions.

Theorem 3.2. Brouwer's fixed-point theorem. Let $\mathrm{f}: \mathrm{X} \longrightarrow \mathrm{X}$ be a continuous function mapping a compact and convex set $\mathrm{X}$ into itself. Then $\mathrm{f}$ has a fixed point in $\mathrm{X}$, that is, there exists at least one $\mathrm{x}^{*} \in \mathrm{X}$ such that $\mathrm{f}\left(\mathrm{x}^{*}\right)=\mathrm{X}^{*}$.
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-227.jpg?height=1214&width=634&top_left_y=198&top_left_x=102)

a

$X=[a, \infty)$, not bounded

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-227.jpg?height=587&width=619&top_left_y=197&top_left_x=769)

$X=[a, b)$, not closed

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-227.jpg?height=633&width=608&top_left_y=863&top_left_x=785)

Figure 5.9. Failure of the assumptions of Brouwer's theorem.

Figure 5.9 illustrates the situation and shows that $f$ may not have a fixed point if some of the assumptions of the theorem fail.

The standard proof of Brouwer's theorem, based on something called "simplicial topology," is a real pain in the butt; see, for example, Border (1985, ch. 2-6). For smooth functions, there exists an alternative and much nicer proof, based, surprisingly enough, on Sard's theorem. This result can then be extended to continuous functions using a theorem of Stone and Weierstrass which says that any continuous function can be uniformly approximated by a polynomial in a compact set. See Milnor (1965, pp. 13ff) or Guillemin and Pollack (1974, pp. 65-6).

For the special case of a univariate real function, Brouwer's theorem can

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-228.jpg?height=1049&width=619&top_left_y=164&top_left_x=105)

Figure 5.10. Brouwer's theorem for univariate functions.

be easily established using the intermediate-value theorem. In this case, the theorem says that a continuous function $f$ that maps a compact interval $[a, b]$ into itself has at least one fixed point in the interval.

Consider the function $g$ defined on $[a, b]$ by $g(x)=f(x)-x$ (Figure 5.10). Because $f$ maps $[a, b]$ into itself, we must have

$$
g(a)=f(a)-a \geq 0 \text { and } g(b)=f(b)-b \leq 0
$$

If any of these expressions holds with equality, the fixed point is one of the end points of the interval. Otherwise, the intermediate-value theorem implies the existence of an interior zero of $g($ ) (i.e., a fixed point of $f$ ). In some sense, therefore, we can think of Brouwer's theorem as a generalization of the intermediate-value theorem to spaces of dimension higher than 1.

A second fixed-point theorem for functions, due to Tarsky, dispenses with the assumption of continuity, but requires that the function be nondecreasing.

Theorem 3.3. Tarsky's fixed-point theorem. Let $\mathrm{f}$ be a nondecreasing function mapping the $\mathrm{n}$-dimensional cube $[0,1]^{\mathrm{n}}=[0,1] \times \ldots \times[0,1]$ into itself. Then f has a fixed point.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-229.jpg?height=559&width=727&top_left_y=191&top_left_x=375)

Figure 5.11. Tarsky's theorem.

Figure 5.11 illustrates the intuition behind this result in the one-dimensional case. Notice that if $f(0)=0$, then 0 is a fixed point of $f$, and we are done. Otherwise, $f(0)>0$, and $f()$ starts out above the $45^{\circ}$ line. Because the function must jump up at points of discontinuity, moreover, it cannot cross the diagonal at such points. Finally, because $f(1) \leq 1$ by assumption, the graph of $f$ must at some point cross the diagonal.

We close this section with two fixed-point theorems for hemicontinuous correspondences. ${ }^{7}$ For a proof and further results, the reader should refer to Border (1985, ch. 15).

Theorem 3.4. Kakutani's fixed-point theorem. Consider a correspondence $\Psi$ from a set $\mathrm{X} \subseteq \mathbb{R}^{n}$ to itself. Let $\mathrm{X}$ be compact and convex, and assume that $\Psi$ is upper-hemicontinuous (or closed), as well as nonempty, compact, and convex-valued for all $\mathrm{x} \in \mathrm{X}$. Then $\Psi$ has a fixed point in $\mathrm{X}$, that is,

$$
\exists x^{*} \in X \text { s.th. } x^{*} \in \Psi\left(x^{*}\right)
$$

Theorem 3.5. Let $\mathrm{B} \subseteq \mathbb{R}^{n}$ be a compact and convex set, and let $\mu: \mathrm{B} \rightarrow \rightarrow \mathrm{B}$ be a lower-hemicontinuous correspondence with closed and convex values. Then $\mu$ has a fixed point in $\mathrm{B}$.

## 4. Problems

Problem 4.1. Given the IS-LM model

$$
\begin{align*}
& y=E_{0}+\alpha y-\beta r+G  \tag{A}\\
& M^{s} / P=M_{0}+\gamma y-\delta r \tag{B}
\end{align*}
$$

where $y$ is national income, $r$ is the interest rate, $G$ is public expenditure, $M^{s} / P$ is the money supply divided by a price index, and all the Greek letters are positive parameters.

(i) Analyze graphically the effects of increases in (a) government spending and (b) the price level on the equilibrium values of national income and the interest rate.

(ii) Write the model in matrix form. Use Cramer's rule to solve the model, writing the equilibrium values of $(y, r)$ as functions of the parameters $\left(G, M^{s} / P, E_{0}\right.$, and $M_{0}$ ), and show that the result is compatible with the conclusions of the graphical analysis.

Problem 4.2. The seller of a product pays a proportional tax at a flat rate $\theta$ $\in(0,1)$. Hence, the effective price received by the seller is $(1-\theta) P$, where $P$ is the market price for the good. Market supply and demand are given by the differentiable functions

$$
\begin{array}{ll}
Q^{d}=D(P), & \text { with } D^{\prime}()<0 \\
Q^{s}=S((1-\theta) P), & \text { with } S^{\prime}()>0
\end{array}
$$

and equilibrium requires market clearing, that is, $Q^{s}=Q^{d}$.

Analyze, graphically and analytically, the effects of a decrease in the tax rate on the quantity transacted and the equilibrium price. (Use the implicitfunction theorem.)

Problem 4.3. A competitive firm chooses the quantity of labor $L$ to be hired in order to maximize profits, taking as given the salary $w$ and the value of a productivity parameter $\theta$. That is, the firm solves

$$
\max _{L}(\theta f(L)-w L)
$$

Assume that the production function $f()$ is twice continuously differentiable, increasing, and strictly concave (i.e., $f^{\prime}>0, f^{\prime \prime}<0$ ).

(i) Write the first-order condition for the firm's problem, and verify that the second-order sufficient condition for a maximum holds.

(ii) Interpret the first-order condition as an equation that implicitly defines a labor demand function of the form $L^{*}=L(w, \theta)$. Show, using the implicit-function theorem, that

$$
\partial L^{*} / \partial w<0 \text { and } \partial L^{*} / \partial \theta>0
$$

Problem 4.4. Consider an individual who lives for two periods and consumes a single good ("output"). The agent is endowed with $y_{1}$ units of output in youth, and $y_{2}$ units in old age. There exists a perfectly competitive market
for output loans in which the agent may borrow or lend at an interest rate $r$ that he takes as given. Call $c_{1}$ and $c_{2}$ his consumption levels during the first and second periods of life, and let $s$ denote his first-period savings, $s=y_{1}-c_{1}$ (note that $s$ will be negative if the agent is a net borrower).

The agent's preferences are represented by a utility function of the form

$$
U\left(c_{1}\right)+\beta U\left(c_{2}\right)
$$

where $U$ is a strictly increasing and strictly concave $C^{2}$ function that satisfies the following "corner" conditions:

$$
U^{\prime}(c) \rightarrow 0 \quad \text { as } c \rightarrow \infty \quad \text { and } \quad U^{\prime}(c) \rightarrow \infty \quad \text { as } c \rightarrow 0
$$

Suppose also that

$$
y_{1}, y_{2}>0, \quad \beta \in(0,1), \quad \text { and } \quad R \equiv 1+r>0
$$

The individual solves the following problem:

$$
\max _{c_{1}, c_{2}}\left\{U\left(c_{1}\right)+\beta U\left(c_{2}\right) \text { subject to } c_{1}=y_{1}-s, c_{2}=y_{2}+s R\right\}
$$

Substituting the constraints into the objective function, we obtain a maximization problem in a single decision variable, $s$.

(i) Write the first-order condition for this problem, and check that the secondorder sufficient condition for a maximum holds.

We will interpret the first-order condition as an equation that implicitly defines a savings function of the form $s^{*}=s\left(y_{1}, y_{2}, R\right)$. We fix the values of $\left(y_{1}\right.$, $y_{2}$ ) and study the behavior of $s^{*}$ as a function of $R$.

(ii) Show that for a given value of $R$, the first-order condition has a unique solution $s^{*}$. (Use the intermediate-value theorem, and think of what will happen in extreme cases, e.g., if the agent decides not to eat during one of the periods.)

(iii) From (ii), we know that $s(R)$ is a well-defined function for $R>0$. The implicitfunction theorem guarantees that $s(R)$ is also differentiable. (Why? Which of our assumptions are we using here?) Substituting $s(R)$ back into the first-order condition, we have an identity. Hence, we can differentiate both sides of it with respect to $R$, and the equality will continue to hold. Differentiate implicitly with respect to $R$, and solve for $s^{\prime}(R)$ in the resulting expression.

What can we say about the sign of $s^{\prime}(R)$ ? That is, does $s^{*}$ increase or decrease with the interest factor $R$ ? Does it matter whether or not the agent is a net borrower? (It should. In one of the cases you should not be able to sign the derivative. Why?)

(iv) Show that there exists some value of $R$ (say $R^{0}$ ) for which the agent neither borrows nor lends, but consumes precisely his endowment each period. We say that $R^{0}$ is the agent's autarkic interest factor.

Hint: Go back to the original formulation of the agent's decision problem
and think in terms of indifference curves and budget constraints in the $\left(c_{1}, c_{2}\right)$ plane. Plot the indifference curve that goes through the endowment point $\left(y_{1}\right.$, $y_{2}$ ). What value of $R$ will make the agent "happy" eating precisely his endowment each period?

(v) Show that on one side of $R^{0}$ the agent is always a net saver in youth, and on the other always a net borrower. (What is the sign of $s^{\prime}\left(R^{0}\right)$ ? Note that this does not imply that $s()$ is always monotonic.)

Problem 4.5. Consider now an economy in which there are two different types of agents who face the decision analyzed in Problem 4.4, but may have different endowment streams, discount factors, or utility functions. To simplify, assume that there is only one agent of each type, but they both behave competitively (i.e., taking the value of $R$ as given).

Let $s_{1}(R)$ and $s_{2}(R)$ be the savings functions for the two agents. In equilibrium, the credit market must clear (i.e., if one is a net borrower, the other must be a net lender), and aggregate savings must be zero. That is, we must have

$$
\begin{equation*}
Z(R) \equiv s_{1}(R)+s_{2}(R)=0 \tag{1}
\end{equation*}
$$

Show that under the assumptions of Problem 4.4 there exists at least one competitive equilibrium, that is, a value of $R$ for which (1) holds.

Hint: Let $R_{1}^{0}$ and $R_{2}^{0}$ be the autarkic interest factors for the two agents. Without loss of generality, we can assume that $R_{1}^{0}>R_{2}^{0}$. What happens when $R=R_{1}^{0}, \mathbf{R}_{2}^{0}$ ? Use the intermediate-value theorem.

## Bibliography

Apostol, T. 1974. Mathematical Analysis, 2nd ed. Reading, MA: Addison-Wesley.

Border, K. 1985. Fixed Point Theorems with Applications to Economics and Game Theory. Cambridge University Press.

Buck, R. 1978. Advanced Calculus, 3rd ed. New York: McGraw-Hill.

Chow, S., and Pollack, A. 1982. Methods of Bifurcation Theory. Berlin: SpringerVerlag.

Guillemin, V., and Pollack, A. 1974. Differential Topology. Englewood Cliffs, NJ: Prentice-Hall.

Hadley, G. 1961. Linear Algebra. Reading, MA: Addison-Wesley.

Luenberger, D. 1973. Introduction to Linear and Non-Linear Programming. Reading, MA: Addison-Wesley.

Mas-Colell, A. 1985. The Theory of General Economic Equilibrium: A Differentiable Approach. Cambridge University Press.

Mas-Colell, A., Whinston, M., and Green, J. 1995. Microeconomic Theory. Oxford University Press.

Milnor, J. 1965. Topology from a Differentiable Viewpoint. University Press of Virginia.

Rudin, W. 1976. Principles of Mathematical Analysis, 3rd ed. New York: McGrawHill.

Samuelson, P. 1985. Foundations of Economic Analysis. Harvard University Press. Silberberg, E. 1978. The Structure of Economics, a Mathematical Analysis. New York: McGraw-Hill.

Strang, G. 1980. Linear Algebra and Its Applications. New York: Academic Press. Sydsæter, K. 1981. Topics in Mathematical Analysis for Economists. Orlando, FL: Academic Press.

## Notes

1 If the system had two solutions, say $x^{\prime}$ and $x^{\prime \prime}$, then it would have an infinite number of them, for every linear combination of the form $(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}$ would also be a solution (the reader should verify that this is true). But then we would have an affine subspace of dimension at least 1 .

2 Differentiating implicitly $F[x(\alpha), \alpha]=0$, we see that $F_{x}() x^{\prime}(\alpha)+F_{\alpha}()=0$, from where $x^{\prime}(\alpha)=-F_{\alpha}() / F_{x}()$. Hence, the curve $x(\alpha)$ will have infinite slope whenever $F_{x}()=0$.

3 See Chapter 4 for a definition of the regular value of a function.

4 To simplify, we think of a manifold as embedded in a larger ambient space, $\mathbb{R}^{n}$, but a more general definition could be given in which this need not be the case.

5 The third possible case may seem a little strange at first sight. Recall that $y$ is a regular value of $f$ if $\operatorname{rank} D f(x)=m$ for all $x$ in $f^{-1}(y)$. Because $D f(x)$ is an $m \times n$ matrix, its maximum rank is $\min \{m, n\}$. Hence, if $m>n$, every point in $f^{-1}(y)$ is a critical point, and the only regular values are those points that are not in the range of the function. For each of these points, $f^{-1}(y)$ is the empty set. Because, as we will see later, "most" of the values of $f$ are regular, the theorem implies that the normal situation in this case is for the system $f(x)=y$ not to have any solutions. Because we have more equations than unknowns, this is precisely what we should expect.

6 On the other hand, if we consider "paths" of possible environments, these paths typically will cross values of $\alpha$ for which $\underline{0}$ is a critical value of $f_{\alpha}$. If the environment changes slowly over time, we can imagine the equilibrium of the system $x(\alpha)$ changing along with it. Most of the time, the change will be smooth, with small changes in the environment yielding small displacements of the equilibrium. At some points, however, the system may undergo drastic changes. Such phenomena are known as bifurcations or catastrophes.

7 See Section 11 of Chapter 2 for the definitions of upper hemicontinuity and lower hemicontinuity.

## Convex Sets and Concave Functions

Convexity conditions play a crucial role in optimization. In the context of economic theory, moreover, convexity often appears as a sensible restriction on preferences or technology. Thus the convexity of preferences can be interpreted as capturing consumers' preference for variety, and the convexity of production sets is closely related to the existence of nonincreasing returns to scale.

This chapter contains an introduction to the theory of convex sets and concave and quasiconcave functions. Much of this material will be useful in connection with the theory of optimization developed in Chapters 7 and 12. In Chapter 8 we will discuss the roles that these concepts play in some basic economic models.

## 1. Convex Sets and Separation Theorems in $\mathbb{R}^{\mathrm{n}}$

Definition 1.1. Convex set. A set $X$ in $\mathbb{R}^{\mathrm{n}}$ (or, more generally, in a vector space over the real field) is convex if given any two points $x^{\prime}$ and $x^{\prime \prime}$ in $X$, the point

$$
x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}
$$

is also in $X$ for every $\lambda \in[0,1]$.

A vector of the form $x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}$, with $\lambda \in[0,1]$, is called a convex combination of $x^{\prime}$ and $x^{\prime \prime}$. The set of all convex combinations of $x^{\prime}$ and $x^{\prime \prime}$ is the straight line segment connecting these two points. This line segment is sometimes denoted by $L\left(x^{\prime}, x^{\prime \prime}\right)$ or $\left[x^{\prime}, x^{\prime \prime}\right]$, or by $\left(x^{\prime}, x^{\prime \prime}\right]$, for example, if we want to exclude one of the end points. The points $x^{\prime}$ and $x^{\prime \prime}$ are the end points of the segment, and points $x^{\lambda}$, with $0<\lambda<1$, are said to be interior to the segment. A set $X$ is convex if given any two points $x^{\prime}$ and $x^{\prime \prime}$ in it, $X$ contains the line segment that joins them.

A convex set with a nonempty interior is sometimes called a convex body.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-235.jpg?height=344&width=205&top_left_y=197&top_left_x=141)

A strictly convex

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-235.jpg?height=281&width=387&top_left_y=195&top_left_x=495)

B convex but not strictly so

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-235.jpg?height=322&width=437&top_left_y=186&top_left_x=898)

C not convex

Figure 6.1. Convex and nonconvex sets.

A convex body $X$ is said to be strictly convex if the line segment connecting any two points $x^{\prime}$ and $x^{\prime \prime}$ in $X$ lies in the interior of $X$, except possibly for its end points, that is, if

$$
\forall x^{\prime}, x^{\prime \prime} \in X \text { and } \forall \lambda \in(0,1), x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{\prime \prime} \in \operatorname{int} X
$$

We now list some useful results concerning convex sets.

Theorem 1.2. Any intersection of convex sets is convex.

## Problem 1.3. Prove Theorem 1.2.

Theorem 1.4. Let $\mathrm{X}$ and $\mathrm{Y}$ be convex sets in $\mathbb{R}^{n}$, and let $\alpha$ be a real number. Then the sets

$$
\alpha \mathrm{X}=\left\{\mathrm{z} \in \mathbb{R}^{\mathrm{n}} ; \mathrm{z}=\alpha \mathbf{x} \text { for some } \mathrm{x} \in \mathrm{X}\right\}
$$

and

$$
\mathrm{X}+\mathrm{Y}=\left\{\mathrm{z} \in \mathbb{R}^{n} ; \mathrm{z}=\mathrm{x}+\mathrm{y} \text { for some } \mathrm{x} \in \mathrm{X} \text { and } \mathrm{y} \in \mathrm{Y}\right\}
$$

are convex.

This result implies that any linear combination $\alpha X+\beta Y$ of convex sets is convex. It is also easy to show by induction that sums or linear combinations involving arbitrary numbers of convex sets are also convex.

Proof. We can prove both parts at the same time by showing that given any convex sets $X$ and $Y$ in $\mathbb{R}^{\mathbf{n}}$ (or, more generally, in a vector space over the real field) and two arbitrary scalars $\alpha$ and $\beta$, the set

$$
Z=\alpha X+\beta Y=\left\{z \in \mathbb{R}^{\mathbb{n}} ; z=\alpha x+\beta y \text { for some } x \in X \text { and } y \in Y\right\}
$$

is also convex.

Take two arbitrary points $z^{\prime}$ and $z^{\prime \prime}$ in $Z=\alpha X+\beta Y$. By the definition of $Z$ there exist points $x^{\prime}, x^{\prime \prime}$ in $X$ and $y^{\prime}, y^{\prime \prime}$ in $Y$ such that

$$
\begin{equation*}
z^{\prime}=\alpha x^{\prime}+\beta y^{\prime} \text { and } z^{\prime \prime}=\alpha x^{\prime \prime}+\beta y^{\prime \prime} \tag{1}
\end{equation*}
$$

Using (1), an arbitrary convex combination of $z^{\prime}$ and $z^{\prime \prime}$ can be written

$$
\begin{align*}
z^{\lambda} & =\lambda z^{\prime}+(1-\lambda) z^{\prime \prime}=\lambda\left(\alpha x^{\prime}+\beta y^{\prime}\right)+(1-\lambda)\left(\alpha x^{\prime \prime}+\beta y^{\prime \prime}\right) \\
& =\alpha\left[\lambda x^{\prime}+(1-\lambda) x^{\prime \prime}\right]+\beta\left[\lambda y^{\prime}+(1-\lambda) y^{\prime \prime}\right] \in \alpha X+\beta Y \tag{2}
\end{align*}
$$

By the convexity of $X$ and $Y, \lambda x^{\prime}+(1-\lambda) x^{\prime \prime} \in X$, and $\lambda y^{\prime}+(1-\lambda) y^{\prime \prime} \in Y$. Hence, $z^{\lambda} \in \alpha X+\beta Y$, which establishes the convexity of $Z$.

## (a) Convex Combinations and Convex Hull

The concept of convex combinations can be extended to sets of more than two vectors.

Definition 1.5. Convex combination. A point $y$ in $\mathbb{R}^{\mathrm{n}}$ is said to be a convex combination of the vectors $x_{1}, \ldots, x_{m} \in \mathbb{R}^{\mathrm{n}}$ if it can be written in the form

$$
\begin{equation*}
y=\sum_{i=1}^{m} \lambda_{i} x_{i} \tag{1}
\end{equation*}
$$

with

$$
\begin{equation*}
\lambda_{i} \in[0,1] \text { for all } i \text { and } \sum_{i=1}^{m} \lambda_{t}=1 \tag{2}
\end{equation*}
$$

Hence, a convex combination is an affine combination with the additional requirement that $\lambda_{i} \geq 0$. (Notice that this, in turn, implies $\lambda_{i} \in[0,1]$, because the sum of the $\lambda_{i}$ 's cannot exceed 1.)

We can now give an equivalent characterization of convexity in terms of (generalized) convex combinations.

Theorem 1.6. A set $\mathrm{X}$ is convex if and only if every convex combination of points of $\mathrm{X}$ lies in $\mathrm{X}$.

Problem 1.7. Prove Theorem 1.6. Hint: To establish necessity, use the modified induction principle discussed in Problem 2.8 of Chapter 1.

We are sometimes interested in extending a set $X$ so that it becomes convex by adding as few points to it as possible. The resulting set is called the convex hull of $X$.

Definition 1.8. Convex hull. Let $X$ be a set in $\mathbb{R}^{\mathrm{n}}$. The smallest convex set that contains $X$ is called the convex hull of $X$ and is denoted by conv $X$.

Clearly, there is at least one convex set that contains $X$, namely, $\mathbb{R}^{\mathrm{n}}$ itself. If there are more, conv $X$ is the intersection of all such sets. An alternative characterization is given by the following result.

Theorem 1.9. The convex hull of $\mathrm{X}$ is the set of all convex combinations of elements of $\mathrm{X}$, that is,

$$
\begin{align*}
\operatorname{conv} \mathrm{X}= & \left\{\mathrm{y}=\sum_{\mathrm{i}=1}^{\mathrm{m}} \lambda_{\mathrm{i}} \mathrm{x}_{\mathrm{i}} ; \text { for some } \mathrm{m},\right. \\
& \text { with } \left.\mathrm{x}_{\mathrm{i}} \in \mathrm{X}, \lambda_{\mathrm{i}} \in[0,1] \text { for all } \mathrm{i} \text {, and } \sum_{\mathrm{i}=1}^{\mathrm{m}} \lambda_{\mathrm{i}}=1\right\} \tag{1}
\end{align*}
$$

Proof. Let

$$
\begin{aligned}
Y=\{ & y=\sum_{i=1}^{m} \lambda_{i} x_{i} ; \text { for some } m, \text { with } x_{i} \in X, \\
& \left.\lambda_{i} \in[0,1] \text { for all } i, \text { and } \sum_{i=1}^{m} \lambda_{i}=1\right\}
\end{aligned}
$$

Clearly $Y$ contains $X$, for any $x$ in $X$ can be written as a trivial convex combination with itself.

Next, we show that $Y$ is a convex set. Let $y_{1}$ and $y_{2}$,

$$
y_{1}=\sum_{i=1}^{m} \lambda_{i} x_{i} \quad \text { and } \quad y_{2}=\sum_{k=1}^{n} \mu_{k} x_{k}
$$

with

$$
\lambda_{i}, \mu_{k} \in[0,1] \text { for all } i \text { and } k \text { and } \sum_{k=1}^{n} \mu_{k}=\sum_{i=1}^{m} \lambda_{i}=1
$$

be arbitrary points of $Y$, and take some $\alpha \in[0,1]$. Then

$$
\begin{align*}
y^{\lambda} & =(1-\alpha) y_{1}+\alpha y_{2}=(1-\alpha)\left(\sum_{i=1}^{m} \lambda_{i} x_{i}\right)+\alpha\left(\sum_{k=1}^{n} \mu_{k} x_{k}\right) \\
& =\sum_{i=1}^{m}(1-\alpha) \lambda_{i} x_{i}+\sum_{k=1}^{n} \alpha \mu_{k} x_{k} \tag{2}
\end{align*}
$$

Notice that

$$
(1-\alpha) \lambda_{i} \in[0,1] \text { for each } i, \quad \alpha \mu_{k} \in[0,1] \text { for each } k
$$

and

$$
\sum_{i=1}^{m}(1-\alpha) \lambda_{i}+\sum_{k=1}^{n} \alpha \mu_{k}=(1-\alpha) \sum_{i=1}^{m} \lambda_{i}+\alpha \sum_{k=1}^{n} \mu_{k}=(1-\alpha)+\alpha=1
$$

Thus, (2) shows that $y^{\lambda}$ is a convex combination of points in $X$, and it follows that $y^{\lambda} \in Y$, which is therefore a convex set.

Hence $Y$ is a convex set that contains $X$. Moreover, any convex set that contains $X$ must include all convex combinations of points in $X$ (by Theorem 1.6) and must therefore contain $Y$. It follows that $Y$ is the smallest convex set containing $X$ (i.e., $Y=\operatorname{conv} X$ ).

Theorem 1.9 tells us that any point in the convex hull of $X$ can be written as a convex combination of a finite number of points of $X$, but it does not
tell us how many such points are required. The following result says that if $X$ is a set in an $n$-dimensional vector space, this convex combination can be constructed with, at most, $n+1$ points of $X$.

Theorem 1.10. Caratheodory. Let $\mathrm{X}$ be a set in $\mathbb{R}^{n}$. If $\mathrm{y}$ is a convex combination of points of $\mathrm{X}$, then $\mathrm{y}$ is a convex combination of $\mathrm{n}+1$ or fewer points of $\mathrm{X}$.

Proof. Let

$$
\begin{equation*}
y=\sum_{i=1}^{m} \lambda_{i} x_{i} \tag{1}
\end{equation*}
$$

with $x_{i} \in X, \lambda_{i} \in[0,1]$ for all $i$, and $\sum_{i=1}^{m} \lambda_{i}=1$. We will show that if $m>n+1$, then $y$ can be written as a convex combination of $m-1$ points of $X$. By applying this result repeatedly, the theorem follows.

If any $\lambda_{i}$ in (1) is zero, then $y$ is a convex combination of $m-1$ or fewer points of $X$, and we are done. Otherwise, $\lambda_{i}>0$ for all $i$.

Assume $m>n+1$. Then $m-1>n$ (the dimension of the vector space in which we are working), and it follows that any collection of $m-1$ vectors is linearly dependent. In particular, the $m-1$ vectors $\left\{x_{2}-x_{1}, x_{3}-x_{1}, \ldots\right.$, $\left.x_{m}-x_{1}\right\}$ are linearly dependent (see Chapter 3). Thus, there exist scalars $\alpha_{2}$, $\ldots, \alpha_{m}$, not all zero, such that

$$
\begin{equation*}
\sum_{i=2}^{m} \alpha_{i}\left(x_{i}-x_{1}\right)=\underline{0} \tag{2}
\end{equation*}
$$

Letting

$$
\alpha_{1}=-\sum_{i=2}^{m} \alpha_{i}
$$

we have

$$
\begin{equation*}
\sum_{i=1}^{m} \alpha_{i}=0 \tag{3}
\end{equation*}
$$

and

$$
\begin{equation*}
\sum_{i=1}^{m} \alpha_{i} x_{i}=-\left(\sum_{i=2}^{m} \alpha_{i}\right) x_{1}+\sum_{i=2}^{m} \alpha_{i} x_{i}=\sum_{i=2}^{m} \alpha_{i}\left(x_{i}-x_{1}\right)=\underline{0} \tag{4}
\end{equation*}
$$

By subtracting an appropriate multiple of (4) from (1), we can obtain $y$ as a convex combination of $m-1$ or fewer points of $X$.

Define $\gamma$ and $\beta_{i}$ by ${ }^{1}$

$$
\begin{equation*}
\frac{1}{\gamma}=\max _{i} \frac{\alpha_{i}}{\lambda_{i}}=\frac{\alpha_{r}}{\lambda_{r}} \quad \text { for some } r \tag{5}
\end{equation*}
$$

and

$$
\begin{equation*}
\beta_{i}=\lambda_{i}-\gamma \alpha_{i} \tag{6}
\end{equation*}
$$

and observe that $\gamma=\lambda_{r} / \alpha_{r} \leq \lambda_{i} / \alpha_{i}$ for all $i$. It then follows that

$$
\begin{equation*}
\beta_{i}=\lambda_{i}-\gamma \alpha_{i}=\lambda_{i}-\frac{\lambda_{r}}{\alpha_{r}} \alpha_{i} \geq 0 \text { and } \beta_{r}=0 \tag{7}
\end{equation*}
$$

Using (7) and (6) we have

$$
\sum_{i \neq r}^{m} \beta_{i}=\sum_{i=1}^{m} \beta_{i}=\sum_{i=1}^{m} \lambda_{i}-\gamma \sum_{i=1}^{m} \alpha_{i}=\sum_{i=1}^{m} \lambda_{i}-0=1
$$

by (3), and

$$
y=\sum_{i=1}^{m} \lambda_{i} x_{i}=\sum_{i=1}^{m} \beta_{i} x_{i}+\gamma \sum_{i=1}^{m} \alpha_{i} x_{i}=\sum_{i \neq r}^{m} \beta_{i} x_{i}+0
$$

by (4). Hence, $y$ is a convex combination of $m-1$ points of $X$. This establishes the result.

## (b) Topological Properties of Convex Sets

Convexity implies some interesting topological properties. A convex set, for example, is clearly arcwise-connected and therefore connected. In this section we collect some less obvious results.

Theorem 1.11. Let $\mathrm{X}$ be a convex set in $\mathbb{R}^{n}$ (or, more generally, in a normed vector space). Then both its closure and its interior are convex sets.

Proof. We prove only the second part of the theorem, leaving the first as an exercise. Given two interior points of $X, x$ and $y$, let $z=(1-\lambda) x+\lambda y$ for some $\lambda \in(0,1)$. We will show that $z$ is an interior point of $X$.

Given some $\delta>0$, let $z^{\prime}$ be an arbitrary point in $B_{\delta}(z)$. Then $z^{\prime}=z+h$, where $\|h\|<\delta$, and we can write

$$
z^{\prime}=z+h=(1-\lambda) x+\lambda y+(1-\lambda) h+\lambda h=(1-\lambda)(x+h)+\lambda(y+h)
$$

where $x+h \in B_{\delta}(x)$ and $y+h \in B_{\delta}(y)$. Hence, for any $\delta$ we have

$$
\begin{equation*}
B_{\delta}(z) \subseteq(1-\lambda) B_{\delta}(x)+\lambda B_{\delta}(y) \tag{1}
\end{equation*}
$$

Now, because $x$ and $y$ are interior points of $X$, there exists some $\varepsilon>0$ such that $B_{\varepsilon}(x)$ and $B_{\varepsilon}(y)$ are both contained in $X$. Then, by (1) and the convexity of $X$, we have

$$
B_{\varepsilon}(z) \subseteq(1-\lambda) B_{\varepsilon}(x)+\lambda B_{\varepsilon}(y) \subseteq X
$$

because any point in $B_{\varepsilon}(z)$ is a linear combination of two points in $X$, one in $B_{\varepsilon}(x)$ and the other in $B_{\varepsilon}(y)$. This shows that $z$ is an interior point of $X$.

Problem 1.12. Show that the closure of a convex set is convex.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-240.jpg?height=433&width=1101&top_left_y=191&top_left_x=179)

Figure 6.2.

Theorem 1.13. Let $\mathrm{X}$ be a convex set with a nonempty interior, with $\mathrm{x}^{\prime}$ an interior point of $\mathrm{X}$ and $\mathrm{x}^{\prime \prime}$ any closure point of $\mathrm{X}$. Then every point of the segment $\left[\mathrm{x}^{\prime}, \mathrm{x}^{\prime \prime}\right]$, except possibly for $\mathrm{x}^{\prime \prime}$, is an interior point of $\mathrm{X}$.

Proof. Because $x^{\prime}$ is an interior point of $X$, there exists some $\varepsilon>0$ such that $B_{\varepsilon}\left(x^{\prime}\right) \subseteq X$. Consider an arbitrary point $x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}$, with $\lambda \in[0,1)$. To show that $x^{\lambda}$ is an interior point of $X$, we shall verify that the open ball with center at $x^{\prime}$ and radius $(1-\lambda) \varepsilon$ is contained in $X$. In particular, let $y$ be an arbitrary point in $B_{(1-\lambda) \varepsilon}\left(x^{\lambda}\right)$; we will prove that $y$ belongs to $X$ by showing that it can be written as a convex combination of two points in $X$, one close to $x^{\prime}$, and the other close to $x^{\prime \prime}$.

Because $y \in B_{(1-\lambda) \varepsilon}\left(x^{\lambda}\right)$,

$$
\begin{equation*}
\left\|y-x^{\lambda}\right\|<(1-\lambda) \varepsilon \tag{1}
\end{equation*}
$$

and because $x^{\prime \prime}$ is a closure point of $X$ (i.e., any open ball around $x^{\prime \prime}$ contains at least one point of $X$ ), there is a point $z \in X$ sufficiently close to $x^{\prime \prime}$ that the segment $\left[z, x^{\prime}\right]$ passes close to $y$. In particular, we can choose $z \in X$ such that

$$
\begin{equation*}
\left\|z-x^{\prime \prime}\right\|<\frac{1}{\lambda}\left((1-\lambda) \varepsilon-\left\|y-x^{\lambda}\right\|\right) \tag{2}
\end{equation*}
$$

Hence, by the triangle inequality and (2),

$$
\begin{align*}
\left\|y-\left[(1-\lambda) x^{\prime}+\lambda z\right]\right\|= & \left\|y-\left[(1-\lambda) x^{\prime}+\lambda z+\lambda x^{\prime \prime}-\lambda x^{\prime \prime}\right]\right\| \\
= & \left\|\left(y-x^{\lambda}\right)+\lambda\left(x^{\prime \prime}-z\right)\right\| \leq\left\|y-x^{\lambda}\right\|+\lambda\left\|x^{\prime \prime}-z\right\| \\
& <\left\|y-x^{\lambda}\right\|+\left((1-\lambda) \varepsilon-\left\|y-x^{\lambda}\right\|\right)=(1-\lambda) \varepsilon \tag{3}
\end{align*}
$$

Next, consider the line segment through $z$ and $y$, and let us extend it toward $x^{\prime}$. If we want $y$ to be of the form $y=(1-\lambda) a+\lambda z$, then $a$ must be the point

$$
a=\frac{1}{1-\lambda}(y-\lambda z)
$$

Dividing both sides of (3) by $(1-\lambda)$, we obtain

$$
\begin{equation*}
\left\|\frac{1}{1-\lambda}(y-\lambda z)-x^{\prime}\right\|=\left\|a-x^{\prime \prime}\right\|<\varepsilon \tag{4}
\end{equation*}
$$

This expression shows that the "new" end point of the segment through $z$ and $y$ lies inside $B_{\varepsilon}\left(x^{\prime}\right)$ and is therefore a point of $X$, as is $z$. Hence, $y=(1-\lambda) a+\lambda z$ is a convex combination of points in $X$, and by the convexity of this set, we conclude that $y \in Z$, which proves the theorem, for $y$ is an arbitrary point in $B_{(1-\lambda) \epsilon}\left(x^{\lambda}\right)$.

Problem 1.14. Using Theorem 1.13, show that given a convex set $X$ and an interior point $x$ of $X$, any ray emanating from $x$ contains at most one boundary point of $X$.

Theorem 1.15. Let $\mathrm{X}$ be a convex set with a nonempty interior. Then $\mathrm{cl} \mathrm{X}=$ cl(int X).

Proof. Because int $X \subseteq X$, it follows immediately that $\operatorname{cl}($ int $X) \subseteq \operatorname{cl} X$. Conversely, let $x$ be an interior point of $X$. Then for any closure point $c$ of $X$, with $c \neq x$, the line segment $[x, c)$ is contained in int $X$, by Theorem 1.13. Hence, there are points in int $X$ arbitrarily close to $c$, and it follows that $c \in \operatorname{cl}($ int $X$ ). Because $c$ was an arbitrary closure point of $X$, moreover, we have $\operatorname{cl} X \subseteq \operatorname{cl}($ int $X)$.

Theorem 1.16. Let $\mathrm{X}$ be a convex set with a nonempty interior. Then $b d y(c l \mathrm{X})=b d y \mathrm{X}$.

## Proof

(i) bdy $X \subseteq$ bdy(cl $X$ ). Let $a$ be a boundary point (and therefore a closure point) of $X$, and suppose that $a$ is not a boundary point of $\mathrm{cl} X$. Then, because $a \in$ cl $X, a$ must be an interior point of $\operatorname{cl} X$, and it follows that there exists some $\varepsilon>0$ such that $B_{\varepsilon}(a) \subseteq \mathrm{cl} X$. Because int $X$ is nonempty by assumption, Theorem 1.15 implies that $\operatorname{cl} X=\operatorname{cl}($ int $X)$, and we have

$$
B_{\varepsilon}(a) \subseteq \operatorname{cl}(\text { int } X)
$$

It follows that $B_{\varepsilon}(a)$ contains at least one interior point of $X$, say $b$.

Let $c=2 a-b$. Then $c-a=a-b$ and $\|c-a\|=\|a-b\|<\varepsilon$, implying that $c \in$ $B_{\varepsilon}(a) \subseteq \operatorname{cl} X$. Moreover, notice that

$$
a=\frac{1}{2} b+\frac{1}{2} c
$$

so $a$ lies on the line segment $[b, c)$, where $b$ is an interior point of $X$ and $c$ is a closure point of the same set. Because $X$ is convex, it follows, by Theorem 1.13, that $a$ must be an interior point of $X$, which contradicts the assumption that $a$ is a boundary point of this set.

(ii) $\operatorname{bdy}(\operatorname{cl} X) \subseteq$ bdy $X$. Let $a$ be a boundary point of $\operatorname{cl} X$. Then for each $\varepsilon>0, B_{\varepsilon}(a)$ contains a point not in the closure of $X$ and therefore not in $X$. Similarly, $B_{\varepsilon}(a)$ contains at least a closure point of $X$, say $b$, and because $b$ must have points of $X$ arbitrarily close, $B_{\varepsilon}(a)$ also contains a point of $X$. Formally, let

$$
\delta=\frac{\varepsilon-\|a-b\|}{2}>0
$$

Then $B_{\delta}(b) \subseteq B_{\varepsilon}(a)$, and because $b$ is a closure point of $X, B_{\delta}(b)$ must contain a point of $X$ that also lies in $B_{\varepsilon}(a)$. Hence, we conclude that $a$ is a boundary point of $X$. (Notice that we did not need convexity or a nonempty interior to establish this part of the theorem.)

Problem 1.17. Let $X$ be a convex set with a nonempty interior. Show that $\operatorname{int}(\mathrm{cl} X)=\operatorname{int} X$.

## (c) Relative Interior and Boundary of a Convex Set

A circle in $\mathbb{R}^{3}$ is an example of a convex set with an empty interior. If we restrict ourselves to the plane that contains it, however, the same circle now has a nonempty interior. More generally, we may want to consider the relative interior of a convex set $X$ in $\mathbb{R}^{n}$, defined as its interior relative to the smallest affine subspace of $\mathbb{R}^{\mathrm{n}}$ that contains $X$. We begin by showing that such a subspace always exists. But first we need to introduce the concept of "hyperplane."

Definition 1.18. Hyperplane. A hyperplane in $\mathbb{R}^{\mathrm{n}}$ is the ( $\left.n-1\right)$-dimensional affine subspace ${ }^{3}$ of $\mathbb{R}^{\mathbf{n}}$ formed by all the $n$-vectors that satisfy a linear equation in $n$ unknowns. A vector $p \neq 0$ in $\mathbb{R}^{\mathrm{n}}$ and a scalar $\alpha$ define the hyperplane $H(p, \alpha)$ given by

$$
H(p, \alpha)=\left\{x=\left(x^{1}, \ldots, x^{n}\right) \in \mathbb{R}^{\mathbf{n}} ; p x=\sum_{i=1}^{n} p_{i} x^{i}=\alpha\right\}
$$

Given any two vectors $x^{\prime}$ and $x^{\prime \prime}$ in $H(p, \alpha), p x^{\prime}=\alpha=p x^{\prime \prime}$. It follows that for any scalar $\lambda$ (not necessarily between 0 and 1 ), we have

$$
\begin{equation*}
p x^{\lambda}=p\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right]=(1-\lambda) p x^{\prime}+\lambda p x^{\prime \prime}=(1-\lambda) \alpha+\lambda \alpha=\alpha \tag{1}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-243.jpg?height=646&width=887&top_left_y=181&top_left_x=286)

Figure 6.3. A hyperplane and its normal.

If we restrict ourselves to values of $\lambda$ between 0 and 1 , this expression shows that $H(p, \alpha)$ is a convex set. More generally, (1) establishes that $H(p, \alpha)$ is an affine subspace of $\mathbb{R}^{\mathrm{n}}$, that is, a set of the form $H(p, \alpha)=x^{0}+L$, where $x^{0}$ is an arbitrary vector in $\mathbb{R}^{\mathbf{n}}$, and $L$ is a linear subspace of $\mathbb{R}^{\mathrm{n}}$. We define the dimension of a hyperplane $H(p, \alpha)$, or, more generally, of an affine subspace $H$, to be the dimension of the vector subspace $L$ "parallel" to $H$.

Notice that any two vectors $x^{\prime}$ and $x^{\prime \prime}$ in $H(p, \alpha)$ satisfy $p\left(x^{\prime}-x^{\prime \prime}\right)=0$. Hence, $p$ is orthogonal to any line segment in $H(p, \alpha)$. The vector $p$ is sometimes called the normal to the hyperplane $H(p, \alpha)$.

We can now show that a convex set in $\mathbb{R}^{\mathbf{n}}$ is contained in a hyperplane if and only if it has an empty interior.

Theorem 1.19. Let $\mathrm{X}$ be a convex set in $\mathbb{R}^{n}$. Then there exists a hyperplane $\mathrm{H}$ that contains $\mathrm{X}$ if and only if int $\mathrm{X}=\emptyset$.

## Proof

(i) A convex set with an empty interior is contained in a hyperplane. We will prove the contrapositive statement: If no such hyperplane exists, then $X$ has a nonempty interior.

Assume that $X$ does not lie on a hyperplane. Then we can find $n+1$ points of $X$, say $x_{0}, x_{1}, \ldots, x_{n}$, that are contained in no hyperplane. We will now show that the vectors

$$
y_{i}=x_{i}-x_{0} \quad \text { for } i=1, \ldots, n
$$

are linearly independent. (Again, we prove the contrapositive.) Suppose $y_{1}, \ldots, y_{n}$ are linearly dependent. Then there exist scalars $p_{1}, \ldots, p_{n}$, not all zero, such that

$$
\sum_{i=1}^{n} p_{i} y_{i}=\underline{0}
$$

that is, there exists a vector $p=\left(p_{1}, \ldots, p_{n}\right) \neq \underline{0}$ such that

$$
p y_{i}=p\left(x_{i}-x_{0}\right)=\underline{0}
$$

Hence, all vectors $x_{0}, x_{1}, \ldots, x_{n}$ solve the equation $p x=\beta$ (with $\beta=p x_{0}$ ) and therefore lie on a hyperplane. Because that is not the case by assumption, it follows that $y_{1}, \ldots, y_{n}$ are linearly independent and therefore span $\mathbb{R}^{n}$.

Now, because $X$ is a convex set, every point $z$ of the form

$$
\begin{equation*}
z=\sum_{i=0}^{n} \lambda_{i} x_{i}, \text { with } \lambda_{i} \in[0,1] \text { for each } i=0, \ldots, n \text { and } \sum_{i=0}^{n} \lambda_{i}=1 \tag{1}
\end{equation*}
$$

lies in $X$. Notice that we can rewrite (1) as follows:

$$
z=\lambda_{0} x_{0}+\sum_{i=1}^{n} \lambda_{i} x_{i}=\left(\lambda_{0}+\sum_{i=1}^{n} \lambda_{i}\right) x_{0}+\sum_{i=1}^{n} \lambda_{i}\left(x_{i}-x_{0}\right)=x_{0}+\sum_{i=1}^{n} \lambda_{i} y_{i}
$$

Hence, every point $z$ of the form

$$
\begin{equation*}
z=x_{0}+\sum_{i=1}^{n} \lambda_{i} y_{l}, \quad \text { with } \lambda_{t} \in[0,1] \text { for each } i=1, \ldots, n \text { and } \sum_{i=1}^{n} \lambda_{i} \leq 1 \tag{2}
\end{equation*}
$$

lies in $X$. Fix one such point,

$$
\hat{z}=x_{0}+\sum_{i=1}^{n} \hat{\lambda}_{i} y_{i} \in X, \text { with } \hat{\lambda}_{i} \in[0,1] \text { for each } i=1, \ldots, n \text { and } \sum_{i=1}^{n} \hat{\lambda}_{t}<1
$$

Next, consider points $\tilde{z}$ near $\hat{z}$. Because $y_{1}, \ldots, y_{n}$ is a basis for $\mathbb{R}^{\mathrm{n}}$, every such point has a representation of the form

$$
\tilde{z}-x_{0}=\sum_{i=1}^{n} \beta_{i} y_{i}
$$

with each $\beta_{i}$ close to $\hat{\lambda}_{i}$. Hence, for all such points sufficiently close to $\hat{z}$, we have $\beta_{i} \in[0,1)$ for each $i$, and $\Sigma_{i=1}^{n} \beta_{i}<1$, and it follows that $\tilde{z} \in X$. This shows that $X$ contains a ball with center at $\hat{z}$ and sufficiently small radius. Hence, $\hat{z}$ is an interior point of $X$, and int $X \neq \varnothing$, as was to be shown.

(ii) We will show that a set $X$ in $\mathbb{R}^{\mathrm{n}}$ with a nonempty interior is not contained in any hyperplane of $\mathbb{R}^{\mathrm{n}}$. Let $x$ be an interior point of $X$. Then there exists some number $2 \varepsilon>0$ such that $B_{2 \varepsilon}(x) \subseteq X$. In particular, the $n$ points of the form $x+$ $\varepsilon e_{i}$, where $e_{i}=(0, \ldots, 1,0, \ldots, 0)$ is the $i$ th unit vector, lie in $X$. Now consider a hyperplane $H(p, \alpha)$ going through $x$ (i.e., such that $p x=\alpha$ ). If this hyperplane contains all the points $x+\varepsilon e_{i}$, we have

$$
p\left(x+\varepsilon e_{i}\right)=p x+\varepsilon p e_{t}=\alpha+\varepsilon p_{i}=\alpha
$$

and therefore $p_{i}=0$ for all $i$, and $p=\underline{0}$. It follows that there is no hyperplane in $\mathbb{R}^{\mathrm{n}}$ that contains $B_{2 \varepsilon}(x)$, and hence no hyperplane containing $X$.

Because $\mathbb{R}^{\mathrm{n}}$ is itself an affine space (of dimension $n$ ), the theorem shows that every convex set $X$ in $\mathbb{R}^{\mathrm{n}}$ can be contained in an affine space. If $X$ has an empty interior, this space is a hyperplane of dimension at most $n-1$, but
it may be of a smaller dimension. Because the intersection of affine subspaces of $\mathbb{R}^{\mathbb{m}}$ is itself an affine subspace, we can define the affine hull of a set $X$ in $\mathbb{R}^{\mathrm{n}}$ as the intersection of all the affine subspaces of $\mathbb{R}^{\mathrm{n}}$ that contain $X$. The dimension of the set $X$ is then defined as the dimension of its affine hull.

It is clear that the affine hull of $X$, aff $X$, is the smallest affine subspace of $\mathbb{R}^{\mathrm{m}}$ that contains $X$. It can be shown that aff $X$ is the set of all affine combinations of elements of $X$. For the case where $X$ is a circle in $\mathbb{R}^{3}$, for example, aff $X$ is formed by taking all lines going through two points in $X$ and extending them outside the set, so as to recover the plane on which the circle lies.

We can now define the relative interior of a convex set $X$, rint $X$, as its interior relative to its affine hull.

Definition 1.20. Relative interior point and relative interior of a set. Let $X$ be a set in $\mathbb{R}^{\mathrm{n}}$. A point $x$ is a relative interior point of $X$ if there exists some $\varepsilon>0$ such that $B_{\varepsilon}(x) \cap$ aff $X \subseteq X$. The set of all relative interior points of $X$ is called the relative interior of $X$, denoted by rint $X$.

It can be shown that the relative interior of a nonempty convex set is never empty. ${ }^{4}$ Hence, the relative interior of a convex set is generally larger than its interior. If int $X \neq \varnothing$, however, we have aff $X=\mathbb{R}^{\mathrm{n}}$, and it follows that rint $X=$ int $X$. Hence, we have rint $X=$ int $X$ if and only if $X \neq \varnothing$.

It must be noted that the relative interior of a set does not inherit the usual properties of the interior of a set. For example, $A \subseteq B$ implies int $A \subseteq$ int $B$, but the analogous expression need not hold for their relative interiors. As an illustration, consider a triangle in $\mathbb{R}^{3}$ and one of its sides. Then the affine hull of the triangle is a plane that contains it, and that of its side is a straight line. The relative interiors of these two sets (the interior of the triangle relative to the plane, and an open interval in the line) are disjoint.

Because aff $X$ is a closed set (its complement is open), the closure of $X$ is contained in aff $X$, and it follows that the "relative closure" of $X$ is simply the closure of $X$. The set rbdy $X=\operatorname{cl} X \sim \operatorname{rint} X$ is called the relative boundary of $X$. Because the closure of $X$ is also its relative closure, rbdy $X$ is actually the boundary of $X$ relative to aff $X$.

If we confine ourselves to the affine hull of a convex set, the proofs of many of the results in the preceding section can be easily adapted to the case of the relative interior. We have, in particular, the following theorem. See Bronsted (1983) or Bazaraa and Shetty (1976) for details.

## Theorem 1.21. Let $\mathrm{X}$ be a convex set in $\mathbb{R}^{n}$. Then

(i) for any $\mathrm{x}_{\mathrm{i}} \in$ rint $\mathrm{X}$ and any $\mathrm{x}_{c} \in c l \mathrm{X}$ (with $\mathrm{x}_{\mathrm{j}} \neq \mathrm{x}_{c}$ ), the half-open line segment [ $\mathbf{x}_{\mathrm{i}}, \mathbf{x}_{\mathrm{c}}$ ) lies in rint $\mathrm{X}$,
(ii) rint $\mathrm{X}$ is convex,

(iii) $\operatorname{cl} \mathrm{X}=c l(\operatorname{rint} \mathrm{X})$,

(iv) $\operatorname{rint} \mathrm{X}=\operatorname{rint}(\mathrm{cl} \mathrm{X}$ ),

(v) $r b d y \mathrm{X}=r b d y(c l \mathrm{X})=r b d y(\operatorname{rint} \mathrm{X})$

Problem 1.22. Show that a point $x_{i}$ in a convex set $X$ is a relative interior point of $X$ if and only if either of the two following (equivalent) conditions holds:

(i) For any line $L$ in aff $X$, with $x_{i} \in L$, there exist points $x^{\prime}$ and $x^{\prime \prime}$ in $L \cap$ aff $X$ such that $x_{i} \in\left(x^{\prime}, x^{\prime \prime}\right)$.

(ii) For any point $x^{\prime} \in X$, with $x^{\prime} \neq x_{t}$, there is a point $x^{\prime \prime} \in X$ such that $x_{1} \in\left(x^{\prime}, x^{\prime \prime}\right)$. That is, the segment $\left[x^{\prime}, y\right]$ in $X$ can be extended beyond $x_{1}$ without leaving the set.

Problem 1.23. Let $X$ be a convex set in $\mathbb{R}^{\mathrm{n}}$, with $\operatorname{int}(\operatorname{cl} X) \neq \emptyset$. Show that int $X$ is nonempty. Hint: Consider the affine hull of $X$, and prove the contrapositive.

## (d) Separation Theorems

A hyperplane $H(p, \alpha)$ divides $\mathbb{R}^{\mathrm{n}}$ into two regions, with all points $z$ "on one side" of $H(p, \alpha)$ satisfying $p z \geq \alpha$, and all those on the other satisfying the reverse inequality. We say that two sets $X$ and $Y$ are separated by a hyperplane $H(p, \alpha)$ if they lie on different sides of $H(p, \alpha)$. More formally, we say that a hyperplane $H(p, \alpha)$ separates two sets $X$ and $Y$ in $\mathbb{R}^{\mathbf{n}}$ if for all $x$ in $X$ and all $y$ in $Y$ we have $p x \leq \alpha \leq p y$. If this expression holds with strict inequalities, we say that $X$ and $Y$ are strictly separated by $H(p, \alpha)$.

A hyperplane $H(p, \alpha)$ is a supporting hyperplane for a set $X$ if it contains a point on the boundary of $X$ and the whole set lies on the same side of $H(p$, $\alpha$ ). Equivalently, $H(p, \alpha)$ supports $X$ if either

$$
\alpha=\inf \{p x ; x \in X\} \quad \text { or } \alpha=\sup \{p x ; x \in X\}
$$

Intuition suggests that a convex set in $\mathbb{R}^{\mathrm{n}}$ will have a supporting hyperplane through each point on its boundary. It also suggests that given two disjoint convex sets in $\mathbb{R}^{\mathrm{rl}}$, we should be able to find a hyperplane that separates them. The following theorems establish that both statements are true.

Theorem 1.24. Let $\mathrm{X}$ be a nonempty closed and convex subset of $\mathbb{R}^{n}$, and $\mathrm{z} \notin \mathrm{X}$ a point outside $\mathrm{X}$.

(i) There exists a point $\mathrm{x}^{0}$ in $\mathrm{X}$ and a hyperplane $\mathrm{H}(\mathrm{p}, \alpha)$ through $\mathrm{x}^{0}$ that supports $\mathrm{X}$ and separates it from $\{\mathrm{z}\}$. That is, $\mathrm{H}(\mathrm{p}, \alpha)$ is such that ${ }^{5}$
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-247.jpg?height=546&width=944&top_left_y=190&top_left_x=266)

Figure 6.4. Supporting and separating hyperplanes.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-247.jpg?height=437&width=416&top_left_y=898&top_left_x=197)

$\mathrm{H}$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-247.jpg?height=434&width=468&top_left_y=895&top_left_x=808)

Figure 6.5.

$$
\mathrm{pz}<\alpha=\mathrm{px}^{0}=\inf \{\mathrm{px} ; \mathrm{x} \in \mathrm{X}\}
$$

(ii) There exists a second hyperplane $\mathrm{H}(\mathrm{p}, \beta)$ that separates $\mathrm{X}$ and $\mathrm{z}$ strictly. That is,

$$
\mathrm{pz}<\beta<\mathrm{px} \forall \mathrm{x} \in \mathrm{X}
$$

Proof. We begin by showing that there is a point $x^{0}$ in $X$ that minimizes the distance between $z$ and $X$. Pick any point $x^{\prime}$ in $X$, and define the set

$$
B=\left\{x \in X ; d(z, x) \leq d\left(z, x^{\prime}\right)\right\}
$$

where $d()$ is the Euclidean metric. Because $B=B_{d\left(z, x^{\prime}\right)}[z] \cap X$ is a closed and bounded set in $\mathbb{R}^{\mathrm{n}}$ and $d(\cdot, z)$ is a continuous function, the extreme-value theorem guarantees the existence of a solution for the problem

$$
\min \{d(x, z) ; x \in B\}
$$

Call $x^{0}$ the point in $B$ (and hence in $X$ ) that solves this problem.
(i) To prove the first part of the theorem, let

$$
p=x^{0}-z \text { and } \alpha=p x^{0}
$$

Then $H(p, \alpha)$ is the hyperplane through $x^{0}$ that is orthogonal to the line segment connecting $x^{0}$ and $z$. We claim that this is the desired hyperplane, that is, that

$$
p z<\alpha=p x^{0}=\inf \{p x ; x \in X\}
$$

First, we have

$$
p z=p x^{0}+p z-p x^{0}=p x^{0}+p\left(z-x^{0}\right)=p x^{0}-p p=\alpha-\|p\|^{2}<\alpha
$$

so $z$ lies below $H(p, \alpha)$.

To show that $X$ lies above the hyperplane, we proceed by contradiction. Suppose there is a point $y$ in $X$ such that $p y<\alpha$, and let

$$
x^{\lambda}=(1-\lambda) x^{0}+\lambda y \quad \text { for } \lambda \in(0,1)
$$

Then $x^{\lambda} \in X$, by the convexity of $X$, and a straightforward computation yields ${ }^{6}$

$$
\begin{equation*}
\left\|z-x^{0}\right\|^{2}-\left\|z-x^{\lambda}\right\|^{2}=-\lambda\left(2 p\left(y-x^{0}\right)+\lambda\left\|y-x^{0}\right\|^{2}\right) \tag{1}
\end{equation*}
$$

Now, by construction $\alpha=p x^{0}$, and by assumption $p y<\alpha$, implying that $p\left(y-x^{0}\right)<0$. This last inequality and (1) imply that

$$
\left\|z-x^{0}\right\|^{2}>\left\|z-x^{\lambda}\right\|^{2}
$$

for small $\lambda>0$. Hence, some $x^{\lambda} \in X$ is strictly closer to $z$ than $x^{0}-$ which is impossible, because $x^{0}$ is defined as the element of $X$ that minimizes the distance $d(x, z)=\|z-x\|$. Hence, we have a contradiction.

(ii) The proof of the second part is almost identical (with the same $p$ ), except that we now choose $\beta$ so that $H(p, \beta)$ goes through the midpoint of the segment connecting $z$ and $x^{0}$.

The next theorem dispenses with the condition that $X$ be closed.

Theorem 1.25. Let $\mathrm{X}$ be a nonempty and convex (but not necessarily closed) set in $\mathbb{R}^{n}$.

(i) If $\mathrm{z} \notin \mathrm{X}$ is a point outside of this set, then there exists a hyperplane $\mathrm{H}(\mathrm{p}, \alpha)$ through $\mathrm{z}$ that separates $[\mathrm{z}$ ) and $\mathrm{X}$, that is, $\mathrm{pz}=\alpha \leq \mathrm{px}$ for all $\mathrm{x} \in \mathrm{X}$.

(ii) If $\mathrm{x}^{0}$ is a boundary point of $\mathrm{X}$, then there exists at least one supporting hyperplane for $\mathrm{X}$ that goes through $\mathrm{x}^{0}$ (supporting-hyperplane theorem).

## Proof

(i) We consider two cases: If $z \notin \mathrm{cl} X$, then we can apply the preceding theorem, because the closure of $X$ is a closed convex set that contains $X$. The other possibility is that $z$ belongs to the closure of $X$, but not to $X$ itself. Then $z$ is a boundary point of $X$ and either an interior point or a boundary point of $\operatorname{cl} X$.

We will show that the first possibility leads to a contradiction. Suppose $z$ is an interior point of $\mathrm{cl} X$. Then int(cl $X$ ) is not empty, and by Problem 1.23, neither is int $X$. But then we have, by Theorem 1.16, that bdy(cl $X)=$ bdy $X$. Hence, because $z$ is a boundary point of $X$, it is also a boundary point of cl $X$, contradicting our assumption that $z \in \operatorname{int}(\mathrm{cl} X)$.

Hence $z$ is a boundary point of $\mathrm{cl} X$, and it follows that because any open ball around $z$ contains at least one point in $(\mathrm{cl} X)^{c}$, we can find a sequence $\left\{z_{n}\right\}$ with $z_{n} \notin \mathrm{cl} X$ and $\left\{z_{n}\right\} \rightarrow z$.

Now, because $z_{n} \notin \mathrm{cl} X$, and $\mathrm{cl} X$ is a closed convex set (by Theorem 1.11), we can find (by Theorem 1.24), a sequence of vectors $\left\{q_{n}\right\}$ such that for each $n$,

$$
\begin{equation*}
q_{n} z_{n}<q_{n} x \forall x \in \operatorname{cl} X \tag{1}
\end{equation*}
$$

Next, define

$$
p_{n}=\frac{1}{\left\|q_{n}\right\|} q_{n}
$$

and observe that this normalization does not affect the inequality in (1). Thus, we have, for each $n$,

$$
\begin{equation*}
p_{n} z_{n}<p_{n} x \forall x \in \operatorname{cl} X \tag{2}
\end{equation*}
$$

Because $\left\|p_{n}\right\| \leq 1$, the sequence $\left\{p_{n}\right\}$ is bounded and therefore has a convergent subsequence $\left\{p_{n_{k}}\right\}$, by the Bolzano-Weierstrass theorem. Call $p$ the limit of this subsequence. Taking limits as $k \rightarrow \infty$, (2) yields

$$
p z \leq p x \forall x \in \operatorname{cl} X
$$

and therefore for all $x$ in $X$. Hence, $H(p, p z)$ is the desired hyperplane.

(ii) Let $x^{0}$ be a boundary point of $X$. If $x^{0} \notin X$, then (i) applies. But even if $x^{0} \in X$, the proof is identical, once we observe that, by the same argument as in (i), a boundary point of $X$ is also a boundary point of $\mathrm{cl} X$. Hence, any open ball around $x^{0}$ contains points of $(\mathrm{cl} X)^{c}$, and we can construct a sequence $\left\{z_{n}\right\}$ as before.

Theorem 1.26. Separating-hyperplane theorem (Minkowski). Let $\mathrm{X}$ and $\mathrm{Y}$ be disjoint and nonempty convex sets in $\mathbb{R}^{n}$. Then there exists a hyperplane $\mathrm{H}(\mathrm{p}, \alpha)$ that separates $\mathrm{X}$ and $\mathrm{Y}$.

Proof. By Theorem 1.4, the set

$$
Z=X-Y=X+(-1) Y
$$

is convex. Moreover, because $X \cap Y=\varnothing$, we have $\underline{Z} \notin Z$. (Because $X$ and $Y$ have no common elements, for any $x \in X$ and any $y \in Y$ we have $x \neq y$, and therefore $z=x-y \neq \underline{0}$ for any $z$ in $Z$.)

By the preceding theorem, there is a vector $p$ in $\mathbb{R}^{\mathrm{n}}$ that separates $Z$ and $\{0\}$, that is, such that

$$
p \underline{0}=0 \leq p z \quad \text { for every } z \text { in } Z
$$

Equivalently, for any $x \in X$ and any $y \in Y$, we have

$$
0 \leq p z=p(x-y) \Rightarrow p y \leq p x
$$

The set of real numbers of the form $\{p y ; y \in Y\}$ is bounded above (by any $p x$ ) and therefore has a supremum, which we call $\alpha$. By the properties of the supremum,

$$
p y \leq \alpha \leq p x
$$

for $x \in X$ and $y \in Y$. Thus, $H(p, \alpha)$ separates $X$ and $Y$.

## 2. Concave Functions

Concavity and quasiconcavity are important concepts in mathematical programming. As a preview, the reader should recall the conditions for a local maximum of a univariate real function. The first-order condition $f^{\prime}(x)=0$ is necessary but not sufficient for a local maximum. It tells us that the tangent to $f$ must be horizontal at $x$, which is certainly true at a local maximum, but also at a local minimum. To separate maxima from minima we use a second set of (sufficient) conditions that are often stated in terms of second derivatives. For a univariate function, $f^{\prime \prime}(x)<0$ tells us that $f$ is concave in a neighborhood of $x$. Intuitively, the curvature of the function is such that a horizontal tangent must signal a "peak" rather than a "valley." Moreover, if $f$ is globally concave, then there can be only one "peak" and no "valleys." Hence, once we find an $x^{*}$ such that $f^{\prime}\left(x^{*}\right)=0$, we have found the global maximum of the function.

In short, the second-order conditions for unconstrained maximization amount to checking the concavity of $f$ in the neighborhood of a critical point. And if the function is globally concave, a local maximum is a global maximum. A similar situation arises in connection with more complicated programming problems, except that then we also have to worry about the curvature of the constraint functions.

In what follows, we consider functions of the form $f: \mathbb{R}^{n} \supseteq X \rightarrow \mathbb{R}$, where $X$ is a convex set in $\mathbb{R}^{\mathrm{n}}$. Given any two points $x^{\prime}$ and $x^{\prime \prime}$ in $X$, any convex combination $x^{\lambda}$ of $x^{\prime}$ and $x^{\prime \prime}$ will also lie in the domain of the function. We can therefore compare $f\left(x^{\lambda}\right)$ with the corresponding convex combination of $f\left(x^{\prime}\right)$ and $f\left(x^{\prime \prime}\right),(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right)$, which traces out the chord through the points $\left(x^{\prime}, f\left(x^{\prime}\right)\right)$ and $\left(x^{\prime \prime}, f\left(x^{\prime \prime}\right)\right)$ on the graph of $f$. If the chord lies always below the function, we say that $f$ is concave. If it lies always above the function, $f$ is convex.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-251.jpg?height=508&width=619&top_left_y=194&top_left_x=118)

f concave

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-251.jpg?height=508&width=619&top_left_y=194&top_left_x=735)

f convex

Figure 6.6. Concave and convex functions.

Definition 2.1. Concave function. The function $f: \mathbb{R}^{\mathbf{n}} \supseteq X \rightarrow \mathbb{R}$, where $X$ is a convex set, is concave if given any two points $x^{\prime}$ and $x^{\prime \prime}$ in $X$ we have

$$
(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right) \leq f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right] \equiv f\left(x^{\lambda}\right) \forall \lambda \in[0,1]
$$

and it is strictly concave if the inequality holds strictly for $\lambda \in(0,1)$, that is, if

$$
\forall x^{\prime}, x^{\prime \prime} \in X \text { and } \lambda \in(0,1),(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right)<f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right] \equiv f\left(x^{\lambda}\right)
$$

Reversing the direction of the inequalities, we obtain the definitions of convexity and strict convexity.

## (a) Some Characterizations

Given a function $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}$, its hypograph is the set of points $(y, x)$ lying on or below the graph of the function:

$$
\text { hyp } f=\left\{(y, x) \in \mathbb{R}^{\mathrm{n}+1} ; x \in X \text { and } y \leq f(x)\right\}
$$

Similarly, the epigraph of $f$ is defined as

$$
\text { epi } f=\left\{(y, x) \in \mathbb{R}^{\mathrm{n}+1} ; x \in X \text { and } y \geq f(x)\right\}
$$

The following result gives a characterization of concave functions in terms of the convexity of their hypographs. A similar characterization of convex functions can be given in terms of the epigraph.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-252.jpg?height=475&width=599&top_left_y=195&top_left_x=106)

f concave

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-252.jpg?height=468&width=666&top_left_y=196&top_left_x=700)

f convex

Figure 6.7.

Theorem 2.2. The function $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$ is concave if and only if its hypograph is a convex set. The function $\mathrm{f}$ is convex if and only if its epigraph is convex.

## Proof

- $f$ concave $\Rightarrow \operatorname{hyp} f$ convex

Let $f$ be a concave function, and take two arbitrary points $\left(x^{\prime}, y^{\prime}\right)$ and $\left(x^{\prime \prime}, y^{\prime \prime}\right)$ in hyp $f$. Then $y^{\prime} \leq f\left(x^{\prime}\right)$ and $y^{\prime \prime} \leq f\left(x^{\prime}\right)$, and for any $\lambda \in[0,1]$,

$$
\begin{equation*}
y^{\lambda}=(1-\lambda) y^{\prime}+\lambda y^{\prime \prime} \leq(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right) \leq f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right] \equiv f\left(x^{\lambda}\right) \tag{1}
\end{equation*}
$$

where the second inequality holds by the concavity of $f$. From (1), $y^{\lambda} \leq f\left(x^{\lambda}\right)$, implying that the point

$$
\left(x^{\lambda}, y^{\lambda}\right)=\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime},(1-\lambda) y^{\prime}+\lambda y^{\prime \prime}\right]=(1-\lambda)\left(x^{\prime}, y^{\prime}\right)+\lambda\left(x^{\prime \prime}, y^{\prime \prime}\right)
$$

lies in hyp $f$. Because $\left(x^{\prime}, y^{\prime}\right)$ and $\left(x^{\prime \prime}, y^{\prime \prime}\right)$ are arbitrary points of hyp $f$, this set is convex. Figure 6.8 illustrates the argument.

- hyp $f$ convex $\Rightarrow f$ concave

Given any two points $x^{\prime}$ and $x^{\prime \prime}$ in the domain of $f$, the points $\left(x^{\prime}, f\left(x^{\prime}\right)\right)$ and $\left(x^{\prime \prime}\right.$, $f\left(x^{\prime \prime}\right)$ ) lie in hyp $f$. By the convexity of this set, so does the point

$$
(1-\lambda)\left(x^{\prime}, f\left(x^{\prime}\right)\right)+\lambda\left(x^{\prime \prime}, f\left(x^{\prime \prime}\right)\right)=\left((1-\lambda) x^{\prime}+\lambda x^{\prime \prime},(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right)\right)
$$

Hence,

$$
(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right) \leq f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right]
$$

and because $x^{\prime}$ and $x^{\prime \prime}$ are arbitrary, we conclude that $f$ is concave.

Definition 2.3. Superdifferential. Let $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}$ be a function, and $x^{0}$ a point in its domain. If there exists a vector $q^{0}$ in $\mathbb{R}^{\mathrm{n}}$ such that
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-253.jpg?height=548&width=1302&top_left_y=184&top_left_x=90)

Figure 6.8.

$$
\begin{equation*}
f(x) \leq f\left(x^{0}\right)+q^{0}\left(x-x^{0}\right) \tag{1}
\end{equation*}
$$

for all $x$ in $X$, we say that $f$ is superdifferentiable at $x^{0}$ and call the vector $q^{0}$ a supergradient of $f$. The set of all supergradients of $f$ at $x^{0}$ is called the superdifferential of $f$ at $x^{0}$, denoted by $\partial f\left(x^{0}\right)$.

If $f$ is a concave function defined on a convex set in $\mathbb{R}^{\mathrm{n}}$, then hyp $f$ is a convex set in $\mathbb{R}^{\mathrm{n}+1}$, and $(x, f(x))$ is a point on its boundary. By Theorem 1.25, hyp $f$ has a supporting hyperplane through each point on the graph of $f$, and the function itself lies below the supporting hyperplane. Hence, concave functions are superdifferentiable.

The following theorem shows that the result we have just anticipated and its converse are both true, giving us another characterization of concavity. Notice that the supergradient of a concave function need not be unique: If the function has a kink, it will have several supporting hyperplanes, as shown in Figure 6.9.

Theorem 2.4. Let $\mathrm{f}$ be a real-valued function defined on an open and convex set $\mathrm{X}$ in $\mathbb{R}^{n}$. Then $\mathrm{f}$ is concave if and only if is superdifferentiable everywhere in its domain, that is, if given any $\mathrm{x}^{0}$ in $\mathrm{X}$, there exists a vector $\mathrm{q}^{0}$ in $\mathbb{R}^{n}$ such that

$$
\begin{equation*}
f(x) \leq f\left(x^{0}\right)+q^{0}\left(x-x^{0}\right) \tag{1}
\end{equation*}
$$

for all $\mathrm{x}$ in $\mathrm{X}$.

Proof

(i) $f$ concave on an open set $\Rightarrow f$ superdifferentiable

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-254.jpg?height=775&width=1031&top_left_y=191&top_left_x=212)

Figure 6.9. Supergradients of a concave function.

Let $f$ be a concave function defined on an open and convex set $X$ in $\mathbb{R}^{\mathrm{n}}$. Then hyp $f$ is a convex set in $\mathbb{R}^{\mathrm{n}+1}$, and for any given $x^{0}$ in $X,\left(f\left(x^{0}\right), x^{0}\right)$ is a point on the boundary of this set. By Theorem 1.25, hyp $f$ has a supporting hyperplane $H\left[\left(p_{0}, p\right), \alpha\right]$ through $\left(f\left(x^{0}\right), x^{0}\right)$. That is, there exists a nonzero vector $\left(p_{0}, p\right) \in$ $\mathbb{R}^{\mathrm{n}+1}$ (with $p_{0} \in \mathbb{R}$ and $p \in \mathbb{R}^{\mathrm{n}}$ ) such that

$$
\begin{equation*}
p_{0} f\left(x^{0}\right)+p x^{0}=\alpha \tag{1}
\end{equation*}
$$

and hyp $f$ lies entirely on one side of $H$. For concreteness, suppose that

$$
\begin{equation*}
p_{0} y+p x \leq \alpha \forall(y, x) \in \operatorname{hyp} f \tag{2}
\end{equation*}
$$

(If the reverse inequality holds, the proof goes through with the obvious changes.) Combining (1) and (2),

$$
\begin{equation*}
p_{0}\left[y-f\left(x^{0}\right)\right]+p\left(x-x^{0}\right) \leq 0 \forall(y, x) \in \operatorname{hyp} f \tag{3}
\end{equation*}
$$

We begin by determining the sign of $p_{0}$. The point $\left(f\left(x^{0}\right)-\gamma, x^{0}\right)$ lies in hyp $f$ for any $\gamma>0$. By (3),

$$
p_{0}\left[f\left(x^{0}\right)-\gamma-f\left(x^{0}\right)\right]+p\left(x^{0}-x^{0}\right) \leq 0 \Rightarrow-\gamma p_{0} \leq 0 \Rightarrow p_{0} \geq 0
$$

so $p_{0}$ is a nonnegative number. Next, we show that in fact $p_{0}$ must be strictly positive. We proceed by contradiction: Suppose $p_{0}=0$, then (3) implies that

$$
\begin{equation*}
p\left(x-x^{0}\right) \leq 0 \forall x \in X \tag{4}
\end{equation*}
$$

If $p_{0}=0$, at least one of the components of $p$, say $p_{k}$, must be different from zero. Consider a point $x^{\prime}$, with

$$
x_{k}^{\prime}=x_{k}^{0}+\varepsilon p_{k} \quad \text { and } \quad x_{i}^{\prime}=x_{i}^{0} \quad \text { for } i \neq k
$$

Because $X$ is an open set, we can choose $\varepsilon>0$ small enough that $x^{\prime}$ lies in $X$. By (4), it follows that

$$
p\left(x^{\prime}-x^{0}\right)=p_{k}\left(x_{k}^{0}+\varepsilon p_{k}-x_{k}^{0}\right)+\sum_{i \neq k}^{n} p_{i}\left(x_{i}^{0}-x_{i}^{0}\right)=\varepsilon p_{k}^{2} \leq 0
$$

which is impossible, because $\varepsilon>0$. Hence, we conclude that $p_{0}>0$.

Finally, given an arbitrary point $x \in X$, the point $(f(x), x)$ lies in hyp $f$. By (3),

$$
p_{0}\left[f(x)-f\left(x^{0}\right)\right]+p\left(x-x^{0}\right) \leq 0
$$

Dividing through by $p_{0}>0$ and rearranging,

$$
f(x) \leq f\left(x^{0}\right)+\frac{-1}{p_{0}} p\left(x-x^{0}\right)
$$

Putting $q^{0}=\left(-1 / p_{0}\right) p$, we obtain the desired result.

(ii) $f$ superdifferentiable on $X \Rightarrow f$ concave

Fix two arbitrary points $x$ and $x^{0}$ in $X$, and let $x^{\lambda}=(1-\lambda) x^{0}+\lambda x$ for some $\lambda \in(0,1)$. Because $X$ is a convex set, $x^{\lambda} \in X$, and, by assumption, there exists a vector $q^{\lambda} \in \mathbb{R}^{\mathrm{n}}$ such that

$$
\begin{align*}
f(x) & \leq f\left(x^{\lambda}\right)+q^{\lambda}\left(x-x^{\lambda}\right)  \tag{5}\\
f\left(x^{0}\right) & \leq f\left(x^{\lambda}\right)+q^{\lambda}\left(x^{0}-x^{\lambda}\right) \tag{6}
\end{align*}
$$

Multiplying these two inequalities by $\lambda$ and $(1-\lambda)>0$, respectively, and adding them,

$$
\begin{gather*}
\lambda f(x) \leq \lambda f\left(x^{\lambda}\right)+\lambda q^{\lambda}\left(x-x^{\lambda}\right) \\
\frac{(1-\lambda) f\left(x^{0}\right) \leq(1-\lambda) f\left(x^{\lambda}\right)+(1-\lambda) q^{\lambda}\left(x^{0}-x^{\lambda}\right)}{(1-\lambda) f\left(x^{0}\right)+\lambda f(x) \leq f\left(x^{\lambda}\right)+q^{\lambda}\left[\lambda\left(x-x^{\lambda}\right)+(1-\lambda)\left(x^{0}-x^{\lambda}\right)\right]} \tag{7}
\end{gather*}
$$

Now consider the expression inside brackets; we have

$$
\lambda\left(x-x^{\lambda}\right)+(1-\lambda)\left(x^{0}-x^{\lambda}\right)=\lambda x+(1-\lambda) x^{0}-x^{\lambda}=\underline{0}
$$

Hence, (7) reduces to

$$
(1-\lambda) f\left(x^{0}\right)+\lambda f(x) \leq f\left(x^{\lambda}\right)
$$

which shows that $f$ is concave.

Given a function $f: \mathbb{R}^{\mathbf{n}} \supseteq X \longrightarrow \mathbb{R}$ and two points in its domain, $x^{\prime}$ and $x^{\prime \prime}$, we define the univariate function $\phi: \mathbb{R} \longrightarrow \mathbb{R}$ by

$$
\phi(\lambda)=f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right]=f\left[x^{\prime}+\lambda\left(x^{\prime \prime}-x^{\prime}\right)\right]
$$

for fixed $x^{\prime}$ and $x^{\prime \prime}$. Our next theorem says that $f$ is concave if and only if $\phi$ is always concave. Because working with a univariate function is often easier,
this result often provides a convenient way to establish the concavity of a multivariate function.

Theorem 2.5. The function $\mathrm{f}: \mathbb{R}^{\mathrm{n}} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$, where $\mathrm{X}$ is a convex set, is concave if and only if the function $\phi(\lambda)=\mathrm{f}\left[(1-\lambda) \mathrm{x}^{\prime}+\lambda \mathrm{x}^{\prime \prime}\right]$ is concave for any two points $\mathrm{x}^{\prime}$ and $\mathrm{x}^{\prime \prime}$ in the domain of $\mathrm{f}$.

Problem 2.6. Prove Theorem 2.5.

## (b) Properties of Concave Functions

We now establish some useful properties of concave functions.

Theorem 2.7. Let $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$ be a concave function. For any $\alpha \in \mathbb{R}$, the upper contour set of $\mathrm{f}$,

$$
\mathrm{U}_{\alpha}=\{\mathrm{x} \in \mathrm{X} ; \mathrm{f}(\mathrm{x}) \geq \alpha\}
$$

is either empty or convex. Similarly, if $\mathrm{f}$ is convex, then the lower contour set,

$$
\mathrm{L}_{\alpha}=\{\mathrm{x} \in \mathrm{X} ; \mathrm{f}(\mathrm{x}) \leq \boldsymbol{\alpha}\}
$$

is convex whenever it is not empty.

The converse statement is not true. As we will see, the weaker property of quasiconcavity is sufficient to guarantee the convexity of the upper contour sets.

Proof. Let $x^{\prime}$ and $x^{\prime \prime}$ be any two points in $U_{\alpha}$, that is, with $f\left(x^{\prime}\right) \geq \alpha$ and $f\left(x^{\prime \prime}\right)$ $\geq \alpha$. By the concavity of $f$,

$$
f\left(x^{\lambda}\right) \geq(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right) \geq \alpha
$$

for any $\lambda \in[0,1]$. Hence,

$$
x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{\prime \prime} \in U_{\alpha} \quad \text { for any } \lambda \in[0,1]
$$

and $U_{\alpha}$ is therefore a convex set, as illustrated in Figure 6.10.

The results that follow show that certain transformations of concave functions are also concave.

Theorem 2.8. Let $\mathrm{f}: \mathbb{R}^{\mathrm{n}} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$ be a concave function and $\mathrm{g}: \mathbb{R} \rightarrow \mathbb{R}$ an increasing and concave function defined on an interval $I$ containing $\mathrm{f}(\mathrm{X})$. Then the function $\mathrm{g}[\mathrm{f}(\mathrm{x})]$ is concave.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-257.jpg?height=604&width=1018&top_left_y=182&top_left_x=227)

Figure 6.10. Concavity implies convexity of the upper contour sets.

Problem 2.9. Prove Theorem 2.8.

Theorem 2.10. Let $\mathrm{f}$ and $\mathrm{g}$ be concave functions $\mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$. Given arbitrary scalars $\alpha$ and $\beta \geq 0$, the function $\mathrm{h}=\alpha \mathrm{f}+\beta \mathrm{g}$ is concave.

Problem 2.11. Prove Theorem 2.10.

Theorem 2.12. Let $\{\mathrm{f} ; \mathrm{s} \in \mathrm{S}\}$ be a (possibly infinite) family of concave functions $\mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$, all of which are bounded below. Then the function $\mathrm{f}$ defined on $\mathrm{X}$ by

$$
\mathrm{f}(\mathrm{x})=\inf \left\{\mathrm{f}^{\mathrm{s}}(\mathrm{x}) ; \mathrm{s} \in \mathrm{S}\right\}
$$

is concave.

Problem 2.13. Prove Theorem 2.12. Hint: Use Theorem 2.2.

Figure 6.11 illustrates the intuition behind Theorem 2.12.

An interesting property of a concave function is that it is continuous everywhere in the interior of its domain.

Theorem 2.14. Let $\mathrm{f}$ be a concave function defined on an open set $\mathrm{X}$ in $\mathbb{R}^{n}$. Then $\mathrm{f}$ is continuous on $\mathrm{X}$.

Figure 6.12 illustrates why this is true. Concavity requires that the chord through any two points on the graph of the function lie below the function itself. If the domain of the function is open, this will be impossible if the

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-258.jpg?height=682&width=1207&top_left_y=188&top_left_x=126)

Figure 6.11.
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-258.jpg?height=534&width=1250&top_left_y=1017&top_left_x=104)

Figure 6.12.

function is discontinuous. If $X$ is not open, discontinuities are possible, but only at points on the boundary of $X$.

Proof. Pick some $x^{0}$ in $X$. Because $X$ is open, there is some $\delta>0$ small enough that the cube with side $2 \delta$,

$$
C=\left\{x \in \mathbb{R}^{\mathrm{n}} ; x_{i}^{0}-\delta \leq x_{i} \leq x_{i}^{0}+\delta\right\}
$$

is still contained in $X$. Let $V$ be the set of the $2^{n}$ vertices of $C$, and put

$$
\alpha=\min \{f(x) ; x \in V\}
$$

The set $U_{\alpha}=\{x \in X ; f(x) \geq \alpha\}$ is convex, by Theorem 2.7. Moreover, $V \subseteq U_{\alpha}$ by construction, and because $C$ is the convex hull of $V$ (i.e., the smallest convex set containing $V$ ), we also have $C \subseteq U_{\alpha}$, that is,

$$
\begin{equation*}
f(x) \geq \alpha \forall x \in C \tag{1}
\end{equation*}
$$

Let $x$ be an arbitrary point in the ball $B_{\delta}\left(x^{0}\right)$ (which is contained in $C$ ), and let $x^{0}+u$ and $x^{0}-u$ be the points where the line through $x$ and $x^{0}$ intersects the boundary of $B_{\delta}\left(x^{0}\right)$, as shown in Figure 6.13. We can write $x$ as a convex combination of $x^{0}$ and $x^{0}+u$, and $x^{0}$ as a convex combination of $x$ and $x^{0}-u$. Because $x$ lies on the straight line through $x^{0}$ and $x^{0}+u$, we have $x=x^{0}+\lambda u$ for some $\lambda$, and in particular,

$$
\begin{equation*}
x-x^{0}=\lambda u \Rightarrow \lambda=\frac{\left\|x-x^{0}\right\|}{\|u\|}=\frac{\left\|x-x^{0}\right\|}{\delta} \tag{2}
\end{equation*}
$$

Now,

$$
\begin{equation*}
x=x^{0}+\lambda u \Rightarrow x=\lambda\left(x^{0}+u\right)+(1-\lambda) x^{0} \tag{3}
\end{equation*}
$$

and

$$
x^{0}=x-\lambda u \Rightarrow(1+\lambda) x^{0}=x-\lambda u+\lambda x^{0}=x+\lambda\left(x^{0}-u\right)
$$

from where

$$
\begin{equation*}
x^{0}=\frac{1}{1+\lambda} x+\frac{\lambda}{1+\lambda}\left(x^{0}-u\right) \tag{4}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-259.jpg?height=652&width=939&top_left_y=1477&top_left_x=264)

Figure 6.13.

Using (3) and (4), the concavity of $f$ on $X$, and the fact that (1) holds for all points in these expressions, we have

$$
(3) \Rightarrow f(x) \geq \lambda f\left(x^{0}+u\right)+(1-\lambda) f\left(x^{0}\right) \geq \lambda \alpha+(1-\lambda) f\left(x^{0}\right)
$$

implying

$$
\begin{equation*}
f(x)-f\left(x^{0}\right) \geq-\lambda\left[f\left(x^{0}\right)-\alpha\right] \tag{5}
\end{equation*}
$$

and

$$
\text { (4) } \Rightarrow f\left(x^{0}\right) \geq \frac{1}{1+\lambda} f(x)+\frac{\lambda}{1+\lambda} f\left(x^{0}-u\right) \geq \frac{1}{1+\lambda}[f(x)+\lambda \alpha]
$$

from where

$$
\begin{equation*}
(1+\lambda) f\left(x^{0}\right) \geq f(x)+\lambda \alpha \Rightarrow f(x)-f\left(x^{0}\right) \leq \lambda\left[f\left(x^{0}\right)-\alpha\right] \tag{6}
\end{equation*}
$$

Combining (5) and (6) and using (2), we have

$$
\left|f(x)-f\left(x^{0}\right)\right| \leq \lambda\left[f\left(x^{0}\right)-\alpha\right]=\frac{\left\|x-x^{0}\right\|}{\delta}\left[f\left(x^{0}\right)-\alpha\right]
$$

Given any $\varepsilon>0$, we have $\left|f(x)-f\left(x^{0}\right)\right|<\varepsilon$ for all $x$ close enough to $x^{0}$. In particular, it is enough to choose $x$ so that

$$
\left\|x-x^{0}\right\|<\frac{\delta \varepsilon}{f\left(x^{0}\right)-\alpha}
$$

In other words, $f$ is continuous at $x^{0}$, and because this is just an arbitrary point of $X, f$ is continuous on $X$.

Let $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}$ be a concave function. Fix a point $x$ in its domain and a direction vector $h$ in $\mathbb{R}^{\mathrm{n}}$, and consider moving away from $x$ in the direction of $h$, as illustrated in Figure 6.14 (i.e., we consider points of the form $x+\alpha h)$. The following result says that the slope of the chord through the points $(x, f(x))$ and $(x+\alpha h, f(x+\alpha h))$ decreases as we move to the right.

Theorem 2.15. Let $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$ be a concave function defined on an open and convex set $\mathrm{X}$. Then the ratio $(\mathrm{f}(\mathrm{x}+\alpha \mathrm{h})-\mathrm{f}(\mathrm{x})) / \alpha$, where $\mathrm{h} \in \mathbb{R}^{n}$ is $a$ (weakly) decreasing function of $\alpha$.

Proof. Fix $x \in X$, and let $h$ be an arbitrary vector in $\mathbb{R}^{\mathrm{n}}$. Consider first the case where $\alpha>0$. Because $X$ is open, $x+\alpha h \in X$ for sufficiently small but strictly positive $\alpha$. We will establish the desired result by showing that

$$
\frac{f(x+\alpha h)-f(x)}{\alpha} \leq \frac{f(x+\mu h)-f(x)}{\mu}
$$

for any positive number $\mu$ smaller than or equal to $\alpha$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-261.jpg?height=657&width=927&top_left_y=189&top_left_x=268)

Figure 6.14.

Put $\mu=\lambda \alpha$ for $\lambda \in(0,1)$, and observe that we can write

$$
x+\mu h=x+\lambda \alpha h=x+\lambda x-\lambda x+\lambda \alpha h=(1-\lambda) x+\lambda(x+\alpha h)
$$

Now, the concavity of $f$ implies that

$$
f(x+\mu h)=f[(1-\lambda) x+\lambda(x+\alpha h)] \geq(1-\lambda) f(x)+\lambda f(x+\alpha h)
$$

and, upon rearranging,

$$
f(x+\mu h)-f(x) \geq \lambda[f(x+\alpha h)-f(x)]
$$

Finally, because $\lambda=\mu / \alpha>0$, we obtain the desired result:

$$
\frac{f(x+\mu h)-f(x)}{\mu} \geq \frac{f(x+\alpha h)-f(x)}{\lambda}
$$

If $\alpha<0$, then the last inequality is reversed, but then $\mu \geq \alpha$, so the function is still increasing.

This result has some interesting implications. Notice that the limit of the difference quotient $(f(x+\alpha h)-f(x)) / \alpha$ as $\alpha$ approaches zero from above is the one-sided directional derivative of $f$ at $x$ in the direction of $h: D f\left(x ; h^{+}\right)$ (or $D f\left(x ; h^{-}\right)$if $\alpha \rightarrow 0$ from below.) As we know from Chapter 2 (Section 6), monotonic functions defined on an open interval always have one-sided limits. Hence, concave functions have one-sided directional derivatives (and, in particular, one-sided partial derivatives) at all interior points of their domains.

The supergradients of a concave function can be related to its one-sided partial derivatives. Let $f$ be a concave function defined on an open set $X$, and consider moving away from a point $x \in X$ in the direction $h$. If $q$ is a supergradient of $f$ at $x$, then

$$
f(x+\alpha h) \leq f(x)+q(\alpha h)
$$

for any $\alpha$ such that $x+\alpha h \in X$. Rearranging this expression,

$$
\begin{array}{ll}
\frac{f(x+\alpha h)-f(x)}{\alpha} \leq q h & \text { for } \alpha>0 \\
\frac{f(x+\alpha h)-f(x)}{\alpha} \geq q h & \text { for } \alpha<0
\end{array}
$$

Taking the limits of these expressions as $\alpha$ goes to zero from above and from below, we obtain

$$
D f\left(x ; h^{+}\right) \leq q h \leq D f\left(x ; h^{-}\right)
$$

Finally, taking $h$ to be the $i$ th coordinate vector in $\mathbb{R}^{\mathrm{n}}, e^{i}$, we arrive at

$$
f_{i}\left(x^{+}\right) \leq q_{i} \leq f_{i}\left(x^{-}\right) \text {for each } i=1, \ldots, n
$$

Hence, the components of the supergradient of $f$ at $x$ are bounded by the function's left- and right-hand partial derivatives. If $f$ is differentiable, the two one-sided partials coincide, and the unique supergradient is the derivative of $f$ at $x$. Conversely, it can be shown that if $f$ has a unique supergradient at a point $x$, then it is differentiable at $x$.

Furthermore, it can be shown that a concave function is differentiable (and in fact continuously differentiable) almost everywhere in the interior of its domain (i.e., at all points except possibly for a set of measure zero) (Rockafellar, 1970, p. 246).

We are sometimes interested in determining whether or not a given concave function is differentiable at a specific point. The following result, due to Benveniste and Scheinkman (1982), is sometimes useful in this situation.

Theorem 2.16. Let $\mathrm{X}$ be a convex subset of $\mathbb{R}^{n}$, and $\mathrm{V}: \mathrm{X} \rightarrow \mathbb{R}$ a concave function. Let $\mathrm{x}^{0} \in$ int $\mathrm{X}$, and suppose there exists some $\varepsilon>0$ and a concave and differentiable function $\mathrm{W}: \mathrm{X} \longrightarrow \mathbb{R}$ such that

$$
\begin{equation*}
\mathrm{W}(\mathrm{x}) \leq \mathrm{V}(\mathrm{x}) \forall \mathrm{x} \in \mathrm{B}_{\varepsilon}\left(\mathrm{x}^{0}\right) \quad \text { and } \quad \mathrm{W}\left(\mathrm{x}^{0}\right)=\mathrm{V}\left(\mathrm{x}^{0}\right) \tag{1}
\end{equation*}
$$

Then $\mathrm{V}$ is differentiable at $\mathrm{x}^{0}$, and

$$
\mathrm{DV}\left(\mathrm{x}^{0}\right)=\mathrm{DW}\left(\mathrm{x}^{0}\right)
$$

Proof. Because $V$ is concave, it is superdifferentiable, and any supergradient $q$ of $V$ at $x^{0}$ satisfies

$$
V(x) \leq V\left(x^{0}\right)+q\left(x-x^{0}\right)
$$

for any $x$ in $B_{\varepsilon}\left(x^{0}\right)$. Rearranging this expression and using (1),

$$
W(x)-W\left(x^{0}\right) \leq V(x)-V\left(x^{0}\right) \leq q\left(x-x^{0}\right)
$$

so $q$ is also a supergradient of $W$ at $x^{0}$. Because $W$ is differentiable, moreover, $q$ is unique, and because any concave function with a unique supergradient at an interior point of its domain is differentiable, $V$ is differentiable at $x^{0}$, with $D V\left(x^{0}\right)=q=D W\left(x^{0}\right)$.

## (c) Concavity for Smooth Functions

We will now establish some characterizations of concavity for $C^{1}$ and $C^{2}$ functions that will be useful in our development of nonlinear programming in the following chapter. In this section we will assume that $f$ is a smooth, real-valued function defined on an open and convex set $X$ in $\mathbb{R}^{\mathrm{n}}$. Openness is required so that we can assume that $f$ is differentiable at all points in $X$.

If $f$ is a smooth concave function, its graph lies everywhere below the tangent hyperplane defined by its derivative, and vice versa, a $C^{1}$ function that lies everywhere below its tangent hyperplane is concave. The following theorem shows that a slight strengthening of this statement yields a characterization of strictly concave $C^{1}$ functions.

Theorem 2.17. Let $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$ be a $\mathrm{C}^{l}$ function defined on an open and convex set $\mathrm{X}$. Then $\mathrm{f}$ is concave if and only if given any two points $\mathrm{x}^{0}$ and $\mathrm{x}$ in $\mathrm{X}$, we have

$$
f(x) \leq f\left(x^{0}\right)+\operatorname{Df}\left(x^{0}\right)\left(x-x^{0}\right)
$$

Moreover, $\mathrm{f}$ is strictly concave if and only if the inequality holds strictly, that is, if and only if

$$
\mathrm{f}(\mathrm{x})<\mathrm{f}\left(\mathrm{x}^{0}\right)+\operatorname{Df}\left(\mathrm{x}^{0}\right)\left(\mathrm{x}-\mathrm{x}^{0}\right)
$$

for all pairs of distinct points $\mathrm{x}^{0}$ and $\mathrm{x}$ in $\mathrm{X}$.

Proof

- $f$ concave $\Rightarrow f(x) \leq f\left(x^{0}\right)+D f\left(x^{0}\right)\left(x-x^{0}\right) \forall x, x^{0} \in X$

Fix $x$ and $x^{0}$ in $X$ and write

$$
x^{\lambda}=(1-\lambda) x^{0}+\lambda x=x^{0}+\lambda\left(x-x^{0}\right)
$$

with $\lambda \in(0,1)$. By the concavity of $f$, we have:

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-264.jpg?height=601&width=792&top_left_y=181&top_left_x=340)

Figure 6.15. A $C^{1}$ concave function.

$$
\begin{equation*}
(1-\lambda) f\left(x^{0}\right)+\lambda f(x) \leq f\left[x^{0}+\lambda\left(x-x^{0}\right)\right] \tag{1}
\end{equation*}
$$

from where, rearranging,

$$
\begin{equation*}
f(x)-f\left(x^{0}\right) \leq \frac{f\left[x^{0}+\lambda\left(x-x^{0}\right)\right]-f\left(x^{0}\right)}{\lambda} \tag{2}
\end{equation*}
$$

When we take the limit of this expression as $\lambda \rightarrow 0$, the inequality is preserved. Moreover, the limit of the right-hand side is precisely the directional derivative of $f$ in the direction $x-x^{0}$. Because $f$ is $C^{1}$, the limit exists and is equal to $D f\left(x^{0}\right)$ $\left(x-x^{0}\right)$ (see Chapter 4). Hence, (2) implies

$$
f(x)-f\left(x^{0}\right) \leq D f\left(x^{0}\right)\left(x-x^{0}\right)
$$

- Next, suppose $f$ is strictly concave. Then (2) holds with strict inequality, that is,

$$
\begin{equation*}
f(x)-f\left(x^{0}\right)<\frac{f\left[x^{0}+\lambda\left(x-x^{0}\right)\right]-f\left(x^{0}\right)}{\lambda}=\frac{f\left(x^{\lambda}\right)-f\left(x^{0}\right)}{\lambda} \tag{3}
\end{equation*}
$$

for $\lambda \in(0,1)$. Moreover, the concavity of $f$ implies, as we have just shown, that

$$
f\left(x^{\lambda}\right)-f\left(x^{0}\right) \leq D f\left(x^{0}\right)\left(x^{\lambda}-x^{0}\right)
$$

Substituting this expression into (3) and observing that

$$
\frac{1}{\lambda}\left(x^{\lambda}-x^{0}\right)=\frac{1}{\lambda}\left[x^{0}+\lambda\left(x-x^{0}\right)-x^{0}\right]=x-x^{0}
$$

we obtain the desired result:

$$
f(x)-f\left(x^{0}\right)<\frac{f\left(x^{\lambda}\right)-f\left(x^{0}\right)}{\lambda} \leq \frac{D f\left(x^{0}\right)\left(x^{\lambda}-x^{0}\right)}{\lambda}=D f\left(x^{0}\right)\left(x-x^{0}\right)
$$

- For the sufficiency part of the theorem, a straightforward adaptation of the proof of Theorem 2.3 will work.

Theorem 2.18. Let $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$ be a $\mathrm{C}^{2}$ function defined on an open and convex set $\mathrm{X}$. Then $\mathrm{f}$ is concave if and only if the Hessian matrix of second partial derivatives $\mathrm{D}^{2} \mathrm{f}(\mathrm{x})$ is negative semidefinite for any $\mathrm{x}$ in $\mathrm{X}$; that is,

$$
\forall \mathrm{x} \in \mathrm{X} \text { and } \forall \mathrm{h} \in \mathbb{R}^{n}, \mathrm{~h}^{\mathrm{T}} \mathrm{D}^{2} \mathrm{f}(\mathrm{x}) \mathrm{h} \leq 0
$$

Moreover, if the Hessian is negative definite (i.e., if $\mathrm{h}^{\mathrm{T}} \mathrm{D}^{2} \mathrm{f}(\mathrm{x}) \mathrm{h}<0$ for all $\mathrm{x} \in \mathrm{X}$ and all $\mathrm{h} \neq \underline{0}$ in $\mathbb{R}^{n}$ ), then $\mathrm{f}$ is strictly concave.

Note that the negative definiteness of the Hessian is sufficient but not necessary for the strict concavity of $f$.

## Proof

- $f$ concave $\Rightarrow D^{2} f(x)$ negative semidefinite for all $x \in X$

Fix some point $x$ in $X$ and an arbitrary direction vector $h \in \mathbb{R}^{\mathrm{n}}$. Because $X$ is open, there exists some $\delta>0$ such that $x+\alpha h \in X$ for all $\alpha \in I=(-\delta, \delta)$. Define a function $g$ from $I$ to $\mathbb{R}$ by

$$
\begin{equation*}
g(\alpha)=f(x+\alpha h)-f(x)-\alpha D f(x) h \tag{1}
\end{equation*}
$$

Observe that $g$ is $C^{2}$, with $g(0)=0$, and that, by the preceding theorem and the concavity of $f$,

$$
f(x+\alpha h) \leq f(x)+D f(x)(\alpha h) \quad \text { for any } \alpha \in I
$$

which implies that $g(\alpha) \leq 0$ for all $\alpha$ in $I$. Hence, $g$ is a $C^{2}$ univariate function with an interior maximum at 0 and must therefore satisfy the necessary conditions $g^{\prime}(0)=0$ and $g^{\prime \prime}(0) \leq 0$. Differentiating (1) with respect to $\alpha$,

$$
\begin{aligned}
& g^{\prime}(\alpha)=D f(x+\alpha h) h-D f(x) h \\
& g^{\prime \prime}(\alpha)=h^{T} D^{2} f(x+\alpha h) h
\end{aligned}
$$

Thus, $g^{\prime \prime}(0) \leq 0$ becomes

$$
g^{\prime \prime}(0)=h^{T} D^{2} f(x) h \leq 0
$$

Because $h$ is an arbitrary vector in $\mathbb{R}^{n}$, we conclude that $D^{2} f(x)$ is negative semidefinite for any $x$ in $X$.

- $D^{2} f(x)$ negative semidefinite for all $x \in X \Rightarrow f$ concave

Because $f$ is $C^{2}$, it is $C^{1}$, and, by Theorem 2.17, it is enough to show that

$$
\begin{gather*}
h^{T} D^{2} f(x) h \leq 0 \quad \text { for any } x \text { in } X \text { and all } h \in \mathbb{R}^{\mathrm{m}}  \tag{1}\\
\Rightarrow f(x+h) \leq f(x)+D f(x) h \tag{2}
\end{gather*}
$$

Assume that (1) holds, and pick two points $x$ and $x+h$ in $X$. By Taylor's theorem, we have, for some $\alpha \in(0,1)$,

$$
\begin{equation*}
f(x+h)-f(x)-D f(x) h=\frac{1}{2} h^{T} D^{2} f(x+\alpha h) h \tag{3}
\end{equation*}
$$

where $x+\alpha h \in(x, x+h) \subseteq X$. Now, $D^{2} f(x+\alpha h)$ is negative semidefinite by assumption, implying that the right-hand side of the preceding expression is nonpositive and therefore that

$$
\begin{equation*}
f(x+h) \leq f(x)+D f(x) h \tag{4}
\end{equation*}
$$

which is the desired result.

- If $D^{2} f(x)$ is negative definite for all $x$, then (4) holds with strict inequality, and $f$ is strictly concave, by Theorem 2.17 .

The negative definiteness or semidefiniteness of the Hessian can be checked using the appropriate principal-minors test (see the appendix to this chapter). Hence, $D^{2} f(x)$ is negative definite, and $f$ is strictly concave if the leading principal minors alternate in sign, with $f_{11}<0$, that is, if

$$
(-1)^{r}\left|\begin{array}{cccc}
f_{11} & \cdots \cdots & f_{1 r} \\
\cdots & \cdots & \cdots & \cdots \\
f_{r 1} & \cdots & \cdots & f_{r r}
\end{array}\right|>0 \quad \text { for } r=1,2, \ldots, n
$$

and strictly convex if $D^{2} f(x)$ is positive definite, which requires that all leading principal minors be positive, that is,

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-266.jpg?height=176&width=557&top_left_y=1123&top_left_x=460)

## 3. Quasiconcave Functions

Definition 3.1. Quasiconcavity. Let $f: \mathbb{R}^{\mathrm{n}} \supseteq X \rightarrow \mathbb{R}$ be a real-valued function defined on a convex set $X$. We say that $f$ is quasiconcave if for all $x^{\prime}$ and $x^{\prime \prime}$ in $X$ and all $\lambda \in[0,1]$ we have

$$
f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right] \geq \min \left\{f\left(x^{\prime}\right), f\left(x^{\prime \prime}\right)\right\}
$$

We say that $f$ is strictly quasiconcave if for all $x^{\prime}$ and $x^{\prime \prime}$ in $X$ and all $\lambda \in$ $(0,1)$ we have

$$
f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right]>\min \left\{f\left(x^{\prime}\right), f\left(x^{\prime \prime}\right)\right\}
$$

Given two points $x^{\prime}$ and $x^{\prime \prime}$ in $X$, suppose that $f\left(x^{\prime}\right) \geq f\left(x^{\prime \prime}\right)$. Then quasiconcavity requires that as we move along the line segment from the "low point," $x^{\prime \prime}$, to the "high point," $x^{\prime}$, the value of $f$ never falls below $f\left(x^{\prime \prime}\right)$. Figure 6.16 shows an example of a quasiconcave function.

The following result shows that quasiconcavity is equivalent to the convexity of the upper contour sets. The proof is left as an exercise.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-267.jpg?height=587&width=970&top_left_y=188&top_left_x=251)

Figure 6.16. A quasiconcave function.

Theorem 3.2. Let $\mathrm{f}$ be a real-valued function defined on a convex set $\mathrm{X} \subseteq$ $\mathbb{R}^{n}$. Then $\mathrm{f}$ is quasiconcave if and only if the upper contour sets of $\mathrm{f}$ are all convex, that is, if for any $\alpha \in \mathbb{R}$ the set

$$
\mathrm{U}_{\alpha}=\{\mathrm{x} \in \mathrm{X} ; \mathrm{f}(\mathrm{x}) \geq \alpha\}
$$

is convex.

Problem 3.3. Prove Theorem 3.2.

A direct implication of this result is that concavity implies quasiconcavity. It is also easy to show that strict concavity implies strict quasiconcavity, but the converse statements are not true. Hence, quasiconcavity is a weaker property than concavity, and quasiconcave functions need not inherit some of the useful properties of concave functions. For example, a quasiconcave function, unlike a concave one, may have discontinuities at interior points of its domain, and a nonnegative linear combination of quasiconcave functions may not be quasiconcave. The following theorem shows, however, that quasiconcavity is preserved under increasing (and not necessarily concave) transformations.

Theorem 3.4. Let $\mathrm{f}$ be a quasiconcave function defined on a convex set $\mathrm{X} \subseteq$ $\mathbb{R}^{n}$, and let $\mathrm{g}: \mathbb{R} \longrightarrow \mathbb{R}$ be a weakly increasing function defined on an interval $\mathrm{I}$ that contains $\mathrm{f}(\mathrm{X})$. Then the composite function $\mathrm{g}[\mathrm{f}(\mathrm{x})]$ is quasiconcave in $\mathrm{X}$.

Problem 3.5. Prove Theorem 3.4.

Problem 3.6. Show that the Cobb-Douglas function

$$
f(x)=A \prod_{i=1}^{n} x_{i}^{\alpha_{2}}, \quad \text { where } \alpha_{i}>0 \forall i
$$

is quasiconcave for $x \gg \underline{0}$. Hint: Consider $\ln f(x)$, and use Theorems 2.18 and 3.4.

We will now obtain a characterization of quasiconcavity for $C^{1}$ functions that resembles its analogue for smooth concave functions.

Theorem 3.7. Let $\mathrm{f}$ be a real-valued $\mathrm{C}^{l}$ function defined on an open and convex set $\mathrm{X} \subseteq \mathbb{R}^{n}$. Then $\mathrm{f}$ is quasiconcave in $\mathrm{X}$ if and only if for every $\mathrm{x}^{\prime}$ and $\mathrm{x}^{\prime \prime}$ in $\mathrm{X}$ we have

$$
f\left(x^{\prime \prime}\right) \leq f\left(x^{\prime}\right) \Rightarrow \operatorname{Df}\left(x^{\prime \prime}\right)\left(x^{\prime}-x^{\prime \prime}\right) \geq 0
$$

If, moreover,

$$
\mathrm{x}^{\prime} \neq \mathrm{x}^{\prime \prime} \text { and } \mathrm{f}\left(\mathrm{x}^{\prime \prime}\right) \leq \mathrm{f}\left(\mathrm{x}^{\prime}\right) \Rightarrow \operatorname{Df}\left(\mathrm{x}^{\prime \prime}\right)\left(\mathrm{x}^{\prime}-\mathrm{x}^{\prime \prime}\right)>0
$$

then $\mathrm{f}$ is strictly quasiconcave, but the converse statement is not necessarily true.

Proof. Given $x^{\prime}$ and $x^{\prime \prime}$ in $X$ and $\lambda \in[0,1]$, define

$$
g(\lambda)=f\left[x^{\prime \prime}+\lambda\left(x^{\prime}-x^{\prime \prime}\right)\right]
$$

Because $f$ is $C^{1}, g$ is differentiable, and

$$
g^{\prime}(\lambda)=D f\left[x^{\prime \prime}+\lambda\left(x^{\prime}-x^{\prime \prime}\right)\right]\left(x^{\prime}-x^{\prime \prime}\right)
$$

(i) Assume that $f$ is quasiconcave and $f\left(x^{\prime}\right) \geq f\left(x^{\prime \prime}\right)$. Then

$$
\begin{equation*}
g(\lambda)=f\left[x^{\prime \prime}+\lambda\left(x^{\prime}-x^{\prime \prime}\right)\right] \geq f\left(x^{\prime \prime}\right)=g(0) \forall \lambda \in[0,1] \tag{1}
\end{equation*}
$$

Hence, $g$ is weakly increasing at zero, with

$$
g^{\prime}(0)=D f\left(x^{\prime \prime}\right)\left(x^{\prime}-x^{\prime \prime}\right) \geq 0
$$

If $f$ is strictly quasiconcave, (1) holds with strict inequality, and $g$ is strictly increasing at zero - but note that this does not imply $g^{\prime}(0)>0$ (e.g., $f(x)=x^{3}$ is strictly increasing at 0 , even though $f^{\prime}(0)=0$ ).

(ii) Assume that $f\left(x^{\prime}\right) \geq f\left(x^{\prime \prime}\right)$ implies $D f\left(x^{\prime \prime}\right)\left(x^{\prime}-x^{\prime \prime}\right) \geq 0$ for any $x^{\prime}$ and $x^{\prime \prime}$ in $X$. We want to show that this implies the quasiconcavity of $f$, that is,

$$
g(\lambda)=f\left[x^{\prime \prime}+\lambda\left(x^{\prime}-x^{\prime \prime}\right)\right] \geq f\left(x^{\prime \prime}\right)=g(0) \forall \lambda \in[0,1]
$$

Assume that this is not true. That is, suppose that there exists some $\lambda^{0} \in(0,1)$ such that $g\left(\lambda^{0}\right)<g(0)$. Because $g(1)=f\left(x^{\prime}\right) \geq f\left(x^{\prime \prime}\right)=g(0)$, we can choose $\lambda^{0}$ such that $g^{\prime}\left(\lambda^{0}\right)>0$ (if $g^{\prime}(\lambda)<0$ for all $\lambda$ such that $g(\lambda)<g(0)$, then we cannot have

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-269.jpg?height=565&width=724&top_left_y=195&top_left_x=374)

Figure 6.17.

$g(1) \geq g(0)$ as suggested in Figure 6.17). We will show that the existence of such a $\lambda^{0}$ leads to a contradiction.

Put $x^{0}=x^{\prime \prime}+\lambda^{0}\left(x^{\prime}-x^{\prime \prime}\right)$. Because

$$
f\left(x^{\prime \prime}\right)=g(0)>g\left(\lambda^{0}\right)=f\left(x^{0}\right)
$$

and $x^{0}$ is in $X$, we have, by assumption,

$$
D f\left(x^{0}\right)\left(x^{\prime \prime}-x^{0}\right)=D f\left(x^{0}\right)\left(-\lambda^{0}\right)\left(x^{\prime}-x^{\prime \prime}\right) \geq 0
$$

and hence

$$
D f\left(x^{0}\right)\left(x^{\prime}-x^{\prime \prime}\right) \leq 0
$$

On the other hand,

$$
g^{\prime}\left(\lambda^{0}\right)=D f\left(x^{0}\right)\left(x^{\prime}-x^{\prime \prime}\right)>0
$$

by assumption, which contradicts the foregoing expression. Hence, there can be no $\lambda^{0} \in(0,1)$ such that $g\left(\lambda^{0}\right)<g(0)$, and we conclude that $f$ is quasiconcave. The same logic will work for the case of strict quasiconcavity.

Let $f$ be a $C^{1}$ quasiconcave function, and $x^{\prime}$ and $x^{\prime \prime}$ two points in its domain, with $f\left(x^{\prime \prime}\right) \leq f\left(x^{\prime}\right)$. The preceding theorem says that the directional derivative

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-269.jpg?height=52&width=1263&top_left_y=1815&top_left_x=107)
negative. Roughly speaking, the derivative gives us the correct signal about the direction of change of the function, which is quite helpful when looking for a maximum. Notice, however, that plain quasiconcavity is compatible with a zero directional derivative at $x^{\prime \prime}$ even if $f\left(x^{\prime \prime}\right)<f\left(x^{\prime}\right)$. Hence, a zero gradient could send the wrong signal that $x^{\prime \prime}$ is a candidate for a maximum. Strict quasiconcavity rules out this possibility, as does pseudoconcavity, a concept we now define.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-270.jpg?height=529&width=578&top_left_y=186&top_left_x=107)

$f$ strictly quasiconcave, $\operatorname{Df}\left(x^{\prime \prime}\right)\left(x^{\prime}-x^{\prime \prime}\right)>0$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-270.jpg?height=518&width=689&top_left_y=196&top_left_x=682)

f quasiconcave but not strictly so, $\operatorname{Df}\left(x^{\prime \prime}\right)\left(x^{\prime}-x^{\prime \prime}\right)=0$

Figure 6.18.

Definition 3.8. Pseudoconcavity. A $C^{1}$ function $f$ is pseudoconcave in a set $X$ if given any two points $x^{\prime}$ and $x^{\prime \prime}$ in $X$ we have that

$$
f\left(x^{\prime}\right)>f\left(x^{\prime \prime}\right) \Rightarrow D f\left(x^{\prime \prime}\right)\left(x^{\prime}-x^{\prime \prime}\right)>0
$$

Note that strict quasiconcavity implies pseudoconcavity, but quasiconcavity does not, as illustrated in Figure 6.18. The following problem shows that nonstationarity is also sufficient to guarantee the pseudoconcavity of a quasiconcave function.

Problem 3.9. A $C^{1}$ function that has no critical points (i.e., such that $D f(x)$ $\neq \underline{0}$ for all $x$ ) is said to be nonstationary. Show that a nonstationary $C^{1}$ quasiconcave function is pseudoconcave.

Hint: Let $x^{\prime}$ and $x^{\prime \prime}$ be any two points in the domain of $f$ such that $f\left(x^{\prime}\right)>$ $f\left(x^{\prime \prime}\right)$. Define the point $\hat{x}$ by $\hat{x}_{1}=x_{1}^{\prime}-\varepsilon$, and $\hat{x}_{i}=x_{i}^{\prime}$ for $i=2, \ldots, n$, and show that for $\varepsilon>0$ and sufficiently small, $D f\left(x^{\prime \prime}\right)\left(\hat{x}-x^{\prime \prime}\right)<0$, which contradicts the quasiconcavity of $f$.

Problem 3.10. Suppose $f: \mathbb{R}_{++}^{\mathbf{n}} \longrightarrow \mathbb{R}$ is $C^{1}$, homogeneous of degree 1 , and positive-valued. Show that $f$ is concave if and only if it is quasiconcave.

Hint: Concavity always implies quasiconcavity. To prove the other part of the theorem, let $x^{\prime}$ and $x^{\prime \prime}$ be two points in $\mathbb{R}_{++}^{\mathbf{n}}$. Because $f \geq 0$, we can define $\lambda$ by $\lambda=f\left(x^{\prime}\right) / f\left(x^{\prime \prime}\right)$ and $\lambda>0$. Because $f$ is homogeneous of degree 1 , we have

$$
\begin{equation*}
f\left(\lambda x^{\prime \prime}\right)=\lambda f\left(x^{\prime \prime}\right)=f\left(x^{\prime}\right) \tag{1}
\end{equation*}
$$

and quasiconcavity therefore implies that

$$
\begin{equation*}
D f\left(\lambda x^{\prime \prime}\right)\left(x^{\prime}-\lambda x^{\prime \prime}\right) \geq 0 \tag{2}
\end{equation*}
$$

Exploiting the properties of homogeneous functions, show that (1) implies $D f\left(x^{\prime \prime}\right)\left(x^{\prime}-x^{\prime \prime}\right) \geq f\left(x^{\prime}\right)-f\left(x^{\prime \prime}\right)$ and therefore the concavity of $f$.

The following theorem gives some useful second-derivative characterizations of quasiconcavity. For a proof and further results, see Arrow and Enthoven (1961) and Crouzeix and Ferland (1982).

Theorem 3.11. Let $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$ be a $\mathrm{C}^{2}$ function defined on an open and convex set $\mathrm{X} \subseteq \mathbb{R}^{n}$, and let $\overline{\mathrm{H}}_{\mathrm{r}}$ be the leading principal minor of the bordered Hessian of $\mathrm{f}$, given by

$$
\overline{\mathrm{H}}_{\mathrm{r}}=\left|\begin{array}{cccc}
0 & \mathrm{f}_{l} & \cdots & \mathrm{f}_{\mathrm{r}} \\
\mathrm{f}_{l} & \mathrm{f}_{I I} & \cdots & \mathrm{f}_{I \mathrm{r}} \\
\cdots & \cdots & \cdots & \cdots \\
\mathrm{f}_{\mathrm{r}} & \mathrm{f}_{\mathrm{r}} & \cdots & \mathrm{f}_{\mathrm{rr}}
\end{array}\right|
$$

(i) A necessary condition for the quasiconcavity of $\mathrm{f}$ is that

$$
(-1)^{\mathrm{r}} \overline{\mathrm{H}}_{\mathrm{r}} \geq 0 \forall \mathrm{r}=1, \ldots, \mathrm{n} \text { and } \forall \mathrm{x} \in \mathrm{X}
$$

(ii) A sufficient condition for $\mathrm{f}$ to be quasiconcave is that

$$
(-1)^{\mathrm{r}} \overline{\mathrm{H}}_{\mathrm{r}}>0 \forall \mathrm{r}=1, \ldots, \mathrm{n} \text { and } \forall \mathrm{x} \in \mathbb{R}_{+}^{n}
$$

(iii) If $\mathrm{X} \subseteq \mathbb{R}_{++}^{\mathrm{n}}$, if $\mathrm{f}$ is monotonically increasing, and if

$$
(-1)^{\mathrm{r}} \overline{\mathrm{H}}_{\mathrm{r}}>0 \forall \mathrm{r}=1, \ldots, \mathrm{n} \text { and } \forall \mathrm{x} \in \mathrm{X}
$$

then $\mathrm{f}$ is strictly quasiconcave.

The following problem asks the reader to give a direct proof for a special case of Theorem 3.11.

Problem 3.12. Let $f: \mathbb{R}^{2} \supseteq X \longrightarrow \mathbb{R}$ be a $C^{2}$ function defined on an open and convex set $X \subseteq \mathbb{R}^{\mathbf{n}}$, with $f_{x}(x, y)>0$ and $f_{y}(x, y)>0$ for all $(x, y)$ in $X$. Show that $f(x, y)$ is quasiconcave in $X$ if and only if

$$
|B|=\left|\begin{array}{lll}
0 & f_{x} & f_{y} \\
f_{x} & f_{x x} & f_{x y} \\
f_{y} & f_{x y} & f_{y y}
\end{array}\right|>0 \forall x \in X
$$

Hint: Use the characterization of quasiconcavity in terms of the convexity of upper contour sets (Theorem 3.2). Apply the implicit-function theorem to an arbitrary level set of $f(x, y)$ to define a function $y=g(x)$, compute the second derivative of this function, and use Theorem 2.2.

## Concavifiable functions

As we will see in Chapter 7, the solutions of maximization problems involving concave (objective and constraint) functions are particularly easy to characterize. These nice results can be easily extended to a larger class of functions by observing that a monotonically increasing tranformation preserves the set of maximizers and, more generally, the family of upper contour sets of a given function. It follows that whenever the function of interest can be transformed into a concave function by a monotonically increasing transformation, we are back, effectively, to the relatively simple problem of maximizing a concave function. Functions that have this convenient property are said to be concavifiable.

Definition 3.13. Concavifiable function. Let $f: \mathbb{R}^{\mathfrak{n}} \supseteq X \rightarrow \mathbb{R}$ be a function defined on a convex set $X \subseteq \mathbb{R}^{\mathrm{n}}$. We say that $f$ is concavifiable in $X$ if there exists a $C^{1}$ and strictly increasing function $h: \mathbb{R} \supseteq A \longrightarrow \mathbb{R}$ defined on a set $A$ that contains $f(X)$ such that $g(x)=h[f(x)]$ is a concave function.

Because concave functions have convex upper contour sets, and increasing transformations preserve the family of such sets, a necessary condition for concavifiability is that the given function be quasiconcave. This is not sufficient, however, as shown in Problem 3.15. The following result shows that a sufficient condition for a smooth quasiconcave function to be concavifiable in a compact set is that its partial derivatives be strictly positive in the set.

Theorem 3.14. A sufficient condition for concavifiability. Let $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow$ $\mathbb{R}$ be a $\mathrm{C}^{2}$ quasiconcave function defined on an open and convex set $\mathrm{X} \subseteq$ $\mathbb{R}^{n}$. Suppose $\mathrm{f}_{\mathrm{i}}(\mathrm{x})>0$ for all $\mathrm{x}$ in $\mathrm{X}$. Then the restriction of $\mathrm{f}$ to any compact and convex subset $\mathrm{C}$ of $\mathrm{X}$ is concavifiable. In particular, there exists some number $\beta>0$ such that the function $\mathrm{g}: \mathrm{X} \supseteq \mathrm{C} \longrightarrow \mathbb{R}$ defined by $\mathrm{g}(\mathrm{x})=-\mathrm{e}^{-\beta \mathrm{f}(\mathrm{x})}$ is concave.

Proof. We shall prove the result for the case of a univariate function. The idea is the same in the general case, but checking the sign (definiteness) of the second derivative is a bit more complicated.

Differentiating the function $g(x)=-e^{-\beta f(x)}$, we see that

$$
g^{\prime}(x)=\beta f^{\prime}(x) e^{-\beta f(x)}
$$

and

$$
g^{\prime \prime}(x)=\beta\left[-f^{\prime}(x) \beta f^{\prime}(x) e^{-\beta f(x)}+e^{-\beta f(x)} f^{\prime \prime}(x)\right]=\beta e^{-\beta f(x)}\left[f^{\prime}(x)\right]^{2}\left(\frac{f^{\prime \prime}(x)}{\left[f^{\prime}(x)\right]^{2}}-\beta\right)
$$

Let $C$ be a convex and compact subset of $X$. Because $f$ is $\left.C^{2}, f^{\prime \prime}(x) /\left[f^{\prime}(x)\right]^{2}\right)$ is a continuous function, and therefore it attains a maximum in $C$, by the extreme-value theorem. Call this maximum $\mu$. If we choose $\beta$ to be positive and larger than $\mu$, then we have $g^{\prime \prime}(x)<0$ for all $x$ in $C$, and it follows that $g()$ is concave, by Theorem 2.18.

Problem 3.15. Show that the function $f(x)=x^{3}$ cannot be concavified in any set that has zero as an interior point. Hint: Use Theorem 2.17.

## Appendix: Quadratic Forms

Definition A.1. Quadratic form. A quadratic form is a function $Q: \mathbb{R}^{\mathbf{n}} \longrightarrow$ $\mathbb{R}$ of the form

$$
Q(x)=x^{T} A x=\sum_{i=1}^{n} \sum_{k=1}^{n} a_{i k} x_{i} x_{k}
$$

where $A=\left[a_{i k}\right]$ is a symmetric square matrix with real entries, $x \in \mathbb{R}^{\mathrm{n}}$ is a column vector, and $x^{T}$ is its transpose.

Definition A.2. Definite quadratic form. A quadratic form $Q(x)=x^{T} A x$ (or its associated matrix $A$ ) is

- positive definite if $Q(x)=x^{T} A x>0$ for all $x \in \mathbb{R}^{\mathrm{n}}$ other than the zero vector,
- positive semidefinite if $Q(x)=x^{T} A x \geq 0$ for all $x \in \mathbb{R}^{\mathrm{n}}$,
- negative definite if $Q(x)=x^{T} A x<0$ for all $x \in \mathbb{R}^{\mathrm{n}}$, with $x \neq \underline{0}$,
- negative semidefinite if $Q(x)=x^{T} A x \leq 0$ for all $x \in \mathbb{R}^{n}$,
- indefinite if it is neither positive nor negative semidefinite, that is, if there exist vectors $x$ and $z$ in $\mathbb{R}^{\mathrm{n}}$ such that $x^{T} A x<0$ and $z^{T} A z>0$.

The next theorem gives necessary and sufficient conditions for the positive or negative definiteness of a matrix in terms of its eigenvalues.

Theorem A.3. Given a quadratic form $\mathrm{Q}(\mathrm{x})=\mathrm{x}^{\mathrm{T}} \mathrm{Ax}$, let $\lambda_{1}, \ldots, \lambda_{\mathrm{n}}$ be the eigenvalues of $\mathrm{A}$ (which will be real numbers, because $\mathrm{A}$ is symmetric). Then $\mathrm{Q}(\mathrm{x})$ is

- positive definite if and only if all eigenvalues of $\mathbf{A}$ are strictly positive (i.e., $\lambda_{i}>0$ $\forall$ i),
- positive semidefinite if and only if $\lambda_{\mathrm{i}} \geq 0 \forall \mathrm{i}=1, \ldots, \mathrm{n}$,
- negative definite if and only if $\lambda_{\mathrm{i}}<0 \forall \mathrm{i}=1, \ldots, \mathrm{n}$,
- negative semidefinite if and only if $\lambda_{\mathrm{i}} \leq 0 \forall \mathrm{i}=1, \ldots, \mathrm{n}$.

Proof. We show only that $Q(x)$ is positive definite if and only if $\lambda_{i}>0 \forall$ $i=1, \ldots, n$. The rest of the theorem follows by exactly the same logic.

- Necessity: $\left[x^{T} A x>0 \forall x \in \mathbb{R}^{\mathrm{n}}, x \neq \underline{0}\right] \Rightarrow\left[\lambda_{i}>0 \forall i=1, \ldots, n\right]$

Let $x_{l}$ be the normalized eigenvector of $A$ (i.e., with norm 1) associated with the eigenvalue $\lambda_{i}$. By definition,

$$
\begin{equation*}
A x_{i}=\lambda_{i} x_{i} \tag{1}
\end{equation*}
$$

Premultiplying (1) by $x_{i}^{T}$, we have

$$
\begin{equation*}
0<x_{i}^{T} A x_{i}=\lambda_{i} x_{i}^{T} x_{t}=\lambda_{i} \tag{2}
\end{equation*}
$$

where the inequality holds by the assumption that $A$ is positive definite, and the last equality holds because $x_{i}^{T} x_{i}=\left\|x_{i}\right\|_{E}=1$ by assumption.

- Sufficiency: $\left[\lambda_{i}>0 \forall i=1, \ldots, n\right] \Rightarrow\left[x^{T} A x>0 \forall x \in \mathbb{R}^{\mathrm{n}}, x \neq \underline{0}\right]$

Because $A$ is a symmetric real matrix, it has a full set of linearly independent (actually orthogonal) eigenvectors. Hence the matrix $E$, with the normalized eigenvectors as columns, is invertible and satisfies ${ }^{7}$

$$
E^{T} A E=\Lambda
$$

where $\Lambda$ is the diagonal matrix with the eigenvalues of $A\left(\lambda_{i}\right)$ along its principal diagonal.

Putting $y=E^{-1} x$, we can write $Q()$ in the form

$$
\begin{equation*}
Q(x)=x^{T} A x=y^{T} E^{T} A E y=y^{T} \Lambda y=\sum_{i=1}^{n} \lambda_{i} y_{i}^{2} \tag{3}
\end{equation*}
$$

Hence, a quadratic form can always be written as the weighted sum of squares of a transformed vector $y$, with the eigenvalues of $A$ as weights.

From (3) it is clear that if all the eigenvalues are positive, $Q(x)$ is positive, whatever the value of $x$ (or $y$ ), as long as $x \neq \underline{0}(\Rightarrow y \neq \underline{0})$.

An alternative test of sign definiteness for quadratic forms uses the concepts of principal minor and leading principal minor of a matrix. If $A$ is an $n \times n$ matrix, and we eliminate $n-k$ rows and the corresponding columns of $A$, we obtain a submatrix of dimension $k \times k$. The determinant of this submatrix is called a principal minor of order $k$ of $A$. The leading principal minors of $A$ are the principal minors obtained by keeping the first $k$ rows and columns of $A$. Hence, the leading principal minor of order $k$ of the matrix $A$, denoted $d_{k}$, is the determinant of the square $k \times k$ matrix $A_{k}$, formed by the first $k$ columns and rows of $A$ :

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-274.jpg?height=181&width=447&top_left_y=1848&top_left_x=510)

Theorem A.4. The quadratic form $\mathrm{Q}(\mathrm{x})=\mathrm{x}^{\mathrm{T}} \mathrm{Ax}$ is positive definite if and only if all the leading principal minors of $\mathrm{A}\left(\mathrm{d}_{\mathrm{i}} ; \mathrm{i}=1, \ldots, \mathrm{n}\right)$ are positive, and negative definite if and only if (iff) their signs alternate with $\mathrm{d}_{1}<0$. That is,

- $\mathrm{Q}(\mathrm{x})$ is positive definite iff $\mathrm{d}_{1}>0, \mathrm{~d}_{2}>0, \ldots, \mathrm{d}_{\mathrm{n}}=|\mathrm{A}|>0$,
- $\mathrm{Q}(\mathrm{x})$ is negative definite iff $\mathrm{d}_{1}<0, \mathrm{~d}_{2}>0, \mathrm{~d}_{3}<0, \ldots$

Moreover, $\mathrm{Q}$ is positive semidefinite if and only if all the principal minors of A are nonnegative.

Note that we can determine whether a quadratic form is positive or negative definite by checking the signs of only the leading principal minors, but we have to check all the principal minors to see if it is positive semidefinite. To test for negative semidefiniteness, observe that $A$ is negative semidefinite if and only if $-A$ is positive semidefinite.

Proof. We prove only the necessity of the leading-principal-minor condition for sign definiteness.

- Consider first the case of positive definiteness. We want to show that

$$
\left[x^{T} A x>0 \forall x \in \mathbb{R}^{\mathrm{n}}, x \neq 0\right] \Rightarrow\left[d_{i}>0 \forall i=1, \ldots, n\right]
$$

If $A$ is positive definite, then $x^{T} A x>0$ for any $x \neq \underline{0}$. Consider vectors whose first elements are nonzero and whose last $n-r$ elements are all zero: $x=\left(x_{r}, \underline{0}\right)$. The corresponding quadratic form is

$$
Q(x)=x^{T} A x=\left[x_{r}, \underline{0}\right]\left[\begin{array}{c}
A_{r} *  \tag{1}\\
* *
\end{array}\right]\left[\begin{array}{c}
x_{r} \\
\underline{0}
\end{array}\right]=x_{r}^{r} A_{r} x_{r}>0
$$

where the "*" terms represent the last $n-r$ columns and rows of $A$, which will be wiped out by the zero subvector of $x$. Because the original form is assumed to be positive definite, we have $x_{r}^{T} A_{r} x_{r}>0$, and this new "smaller" form is also positive definite. By Theorem A.3, this implies that the eigenvalues of the matrix $A_{r}$ are all positive, and hence its determinant $\left|A_{r}\right|=d_{r}$ (which is the leading principal minor of order $r$ of $A$ ) is also positive. ${ }^{8}$ If $A$ is positive definite, regardless of how many zeros we put in $x, Q(x)>0$, so $\left|A_{r}\right|>0$ for all $r=1, \ldots, n$. Positive definiteness requires that all leading principal minors be positive.

- To derive conditions for negative definiteness, note that

$$
\left[x^{T} A x>0 \forall x \in \mathbb{R}^{\mathrm{n}}, x \neq \underline{0}\right] \Leftrightarrow\left[-x^{T} A x=x^{T}(-A) x<0 \forall x \in \mathbb{R}^{\mathrm{n}}, x \neq \underline{0}\right]
$$

so $A$ is positive definite if and only if $-A$ is negative definite, and vice versa. Moreover,

$$
|-A|=(-1)^{n}|A| \quad \text { (where } n \text { is the order of the square matrix } A \text { ) }
$$

Hence, $A$ will be negative semidefinite if and only if $-A$ is positive definite, requiring

$$
\left|-A_{i}\right|=(-1)^{n}\left|A_{i}\right|=(-1)^{n} d_{i}>0 \forall i=1, \ldots, n \Leftrightarrow d_{1}<0, d_{2}>0, d_{3}<0, \ldots .
$$

For a proof of the sufficiency part of the theorem, see Hadley (1973, p. 261).

A useful property of positive definite (semidefinite) matrices is that their diagonal elements must be positive (nonnegative). To see this, consider the vector $e_{i}=(0, \ldots, 0,1,0, \ldots, 0)^{T}$, whose components are all zero except the $i$ th, which is a 1 . Note that the quadratic form

$$
Q\left(e_{i}\right)=e_{i}^{T} A e_{i}=\sum_{i=1}^{n} \sum_{i=1}^{n} a_{i k} x_{i} x_{k}=a_{i i}
$$

gives us back the $i$ th diagonal element of the $A$ matrix. Hence, if $Q(x)>0$ for all $x$, we must have, in particular, $Q\left(e_{i}\right)=a_{i i}>0$. Clearly, a similar property holds for negative definite or semidefinite matrices.

A quadratic form is positive definite if its value exceeds zero when evaluated at any nonzero vector $x \in \mathbb{R}^{\mathrm{n}}$. In some cases we are interested only in whether a given quadratic form is positive or negative when evaluated at a particular set of vectors, for example, those that satisfy a certain system of linear equations.

Consider a quadratic form $Q(x)=x^{T} A x$, with $x \in \mathbb{R}^{\mathrm{n}}$, and a system of $m$ linear equations $B x=\underline{0}$, where $B$ is an $m \times n$ matrix (with $m<n$ ) of rank $m$ (i.e., we assume that all equations are linearly independent, otherwise we eliminate the redundant ones). We form the bordered matrix

$$
\bar{A}=\left[\begin{array}{cc}
0_{m \times m} & B \\
B^{T} & A
\end{array}\right]
$$

and consider its leading principal minor of order $r$ :

$$
\left|\bar{A}_{r}\right|=\left[\begin{array}{cc}
0_{m \times m} & B_{m r} \\
B_{m r}^{T} & A_{r}
\end{array}\right]
$$

where $A_{r}$ is the square matrix formed by the first $r$ columns and rows of $A$, and $B_{m r}$ is the $m \times r$ matrix formed by keeping all the $m$ rows of $B$ and its first $r$ columns. The following result gives us necessary and sufficient conditions for the positive or negative definiteness of $A$ subject to the constraints $B x=\underline{0}$ in terms of the signs of the determinants $\left|\bar{A}_{r}\right|$.

Theorem A.5. Sign definiteness under constraints. The quadratic form $\mathrm{Q}(\mathrm{x})$ $=\mathrm{x}^{\mathrm{T}} \mathrm{Ax}$ is positive definite under the constraints $\mathrm{Bx}=\underline{0}$, if and only if the last $\mathrm{n}-\mathrm{m}$ leading principal minors of the bordered matrix $\overline{\mathrm{A}}$ are all of the same sign as $(-1)^{\mathrm{m}}$. That is, if $\mathrm{m}$ is even (odd), then all the last $\mathrm{n}-\mathrm{m}$ leading principal minors are positive (negative). This can be written

$$
(-1)^{\mathrm{m}}\left|\overline{\mathrm{A}}_{\mathrm{r}}\right|>0 \quad \text { for } \mathrm{r}=\mathrm{m}+1, \ldots, \mathrm{n}
$$

Moreover, $\mathrm{Q}$ is negative definite if and only if the last $\mathrm{n}-\mathrm{m}$ leading principal minors of the bordered matrix $\overline{\mathrm{A}}$ alternate in sign, with the first equal to $(-1)^{\mathrm{m}+1}$. That is,

$$
(-1)^{\mathrm{r}}\left|\overline{\mathbf{A}}_{\mathrm{r}}\right|>0 \quad \text { for } \mathrm{r}=\mathrm{m}+1, \ldots, \mathrm{n}
$$

Notice that as the number of constraints increases, we have to evaluate fewer determinants. This is not surprising, because an increase in the number of constraints reduces the size of the set of vectors for which we have to determine the sign of $Q$.

## Bibliography

Arrow, K., and Enthoven, A. 1961. Quasi-Concave Programming. Econometrica 29:779-800.

Bazaraa, M., and Shetty, C. 1976. Foundations of Optimization. Lecture Notes in Economics and Mathematical Systems, no. 122. Berlin: Springer-Verlag.

Beavis, B., and Dobbs, I. 1990. Optimization and Stability Theory for Economic Analysis. Cambridge University Press.

Benveniste, L., and Scheinkman, J. 1982. Duality Theory for Dynamic Optimizing Models in Economics: The Continuous Time Case. Journal of Economic Theory 30:1-19.

Bronsted, A. 1983. An Introduction to Convex Polytopes. Berlin: Springer-Verlag.

Crouzeix, J. P., and Ferland, J. 1982. Criteria for Quasi-Convexity and PseudoConvexity: Relationships and Comparisons. Mathematical Programming 23:193-205.

Green, J., and Heller, W. 1987. Mathematical Analysis and Convexity with Applications to Economics. In: Handbook of Mathematical Economics, vol. 1, ed. K. Arrow and M. Intriligator, Amsterdam: North Holland.

Hadley, G. 1973. Linear Algebra. Reading, MA: Addison-Wesley.

Lancaster, K. 1968. Mathematical Economics. New York: Macmillan.

Madden, P. 1986. Concavity and Optimization in Microeconomics. London: Basil Blackwell.

Mangasarian, O. 1982. Nonlinear Programming. Malabar, FL: Krieger.

Michel, P. 1984. Cours de Mathématiques pour Economistes. Paris: Economica.

Nikaido, H. 1968. Convex Structures and Economic Theory. New York: Academic Press.

Nikaido, H. 1972. Introduction to Sets and Mappings in Modern Economics. Amsterdam: North Holland.

Rockafellar, R. T. 1970. Convex Analysis. Princeton University Press.

Simon, C., and Blume, L. 1994. Mathematics for Economists. New York: Norton.

Sydsæter, K. 1984. Topics in Mathematical Analysis for Economists. Orlando, FL: Academic Press.

Sydsæter, K., and Hammond, P. 1995. Mathematics for Economic Analysis. Englewood Cliffs, NJ: Prentice-Hall.

Takayama, A. 1987. Mathematical Economics, 2nd ed. Cambridge University Press.

## Notes

1 Recall that $\lambda_{i}>0$, but there is no guarantee that $\alpha_{i}>0$ for all $i$.

2 If $X$ has no closure points different from $x$, then $\operatorname{cl} X=\{x\} \subseteq$ int $X$, and because int $X \subseteq \operatorname{cl} X$, we have int $X=\operatorname{cl} X$, a contradiction, except if $X=\mathbb{R}^{\mathrm{n}}$.

3 See Section 1 of Chapter 3.

4 If $X$ consists of a single point, $x$, then its affine hull consists also of a single point (has dimension zero), and int $X=x$. See Bazaraa and Shetty (1976) or Bronsted (1983) for a proof of these results.

5 The direction of the inequalities in the statement of the theorem does not matter. Notice that in order to reverse them, it suffices to take $H(-p,-\alpha)$.

6 Note that

$$
\left(z-x^{\lambda}\right)=z-\left[(1-\lambda) x^{0}+\lambda y\right]=z-\left[x^{0}+\lambda\left(y-x^{0}\right)\right]=-p-\lambda\left(y-x^{0}\right) \text { and }\left(z-x^{0}\right)=-p
$$

Hence,

$$
\begin{aligned}
\left\|z-x^{\lambda}\right\|^{2} & =\left(z-x^{\lambda}\right)^{T}\left(z-x^{\lambda}\right)=\left[p+\lambda\left(y-x^{0}\right)\right]^{T}\left[p+\lambda\left(y-x^{0}\right)\right] \\
& =\|p\|^{2}+2 \lambda p\left(y-x^{0}\right)+\lambda^{2}\left\|y-x^{0}\right\|^{2}
\end{aligned}
$$

and

$$
\left\|z-x^{0}\right\|^{2}-\left\|z-x^{\lambda}\right\|^{2}=-\lambda\left(2 p\left(y-x^{0}\right)+\lambda\left\|y-x^{0}\right\|^{2}\right)
$$

7 See the discussion of eigenvalues, eigenvectors, and diagonalization of a square matrix in Chapter 4.

8 The product of the eigenvalues of a matrix is equal to its determinant.

## Static Optimization

One purpose in using economic models is to make predictions concerning the behavior of individuals and groups in certain situations of interest. Clearly, this is possible only if their behavior exhibits some sort of regularity. In economic theory, it is typically assumed that the source of such regularity is the rationality of the agents involved - an axiom that is generally understood to mean that

(i) economic agents have well-specified and consistent preferences over the set of possible results of their actions, and,

(ii) given those preferences, they choose their actions so as to obtain the best result among those available.

The postulate of rationality naturally leads us to model the behavior of economic agents as the outcome of a constrained optimization problem. This approach imposes a unifying structure on any model of the behavior of a single agent and provides us a method for reducing situations of economic interest to tractable mathematical problems. This chapter deals with the "technology" for analyzing such problems (i.e., the theory of nonlinear programming or constrained optimization).

## 1. Nonlinear Programming

The term "mathematical programming" or "nonlinear programming" (NLP) refers to a set of mathematical methods for characterizing the solutions to constrained optimization problems. In general terms, the basic programming problem can be written

$$
\begin{equation*}
\max _{x}\{f(x ; \alpha) ; x \in C(\alpha)\} \tag{P}
\end{equation*}
$$

That is, given some value of $\alpha$, we seek the value of $x$ that will maximize the function $f(\cdot \alpha)$ within the set $C(\alpha)$. In this expression,

- $x=\left(x_{1}, \ldots, x_{n}\right) \in X \subseteq \mathbb{R}^{\mathrm{n}}$ is a vector of decision variables or choice variables,
- $\alpha=\left(\alpha_{1}, \ldots, \alpha_{p}\right) \in \Omega \subseteq \mathbb{R}^{\mathrm{p}}$ is a vector of parameters whose values we take as given,
- $C(\alpha) \subseteq X$, the constraint set or feasible set, is the set of all feasible values of $x$ for given values of the parameters $\alpha$, and
- $f$ is a real-valued function $f: \mathbb{R}^{\mathrm{n}+\mathrm{p}} \supseteq X \times \Omega \longrightarrow \mathbb{R}$, known as the objective function.

For our purposes, the following interpretation will often be appropriate. Let $\Omega$ be the set of all possible "environments" in which an agent may find himself, each described by a value of the parameter vector $\alpha$, and let $X$ be the set of all actions that may conceivably be available to him. Given a value of $\alpha$, the agent will find his choices restricted to some subset $C$ of $X$ (e.g., the budget set, in consumer theory). Changes in the parameters will result in changes in the feasible set, as described by the constraint correspondence, $C: \Omega \rightarrow \rightarrow X$.

The function $f: X \times \Omega \longrightarrow \mathbb{R}$ is the agent's objective function; $f(x ; \alpha)$ gives his payoff when he faces environment $\alpha$ and chooses action $x$. A rational agent will choose an optimal plan, defined as one that will maximize the value of the objective function over the constraint set for the given value of the parameter vector. The set of optimal actions is described by the decision rule or best-response correspondence $S(\alpha)$,

$$
S: \Omega \rightarrow \rightarrow X, \quad \text { where } S(\alpha)=\arg \max _{x}\{f(x ; \alpha) ; x \in C(\alpha)\}
$$

That is, $S(\alpha)$ is the set whose elements $x^{*}$ are the optimal solutions of (P). If the solution to $(\mathrm{P})$ is unique for each value of $\alpha$, the best-response correspondence becomes a function, and we write $x^{*}=x(\alpha)$.

The payoff accruing to an optimizing agent is given by the (maximum-) value function, $V: \Omega \longrightarrow \mathbb{R}$, defined by

$$
V(\alpha)=\max _{x}\{f(x ; \alpha) ; x \in C(\alpha)\}=f\left(x^{*}, \alpha\right), \quad \text { where } x^{*} \in S(\alpha)
$$

Given a value of the parameter vector, $V()$ yields the highest attainable payoff. Clearly, $V()$ is identically equal to the value of the objective function $f()$ evaluated at an optimal solution $x^{*}$ for the given $\alpha$.

In most economic applications we are interested in the comparative statics and other properties of the decision rule $S(\alpha)=\arg \max _{x}\{f(x ; \alpha) ; x \in C(\alpha)\}$. That is, we would like to know how the behavior of an agent varies in response to changes in his environment (the prices he faces, his income, etc.). Mathematically, the question is how the solution to the problem $(\mathrm{P})$ changes with the parameters $\alpha$. The problem should be familiar from an earlier chapter, but the "form" of the model looks different. The main task of this section is to show how, given certain differentiability assumptions, $(\mathrm{P})$ can be reduced to an equivalent system of equations that can be analyzed by the
methods developed in Chapter 5. This is what "characterizing the solution to $(\mathrm{P})$ " means.

We will consider three versions of the programming problem that differ in terms of the way in which the feasible set is described:

- Convex constraint set. $C$ is a convex subset of $\mathbb{R}^{n}$; as special cases, we have the case of unconstrained maximization, where $C$ is the whole of $\mathbb{R}^{\mathrm{n}}$, and maximization subject to nonnegativity constraints, where the feasible set is the nonnegative orthant of $\mathbb{R}^{\mathrm{n}}$.
- Lagrange problem. The constraint set is defined by a set of equality constraints:

$$
C(\alpha)=\{x \in X ; g(x ; \alpha)=\underline{0}\}
$$

- Kuhn-Tucker problem. The constraint set is defined by a set of inequality constraints:

$$
C(\alpha)=\{x \in X ; g(x ; \alpha) \geq \underline{0}\}
$$

We will start with the simplest case and then proceed by manipulating each new problem in order to reduce it to one we already know how to handle. For the most part, we will assume that the objective and constraint functions are either once or twice continuously differentiable. This will allow us to use the calculus and obtain results stated in terms of first and second derivatives.

The results we seek in this section are necessary and sufficient conditions for a solution to the constrained optimization problem (P). First-order necessary conditions allow us to identify potential maximizers as the solutions of a system of equations involving first derivatives. These equations are obtained from the observation that, starting from an optimal solution $x^{*}$, any sufficiently small movement that keeps us inside the feasible set cannot increase the value of the objective function. If the relevant functions are sufficiently smooth, this translates into some generalization of the zeroderivative rule for a local maximum of a univariate real-valued function. Sufficient conditions are then used to identify the true optimal solutions within the set of candidates, or to ensure that this set cannot contain minimizers or other "false signals." Essentially, sufficient conditions tell us that if the function has a certain curvature (either locally or globally) around a point that satisfies the necessary conditions, then this point must be a (local or global) solution to the programming problem.

Once we have characterized the solutions of $(P)$ in terms of a system of necessary conditions, the comparative-statics problem can be approached using the techniques of Chapter 5. Moreover, the fact that the system we shall be working with comes from an optimization problem will allow us to be more specific about the properties of the solution functions than we could be earlier. This will be discussed in detail in a later section.

## (a) Convex Constraint Set

Consider the problem

$$
\begin{equation*}
\max _{x}\{f(x) ; x \in C\} \tag{P.C}
\end{equation*}
$$

where $C$ is a convex set in $\mathbb{R}^{\mathrm{n}}$, and $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}$ is a $C^{2}$ function. We are omitting the parameters, because for the time being we are interested only in the solution to (P.C) for a fixed value of $\alpha$.

We are familiar with a special case of this problem. If $C=\mathbb{R}^{n}$, then a necessary condition for $x^{*}$ to be a maximizer of $f$ is that $D f\left(x^{*}\right)=\underline{0}$. In the more general case, however, this condition is neither necessary nor sufficient for a maximum. Figure 7.1 shows an example. Notice that $f^{\prime}(b)=f^{\prime}(c)=0$, but neither $b$ nor $c$ maximizes $f$ on $C=[a, b]$. On the other hand, $f$ achieves its maximum on this interval at the point $a$, but $f^{\prime}(a) \neq 0$.

The figure suggests that if the solution to the programming problem happens to be on the boundary of the feasible set, then one or more of the partial derivatives of the objective function may not be zero at the optimum. On the other hand, it must be true that as we move away from an optimum in a feasible direction, the value of the function will decrease. Hence, directional derivatives in feasible directions must be nonpositive. We now state this result formally.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-282.jpg?height=787&width=959&top_left_y=1342&top_left_x=250)

Figure 7.1. A zero derivative is neither necessary nor sufficient for a maximum.

Definition 1.1. Feasible direction. Consider the problem (P.C): $\max _{x}\{f(x)$; $x \in C\}$, where $C$ is a convex set. Take a point $x$ in $C$ and a direction vector $h$ in $\mathbb{R}^{n}$. We say that $h$ is a feasible direction from $x$ if there exists some $\delta>$ 0 such that

$$
x+\alpha h \in C \forall \alpha \in(0, \delta)
$$

that is, if any sufficiently small movement away from $x$ in the direction of $h$ leaves us inside the feasible set.

Theorem 1.2. First-order necessary conditions for a maximum. Assume that $\mathrm{f}$ is $\mathrm{C}^{\mathrm{I}}$, and let $\mathrm{x} *$ be an optimal solution of (P.C); then

$$
\operatorname{Df}\left(\mathrm{x}^{*}\right) \mathrm{h} \leq 0
$$

for every direction vector $\mathrm{h} \in \mathbb{R}^{n}$ feasible from $\mathrm{x}^{*}$.

Proof. Let $x^{*}$ be an optimal solution of (P.C), and $h$ an arbitrary direction vector feasible from $x^{*}$. Then there exists some $\delta>0$ (which may depend on $h)$ such that $x^{*}+\alpha h \in C$ for all $\alpha \in(0, \delta)$. Because any feasible movement away from $x^{*}$ reduces the value of the function, we have

$$
f\left(x^{*}+\alpha h\right) \leq f\left(x^{*}\right)
$$

for all $\alpha$ such that $x^{*}+\alpha h \in C$. Rearranging and dividing by $\alpha>0$,

$$
\begin{equation*}
\frac{f\left(x^{*}+\alpha h\right)-f\left(x^{*}\right)}{\alpha} \leq 0 \tag{1}
\end{equation*}
$$

and taking the limit of this expression as $\alpha \rightarrow 0$,

$$
\lim _{\alpha \rightarrow 0} \frac{f\left(x^{*}+\alpha h\right)-f\left(x^{*}\right)}{\alpha}=D f\left(x^{*} ; h\right)=D f\left(x^{*}\right) h \leq 0
$$

That is, the limit of the ratio on the left-hand side of (1) is the (one-sided) directional derivative of $f$ in the direction of $h$ evaluated at $x^{*}$. Because $f$ is $C^{1}$, the directional derivative exists and can be written as the scalar product of the derivative and the direction vector (see Chapter 4).

If $C$ is an open set, all its points are by definition interior, and given any $x$ in $C$, all directions are feasible from it. In this case the inequality $D f\left(x^{*}\right) h \leq 0$ can hold for all $h$ only if all first partial derivatives of $f$ are zero at $x^{*}$. Otherwise, it is possible to increase the value of the function by moving in the direction of (or opposite to) the coordinate vector corresponding to the nonzero partial. For example, suppose $f_{k}\left(x^{*}\right)>0$ and $f_{i}\left(x^{*}\right)=0$ for all $i \neq k$, and choose a direction vector $h$, with $h_{k}>0$ and $h_{i}=0$ for all $i \neq k$. Then

$$
D f\left(x^{*}\right) h=\sum_{i=1}^{n} f_{i}\left(x^{*}\right) h_{i}=f_{k}\left(x^{*}\right) h_{k}>0
$$

which contradicts Theorem 1.2. Hence, all partials must be zero at an optimum, and we have the following.

Corollary 1.3. Maximization in an open set. Assume that $\mathrm{f}$ is a $\mathrm{C}^{l}$ function and the constraint set $\mathrm{C}$ is open, and let $\mathrm{x}^{*}$ be an optimal solution to (P.C). Then

$$
\left.\operatorname{Df}\left(\mathrm{x}^{*}\right) \mathrm{h}=\underline{0} \quad \text { (i.e., } \partial \mathrm{f}\left(\mathrm{x}^{*}\right) / \partial \mathrm{x}_{\mathrm{i}}=0 \forall \mathrm{i}=1, \ldots, \mathrm{n}\right)
$$

Another special case of the convex-constraint-set problem is that in which $C=\mathbb{R}_{+}^{\text {n }}$ (i.e., where we maximize $f$ subject to the constraint that the choice variables be nonnegative). An argument similar to that used to establish Corollary 1.3 yields the following result.

Corollary 1.4. Maximization with nonnegativity constraints. If $\mathrm{C}=\mathbb{R}_{+}^{n}$ and $\mathrm{x}^{*}$ is an optimal solution of (P.C), then for each $\mathrm{i}=1, \ldots, \mathrm{n}$ we have

$$
\begin{aligned}
& \frac{\partial \mathrm{f}\left(\mathrm{x}^{*}\right)}{\partial \mathrm{x}_{\mathrm{i}}} \leq 0 \text { with equality if } \mathrm{x}_{\mathrm{i}}^{*}>0 \\
& \mathrm{x}_{\mathrm{i}}^{*} \geq 0 \text { with equality if } \frac{\partial \mathrm{f}\left(\mathrm{x}_{-\mathrm{i}}^{*}, 0\right)}{\partial \mathrm{x}_{\mathrm{i}}}<0
\end{aligned}
$$

Problem 1.5. Second-order necessary conditions. Let $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ be a $C^{2}$ function. Show that if $f$ achieves a local maximum at $x^{*}$, then the Hessian of $f$ at $x$ * is negative semidefinite, that is,

$$
h^{T} D^{2} f\left(x^{*}\right) h \leq 0 \forall h \in \mathbb{R}^{\mathbb{n}}
$$

The following theorem shows that if $f$ satisfies certain concavity conditions, a point that satisfies the first-order necessary conditions (FONCs) is indeed an optimal solution.

Theorem 1.6. Sufficient conditions for a global maximum. Let $\mathrm{f}$ be a $\mathrm{C}^{l}$ pseudoconcave function. If $\mathrm{x}^{*} \in \mathrm{C}$, and for every direction $\mathrm{h} \in \mathbb{R}^{n}$ feasible from $\mathrm{x}^{*}$ we have $\mathrm{Df}\left(\mathrm{x}^{*}\right) \mathrm{h} \leq 0$, then $\mathrm{x}^{*}$ is an optimal solution of $(P . C)$.

Proof. We will prove the contrapositive statement. Assume that $C$ is convex and $f$ is pseudoconcave, and fix some point $x^{0} \in C$. We will show that if $x^{0}$ is not an optimal solution to (P.C), then it does not satisfy the first-order condition $D f\left(x^{0}\right) h \leq 0$ for all feasible directions $h \in \mathbb{R}^{\mathrm{n}}$.

Suppose $x^{0}$ is not optimal. Then there exists some point $x \in C$ such that $f(x)>f\left(x^{0}\right)$. By the pseudoconcavity of $f, f(x)>f\left(x^{0}\right)$ implies

$$
D f\left(x^{0}\right)\left(x-x^{0}\right)>0
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-285.jpg?height=685&width=900&top_left_y=191&top_left_x=286)

Figure 7.2. A false signal.

where $\left(x-x^{0}\right)$ is a feasible direction vector from $x^{0}$, by the convexity of $C$. Hence, $x^{0}$ does not satisfy the first-order conditions.

Recall that both concavity and strict quasiconcavity (or quasiconcavity and nonstationarity) imply pseudoconcavity. Hence, any of these conditions will be sufficient for a point that satisfies the necessary conditions to be an optimal solution. On the other hand, quasiconcavity alone will not do. As we mentioned in Chapter 6, quasiconcavity allows "false signals." Figure 7.2 illustrates the problem: $f$ is quasiconcave, and the point $x^{\circ}$ satisfies the firstorder condition, but does not maximize $f$ in $C$.

The following problems provide alternative sufficient conditions for global maxima.

Problem 1.7. Let $f: \mathbb{R}^{\mathrm{n}} \rightarrow \mathbb{R}$ be a $C^{1}$ concave function. Show that if $x^{*}$ is a critical point of $f$, then it is a global maximizer of $f$.

Problem 1.8. Let $f: \mathbb{R}^{\mathrm{n}} \longrightarrow \mathbb{R}$ be a concave function. Show that if $x^{*}$ is a local maximizer of $f$, then it is also a global maximizer. Hint: Proceed by contradiction.

The following theorem gives sufficient conditions for a stationary point $x^{*}$ of $f$ to be a strict local maximizer in an open set. That is, $f\left(x^{*}\right)>f(x)$ for all $x$ in some open ball with center at $x^{*}$. Notice that what the theorem requires is essentially the strict concavity of $f$ in some neighborhood of $x^{*}$. ${ }^{1}$ A point that satisfies the conditions of this theorem is said to be a regular maximizer of $f$ in $C$.

Theorem 1.9. Sufficient conditions for a strict local maximum. Let $\mathrm{f}$ be a $\mathrm{C}^{2}$ function, with $\mathrm{C}$ an open and convex set, and $\mathrm{x}^{*} a$ point in $\mathrm{C}$ such that $\mathrm{Df}\left(\mathrm{x}^{*}\right)=\underline{0}$. If the Hessian matrix at $\mathrm{x}^{*}, \mathrm{D}^{2} \mathrm{f}\left(\mathrm{x}^{*}\right)$, is negative definite, then $\mathrm{f}$ achieves a strict local maximum at $\mathrm{x}$.

Proof. Let $h$ be an arbitrary direction vector in $\mathbb{R}^{\text {s. }}$. By the convexity and openness of $C$ there exists some $\delta>0$ such that $x^{*}+\alpha h \in C$ for all $\alpha \in(0, \delta)$. Fixing some $\alpha$ in this interval, both $x^{*}$ and $x^{*}+\alpha h$ lie in $C$, and we can use Taylor's formula to write

$$
\begin{equation*}
f\left(x^{*}+\alpha h\right)-f\left(x^{*}\right)=D f\left(x^{*}\right)(\alpha h)+\frac{1}{2}(\alpha h)^{T} D^{2} f\left(x^{*}+\lambda_{\alpha} \alpha h\right)(\alpha h) \tag{1}
\end{equation*}
$$

for some $\lambda_{\alpha} \in(0,1)$. Moreover, because $x^{*}$ is by assumption a stationary point, we have $D f\left(x^{*}\right)=\underline{0}$, and (1) reduces to

$$
\begin{equation*}
f\left(x^{*}+\alpha h\right)-f\left(x^{*}\right)=\frac{\alpha^{2}}{2} h^{T} D^{2} f\left(x^{*}+\lambda_{\alpha} \alpha h\right) h \tag{2}
\end{equation*}
$$

Now, for the given $h$ the quadratic form on the right-hand side of (2) can be shown to be a continuous function of $\alpha$, say $Q(\alpha)$, at $\alpha=0$ (see Problem 1.10). By assumption, moreover, $D^{2} f\left(x^{*}\right)$ is negative definite, implying that

$$
Q(0)=h^{T} D^{2} f\left(x^{*}\right) h<0
$$

Hence, it follows by continuity that $Q()$ will preserve its sign for sufficiently small $\alpha$, that is, there exists some $\gamma>0$ such that

$$
\begin{equation*}
Q(\alpha)=h^{T} D^{2} f\left(x^{*}+\lambda_{\alpha} \alpha h\right) h<0 \tag{3}
\end{equation*}
$$

for all $\alpha<\gamma$. Finally, (2) and (3) imply that

$$
f\left(x^{*}\right)>f\left(x^{*}+\alpha h\right) \forall \alpha<\gamma
$$

Because $h$ is arbitrary, any sufficiently small movement away from $x^{*}$ reduces the value of the objective function. Hence, $f$ has a strict local maximum at $x^{*}$.

We saw in the appendix to Chapter 6 that a matrix $A$ is negative definite if and only if its leading principal minors alternate in sign, with the first one negative. As we will see later, this information will be very useful when we turn to the comparative statics of optimization models.

Problem 1.10. Let $A=\left[a_{i k}\right]$ be an $n \times n$ matrix, and consider the quadratic form $h^{T} A h=\Sigma_{i} \Sigma_{k} h_{i} a_{i k} h_{k}$. Using the Cauchy-Schwarz inequality, show that

$$
\left|h^{T} A h\right| \leq \sqrt{\sum_{i} \sum_{k} a_{i k}^{2}}\|h\|^{2}
$$

where $\|\cdot\|$ is the Euclidean norm. Using this result, verify that the function $Q(\alpha)$ in the proof of Theorem 1.9 is continuous at zero (provided $f$ is $C^{2}$ ) by showing that $|Q(\alpha)-Q(0)| \rightarrow 0$ as $\alpha \rightarrow 0$.

Notice that whereas Theorem 1.9 implies the local uniqueness of the maximizer, Theorem 1.6 allows for the existence of multiple optimal solutions. We close this section with a sufficient condition for the global uniqueness of the optimal solution to (P.C).

Theorem 1.11. Global uniqueness. Let $\mathrm{x}^{*}$ be an optimal solution of (P.C), with $\mathrm{C}$ convex. If $\mathrm{f}$ is strictly quasiconcave, then $\mathrm{x}$ is the unique optimal solution to the problem.

Proof. By contradiction. Suppose that there exist two optimal solutions $x^{\prime}$ and $x^{\prime \prime}$ in $C$. Then $f\left(x^{\prime}\right)=f\left(x^{\prime \prime}\right)=M$, and by the strict quasiconcavity of $f$, we have, for any $\lambda \in(0,1)$,

$$
f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right]>\min \left\{f\left(x^{\prime}\right), f\left(x^{\prime \prime}\right)\right\}=M
$$

where $x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}$ is a feasible point, by the convexity of $C$. Because $f\left(x^{\lambda}\right)>f\left(x^{\prime}\right)=f\left(x^{\prime \prime}\right)$, neither $x^{\prime}$ nor $x^{\prime \prime}$ can be an optimal solution to begin with.

Problem 1.12. Derivation of factor demand functions. Consider a competitive firm that produces a single output $y$ using two inputs $x_{1}$ and $x_{2}$. The firm's production technology is described by a Cobb-Douglas function

$$
y=f\left(x_{1}, x_{2}\right)=x_{1}^{\alpha} x_{2}^{\beta}, \quad \text { where } \beta+\alpha<1, \beta>0, \text { and } \alpha>0
$$

Taking as given the price of its output $p$ and input prices $w_{1}$ and $w_{2}$, the firm maximizes its profits, given by

$$
\Pi\left(x_{1}, x_{2}\right)=p x_{1}^{\alpha} x_{2}^{\beta}-w_{1} x_{1}-w_{2} x_{2}
$$

Write the first-order conditions for the firm's problem, and check that sufficient conditions for a maximum are satisfied. Using the first-order conditions, solve for the firm's factor demands, giving the optimal input levels $x_{i}^{*}$ as functions of input and output prices.

## (b) Equality Constraints: The Lagrange Problem

Consider the problem

$$
\begin{equation*}
\max _{x}\{f(x) \text { s.t. } g(x)=\underline{0}\} \tag{P.L}
\end{equation*}
$$

where $f: \mathbb{R}^{\mathrm{n}} \supseteq X \rightarrow \mathbb{R}$ and $g: \mathbb{R}^{\mathrm{n}} \supseteq X \rightarrow \mathbb{R}^{\mathrm{c}}$ are $C^{2}$ functions, and "s.t." means "subject to." We will refer to the components of $g=\left(g^{1}, \ldots, g^{c}\right)^{T}$ as
the constraint functions and assume that $c \leq n$ (i.e., that we have fewer constraints than choice variables).

We will start by giving an intuitive interpretation of the method of Lagrange multipliers. Consider a simple version of (P.L) with only two decision variables and one constraint:

$$
\begin{equation*}
\max _{x_{1}, x_{2}}\left\{f\left(x_{1}, x_{2}\right) ; g\left(x_{1}, x_{2}\right)=c\right\} \tag{P.L'}
\end{equation*}
$$

Instead of directly forcing the agent to respect the constraint, imagine that we allow him to choose the values of the instruments $x_{1}$ and $x_{2}$ freely, but make him pay a fine $\lambda$ "per unit violation" of the restriction. The agent's payoff, net of the penalty, is given by the Lagrangian function:

$$
\begin{equation*}
£\left(x_{1}, x_{2}, \lambda\right)=f\left(x_{1}, x_{2}\right)-\lambda\left[c-g\left(x_{1}, x_{2}\right)\right] \tag{1}
\end{equation*}
$$

The agent then maximizes (1), taking $\lambda$ as given. The first-order conditions for this problem are

$$
\begin{align*}
& \frac{\partial £\left(x_{1}, x_{2}, \lambda\right)}{\partial x_{1}}=\frac{\partial f}{\partial x_{1}}+\lambda \frac{\partial g}{\partial x_{1}}=0 \Rightarrow \frac{\partial f\left(x^{*}\right)}{\partial x_{1}}=-\lambda \frac{\partial g\left(x^{*}\right)}{\partial x_{1}}  \tag{L.1}\\
& \frac{\partial £\left(x_{1}, x_{2}, \lambda\right)}{\partial x_{2}}=\frac{\partial f}{\partial x_{2}}+\lambda \frac{\partial g}{\partial x_{2}}=0 \Rightarrow \frac{\partial f\left(x^{*}\right)}{\partial x_{2}}=-\lambda \frac{\partial g\left(x^{*}\right)}{\partial x_{2}} \tag{L.2}
\end{align*}
$$

Given an arbitrary $\lambda$, there is no guarantee that the solutions of this system of equations will be optimal solutions of the original problem. But if we pick the correct penalty $\lambda^{*}$, the agent will choose to respect the constraint even if in principle he is free not to, and then the artificial problem we have constructed will give us the correct answers. Thus, $\lambda^{*}$ must be such that the constraint holds. Hence, in addition to (L.1) and (L.2), the optimal solution $\left(x_{1}^{*}, x_{2}^{*}, \lambda^{*}\right)$ must satisfy the feasibility condition, which can be conveniently written in the form

$$
\begin{equation*}
\frac{\partial £\left(x_{1}, x_{2}, \lambda\right)}{\partial \lambda}=g\left(x_{1}, x_{2}\right)-c=0 \tag{F}
\end{equation*}
$$

We have, then, a system of three equations that can be solved for the optimal values of the instruments $\left(x_{1}^{*}, x_{2}^{*}\right)$ and the Lagrange multiplier $\lambda^{*}$. Notice that these equations are the conditions that define a stationary point of the Lagrangian. The optimal solution $\left(x_{1}^{*}, x_{2}^{*}, \lambda^{*}\right)$, however, is likely to be a saddle point rather than a maximizer of $£()$ : Whereas $x^{*}$ does maximize $£\left(x, \lambda^{*}\right)$, it will not be true in general that $\lambda^{*}$ maximizes $£\left(x^{*}, \lambda\right)$.

Although a formal discussion of the topic will have to wait until we establish the envelope theorem, it should be noted that $\lambda^{*}$ often contains useful information about the effect of the constraint. In a possible economic inter-

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-289.jpg?height=952&width=1267&top_left_y=190&top_left_x=105)

Figure 7.3. Optimal solution of a Lagrange problem.

pretation, $c$ denotes the available stock of a certain resource, and the objective function measures something like the profit obtained through an activity that uses the resource as an input. Then the multiplier gives the maximum increase in profit that could be obtained if we had one more unit of the input - and hence the maximum amount that a rational decision-maker would be willing to pay for one additional unit of it. This is clearly a good measure of the marginal value of the resource, and it justifies the interpretation of the multiplier as a "shadow price."

Graphically, the feasible set of (P.L') is a curve on the $\left(x_{1}, x_{2}\right)$ plane, and the optimal solution to the problem is the point $x^{*}$ on this curve that lies on the highest possible level set of $f$. Given certain convexity assumptions, $x^{*}$ will be a tangency point of the two level curves, as shown in Figure 7.3. The existence of a common tangent to both curves implies that the gradients of $f$ and $g$ (both perpendicular to the tangent) lie on the same straight line. This allows us to write one of them as the product of the other and a scalar. That is, there exists a number $-\lambda^{*}$ such that

$$
D f\left(x^{*}\right)=-\lambda^{*} D g\left(x^{*}\right)
$$

which is another way of writing (L.1) and (L.2). Clearly, $x^{*}$ also satisfies the constraint $g\left(x_{1}, x_{2}\right)=c$. Hence, the graphical argument also suggests that the constrained maximizer of $f$ will be characterized by the conditions discussed earlier.

The necessary conditions for the general Lagrange problem

$$
\begin{equation*}
\max _{x}\{f(x) ; g(x)=\underline{0}\} \tag{P.L}
\end{equation*}
$$

can be obtained in a similar way. Introducing a column vector of Lagrange multipliers $\lambda=\left(\lambda_{1}, \ldots, \lambda_{c}\right)^{T}$, one for each constraint, we write the Lagrangian

$$
£(x, \lambda)=f(x)+\lambda^{T} g(x)
$$

Differentiating $£($ ) with respect to $x$ and $\lambda$, we obtain the first-order conditions

$$
\begin{gather*}
D_{x} £(x, \lambda)=D f(x)+\lambda^{T} D g(x)=\underline{0}  \tag{L}\\
D_{\lambda} £(x, \lambda)=g(x)=\underline{0} \tag{F}
\end{gather*}
$$

This is a system of $m+c$ equations in the $m+c$ unknowns $(x, \lambda)$ whose solution set contains the optimal solution to the programming problem, $x^{*}$, and the "correct" values of the multipliers, $\lambda^{*}$. The $c$ equations in $(\mathrm{F})$ are simply the constraints of the original problem, and (L) tells us that the gradient of the objective function $f$ can be written as a linear combination of the gradients of the constraint functions, all evaluated at an optimal solution.

Theorem 1.13. Lagrange. Let $\mathrm{x}^{*}$ be an optimal solution of

$$
\begin{equation*}
\max _{\mathrm{x}}\{\mathrm{f}(\mathrm{x}) ; \mathrm{g}(\mathrm{x})=\underline{0}\} \tag{P.L}
\end{equation*}
$$

where $\mathrm{f}$ and $\mathrm{g}$ are $\mathrm{C}^{l}$ functions, and rank $\mathrm{Dg}\left(\mathrm{x}^{*}\right)=\mathrm{c} \leq \mathrm{n}$. Then there exist unique Lagrange multipliers $\lambda^{*} \in \mathbb{R}^{\mathfrak{c}}$ such that

$$
\operatorname{Df}\left(\mathrm{x}^{*}\right)+\lambda^{* \mathrm{~T}} \operatorname{Dg}\left(\mathrm{x}^{*}\right)=\underline{0}
$$

The logic of the proof is very simple, even though the notation gets messy. We want to show that given certain assumptions, there is some vector $\lambda^{*} \in \mathbb{R}^{\mathrm{c}}$ with certain properties, so we go ahead and construct such an object. A simple way to illustrate what we are doing is to consider the simplest possible case. Assume that we have $n$ constraints, and rank $D g\left(x^{*}\right)=n$. Then $D g\left(x^{*}\right)$ is an invertible square matrix, and finding a vector $\lambda^{*} \in \mathbb{R}^{\mathrm{n}}$ that satisfies the Lagrange condition

$$
\begin{equation*}
D f\left(x^{*}\right)+\lambda^{T} D g\left(x^{*}\right)=\underline{0} \tag{L}
\end{equation*}
$$

is easy: We can solve (L) explicitly to get

$$
\lambda^{* T}=-D f\left(x^{*}\right)\left[D g\left(x^{*}\right)\right]^{-1}
$$

Under these assumptions, however, the maximization problem is trivial, because the feasible set reduces, at least locally, to a unique point that is therefore also optimal.

In the general case, the invertibility of $D g\left(x^{*}\right)$ is not guaranteed, but we will show that it contains an invertible submatrix that can be used in exactly the same way. We begin by partitioning the vector $x$ into two components:

$$
x=\left(x_{\alpha}, x_{\beta}\right), \text { with } x_{\alpha}=\left(x_{1}, \ldots, x_{c}\right) \text { and } x_{\beta}=\left(x_{c+1}, \ldots, x_{n}\right)
$$

In this notation, we can write the constraints $g\left(x_{\alpha}, x_{\beta}\right)=\underline{0}$ and partition the derivative of the constraint function in the corresponding manner, with

$$
D g\left(x^{*}\right)=\left[D_{\alpha} g\left(x^{*}\right), D_{\beta} g\left(x^{*}\right)\right]
$$

Now, by the assumption that rank $D g\left(x^{*}\right)=c, D g\left(x^{*}\right)$ has $c$ linearly independent columns. Without loss of generality, we can relabel the $x_{i}$ 's in such a way that the square submatrix $D_{\alpha} g\left(x^{*}\right)$ has full rank and is therefore invertible. Partitioning the relevant vectors and matrices appropriately, (L) can be written

$$
\left[\begin{array}{c}
D_{\alpha} f\left(x^{*}\right) \\
D_{\beta} f\left(x^{*}\right)
\end{array}\right]+\left[\begin{array}{ll}
\lambda^{* T} & D_{\alpha} g\left(x^{*}\right) \\
\lambda^{* T} & D_{\beta} g\left(x^{*}\right)
\end{array}\right]=\left[\begin{array}{l}
\underline{0} \\
\underline{0}
\end{array}\right]
$$

Because $D_{\alpha} g\left(x^{*}\right)$ is invertible, we can solve the first $c$ equations of the system for a unique value of $\lambda^{*}$ :

$$
\begin{align*}
& D_{\alpha} f\left(x^{*}\right)+\lambda^{* T} D_{\alpha} g\left(x^{*}\right)=\underline{0} \\
& \quad \Rightarrow \lambda^{* T}=-D_{\alpha} g\left(x^{*}\right)\left[D_{\alpha} g\left(x^{*}\right)\right]^{-1} \tag{1}
\end{align*}
$$

It only remains to show that the vector $\lambda^{*}$ also satisfies the remaining equations of the system:

$$
\begin{equation*}
D_{\beta} f\left(x^{*}\right)+\lambda^{* T} D_{\beta} g\left(x^{*}\right)=\underline{0} \tag{2}
\end{equation*}
$$

To establish that (2) holds, we start from the observation that if $x^{*}$ is an optimal solution of (P.L), then any small feasible movement away from it will reduce the value of the objective function. The complication, relative to the simpler problems we have considered so far, is that we now have to make sure that we consider only movements that do not violate the constraint equations. One way to do this is to apply the implicit-function theorem (IFT) to "solve" the system of constraint equations, $g\left(x_{\alpha}, x_{\beta}\right)=\underline{0}$, for some of the choice variables as a function of the rest. Then we substitute this function into $f$ to "eliminate" the constraints. This procedure allows us to transform the Lagrange problem into an equivalent problem of maximization in an
open set. Direct computation using the first-order conditions for this modified problem shows that condition (2) holds.

## Proof

(i) We apply the IFT to the system of constraint equations. Let $x^{*}=\left(x_{\alpha}^{*}, x_{\beta}^{*}\right)$ be an optimal solution of (P.L). Because $x^{*}$ is feasible by definition, $g\left(x_{\alpha}^{*}, x_{\beta}^{*}\right)=\underline{0}$ and $\left|D_{\alpha} g\left(x_{\alpha}^{*}, x_{\beta}^{*}\right)\right| \neq 0$ by the rank assumption. Hence, $x^{*}$ satisfies the conditions of the IFT, and it follows that for any given value of $x_{\beta}$ in some neighborhood of $x_{\beta}^{*}$, there exists a unique value of $x_{\alpha}$ close to $x_{\alpha}^{*}$ and locally unique such that $g\left(x_{\alpha}, x_{\beta}\right)=0$. Formally, there exists a $C^{1}$ function,

$$
h: U_{\beta} \longrightarrow U_{\alpha} \text {, with } h\left(x_{\beta}\right)=x_{\alpha} \text { s.th. } g\left(x_{\alpha}, x_{\beta}\right)=\underline{0}
$$

where $U_{\alpha}$ and $U_{\beta}$ are open balls centered at $x_{\alpha}^{*}$ and $x_{\beta}^{*}$. The derivative of $h$ can be easily calculated by implicit differentiation:

$$
\begin{align*}
& g\left[h\left(x_{\beta}\right), x_{\beta}\right] \equiv \underline{0} \Rightarrow D_{\alpha} g(x) D h\left(x_{\beta}\right)+D_{\beta} g(x)=\underline{0} \\
& \quad \Rightarrow D h\left(x_{\beta}\right)=-\left[D_{\alpha} g(x)\right]^{-1} D_{\beta} g(x) \tag{3}
\end{align*}
$$

The usefulness of the function $h()$ lies in the fact that it allows us to avoid explicit consideration of the constraints. Given a value of $x_{\beta}, h()$ gives us a value of $x_{\alpha}$ such that $\left(x_{\alpha}, x_{\beta}\right)$ is feasible.

(ii) We now use $h$ ( ) to transform (P.L) into an equivalent problem of maximization in an open and convex set. Define the function $F: U_{\beta} \longrightarrow \mathbb{R}$ by

$$
F\left(x_{\beta}\right)=f\left[h\left(x_{\beta}\right), x_{\beta}\right]
$$

Now, if $x^{*}=\left(x_{\alpha}^{*}, x_{\beta}^{*}\right)$ is an optimal solution of (P.L), then $x_{\beta}^{*}$ will be a solution of

$$
\begin{equation*}
\max _{x_{\beta}}\left\{F\left(x_{\beta}\right) ; x_{\beta} \in U_{\beta}\right\} \tag{P.U}
\end{equation*}
$$

and therefore will satisfy the first-order condition

$$
\begin{equation*}
D F\left(x_{\beta}^{*}\right)=\underline{0} \tag{4}
\end{equation*}
$$

Using (1)-(4), we can now establish the desired result by direct computation:

$$
\begin{aligned}
\underline{0} & =D F\left(x_{\beta}^{*}\right)=D f\left[h\left(x_{\beta}^{*}\right), x_{\beta}^{*}\right]=D_{\alpha} f\left(x^{*}\right) D h\left(x_{\beta}^{*}\right)+D_{\beta} f\left(x_{\beta}^{*}\right) \quad[\mathrm{by}(3)] \\
& =-D_{\alpha} f\left(x^{*}\right)\left[D_{\alpha} g\left(x^{*}\right)\right]^{-1} D_{\beta} g\left(x^{*}\right)+D_{\beta} f\left(x^{*}\right) \quad[\text { by (1)] } \\
& =\lambda^{* T} D_{\beta} g\left(x^{*}\right)+D_{\beta} f\left(x^{*}\right)=\underline{0}
\end{aligned}
$$

Hence, equation (2) holds, which proves the theorem.

One of the assumptions of the Lagrange theorem is that the rank of the matrix of first partial derivatives of the constraint functions, evaluated at the
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-293.jpg?height=604&width=1278&top_left_y=188&top_left_x=106)

Figure 7.4. Failure of the constraint qualification.

optimal solution, is equal to the number of constraints, $c$. This condition is sometimes called a constraint qualification. To understand its role, observe that the Lagrange condition can be written

$$
\begin{equation*}
D f\left(x^{*}\right)=-\lambda^{T} D g\left(x^{*}\right)=-\sum_{j=1}^{n} \lambda_{j} D g^{j}\left(x^{*}\right) \tag{L}
\end{equation*}
$$

Thus, (L) requires that we be able to write the gradient of $f$ as a linear combination of the gradients of the constraint functions. If the constraint qualification fails, we may find that we do not have enough linearly independent constraint gradients for $(\mathrm{L})$ to hold.

Figure 7.4 illustrates the geometry of the problem for a couple of trivial examples. In each case, $x^{*}$ clearly maximizes $f$ subject to $g(x)=\underline{0}$, because it is the only point in the feasible set. However, the Lagrange condition $D f\left(x^{*}\right)+\lambda^{T} D g\left(x^{*}\right)=\underline{0}$ does not hold in either case. In the first panel of the figure we have $D f\left(x^{*}\right)>0$ and $D g\left(x^{*}\right)=0$, so there is no number such that $D f\left(x^{*}\right)=-\lambda D g\left(x^{*}\right)$. In the second, the zero level curves of the two constraints are tangent at the optimum. As a result, the gradients of the constraint functions lie on the same straight line and therefore do not span the $\left(x_{1}, x_{2}\right)$ plane. Hence, $D f\left(x^{*}\right)$ cannot be written as a linear combination of $D g^{1}\left(x^{*}\right)$ and $D g^{2}\left(x^{*}\right)$, unless, by chance, it lies on the same straight line.

The following theorem gives sufficient conditions for a point that satisfies the Lagrange condition to be an optimal solution of (P.L). Before stating the result, we should observe that there is no loss of generality in assuming that the Lagrange multipliers are nonnegative, because we can always reverse their signs by rewriting one or more of the constraints in the form $-g^{j}(x)=0$. For example, assume that all multipliers are nonnegative, except
for one, $\lambda_{j}<0$. When we multiply the corresponding constraint by -1 , we reverse the signs of the partial derivatives of the constraint function and therefore the sign of the determinant of the matrix $J=D_{\alpha} g(x) .^{2}$ Now, the Lagrange multipliers are the solution to

$$
\lambda^{* T} D_{\alpha} g\left(x^{*}\right)=-D_{\alpha} f\left(x^{*}\right)
$$

and, by Cramer's rule, $\lambda_{j}$ is given by

$$
\lambda_{j}=\frac{\left|J_{j}\right|}{|J|}
$$

where $J_{j}$ is the matrix obtained by replacing the $j$ th column of $J$, given by $D_{\alpha} g^{j}\left(x^{*}\right)$, with the right-hand-side vector, $-D_{\alpha} f\left(x^{*}\right)$. Hence, multiplication of the constraint by -1 reverses the sign of the corresponding multiplier.

With this in mind, the theorem says that if there is some way to write the Lagrangian so that the restrictions are quasiconcave and the multipliers are nonnegative, then a feasible point that satisfies the Lagrange condition is an optimum.

Theorem 1.14. Sufficient conditions for a global maximum. Let $\mathrm{f}$ be pseudoconcave, and all $\mathrm{g}^{\mathrm{j}}(\mathrm{x})$ quasiconcave. If $\left(\mathrm{x}^{*}, \lambda^{*}\right)$ satisfy the Lagrange condition, $\operatorname{Df}\left(\mathrm{x}^{*}\right)+\lambda^{* \mathrm{~T}} \operatorname{Dg}\left(\mathrm{x}^{*}\right)=\underline{0}$, with $\mathrm{x}^{*}$ feasible and $\lambda^{*} \geq \underline{0}$, then $\mathrm{x}^{*}$ is an optimal solution to the Lagrange problem (P.L).

Problem 1.15. Prove Theorem 1.14. Hint: Follow the proof of Theorem 1.6.

We now give a second set of sufficient conditions that, although only local in character, often are quite useful in economic applications. A point that satisfies the conditions of the theorem is said to be a regular maximizer of $f$ subject to the constraints.

Theorem 1.16. Sufficient conditions for a strict local maximum. Let $\mathrm{x}^{*}$ be a feasible point satisfying the Lagrange condition for some $\lambda^{*}$. Assume that the matrix of second partial derivatives of the Lagrangian function with respect to the choice variables $\mathrm{x}$, evaluated at $\left(\mathrm{x}^{*}, \lambda^{*}\right)$,

$$
\mathrm{D}_{\mathrm{x}}^{2} £\left(\mathrm{x}^{*}, \lambda^{*}\right)=\mathrm{D}^{2} \mathrm{f}\left(\mathrm{x}^{*}\right)+\lambda^{* \mathrm{~T}} \mathrm{D}^{2} \mathrm{~g}\left(\mathrm{x}^{*}\right)
$$

is negative definite subject to the constraints $\operatorname{Dg}\left(\mathrm{x}^{*}\right) \mathrm{h}=\underline{0}$, that is,

$$
\mathrm{h}^{\mathrm{T}} \mathrm{D}_{\mathrm{x}}^{2} £\left(\mathrm{x}^{*}, \lambda^{*}\right) \mathrm{h}<0 \forall \mathrm{h} \in \mathbb{R}^{n} \text { s.th. } \mathrm{Dg}\left(\mathrm{x}^{*}\right) \mathrm{h}=\underline{0}
$$

Then $\mathrm{x}^{*}$ is a strict local maximizer of $\mathrm{f}$ subject to $\mathrm{g}(\mathrm{x})=\underline{0}$.

Proof. Let $h$ be a direction vector in $\mathbb{R}^{\mathrm{n}}$, and consider a feasible point $x^{*}+\alpha h$, where $\alpha>0$. Using Taylor's formula, we can write

$$
\begin{equation*}
£\left(x^{*}+\alpha h, \lambda^{*}\right)-\mathfrak{£}\left(x^{*}, \lambda^{*}\right)=D_{x} \mathfrak{(}\left(x^{*}, \lambda^{*}\right)(\alpha h)+\frac{\alpha^{2}}{2} h^{T} D_{x}^{2} \mathfrak{E}\left(x^{*}+\theta_{\alpha} \alpha h, \lambda^{*}\right) h \tag{1}
\end{equation*}
$$

for some $\theta_{\alpha} \in(0,1)$. Writing out (1) in more detail, we have

$$
\begin{align*}
& f\left(x^{*}+\alpha h\right)+\lambda^{* T} g\left(x^{*}+\alpha h\right)-f\left(x^{*}\right)-\lambda^{* T} g\left(x^{*}\right) \\
& \quad=\left[D f\left(x^{*}\right)+\lambda^{* T} D g\left(x^{*}\right)\right](\alpha h)+\frac{1}{2} \alpha^{2} h^{T} D_{x}^{2} £\left(x^{*}+\theta_{\alpha} \alpha h\right) h \tag{2}
\end{align*}
$$

Observing that

- by assumption both $x^{*}$ and $x^{*}+\alpha h$ are feasible, that is, $g\left(x^{*}\right)=g\left(x^{*}+\alpha h\right)=\underline{0}$, and - $x^{*}$ satisfies the Lagrange condition, $D f\left(x^{*}\right)+\lambda^{*} D g\left(x^{*}\right)=\underline{0}$,

equation (2) reduces to

$$
\begin{equation*}
f\left(x^{*}+\alpha h\right)-f\left(x^{*}\right)=\frac{\alpha^{2}}{2} h^{T} D_{x}^{2} £\left(x^{*}+\theta_{\alpha} \alpha h\right) h \tag{3}
\end{equation*}
$$

We will show that if $x^{*}$ is not a strict local maximizer, then $D_{x^{2}}^{2}\left(x^{*}, \lambda^{*}\right)$ cannot be negative definite subject to $D g\left(x^{*}\right) h=\underline{0}$.

Suppose $x^{*}$ is not a strict local maximizer, and consider a decreasing sequence of real numbers $\delta_{k}>0$ convergent to zero. For each $\delta_{k}$ there exists a feasible point $x^{\delta_{k}} \in B_{\delta_{k}}\left(x^{*}\right)$ such that $f\left(x^{\delta_{k}}\right) \geq f\left(x^{*}\right)$. We can write the vectors $x^{\delta_{k}}$ in the form

$$
x^{\delta_{k}}=x^{*}+\alpha_{k} h^{k}
$$

where $h^{k}$ is a normalized direction vector (with unit norm). Now, $\left\{x^{\delta_{k}}\right\} \rightarrow x^{*}$ by construction, implying that $\left\{\alpha_{k}\right\} \rightarrow 0$. Applying the Bolzano-Weierstrass theorem component by component to the bounded sequence $\left\{h^{k}\right\}$, we see that this sequence has a convergent subsequence (see Problem 3.12 in Chapter 2). For simplicity of notation, assume that $\left\{h^{k}\right\}$ itself converges to some $h$. Then we have, for each $x^{*}+\alpha_{k} h^{k}$, the following:

- By feasibility, we have

$$
\frac{1}{\alpha_{k}}\left[g\left(x^{*}+\alpha_{k} h^{k}\right)-g\left(x^{*}\right)\right]=\underline{0}
$$

and taking the limit of this expression as $k \rightarrow \infty$,

$$
\begin{equation*}
D g\left(x^{*}\right) h=\underline{0} \tag{4}
\end{equation*}
$$

- Using (3) and the assumption that $f\left(x^{\delta_{k}}\right) \geq f\left(x^{*}\right)$,

$$
\frac{\alpha_{k}^{2}}{2} h^{k r} D_{x}^{2} £\left(x^{*}+\theta_{k} \alpha_{k} h\right) h^{k}=f\left(x^{*}+\alpha_{k} h^{k}\right)-f\left(x^{*}\right) \geq 0
$$

Dividing by $\alpha_{k}^{2}$ and taking the limit of the resulting expression as $k \rightarrow \infty$, the inequality is preserved. Hence, there exists a vector $h$, with $D g\left(x^{*}\right) h=\underline{0}$, and such that

$$
\begin{equation*}
h^{T} D_{x}^{2} £\left(x^{*}, \lambda *\right) h \geq 0 \tag{5}
\end{equation*}
$$

It follows that $D_{x}^{2} £()$ is negative definite subject to the linearized constraints, and this establishes the desired result.

Problem 1.17. Solve the problem

$$
\max _{x, y, z} 2 x-2 y+z \text { s.t. } x^{2}+y^{2}+z^{2}=9
$$

by the method of Lagrange multipliers. Use the sufficient second-order conditions for a strict maximum to determine which of the two solutions to the system of first-order conditions yields a maximum. Verify that this is correct by comparing the values of the objective function in both cases.

## (c) Inequality Constraints: The Kuhn-Tucker Problem

In this section we consider problems of the form

$$
\begin{equation*}
\max _{x}\{f(x) ; g(x) \geq \underline{0}\} \tag{P.K-T}
\end{equation*}
$$

where $f: \mathbb{R}^{n} \supseteq X \rightarrow \mathbb{R}$ and $g: \mathbb{R}^{n} \supseteq X \rightarrow \mathbb{R}^{c}$ are $C^{2}$ functions. The only difference from the Lagrange problem is that the constraints are now written as weak inequalities, rather than equalities.

An inequality constraint, $g^{j}(x) \geq 0$, is binding or active at a feasible point $x^{0}$ if it holds with equality $\left(g^{j}\left(x^{0}\right)=0\right.$ ), and not binding or inactive if it holds with strict inequality. Intuitively, it is clear that only active constraints matter and that inactive ones have no effect on the local properties of an optimal solution. Hence, if we knew from the beginning which restrictions would be binding at an optimum, the Kuhn-Tucker problem would reduce to a Lagrange problem in which we would take the active constraints as equalities and ignore the rest.

As in the Lagrange case, a good recipe for remembering the first-order conditions consists in introducing a vector $\lambda$ of multipliers, one for each constraint, and writing the Lagrangian

$$
£(x, \lambda)=f(x)+\lambda^{T} g(x)
$$

Next, we proceed as if we wanted to maximize $£(x, \lambda)$ with respect to $x$ (without constraints) and minimize it with respect to $\lambda$ subject to the nonnegativity constraints $\lambda \geq \underline{0}$. This yields the following conditions:

$$
\begin{gather*}
D_{x} £(x, \lambda)=D f(x)+\lambda^{T} D g(x)=\underline{0}  \tag{L}\\
D_{\lambda j} £(x, \lambda)=g^{j}(x) \geq 0 \quad \text { and } g^{j}(x)=0 \quad \text { if } \lambda_{j}>0 \\
\lambda_{j} \geq 0 \text { and } \lambda_{j}=0 \quad \text { if } g^{j}(x)>0 \tag{C-S}
\end{gather*}
$$

or, equivalently,

$$
\lambda_{j} \geq 0, \quad g^{j}(x) \geq 0, \quad \text { and } \quad \lambda_{j} g^{j}(x)=0 \text { for each } j=1, \ldots, c
$$

That is, either the constraint is binding $\left(g^{j}(x)=0\right)$ or the associated multiplier is zero, or both. Moreover, if the multiplier is strictly positive, the constraint must be binding, and if the constraint is not binding, the multiplier must be zero.

The complementary slackness conditions (C-S) have a very intuitive economic interpretation. Let us return to our informal interpretation of the multipliers as shadow prices that measure the implicit cost, in terms of forgone profit, of resource-availability constraints. In this context, it is clear that if a constraint is not binding (we have more than we need of the resource), a further increase in the available quantity will not increase profit. On the other hand, if the multiplier is positive, an increase in the stock will increase profit. Clearly, this can be the case only if we did not have enough of the resource to begin with, that is, if the constraint is binding. In short, if we already have too much of something, any additional amount will be useless. And if we do not have enough, we should be willing to pay a positive price in order to get a bit more.

In what follows, we will adopt the following notational convention. We will renumber the constraint functions, $g^{j}(x), j=1, \ldots, c$, in such a way that the binding constraints come first. That is, if $x^{*}$ is a feasible point, we arrange the constraints so that

$$
\begin{array}{lll}
g^{j}\left(x^{*}\right)=0 & \text { for } j=1,2, \ldots, B & \text { (binding constraints) } \\
g^{j}\left(x^{*}\right)>0 & \text { for } j=B+1, \ldots, C & \text { (nonbinding constraints) }
\end{array}
$$

and define

$$
\begin{aligned}
& g^{b}\left(x^{*}\right)=\left[g^{1}\left(x^{*}\right), \ldots, g^{B}\left(x^{*}\right)\right]^{T}=\text { vector of constraints active at } x^{*} \\
& g^{n}\left(x^{*}\right)=\left[g^{B+1}\left(x^{*}\right), \ldots, g^{C}\left(x^{*}\right)\right]^{T}=\text { vector of constraints inactive at } x^{*}
\end{aligned}
$$

We can therefore partition the vector of constraints as

$$
g\left(x^{*}\right)=\left[\begin{array}{l}
g^{b}\left(x^{*}\right) \\
g^{n}\left(x^{*}\right)
\end{array}\right]
$$

and partition the vector of multipliers in a corresponding way

$$
\lambda^{T}=\left(\lambda_{b}, \lambda_{n}\right)^{T}
$$

Using this notation, the Lagrange condition

$$
D f(x)+\lambda^{T} D g(x)=\underline{0}
$$

can be written

$$
D f(x)+\left(\lambda_{b}, \lambda_{n}\right)\left[\begin{array}{l}
D g^{b}(x)  \tag{1}\\
D g^{n}(x)
\end{array}\right]=D f(x)+\lambda_{b}^{T} D g^{b}(x)+\lambda_{n}^{T} D g^{n}(x)=\underline{0}
$$

With this in mind, the condition

$$
\operatorname{rank} D g^{b}(x)=B
$$

can be interpreted almost exactly as in the Lagrange case, except that it now applies only to the constraints that are binding at an optimal solution of the problem.

Theorem 1.18. Kuhn-Tucker. Let $\mathrm{x} *$ be an optimal solution to the KuhnTucker problem

$$
\begin{equation*}
\max _{\mathrm{x}}\{\mathrm{f}(\mathrm{x}) ; \mathrm{g}(\mathrm{x}) \geq \underline{0}\} \tag{P.K-T}
\end{equation*}
$$

where $\mathrm{f}$ and $\mathrm{g}$ are $\mathrm{C}^{1}$, and $\operatorname{rank} \mathrm{Dg}^{\mathrm{b}}\left(\mathrm{x}^{*}\right)=\mathrm{B} \leq \mathrm{n}$. Then there exist nonnegative Lagrange multipliers $\lambda^{*} \in \mathbb{R}_{+}^{f}$ such that $\left(\mathrm{x}^{*}, \lambda^{*}\right)$ satisfy the following conditions:

$$
\begin{gather*}
\operatorname{Df}\left(\mathrm{x}^{*}\right)+\lambda^{* \mathrm{~T}} \operatorname{Dg}\left(\mathrm{x}^{*}\right)=\underline{0}  \tag{L}\\
\forall \mathrm{j}=1, \ldots, \mathrm{c}, \quad \mathrm{g}^{\mathrm{j}}(\mathrm{x}) \geq 0 \quad \text { and } \quad \mathrm{g}^{\mathrm{j}}(\mathrm{x})=0 \quad \text { if } \lambda_{\mathrm{j}}>0 \tag{C-S}
\end{gather*}
$$

and

$$
\lambda_{\mathrm{j}} \geq 0 \text { and } \lambda_{\mathrm{j}}=0 \text { if } \mathrm{g}^{\mathrm{j}}(\mathrm{x})>0
$$

Proof. We partition the vector of choice variables,

$$
x=\left(x_{\alpha}, x_{\beta}\right), \text { with } x_{\alpha}=\left(x_{1}, \ldots, x_{B}\right) \text { and } x_{\beta}=\left(x_{B+1}, \ldots, x_{n}\right)
$$

and the matrix $D g^{b}(x)$ correspondingly,

$$
D g^{b}(x)=\left[D_{\alpha} g^{b}(x), D_{\beta} g^{b}(x)\right]
$$

Relabeling the $x_{i}$ 's, if necessary, so that the $B \times B$ matrix $D_{\alpha} g^{b}(x)$ will have rank $B$ (and therefore will be invertible), we can write the Lagrange condition (1) in the form

$$
\left[\begin{array}{l}
D_{\alpha} f(x)  \tag{2}\\
D_{\beta} f(x)
\end{array}\right]+\left[\begin{array}{l}
\lambda_{b}^{T} D_{\alpha} g^{b}(x) \\
\lambda_{b}^{T} D_{\beta} g^{b}(x)
\end{array}\right]+\lambda_{n}^{T} D g^{n}(x)=\underline{0}
$$

We now define the multipliers as follows. First, we set to zero the multipliers associated with the inactive constraints,

$$
\lambda_{n}^{*}=\underline{0}
$$

Then the first $B$ equations of (2) reduce to

$$
D_{\alpha} f\left(x^{*}\right)+\lambda_{b}^{T} D_{\alpha} g^{b}\left(x^{*}\right)=\underline{0}
$$

which we solve for

$$
\begin{equation*}
\lambda_{b}^{* T}=-D_{\alpha} f\left(x^{*}\right)\left[D_{\alpha} g^{b}\left(x^{*}\right)\right]^{-1} \tag{3}
\end{equation*}
$$

It remains to show that the remaining equations in (2) hold for these values of the multipliers and that the multipliers are all nonnegative, that is,

$$
\begin{equation*}
D_{\beta} f\left(x^{*}\right)+\lambda_{b}^{* T} D_{\beta} g^{b}\left(x^{*}\right)=\underline{0} \text { and } \lambda_{b}^{*} \geq \underline{0} \tag{4}
\end{equation*}
$$

The proof proceeds, as in the case of the Lagrange theorem, by showing that an optimal solution of the original problem will also solve a related but simpler maximization. Using the first-order conditions for this problem, we will establish (4).

(i) To eliminate the inequality constraints, we introduce a vector of slack variables, one for each constraint:

$$
z=\left(z_{1}, \ldots, z_{c}\right)^{T}=\left(z_{b}, z_{n}\right)^{T}
$$

where $z_{b} \in \mathbb{R}^{\mathbb{B}}$ and $z_{n} \in \mathbb{R}^{\mathrm{c}-\mathbb{B}}$ are the vectors of slack variables associated respectively with the binding and nonbinding constraints.

The original constraints, $g(x) \geq 0$, can then be written

$$
g(x)-z=\underline{0} \text { and } z \geq \underline{0}
$$

Moreover, if we restrict the value of $x$ to a sufficiently small neighborhood of $x^{*}$, the continuity of the constraint functions implies that those constraints that are not binding at $x^{*}$ will continue to be inactive in this region. That is, there exists some $\varepsilon>0$ such that for all $x \in B_{\varepsilon}\left(x^{*}\right)$ we have

$$
g^{j}(x)>0 \forall j=B+1, \ldots, c \quad \text { (or, equivalently, } z_{n} \gg \underline{0} \text { ) }
$$

As long as we stay in this region, therefore, we can ignore the inactive constraints and focus on the active ones. These can be rewritten in the form

$$
\begin{equation*}
G\left(x, z_{b}\right)=g^{b}(x)-I z_{b}=\underline{0} \quad \text { and } \quad z_{b} \geq \underline{0} \tag{5}
\end{equation*}
$$

where $I$ is the $b \times b$ identity matrix.

Now, if $x^{*}$ solves the Kuhn-Tucker problem

$$
\begin{equation*}
\max _{x}\{f(x) ; g(x) \geq \underline{0}\} \tag{P.K-T}
\end{equation*}
$$

the preceding discussion implies that it will also solve the problem

$$
\max _{x}\left\{f(x) ; G\left(x, z_{b}\right)=\underline{0}, z_{b} \geq \underline{0}, x \in B_{\varepsilon}\left(x^{*}\right)\right\}
$$

(ii) Next, we apply the implicit-function theorem (IFT) to (5) in order to eliminate the binding constraints. We know that $x^{*}=\left(x_{\alpha}^{*}, x_{\beta}^{*}\right)$ satisfies (5) with $z_{b}^{*}=\underline{0}$ (that is, there is no slack for the active constraints at the optimum). Differentiating $G\left(\right.$ ) with respect to $x_{\alpha}$, we have

$$
D_{\alpha} G\left(x^{*}, z_{b}^{*}\right)=D_{\alpha} G\left(x^{*}, \underline{0}\right)=D_{\alpha} g^{b}\left(x^{*}\right)
$$

By the rank assumption (constraint qualification), this is an invertible matrix. Hence, the assumptions of the IFT hold at $\left(x^{*}, z_{b}^{*}\right)=\left(x_{\alpha}^{*}, x_{\beta}^{*}, \underline{0}\right)$ and the system (5) of active constraints implicitly defines $x_{\alpha}$ as a function $h()$ of $\left(x_{\beta}, z_{b}\right)$. That is, there exists a function

$$
h: U_{\beta, z} \rightarrow U_{\alpha} \text {, with } h\left(x_{\beta}, z_{b}\right)=x_{\alpha} \text { s.th. } G\left[h\left(x_{\beta}, z_{b}\right), x_{\beta}, z_{b}\right]=\underline{0}
$$

where $U_{\alpha}$ and $U_{\beta, z}$ are open balls centered respectively at $x_{\alpha}^{*}$ and $\left(x_{\beta}^{*}, \underline{0}\right)$. The function $h()$ assigns to each pair $\left(x_{\beta}, z_{b}\right)$ the value of $x_{\alpha}$ that satisfies the constraints of $\left(\mathrm{P}^{\prime}\right)$.

Implicit differentiation of the identity

$$
G\left[h\left(x_{\beta}, z_{b}\right), x_{\beta}, z_{b}\right]=g^{b}\left[h\left(x_{\beta}, z_{b}\right), x_{\beta}\right]-I z_{b} \equiv \underline{0}
$$

gives

$$
D_{\alpha} g^{b}\left(x^{*}\right) D_{\beta} h\left(x_{\beta}^{*}, z_{b}^{*}\right)+D_{\beta} g^{b}\left(x^{*}\right)=\underline{0}
$$

from where

$$
\begin{equation*}
D_{\beta} h\left(x_{\beta}^{*}, \underline{0}\right)=-\left[D_{\alpha} g^{b}\left(x^{*}\right)\right]^{-1} D_{\beta} g^{b}\left(x^{*}\right) \tag{6}
\end{equation*}
$$

and

$$
D_{\alpha} g^{b}\left(x^{*}\right) D_{z} h\left(x_{\beta}^{*}, z_{b}^{*}\right)-I=\underline{0}
$$

implying

$$
\begin{equation*}
D_{z} h\left(x_{\beta}^{*}, \underline{0}\right)=\left[D_{\alpha} g^{b}\left(x^{*}\right)\right]^{-1} \tag{7}
\end{equation*}
$$

We now define the function $F: U_{\beta, z} \longrightarrow \mathbb{R}$ by

$$
F\left(x_{\beta}, z_{b}\right)=f\left[h\left(x_{\beta}, z_{b}\right), x_{\beta}\right]
$$

and observe that the pair $\left(x_{\beta}^{*}, z_{b}^{*}\right)=\left(x_{\beta}^{*}, \underline{0}\right)$ will be an optimal solution to the problem

$$
\max _{x_{\beta}, z b}\left\{F\left(x_{\beta}, z_{b}\right) ; z_{b} \geq \underline{0},\left(x_{\beta}, z_{b}\right) \in U_{\beta, z}\right\}
$$

and therefore will satisfy the first-order conditions

$$
\begin{equation*}
D_{\beta} F\left(x_{\beta}^{*}, z_{b}^{*}\right)=\underline{0} \quad \text { and } \quad D_{z} F\left(x_{\beta}^{*}, z_{b}^{*}\right) \leq \underline{0} \tag{8}
\end{equation*}
$$

That is, for each $i=1, \ldots, B$,

$$
\begin{array}{ll}
D_{z_{i}} F\left(x_{\beta}^{*}, z_{b}^{*}\right) \leq 0 & \text { and }=0 \\
z_{l} \geq 0 & \text { and } z_{l}>0 \\
=0 & \text { if } D_{z_{l}} F\left(x_{\beta}^{*}, z_{b}^{*}\right)<0
\end{array}
$$

Using (8), we have

$$
\begin{aligned}
\underline{0} & =D_{\beta} F\left(x_{\beta}^{*}, z_{b}^{*}\right)=D_{\beta} f\left[h\left(x_{\beta}^{*}, z_{b}^{*}\right), x_{\beta}^{*}\right]=D_{\alpha} f\left(x^{*}\right) D_{\beta} h\left(x_{\beta}^{*}, z_{b}^{*}\right)+D_{\beta} f\left(x^{*}\right) \\
& =-D_{\alpha} f\left(x^{*}\right)\left[D_{\alpha} g^{b}\left(x^{*}\right)\right]^{-1} D_{\beta} g^{b}\left(x^{*}\right)+D_{\beta} f\left(x^{*}\right) \quad[\text { by (6)] } \\
& =\lambda_{b}^{* T} D_{\beta} g^{b}\left(x^{*}\right)+D_{\beta} f\left(x^{*}\right)=\underline{0} \quad[\text { by (3)] }
\end{aligned}
$$

which is one of the things we wanted to show.

Finally, the condition $D_{z} F\left(x_{\beta}^{*}, z_{b}^{*}\right) \leq \underline{0}$ will guarantee the nonnegativity of the multipliers. Using the second part of (8),

$$
\begin{aligned}
\underline{0} \geq D_{z} F\left(x_{\beta}^{*}, z_{b}^{*}\right) & =D_{z} f\left[h\left(x_{\beta}^{*}, z_{b}^{*}\right), x_{\beta}^{*}\right]=D_{\alpha} f\left(x^{*}\right) D_{z} h\left(x_{\beta}^{*}, z_{b}^{*}\right) \\
& =D_{\alpha} f\left(x^{*}\right)\left[D_{\alpha} g^{b}\left(x^{*}\right)\right]^{-1}=-\lambda_{b}^{* T} \quad[\text { by (7)] }
\end{aligned}
$$

that is, $\lambda_{b}^{* T} \geq \underline{0}$.

Theorem 1.19. Sufficient conditions for a global maximum. Given the problem (P.K-T), assume that the objective function $\mathrm{f}()$ is pseudoconcave and that the constraint functions $\mathrm{g}^{\mathrm{j}}()$ are all quasiconcave. Let $\left(\mathrm{x}^{*}, \lambda^{*}\right)$ be a pair of vectors that satisfy the necessary conditions given in the Kuhn-Tucker theorem (i.e., the Lagrange and complementary slackness conditions). Then $\mathrm{x}^{*}$ is an optimal solution of (P.K-T).

The proof is the same as that for the corresponding theorem for the Lagrange problem, after observing that $\lambda_{n}^{* T} g^{n}\left(x^{*}\right)=\underline{0}$ by construction.

Theorem 1.20. Uniqueness. Let $\mathrm{x}^{*}$ be an optimal solution of (P.K-T). If $\mathrm{f}$ is strictly quasiconcave and the constraint functions $\mathrm{g}^{\mathrm{j}}()$ are all quasiconcave, then $\mathrm{x}^{*}$ is the only optimal solution of $(P . K-T)$.

Proof. This result follows from Theorem 1.11 (uniqueness for the convexconstraint-set problem), after observing that the feasible set $\{x ; g(x) \geq 0\}$ is (the intersection of convex sets and therefore) convex by the quasiconcavity of the constraint functions.

Problem 1.21. Integral objective and constraint functions. Let $f: \mathbb{R}^{\mathrm{n}+1} \rightarrow \mathbb{R}$ and $g: \mathbb{R}^{n+1} \longrightarrow \mathbb{R}$ be $C^{1}$ functions, and consider the problem

$$
\begin{equation*}
\max _{x(s), s \in[a, b]}\left\{\int_{a}^{b} f[x(s), s] d s \text { s.t. } \int_{a}^{b} g[x(s), s] d s \geq 0\right\} \tag{P.I}
\end{equation*}
$$

This problem differs from the ones we have considered so far in that instead of choosing a finite set of decision variables, we must now choose an
infinite number of them. In other words, the object of choice is no longer a vector in $\mathbb{R}^{\mathrm{n}}$ but a continuum of them, as described by a function $x(s)$ : $[a, b] \rightarrow \mathbb{R}^{\mathrm{n}}$, which, for each possible value of the state variable $s$, gives us the choice of the instruments $x$.

Using earlier results, we will derive necessary and sufficient conditions for an optimal solution of (P.I) that will closely resemble those applicable to a standard Kuhn-Tucker problem.

(i) The argument used to derive the first-order conditions for an optimum should be familiar by now. Let $x^{*}(s)$ be an optimal solution function for (P.I), and let us consider a feasible variation from this function. In particular, we will consider a two-parameter family of functions of the form

$$
\tilde{x}(s)=x^{*}(s)+\alpha y(s)+\beta z(s)
$$

where $y(s)$ and $z(s)$ are arbitrary functions from $\mathbb{R}$ to $\mathbb{R}^{\mathrm{n}}$, and the parameters $\alpha$ and $\beta$ will be chosen so that, given $y()$ and $z()$, the constraint holds.

Now, consider the problem

$$
\begin{equation*}
\max _{\alpha, \beta}\{F(\alpha, \beta)\}=\int_{a}^{b} f[\tilde{x}(s), s] d s \text { s.t. } G(\alpha, \beta)=\int_{a}^{b} g[\tilde{x}(s), s] d s \geq 0 \tag{P.I'}
\end{equation*}
$$

This problem is clearly related to the original one. Because $x^{*}(s)$ is optimal for (P.I), we know that the solution of the transformed problem involves setting $\alpha$ and $\beta$ equal to zero. The reformulation is useful, however, in that we can use already familiar techniques to obtain necessary conditions for an optimum.

In particular, introduce a multiplier $\lambda$, define the function

$$
£(\alpha, \beta, \lambda)=\int_{a}^{b} £_{s}[\tilde{x}(s), \lambda, s] d s=\int_{a}^{b} f[\tilde{x}(s), s]+\lambda g[\tilde{x}(s), s] d s
$$

and use the Kuhn-Tucker theorem to derive the following first-order conditions:

$$
\begin{gather*}
D_{x} £_{s}\left[x^{*}(s), \lambda, s\right]=D_{x} f\left[x^{*}(s), s\right]+\lambda D_{x} g\left[x^{*}(s), s\right]=\underline{0}  \tag{K-T}\\
\int_{a}^{b} g\left[x^{*}(s), s\right] d s \geq 0, \quad \text { and } \int_{a}^{b} g\left[x^{*}(s), s\right] d s=0, \quad \text { if } \lambda>0 \\
\lambda \geq 0, \quad \text { and } \lambda=0 \text { if } \int_{a}^{b} g\left[x^{*}(s), s\right] d s>0 \tag{C-S}
\end{gather*}
$$

Notice that (K-T) must hold separately for each $s \in[a, b]$. On the other hand, there is a unique multiplier $\lambda$ that does not depend on $s$.

(ii) Assume that $f(x, s)$ and $g(x, s)$ are concave in $x$ for each $s$, and let $x^{*}(s)$ be a choice function that satisfies the first-order conditions for the problem. Show that $x^{*}(s)$ solves (P.I).

(d) Concave Programming without Differentiability

Although the differentiability of the objective and constraint functions is a convenient assumption, the essence of many of the previous results goes through without it, as shown in the following theorems.

Theorem 1.22. Let $\mathrm{x}^{*}$ be an optimal solution for the problem

$$
\begin{equation*}
\max _{\mathrm{x}}\{\mathrm{f}(\mathrm{x}) ; \mathrm{g}(\mathrm{x}) \geq \underline{0}\} \tag{P.K-T}
\end{equation*}
$$

where $\mathrm{f}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$ and each of the components of $g, g^{j}: \mathbb{R}^{n} \supseteq \mathrm{X} \longrightarrow$ $\mathbb{R}, \mathrm{j}=1, \ldots, \mathrm{c}$, are concave functions. Suppose further that there exists a point $\mathrm{x}^{\prime} \in \mathbb{R}^{n}$ such that $\mathrm{g}\left(\mathrm{x}^{\prime}\right) \gg \underline{0}$. Then there exists a vector of nonnegative multipliers $\lambda^{*} \in \mathbb{R}_{+}^{\mathfrak{c}}$ such that

$$
\begin{aligned}
& \mathrm{f}\left(\mathrm{x}^{*}\right)+\lambda^{* \mathrm{~T}} \mathrm{~g}\left(\mathrm{x}^{*}\right) \geq \mathrm{f}(\mathrm{x})+\lambda^{* \mathrm{~T}} \mathrm{~g}(\mathrm{x}) \forall \mathrm{x} \\
& \lambda_{\mathrm{j}}^{*} \mathrm{~g}^{\mathrm{j}}\left(\mathrm{x}^{*}\right)=0 \quad \text { for each } \mathrm{j}=1, \ldots, \mathrm{c}
\end{aligned}
$$

The assumption that there exists a point $x^{\prime}$ in $\mathbb{R}^{\mathrm{n}}$ such that $g^{j}\left(x^{\prime}\right)>0$ for all $j$ is known as Slater's constraint qualification, or Slater's condition, and it requires that the constraint set have a nonempty interior. The first necessary condition says that $x^{*}$ maximizes the Lagrangian function $£\left(x, \lambda^{*}\right)=f(x)+\lambda^{* T} g(x)$ given the "correct" value of the multipliers. When $f$ and $g$ are $C^{1}$, this reduces to the usual Lagrange condition.

Proof. Let $x^{*}$ be an optimal solution of (P.K-T), and assume that the constraint qualification holds. We shall show that there exist nonnegative multipliers $\lambda_{1}, \ldots, \lambda_{c}$ with the required properties.

Define the set $Y$ by

$$
\begin{equation*}
Y=\left\{y=\left(y_{0}, y_{1}, \ldots, y_{C}\right) \in \mathbb{R}^{c+1} ; y_{0} \leq f(x) \text { and } y_{j} \leq g^{j}(x) \text { for some } x\right\} \tag{1}
\end{equation*}
$$

(i) Claim: $Y$ is a convex set. Given two arbitrary points $y^{\prime}$ and $y^{\prime \prime}$ in $Y$, let $x^{\prime}$ and $x^{\prime \prime}$ be points that "work" for $y^{\prime}$ and $y^{\text {" }}$ in the sense that they satisfy the inequalities in (1). To establish the convexity of $Y$, we will show that for any $\lambda \in(0,1)$, the point $x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}$ works for $y^{\lambda}=(1-\lambda) y^{\prime}+\lambda y^{\prime \prime}$.

By the concavity of $f$ and each of the components of $g$, we have

$$
\begin{aligned}
& y_{0}^{\lambda}=(1-\lambda) y_{0}^{\prime}+\lambda y_{0}^{\prime \prime} \leq(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right) \leq f\left(x^{\lambda}\right) \\
& y_{j}^{\lambda}=(1-\lambda) y_{j}^{\prime}+\lambda y_{j}^{\prime \prime} \leq(1-\lambda) g^{\prime}\left(x^{\prime}\right)+\lambda g^{j}\left(x^{\prime \prime}\right) \leq g^{j}\left(x^{\lambda}\right) \text { for each } j=1, \ldots, c
\end{aligned}
$$

Hence, $y^{\lambda} \in Y$, as we have found an $x$ that works for it.

(ii) Claim: $y^{*}=\left(f\left(x^{*}\right), \underline{0}\right) \in \partial Y$. That is, the vector formed by the maximum value of the objective function and the zero vector in $\mathbb{R}^{\mathrm{c}}$ belongs to the boundary of the set $Y$.

We proceed by contradiction. Suppose $y^{*}$ is not a boundary point of $Y$. Then (because it does belong to the set) $y^{*}$ must be an interior point of $Y$. Hence, there exists some $\varepsilon>0$ such that $B_{\varepsilon}\left(y^{*}\right) \subseteq Y$. That is, starting from $y^{*}=\left(f\left(\mathrm{x}^{*}\right)\right.$, 0 ), we can move a bit in any direction without leaving $Y$. In particular, we can increase the first component of $y^{*}$ a little and still remain in $Y$. Hence, there exists some vector $\mu \in B_{\varepsilon}\left(y^{*}\right) \subseteq Y$ such that

$$
\mu_{0}>f\left(x^{*}\right) \text { and } \mu_{j} \geq 0 \forall j=1, \ldots, c
$$

But then, because $\mu \in Y$, there exists some vector $\hat{x}$ that "works" for it, that is, such that

$$
f(\hat{x}) \geq \mu_{0}>f\left(x^{*}\right) \quad \text { and } \quad g^{j}(\hat{x}) \geq \mu_{\jmath} \geq 0 \forall j
$$

Notice that $\hat{x}$ is a feasible point, with the property that $f(\hat{x})>f\left(x^{*}\right)$. Because $x^{*}$ maximizes $f$, this is impossible, and we have arrived at a contradiction.

(iii) By the supporting-hyperplane theorem (Theorem 1.25 in Chapter 6), $Y$ has a supporting hyperplane through the point $y^{*}$, that is, there exists a vector $p \neq 0$ in $\mathbb{R}^{\mathrm{c}+3}$ such that

$$
\begin{equation*}
p y^{*}=p_{0} f\left(x^{*}\right)+\sum_{j=1}^{c} p_{j} 0 \leq p_{0} y_{0}+\sum_{j=1}^{c} p_{j} y_{j} \quad \text { for every } y \text { in } Y \tag{2}
\end{equation*}
$$

(iv) Claim: $p_{j} \leq 0$ for all $j=0, \ldots, c$. Notice that if $y \in Y$, then any point of the form $y-c$, where $c$ is a vector with nonnegative components, belongs to $Y$. To establish the claim, we proceed by contradiction. Suppose $p_{j}>0$ for some $j$, and choose $c_{j}$ so that $p_{j}-c_{j}$ is a large negative number. Clearly, we can always choose $c_{j}$ large enough that

$$
p_{0} f\left(x^{*}\right) \leq p_{0}\left(y_{0}-c_{0}\right)+\sum_{j=1}^{c} p_{j}\left(y_{j}-c_{j}\right)
$$

does not hold.

(v) Clearly, $(f(x), g(x)) \in Y$ for any $x$. Hence, (2) implies

$$
\begin{equation*}
p_{0} f\left(x^{*}\right) \leq p_{0} f(x)+\sum_{j=1}^{c} p_{j} g^{J}(x) \text { for any } x \tag{3}
\end{equation*}
$$

(vi) Claim: $p_{0}<0$. By contradiction with the Slater condition. Suppose $p_{0}=0$ (we already know it cannot be strictly positive). Then, by (3),

$$
\begin{equation*}
\sum_{j=1}^{c} p_{j} g^{j}(x) \geq 0 \forall x \tag{4}
\end{equation*}
$$

We will now show that this contradicts the Slater condition. Notice that because $p_{j} \leq 0$ for all $j$, and not all the $p_{j}$ 's can be zero, there is at least one $k$ such that $p_{k}<0$. Next, let $x^{\prime}$ be a point such that $g^{j}\left(x^{\prime}\right)>0$ for all $j$ (this point exists by the Slater condition). Then (4) cannot hold for $x^{\prime}$ (because $p_{k} g^{k}\left(x^{\prime}\right)<$ 0 and $p_{j} g^{j}\left(x^{\prime}\right) \leq 0$ for all $j \neq k$, the sum of these terms must be strictly negative).

(vii) Define $\lambda^{*}$ by

$$
\lambda_{0}^{*}=1 \quad \text { and } \quad \lambda_{j}^{*}=\frac{p_{j}}{p_{0}} \geq 0 \text { for } j=1, \ldots, c
$$

Then, dividing both sides of (3) by $p_{0}<0$ (which reverses the inequality), we obtain

$$
\begin{equation*}
f\left(x^{*}\right) \geq f(x)+\sum_{j=1}^{c} \lambda_{j}^{*} g^{j}(x) \text { for any } x \tag{5}
\end{equation*}
$$

Moreover, with $x=x^{*},(5)$ implies that

$$
\sum_{j=1}^{c} \lambda_{j}^{*} g^{j}\left(x^{*}\right) \leq 0
$$

and in fact

$$
\begin{equation*}
\sum_{j=1}^{c} \lambda_{j}^{*} g^{j}\left(x^{*}\right)=0 \tag{6}
\end{equation*}
$$

because $g^{j}\left(x^{*}\right) \geq 0$ and $\lambda_{j}^{*} \geq 0$ for all $j$. For the same reason, each one of the terms of this sum must be nonnegative (i.e., $\lambda_{j}^{*} g^{\prime}\left(x^{*}\right) \geq 0 \forall j$ ), but if any of them is strictly positive, the equality in (6) cannot hold. Hence, it must be that

$$
\lambda_{j}^{*} g^{\prime}(x)=0 \forall j
$$

Using (5) and (6), we can now write

$$
£\left(x^{*}, \lambda^{*}\right)=f\left(x^{*}\right)+\lambda^{* T} g\left(x^{*}\right) \geq f(x)+\lambda^{* T} g(x)=£\left(x, \lambda^{*}\right)
$$

for any $x$. That is, $x^{*}$ maximizes $£\left(x, \lambda^{*}\right)$.

Theorem 1.23. Consider the problem (P.K-T): $\max _{\mathrm{x}}\{\mathrm{f}(\mathrm{x}) ; \mathrm{g}(\mathrm{x}) \geq 0\}$. Assume that there exist vectors $\mathrm{x}^{*} \in \mathbb{R}^{\mathrm{n}}$ and $\lambda^{*} \in \mathbb{R}_{+}^{c}$ such that $\mathrm{x}^{*}$ is feasible (i.e., $\mathrm{g}\left(\mathrm{x}^{*}\right) \geq 0$ ), and

$$
\begin{gather*}
\mathrm{f}\left(\mathrm{x}^{*}\right)+\lambda^{* \mathrm{~T}} \mathrm{~g}\left(\mathrm{x}^{*}\right) \geq \mathrm{f}(\mathrm{x})+\lambda^{* \mathrm{~T}} \mathrm{~g}(\mathrm{x}) \forall \mathrm{x}  \tag{1}\\
\lambda_{\mathrm{j}}^{*} \mathrm{~g}^{\mathrm{j}}\left(\mathrm{x}^{*}\right)=0 \quad \text { for each } \mathrm{j}=1, \ldots, \mathrm{c} \tag{2}
\end{gather*}
$$

Then $\mathrm{x}^{*}$ is an optimal solution to (P.K-T).

Notice that nothing is said about the concavity of the objective and constraint functions, or about a constraint qualification.

Proof. We want to show that $x^{*}$ maximizes $f$ subject to the constraints $g(x) \geq \underline{0}$. By assumption, $x^{*}$ is feasible. By (1),

$$
f\left(x^{*}\right)+\lambda^{* T} g\left(x^{*}\right) \geq f(x)+\lambda^{* T} g(x)
$$

for all $x$, but because $\lambda^{* T} g\left(x^{*}\right)=0$, by (2), we have

$$
f\left(x^{*}\right) \geq f(x)+\lambda^{* T} g(x)
$$

for any $x$. Finally, because $g(x) \geq \underline{0}$ for all feasible points and $\lambda^{*} \geq \underline{0}$, we have $\lambda^{* T} g(x) \geq 0$ for all feasible $x$, and therefore

$$
f\left(x^{*}\right) \geq f(x)
$$

for all $x$ with $g(x) \geq \underline{0}$; that is, $x^{*}$ solves (P.K-T).

## 2. Comparative Statics and Value Functions

Let us now reintroduce the parameters into the analysis and consider the following family of nonlinear programming problems:

$$
\max _{x \in C(\alpha)} f(x, \alpha)
$$

For given values of the parameters $\alpha^{0}$, we can solve (P. $\alpha$ ) for the optimal values $x^{*}$ of the choice variables (assuming a solution exists). A change in $\alpha$ can then be expected to lead to a new optimal solution. Solving the problem for each value of the parameters, we construct its solution correspondence,

$$
S(\alpha)=\arg \max _{x \in C(\alpha)} f(\alpha, x)
$$

and substituting $S()$ into the objective function, we obtain the problem's value function:

$$
V(\alpha)=\max _{x \in C(\alpha)} f(\alpha, x)=f\left(x^{*}, \alpha\right), \quad \text { where } x^{*} \in S(\alpha)
$$

Notice that $V()$ is always a well-defined function (i.e., it is single-valued even if $S(\alpha)$ is not) because all maximizers $x$ in $S(\alpha)$ yield the same value of the objective function by definition. In fact, $S()$ and $V()$ are related by the following expression:

$$
S(\alpha)=\arg \max _{x \in C(\alpha)} f(\alpha, x)=\{x \in C(\alpha) ; f(x, \alpha)=V(\alpha)\}
$$

In the first part of this section we will establish an important theorem that gives sufficient conditions for the solution of (P. $\alpha$ ) to change continuously with the parameters. We will then strengthen these conditions in order to ensure that the solution correspondence $S(\alpha)$ is (at least locally) a welldefined and smooth function $x^{*}=x(\alpha)$, and we shall develop a method for analyzing the comparative-statics properties of this function. In the remainder of the section, we will review some useful results on value functions.

## (a) The Theorem of the Maximum

Theorem 2.1. Berge's theorem of the maximum. Given sets $\mathrm{X} \subseteq \mathbb{R}^{n}$ and $\Omega \subseteq \mathbb{R}^{P}$, let $\mathrm{f}: \mathrm{X} \times \Omega \longrightarrow \mathbb{R}$ be a continuous function, and $\mathrm{C}: \Omega \rightarrow \mathrm{X} a$ compact-valued and continuous correspondence, and consider the parameterized maximization problem

$$
\max _{\mathrm{x} \in \mathrm{C}(\alpha)} \mathrm{f}(\mathrm{x}, \alpha)
$$

Then the value function

$$
\begin{equation*}
V(\alpha)=\max _{x \in C(\alpha)} f(x, \alpha) \tag{1}
\end{equation*}
$$

is continuous, and the solution correspondence $\mathrm{S}: \Omega \rightarrow \mathrm{X}$,

$$
\begin{equation*}
\mathrm{S}(\alpha)=\arg \max _{\mathrm{x} \in \mathrm{C}(\alpha)}=\{\mathrm{x} \in \mathrm{C}(\alpha) ; \mathrm{f}(\mathrm{x}, \alpha)=\mathrm{V}(\alpha)\} \tag{2}
\end{equation*}
$$

is nonempty, compact-valued, and upper-hemicontinuous (uhc).

Proof. Fix some $\alpha \in \Omega$. By assumption, the set $C(\alpha)$ is nonempty and compact, and $f(\cdot, \alpha)$ is continuous. By the extreme-value theorem (Theorem 8.22 in Chapter 2), $f()$ achieves a maximum in the set $C(\alpha)$, and $S(\alpha)$ is nonempty. Moreover, because $S(\alpha)$ is a subset of the compact set $C(\alpha)$, it is bounded. We will now show that it is also closed and therefore compact itself (by Theorem 8.14 in Chapter 2).

Consider a convergent sequence of maximizers for the given $\alpha,\left\{x_{n}\right\}$, with $x_{n} \in S(\alpha)$, and let $x$ be the limit of this sequence. We want to show that $x \in S(\alpha)$, that is, that $S(\alpha)$ is closed (see Theorem 4.13 in Chapter 2). Now, because $C(\alpha)$ is closed by assumption, and $\left\{x_{n}\right\}$ is contained in it, it follows that $x \in C(\alpha)$ (i.e., that $x$ is feasible). Notice also that $V(\alpha)=f\left(x_{n}, \alpha\right)$ for all $x_{n}$, because all $x_{n}$ are maximizers. Because $f()$ is continuous, it follows that $f(x, \alpha)=\lim _{n \rightarrow \infty} f\left(x_{n}, \alpha\right)=V(\alpha)$ (i.e., that $x$ is also a maximizer). Hence, $x \in S(\alpha)$, as was to be shown, and we conclude that $S(\alpha)$ is compact.

Next, we show that $S$ is upper-hemicontinuous (uhc). Because $S$ has just been shown to be compact-valued, we can use the sequential characterization of upper hemicontinuity (Theorem 11.2 in Chapter 2). Fix $\alpha$, let $\left\{\alpha_{n}\right\}$ be an arbitrary sequence with limit $\alpha$, and choose a companion sequence $\left\{x_{n}\right\}$ with $x_{n} \in S\left(\alpha_{n}\right) \subseteq C\left(\alpha_{n}\right)$ for each $n$. To establish that $S$ is uhc, we have to show that $\left\{x_{n}\right\}$ has a convergent subsequence with limit in $S(\alpha)$.

Because $C()$ is uhc, there exists a subsequence $\left\{x_{n_{k}} \in S\left(\alpha_{n_{k}}\right) \subseteq C\left(\alpha_{n_{k}}\right)\right\}$ converging to some point $x \in C(\alpha)$. Next, let $z$ be an arbitrary point in $C(\alpha)$. Because $C()$ is also lhc, $\left\{\alpha_{n_{k}}\right\}$ has a companion sequence $\left\{z_{n_{k}} ; z_{n_{k}} \in C\left(\alpha_{n_{k}}\right)\right\}$ that converges to $z$ (by Theorem 11.3 in Chapter 2). Now, because $x_{n_{k}}$ is optimal for $\alpha_{n_{k}}$, whereas $z_{n_{k}}$ is only assured to be feasible, we have $f\left(x_{n_{k}}, \alpha_{n_{k}}\right)$ $\geq f\left(z_{n_{k}}, \alpha_{n_{k}}\right)$ for each $k$. Taking limits of both sides of this inequality, the continuity of $f()$ implies that $f(x, \alpha) \geq f(z, \alpha)$. Because $z$ was an arbitrary feasible point, it follows that $x$ is a maximizer of $f$ in $C(\alpha)$ (i.e., that $x \in S(\alpha)$ ). Hence, $S()$ is uhc.

Finally, we show that the value function is continuous. For this, we can use the fact that the composition of two uhc correspondences is uhc (Theorem 11.13 in Chapter 2). Notice that $V()$ can be written in the form

$$
V(\alpha)=\max _{x \in C(\alpha)} f(x, \alpha)=f(S(\alpha), \alpha)
$$

where $S(\alpha)$ is the set of maximizers for $\alpha$. Hence, $V()$ is the composition of a continuous function $f()$ and a uhc correspondence $S()$. Because a continuous function can be considered a uhc (single-valued) correspondence, it
follows that $V()$ is uhc. But we also know that $V()$ is single-valued, and this implies that it is a continuous function.

The maximum theorem says that the set of maximizers and the value of the problem change continuously with the parameters provided the objective function is continuous and the constraint correspondence is compactvalued and continuous. Of these conditions, the one most difficult to check is the last. Our next result shows that the constraint correspondence in standard Kuhn-Tucker problems is continuous under certain assumptions. The strategy of the proof can be adapted to establish the continuity of correspondences in some other cases of interest.

Theorem 2.2. Given sets $\mathrm{X} \subseteq \mathbb{R}^{n}$ and $\Omega \subseteq \mathbb{R}^{P}$, where $\mathrm{X}$ is convex, let $\mathrm{g}^{\mathrm{i}}(\mathrm{x}, \alpha): \times \Omega \longrightarrow \mathbb{R}$ be a continuous function that is concave in $\mathrm{x}$ for given $\alpha$ for all $\mathrm{i}=1, \ldots, \mathrm{c}$, and define the correspondence $\mathrm{C}: \Omega \rightarrow \mathrm{X}$ by

$$
\mathrm{C}(\alpha)=\left\{\mathrm{x} \in \mathrm{X} ; \mathrm{g}^{\mathrm{i}}(\mathrm{x}, \alpha) \geq 0 \forall \mathrm{i}=1, \ldots, \mathrm{c}\right\}
$$

Let $\mathrm{C}\left(\alpha^{0}\right)$ be compact, and assume that there exists some point $\mathrm{x}^{\prime} \in \mathrm{C}\left(\alpha^{0}\right)$ such that $\mathrm{g}^{\mathrm{i}}\left(\mathrm{x}^{\prime}, \alpha^{0}\right)>0$ for all $\mathrm{i}$; then $\mathrm{C}()$ is continuous at $\alpha^{0}$.

In the proof of Theorem 2.2 we will make use of the following two lemmas. We will prove both of them under the assumption that there is a single constraint $(c=1)$ and leave the extension to the general case as an exercise.

Lemma 2.3. Under the assumptions of Theorem 2.2, the set

$$
\mathrm{C}_{\varepsilon}\left(\alpha^{0}\right)=\left\{\mathrm{x} \in \mathrm{X} ; \mathrm{g}^{\mathrm{i}}\left(\mathrm{x}, \alpha^{0}\right)+\varepsilon \geq 0 \text { for } \mathrm{i}=1, \ldots, \mathrm{c}\right\}
$$

is compact for all $\varepsilon>0$.

Proof. Assume there is a single constraint of the form $g(x, \alpha) \geq 0$, and fix some arbitrary $\varepsilon>0$. Then $C_{\varepsilon}\left(\alpha^{0}\right)$ is a closed set because it is the inverse image of the closed set $[-\varepsilon, \infty)$ under the continuous function $g\left(\cdot, \alpha^{0}\right)$. To show that $C_{\varepsilon}\left(\alpha^{0}\right)$ is bounded (and therefore compact), we will proceed by contradiction.

Suppose $C_{\varepsilon}\left(\alpha^{0}\right)$ is unbounded. Then there exists a sequence $\left\{x_{n}\right\}$, with $x_{n} \in C_{\varepsilon}\left(\alpha^{0}\right)$ for all $n$ (i.e., with $g\left(x_{n}, \alpha^{0}\right) \geq-\varepsilon$ ), such that $\left\{\left\|x_{n}\right\|\right\} \rightarrow \infty$. We know that there exists some $x^{\prime} \in C\left(\alpha^{0}\right)$ such that $g\left(x^{\prime}, \alpha^{0}\right)=m>0$. Observe that there exists some $\lambda \in(0,1)$ such that

$$
\begin{equation*}
(1-\lambda) m-\lambda \varepsilon>0 \tag{1}
\end{equation*}
$$

(it is enough to choose $0<\lambda<m /(m+\varepsilon)<1)$. We will use this $\lambda$ together with $x^{\prime}$ and $\left\{x_{n}\right\}$ to construct a sequence $\left\{y_{n}\right\}$ of points in $C\left(\alpha^{0}\right)$ that diverges to infinity in norm, contradicting the assumed boundedness of $C\left(\alpha^{0}\right)$.

Let

$$
y_{n}=(1-\lambda) x^{\prime}+\lambda x_{n}
$$

Then, by the concavity of $g()$ in $x$, and using (1), we have

$$
\begin{aligned}
g\left(y_{n}, \alpha^{0}\right)= & g\left((1-\lambda) x^{\prime}+\lambda x_{n}, \alpha^{0}\right) \geq(1-\lambda) g\left(x^{\prime}, \alpha^{0}\right)+\lambda g\left(x_{n}, \alpha^{0}\right) \\
& \geq(1-\lambda) m-\lambda \varepsilon>0
\end{aligned}
$$

Hence $y_{n} \in C\left(\alpha^{0}\right)$ for all $n$. On the other hand,

$$
\left\|y_{n}\right\|=\left\|(1-\lambda) x^{\prime}+\lambda x_{n}\right\| \rightarrow \infty \quad \text { as } n \rightarrow \infty
$$

because $\left\{\left\|x_{n}\right\|\right\} \rightarrow \infty$. This establishes that $C\left(\alpha^{0}\right)$ is unbounded, contradicting our assumptions.

Lemma 2.4. Under the assumptions of Theorem 2.2, for every $\varepsilon>0$ there exists some $\delta>0$ such that $\mathrm{C}(\alpha) \subseteq \mathrm{C}_{\varepsilon}\left(\alpha^{0}\right)$ for all $\alpha \in \mathrm{B}_{\delta}\left(\alpha^{0}\right)$.

Proof. By contradiction. Suppose the result does not hold; then there exists some $\varepsilon>0$, a parameter sequence $\left\{\alpha_{n}\right\} \rightarrow \alpha^{0}$, and a companion sequence $\left\{x_{n}\right\}$, with $x_{n} \in C\left(\alpha_{n}\right)$ and $x_{n} \notin C_{\varepsilon}\left(\alpha^{0}\right)$ for all $n$. We have, then,

$$
\begin{equation*}
g\left(x_{n}, \alpha_{n}\right) \geq 0 \tag{1}
\end{equation*}
$$

and

$$
\begin{equation*}
g\left(x_{n}, \alpha^{0}\right)<-\varepsilon \tag{2}
\end{equation*}
$$

for all $n$. On the other hand, we know that there exists some point $x^{\prime}$ such that

$$
\begin{equation*}
g\left(x^{\prime}, \alpha^{0}\right)>0 \tag{3}
\end{equation*}
$$

and this implies, by the continuity of $g(x, \cdot)$ and the fact that $\left\{\alpha_{n}\right\} \rightarrow \alpha^{0}$, that there exists some $N$ such that

$$
\begin{equation*}
g\left(x^{\prime}, \alpha_{n}\right)>0 \forall n>N \tag{4}
\end{equation*}
$$

Using the continuity of $g\left(\cdot, \alpha^{0}\right),(2)$ and (3) imply that for each $n$ there exists some point $y_{n}$ of the form

$$
\begin{equation*}
y_{n}=\left(1-\lambda_{n}\right) x^{\prime}+\lambda_{n} x_{n}, \quad \text { with } \lambda_{n} \in(0,1) \tag{5}
\end{equation*}
$$

such that

$$
\begin{equation*}
g\left(y_{n}, \alpha^{0}\right)=-\varepsilon \tag{6}
\end{equation*}
$$

Hence $y_{n} \in C_{\varepsilon}\left(\alpha^{0}\right)$ for all $n$. Moreover, the concavity of $g()$ in $x$ implies that

$$
\begin{equation*}
g\left(y_{n}, \alpha_{n}\right)=g\left(\left(1-\lambda_{n}\right) x^{\prime}+\lambda_{n} x_{n}, \alpha_{n}\right) \geq\left(1-\lambda_{n}\right) g\left(x^{\prime}, \alpha_{n}\right)+\lambda_{n} g\left(x_{n}, \alpha_{n}\right)>0 \tag{7}
\end{equation*}
$$

for all $n>N$, and it follows that

$$
y_{n} \in C\left(\alpha_{n}\right) \forall n>N
$$

Now, because $\left\{y_{n}\right\}$ is contained in $C_{\varepsilon}\left(\alpha^{0}\right)$ and this set is compact by Lemma 2.3, it follows (by Theorem 8.5 in Chapter 2) that this sequence has a convergent subsequence $\left\{y_{n_{k}}\right\}$, with limit $y$ in $C_{\varepsilon}\left(\alpha^{0}\right)$.

Finally, consider the limit of this subsequence. By (6) and the continuity of $g()$, we have

$$
g\left(y, \alpha^{0}\right)=\lim _{k \rightarrow \infty} g\left(y_{n_{k}}, \alpha^{0}\right)=-\varepsilon
$$

On the other hand, (7) implies that

$$
g\left(y, \alpha^{0}\right)=\lim _{k \rightarrow \infty} g\left(y_{n_{k}}, \alpha\right) \geq 0
$$

which contradicts the previous statement.

## Proof of Theorem 2.2

- Upper hemicontinuity: Fix some $\varepsilon>0$. By Lemmas 2.3 and 2.4 there exists some $\delta>0$ such that $C(\alpha)$ is contained in the compact set $C_{\varepsilon}\left(\alpha^{0}\right)$ for all $\alpha \in B_{\delta}\left(\alpha^{0}\right)$. Thus, $C(\alpha)$ is bounded for all $\alpha \in B_{\delta}\left(\alpha^{0}\right)$. Moreover, these sets are all closed, because they are inverse images of the closed set $[0, \infty) \times \ldots \times[0, \infty)$ under a continuous function. Hence, $C(\alpha)$ is compact for each $\alpha \in B_{\delta}\left(\alpha^{0}\right)$.

Because the correspondence $C()$ is compact-valued in $B_{\delta}\left(\alpha^{0}\right)$, to establish its upper hemicontinuity at $\alpha^{0}$ it suffices (by Theorem 11.2 in Chapter 2) to show that given any sequence $\left\{\alpha_{n}\right\}$ in $B_{\delta}\left(\alpha^{0}\right)$ converging to $\alpha^{0}$, every companion sequence $\left\{x_{n}\right\}$, with $x_{n} \in C\left(\alpha_{n}\right)$ for each $n$, has a convergent subsequence with limit in $C\left(\alpha^{0}\right)$.

Let $\left\{\alpha_{n}\right\} \rightarrow \alpha^{0}$ be contained in $B_{\delta}\left(\alpha^{0}\right)$, and consider an arbitrary companion sequence $\left\{x_{n}\right\}$, with $x_{n} \in C\left(\alpha_{n}\right)$ for each $n$ (i.e., $g^{i}\left(x_{n}, \alpha_{n}\right) \geq 0$ for all $i$ and $n$ ). Because $C\left(\alpha_{n}\right) \subseteq C_{\varepsilon}\left(\alpha^{0}\right)$ for all $n,\left\{x_{n}\right\}$ is contained in the compact set $C_{\varepsilon}\left(\alpha^{0}\right)$ and therefore contains a convergent subsequence $\left\{x_{n_{k}}\right\}$, with limit $x$ in $C_{\varepsilon}\left(\alpha^{0}\right)$. Hence $\left\{\left(x_{n_{k}}, \alpha_{n_{k}}\right)\right\}$ $\rightarrow\left(x, \alpha^{0}\right)$, and by the continuity of $g^{i}()$ it follows that

$$
g^{i}\left(x, \alpha^{0}\right)=\lim _{k \rightarrow \infty} g^{i}\left(x_{n k}, \alpha_{n k}\right) \geq 0
$$

for all $i$. This implies that $x \in C\left(\alpha^{0}\right)$, as was to be shown.

- Lower hemicontinuity.We will prove the result under the assumption that there is a single constraint (i.e., $c=1$ ). The extension to the general case is straightforward.

Let $\left\{\alpha_{n}\right\} \rightarrow \alpha^{0}$, and consider an arbitrary point $x \in C\left(\alpha^{0}\right)$. We want to show that there exists a companion sequence $\left\{x_{n} ; x_{n} \in C\left(\alpha_{n}\right)\right\}$ that converges to $x$. Notice that because we are concerned only with the limit of this sequence, we can define a finite number of its initial terms arbitrarily.

We will consider two cases in turn.

- Case (i): $g\left(x, \alpha^{0}\right)>0$. Because $g()$ is continuous, there exists some $\varepsilon>0$ such that

$$
\begin{equation*}
g(y, \alpha)>0 \forall(y, \alpha) \in B_{\varepsilon}\left(x, \alpha^{0}\right) \tag{1}
\end{equation*}
$$

Consider the sequence $\left\{\left(x, \alpha_{n}\right)\right\}$. Because $\left\{\left(x, \alpha_{n}\right)\right\} \rightarrow\left(x, \alpha^{0}\right)$, there exists some $N$ such that $\left(x, \alpha_{n}\right) \in B_{\varepsilon}\left(x, \alpha^{0}\right)$ for all $n \geq N$. By (1), this implies that

$$
g\left(x, \alpha_{n}\right)>0 \forall n \geq N
$$

(i.e., that $x \in C\left(\alpha_{n}\right)$ for all $\left.n \geq N\right)$. Hence, we can construct the sequence $\left\{x_{n}\right\}$ as follows:

$$
x_{n}=\left\{\begin{array}{l}
x \quad \text { if } n \geq N \\
\text { an arbitrary } y_{n} \in C\left(\alpha_{n}\right) \text { if } n<N
\end{array}\right.
$$

Notice that by construction $\left\{x_{n}\right\} \rightarrow x$ and $x_{n} \in C\left(\alpha_{n}\right)$ for all $n$, as we wanted to show.

- Case (ii): $g\left(x, \alpha^{0}\right)=0$. We know that there exists some $x^{\prime}$ such that $g\left(x^{\prime}, \alpha^{0}\right)>0$ and that $g()$ is concave in $x$ for given $\alpha$.

Hence, the set

$$
C\left(\alpha^{0}\right)=\left\{x \in X ; g\left(x, \alpha^{0}\right) \geq 0\right\}
$$

is convex, and it follows that the line segment $\left[x, x^{\prime}\right]$ is contained in $C\left(\alpha^{0}\right)$. Moreover, for any point in $\left(x, x^{\prime}\right)$,

$$
\begin{equation*}
x^{\hat{\lambda}}=(1-\lambda) x+\lambda x^{\prime}, \quad \text { with } \lambda \in(0,1) \tag{1}
\end{equation*}
$$

the concavity of $g\left(\cdot, \alpha^{0}\right)$ implies that

$$
\begin{equation*}
g\left(x^{\lambda}, \alpha^{0}\right) \geq(1-\lambda) g\left(x, \alpha^{0}\right)+\lambda g\left(x^{\prime}, \alpha^{0}\right)>0 \tag{2}
\end{equation*}
$$

Consider a sequence of points of the form (1), $\left\{y_{k}\right\} \subseteq\left(x, x^{\prime}\right)$, such that

$$
\left\|y_{k}-x\right\|<1 / k
$$

for each positive integer $k$. (To obtain such a sequence, it is enough to choose 0 $<\lambda_{k}<1 /\left(k\left\|x^{\prime}-x\right\|\right)$ in (1).) Observe that by construction $\left\{y_{k}\right\} \rightarrow x$ and that $g\left(y_{k}\right.$, $\left.\alpha^{0}\right)>0$, by (2). This last expression implies (by the continuity of $g\left(y_{k}, \cdot\right)$ and the fact that $\left.\left\{\alpha_{n}\right\} \rightarrow \alpha^{0}\right)$ that for each given $k$ there exists some positive integer $n_{k}$ such that

$$
\begin{equation*}
g\left(y_{k}, \alpha_{n}\right)>0 \forall n \geq n_{k} \tag{3}
\end{equation*}
$$

Notice, moreover, that we can choose $n_{k}$ as large as we want and that, in particular, we can choose it so that $n_{k}>n_{k-1}$ for all $k$.

We will now construct the desired sequence $\left\{x_{n}\right\}$ as follows: For $n<n_{1}$, let $x_{n}$ be some arbitrary point in $C\left(\alpha_{n}\right)$; for $n_{1} \leq n<n_{2}$, put $x_{n}=y_{1}$, and, in general, for $n_{k} \leq$ $n<n_{k+1}$ let $x_{n}=y_{k}$. Because $x_{n} \in C\left(\alpha_{n}\right)$ by construction (see (3)), it only remains to show that $\left\{x_{n}\right\} \rightarrow x$.

Fix some arbitrary $\varepsilon>0$. Then there exists some integer $M$ such that $1 / M<\varepsilon$. We will show that for all $n>n_{M}$ we have $\left\|x_{n}-x\right\|<\varepsilon$. Let $n>n_{M}$; then $n$ lies between $n_{k}$ and $n_{k+1}$ for some $k>M$.

Hence,

$$
x_{n}=y_{k} \quad \text { and } \quad\left\|x_{n}-x\right\|=\left\|y_{k}-x\right\|<1 / k<1 / M<\varepsilon
$$

which establishes the theorem.

i

Problem 2.5. Extend the proof of Lemmas 2.3 and 2.4 to the case of several constraints.

Problem 2.6. We will give an alternative proof of the lower hemicontinuity of $C()$ under the assumptions of Theorem 2.2.

(i) Assume first that there is a single constraint. We will construct a sequence $\left\{x_{n}\right\}$ of the form

$$
x_{n}=\left\{\begin{array}{l}
x \quad \text { if } x \in C\left(\alpha_{n}\right), \text { i.e., if } g\left(x, \alpha_{n}\right) \geq 0  \tag{1}\\
x_{n} \in C\left(\alpha_{n}\right) \text { s.th. } g\left(x_{n}, \alpha_{n}\right)=0 \text { if } g\left(x, \alpha_{n}\right)<0
\end{array}\right.
$$

for $n$ larger than some $N$, and set $x_{n}$ equal to an arbitrary point in $C\left(\alpha_{n}\right)$ for $n$ $\leq N$. To set $N$, recall that by assumption there exists a point $x^{\prime} \in C(\alpha)$ such that $g\left(\alpha, x^{\prime}\right)>0$. Because $\left\{\alpha_{n}\right\} \rightarrow \alpha$ and $g()$ is continuous in $\alpha$ for given $x$, there is some $N$ such that $g\left(x^{\prime}, \alpha_{n}\right)>0$ for all $n>N$. Use the continuity of $g\left(\cdot, \alpha_{n}\right)$ to show that for $n>N$ we can choose $x_{n}=\left(1-\lambda_{n}\right) x+\lambda_{n} x^{\prime}$ for some $\lambda_{n} \in(0,1)$ whenever $g\left(x, \alpha_{n}\right)<0$.

(ii) To complete the proof we have to show that $\left\{x_{n}\right\} \rightarrow x$. Suppose first that there exists some integer $M$ such that $g\left(x, \alpha_{n}\right)>0$ for all $n>M$. Then, according to (1), we have $x_{n}=x$ for all $n>M$, and the sequence clearly converges to the desired point. If this is not the case, then $\left\{\alpha_{n}\right\}$ must have a subsequence $\left\{\alpha_{n_{k}}\right\}$ with the property that $g\left(x, \alpha_{n_{k}}\right)<0$ for all $n_{k}$, and because $g()$ is continuous and $\left\{\alpha_{n_{k}}\right\} \rightarrow \alpha$, we have:

$$
\lim _{n_{k} \rightarrow \infty} g\left(x, \alpha_{n_{k}}\right)=g(x, \alpha) \leq 0
$$

Because $x \in C(\alpha)$ implies $g(x, \alpha) \geq 0$, moreover, it must be the case that

$$
\begin{equation*}
g(x, \alpha)=0 \tag{2}
\end{equation*}
$$

To show that $\left\{x_{n}=\left(1-\lambda_{n}\right) x+\lambda_{n} x^{\prime}\right\} \rightarrow x$, consider the sequence $\left\{\lambda_{n}\right\}$, and notice that $\left\{x_{n}\right\} \rightarrow x$ if and only if $\left\{\lambda_{n}\right\} \rightarrow 0$. Assume that $\left\{\lambda_{n}\right\} \rightarrow 0$, and use the concavity of $g()$ in $x$ to obtain a contradiction.

(iii) Extend the proof to the case of several constraint functions.

The following problems show that the upper hemicontinuity of $C(\alpha)$ can be established under other sets of assumptions.

Problem 2.7. Given sets $X \subseteq \mathbb{R}^{\mathrm{n}}$ and $\Omega \subseteq \mathbb{R}^{\mathrm{P}}$, let $g^{i}(x, \alpha): X \times \Omega \longrightarrow \mathbb{R}$ be a continuous function for all $I=1, \ldots, c$, and define the correspondence $C: \Omega \rightarrow \rightarrow X$ by

$$
C(\alpha)=\left\{x \in X ;\|x\| \leq B \text { and } g^{i}(x, \alpha) \geq 0 \forall i=1, \ldots, c\right\}
$$

Show that $C()$ is uhc at each $\alpha$.

One of the crucial steps in the proof that the correspondence defined in Problem 2.7 is uhc is establishing that given an arbitrary sequence of parameters $\left\{\alpha_{n}\right\} \rightarrow \alpha$, any companion sequence of feasible choices $\left\{x_{n}\right\}$, with $x_{n} \in C\left(\alpha_{n}\right)$ for each $n$, has a convergent subsequence. The desired result then follows easily by the continuity of the constraint functions $g^{i}()$. In the preceding problem, the existence of such a convergent subsequence was guaranteed by the assumption that the constraint set was contained within a "fixed" bounded set for all parameter values. The following problem shows how this assumption can be relaxed, at the expense of introducing additional assumptions on the constraint functions.

Problem 2.8. Given sets $X \subseteq \mathbb{R}^{\mathrm{n}}$ and $\Omega \subseteq \mathbb{R}^{\mathbb{P}}$, with $X \times \Omega$ convex, let $g^{i}(x, \alpha): X \times \Omega \longrightarrow \mathbb{R}$ be a continuous and concave function (in $(x, \alpha)$ ) for all $i=1, \ldots, c$, and define the correspondence $C: \Omega \rightarrow X$ by

$$
C(\alpha)=\left\{x \in X ; g^{i}(x, \alpha) \geq 0 \forall i=1, \ldots, c\right\}
$$

Fix a value $\alpha^{0}$ of the parameter vector and assume that $C\left(\alpha^{0}\right)$ is bounded. Let $\left\{\alpha_{n}\right\}$ be an arbitrary sequence converging to $\alpha^{0}$, and consider a companion sequence $\left\{x_{n}\right\}$ with $x_{n} \in C\left(\alpha_{n}\right)$ for each $n$. Show that $\left\{x_{n}\right\}$ is bounded.

Hint: By contradiction. Suppose $\left\{x_{n}\right\}$ is unbounded. Then it has a subsequence that diverges to infinity in norm. To simplify the notation, assume that the sequence itself diverges in norm (i.e., that $\left\{\left\|x_{n}\right\|\right\} \rightarrow \infty$ ). Consider the sequence $\left\{X_{n}\right\}=\left\{\left(x_{n}, \alpha_{n}\right)\right\}$. Because $\left\{\left\|x_{n}\right\|\right\} \rightarrow \infty$, it follows that $\left\{\left\|X_{n}\right\|\right\} \rightarrow \infty$.

Construct a new sequence $\left\{Y_{n}\right\}$ by "projecting" $\left\{X_{n}\right\}$ onto the boundary of a ball in $X \times \Omega$ whose interior contains the set $C\left(\alpha^{0}\right) \times\left\{\alpha^{0}\right\}$. The resulting sequence will be bounded and will therefore have a convergent subsequence. Take the limit of this subsequence and seek a contradiction.

Problem 2.9. For each $\alpha$ and each $\varepsilon>0$, define the set $\underline{C}_{\varepsilon}(\alpha)$ by

$$
\underline{C}_{\varepsilon}(\alpha)=\left\{x \in X ; g^{i}(x, \alpha)-\varepsilon \geq 0 \forall i=1, \ldots, c\right\}
$$

Show that, under the assumptions of Theorem 2.2, for every $\varepsilon>0$ there exists some $\delta>0$ such that $C(\alpha) \supseteq \underline{C}_{\varepsilon}\left(\alpha^{0}\right)$ for all $\alpha \in B_{\delta}\left(\alpha^{0}\right)$.

Notice that if $\varepsilon$ is sufficiently large, $\underline{C}_{\varepsilon}(\alpha)$ will be empty, but the result still holds, because the empty set is a subset of every set by convention.

## (b) Comparative Statics of Smooth Optimization Problems

We are often interested in determining how the behavior of an agent will vary in response to changes in some of the parameters that describe his "environment." For example, how would a change in the price of a certain good affect its demand by an optimizing consumer? Mathematically the problem reduces to that of determining the signs of the partial derivatives of the decision function,

$$
x(\alpha)=\arg \max _{x \in C(\alpha)} f(x, \alpha)
$$

with respect to the parameters $\partial x_{i}^{*} / \partial \alpha_{k}$ ).

In this section we discuss the traditional method of approaching this problem. Our assumptions will ensure that $x()$ is a differentiable function defined implicitly as the solution to a system of equations - the first-order necessary conditions (FONCs) for the problem. Hence, the method discussed in Chapter 5 can be applied. After checking that the conditions of the implicit-function theorem (IFT) hold, we differentiate the first-order conditions implicitly with respect to the parameters, solve for the partials of interest, and try to sign them with the help of the sufficient conditions for an optimum.

In order for this method to be applicable, we need to impose the following assumptions on the optimization problem:

(i) $f()$ and $g()$ are $C^{2}$ functions. Because we need to differentiate the FONCs, which involve first derivatives of $f$ and $g$, these functions must be $C^{2}$ for $x()$ to be $C^{1}$.

(ii) The solution to the programming problem is a regular maximum (i.e., it satisfies the sufficient conditions for a strict local maximum). This assumption ensures that the matrix obtained by differentiating the system of FONCs with respect to the choice variables $x$ will be invertible, thus allowing us to use the IFT, and it will also be helpful when it comes to signing the comparative-statics partials.

Consider the unconstrained maximization problem

$$
\begin{equation*}
\max _{x} f(x, \alpha) \tag{P}
\end{equation*}
$$

where $f$ is a $C^{2}$ function of $n$ variables, and fix the vector of parameters at $\alpha^{0}$. Then the first-order condition for a maximum,

$$
\begin{equation*}
D_{x} f\left(x, \alpha^{0}\right)=\underline{0} \tag{1}
\end{equation*}
$$

is a system of $n$ equations in the unknown optimal values of the $n$ instruments. Assume that $x^{0}$ is a regular maximizer of $f$ for $\alpha^{0}$, that is, a solution of (1) such that the Hessian matrix of $f$ evaluated at $\left(x^{0}, \alpha^{0}\right), H=D_{x}^{2} f\left(x^{0}, \alpha^{0}\right)$, is negative definite. Then

$$
D_{x} f\left(x^{0}, \alpha^{0}\right)=\underline{0} \text { and }|H|=\left|D_{x}\left[D_{x} f\left(x^{0}, \alpha^{0}\right)\right]\right|=\left|D_{x}^{2} f\left(x^{0}, \alpha^{0}\right)\right| \neq 0
$$

That is, the conditions of the IFT hold at $\left(x^{0}, \alpha^{0}\right){ }^{3}$ Hence, the solution mapping for the maximization problem, $x^{*}=x(\alpha)$, is locally a well-defined and smooth function. Substituting $x()$ into the first-order conditions, we obtain the identity

$$
\begin{equation*}
D_{x} f[x(\alpha), \alpha] \equiv \underline{0} \tag{2}
\end{equation*}
$$

Differentiating with respect to $\alpha$,

$$
D_{x}^{2} f\left(x^{0}, \alpha^{0}\right) D x\left(\alpha^{0}\right)+D_{x \alpha} f\left(x^{0}, \alpha^{0}\right)=\underline{0}
$$

and solving for $D_{x}\left(\alpha^{0}\right)$,

$$
D x\left(\alpha^{0}\right)=-\left[D_{x}^{2} f\left(x^{0}, \alpha^{0}\right)\right]^{-1} D_{x \alpha} f\left(x^{0}, \alpha^{0}\right)
$$

Finally, using Cramer's rule,

$$
\frac{\partial x_{i}^{*}}{\partial \alpha_{k}}=-\frac{\left|H_{i}\right|}{|H|}
$$

where $\left|H_{i}\right|$ is the determinant of the matrix obtained by replacing the $i$ th column of the Hessian with the $k$ th column of $D_{x \alpha} f\left(x^{0}, \alpha^{0}\right)$, that is, the partials of the form $\left(\partial^{2} f\left(x^{0}, \alpha^{0}\right) / \partial x_{j} \partial \alpha_{k}\right)$ for $j=1, \ldots, n$. Notice that the sign of $|H|$ will be determined by the assumption that the Hessian is negative definite, so we only have to worry about the sign of $\left|H_{i}\right|{ }^{4}$

A similar procedure will work for the parameterized Lagrange problem

$$
\begin{equation*}
\max _{x}\{f(x, \alpha) ; g(x, \alpha)=\underline{0}\} \tag{P.L}
\end{equation*}
$$

where $f$ and $g$ are $C^{2}$ functions. When $\alpha=\alpha^{0}$, the Lagrangian for this problem is

$$
£\left(x, \lambda ; \alpha^{0}\right)=f\left(x, \alpha^{0}\right)+\lambda^{T} g\left(x, \alpha^{0}\right)
$$

The first-order conditions for a maximum give us a system of $n+c$ equations in the unknowns $(x, \lambda)$ :

$$
\begin{gather*}
D_{x} £\left(x, \lambda ; \alpha^{0}\right)=D_{x} f\left(x, \alpha^{0}\right)+\lambda^{T} D_{x} g\left(x, \alpha^{0}\right)=\underline{0} \\
D_{\lambda} £\left(x, \lambda ; \alpha^{0}\right)=g\left(x, \alpha^{0}\right)=\underline{0} \tag{1}
\end{gather*}
$$

Assume that $x^{0}$ is a regular maximum of $f\left(x, \alpha^{0}\right)$ subject to $g\left(x, \alpha^{0}\right)=\underline{0}$. Then (1) holds at $x^{0}$, and

$$
h^{T} D_{x}^{2} £\left(x^{0}, \lambda^{0} ; \alpha^{0}\right) h<0 \forall h \in \mathbb{R}^{\mathbb{n}} \text { s.th. } D_{x} g\left(x^{0}, \alpha^{0}\right) h=\underline{0}
$$

implying that

$$
|\bar{H}|=\left|\begin{array}{cc}
D_{x}^{2} £\left(x^{0}, \lambda^{0} ; \alpha^{0}\right) & D_{x} g\left(x^{0}, \alpha^{0}\right)^{T} \\
D_{x} g\left(x^{0}, \alpha^{0}\right) & 0
\end{array}\right| \neq 0
$$

Now, the bordered Hessian $|\bar{H}|$ is the same as the Jacobian of endogenous variables of the system (1). We can therefore apply the IFT to the system of first-order conditions to obtain

$$
\frac{\partial x_{i}^{*}}{\partial \alpha_{k}}=-\frac{\left|\bar{H}_{l}\right|}{|\bar{H}|}
$$

where the sign of $|\bar{H}|$ is known.

For the Kuhn-Tucker problem, we have one additional complication. At an optimal solution for $\alpha^{0}$, some of the constraints will be active, and others inactive. Now, if a small change in $\alpha$ does not change the set of binding constraints, we can proceed as in the Lagrange case, working with the active constraints and ignoring the inactive ones. At certain points, however, a small perturbation of the constraints may cause some previously active constraint to become inactive, or vice versa, giving rise to a "change of regime." At such transition points, the solution mapping $x(\alpha)$ may not be differentiable. Hence, we have to be a bit more careful and consider all the possibilities that may arise in different regimes.

Problem 2.10. An agent consumes two goods, $x_{1}$ and $x_{2}$, with prices $p_{1}$ and $p_{2}$, respectively. Her utility function is of the form $U\left(x_{1}, x_{2}\right)=\alpha\left(x_{1}^{\alpha}+x_{2}^{\alpha}\right)$, with $\alpha<1$. Verify that $U()$ is strictly concave. Derive the demand function of the agent. In what direction does the demand for good 1 change if there is an increase in the price of good 2 ?

Problem 2.11. A competitive firm maximizes profits, $\Pi(x)=p f(x)-w x$, taking as given the price of its output $p$ and the vector $w \in \mathbb{R}^{m}$ of factor prices. Assume that the production function $f$ is $C^{2}$ and strictly concave, with positive but diminishing marginal products $\left(f_{i}>0, f_{i i}<0, i=1, \ldots, n\right)$.

Write the first-order conditions for the firm's problem, and apply the IFT to the resulting system to show that the demand for each factor is a decreasing function of its price (i.e., that $\partial x_{1}^{*} / \partial w_{i}<0$ ).
(c) Value Functions and Envelope Theorems

The value function $V: \Omega \longrightarrow \mathbb{R}$ for a maximization problem gives the maximum attainable value of the objective function for each value of the parameters:

$$
V(\alpha)=\max _{x}\{f(x ; \alpha) ; x \in C(\alpha)\}=f\left(x^{*}, \alpha\right), \quad \text { where } x^{*} \in S(\alpha)
$$

As an illustration, consider the value function for an unconstrained maximization problem and refer to Figure 7.5. For each particular value of $x$, we can plot $f$ as a function of the parameters alone. This yields a family of curves, some of which are shown in Figure 7.5. Graphically, the maximum-value function corresponds to the upper "envelope" of this family of curves.

Functions of this type are commonly found in economic theory. In general terms, it is clear that the maximum payoff available to a rational agent is a function of the "environment" she faces, as summarized by the vector of parameters $\alpha$. An example of a maximum-value function that we will encounter later is the indirect utility function

$$
\Psi(p, y)=\max _{x}\{U(x) \text { s.t. } p x \leq y\}=U[x(p, y)]
$$

which gives the maximum utility attainable by a consumer as a function of the prices $(p)$ she faces and her income ( $y$ ). Clearly, this is the utility obtained by consuming the optimal bundle, as given by the demand function $x(p, y)$.

In this section we will review some properties of value or envelope functions that play an important role in microeconomic theory. Then we will

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-317.jpg?height=636&width=1076&top_left_y=1458&top_left_x=194)

Figure 7.5. A maximum-value function.
establish some results that will allow us to relate the derivatives of the value function to those of the underlying objective and constraint functions. These so-called envelope theorems provide a convenient way to establish some important relationships in microeconomic theory (e.g., Roy's identity, Shephard's lemma). These results, in turn, can be used to derive some basic comparative-statics results concering demand and supply functions from the curvature properties of the value function. Somewhat surprisingly, this rather roundabout approach to comparative statics often turns out to be more convenient than the traditional route via the IFT and implicit differentiation of the first-order conditions.

We begin with two results that provide sufficient conditions for the concavity or convexity of the value function.

Theorem 2.12. Concavity of the value function. Consider the following problem and the associated value function:

$$
\mathrm{V}(\alpha)=\max _{\mathrm{x}}\{\mathrm{f}(\mathrm{x} ; \alpha) ; \mathrm{g}(\mathrm{x} ; \alpha) \geq \underline{0}\}
$$

Suppose the objective function $\mathrm{f}$ is concave in $(\mathrm{x}, \alpha)$, (i.e., in both parameters and decision variables) and that all the constraint functions $\mathrm{g}^{\mathrm{j}}(), \mathrm{j}=1, \ldots, \mathrm{c}$, are quasiconcave. Then $\mathrm{V}($ ) is concave.

Proof. Take two arbitrary values of the parameter vector, $\alpha^{\prime}$ and $\alpha^{\prime \prime}$, and let $x^{\prime}=x\left(\alpha^{\prime}\right)$ and $x^{\prime \prime}=x\left(\alpha^{\prime \prime}\right)$ be the corresponding optimal choices of $x$. To establish the concavity of $V()$ we need to show that

$$
(1-\lambda) V\left(\alpha^{\prime}\right)+\lambda V\left(\alpha^{\prime \prime}\right) \leq V\left[(1-\lambda) \alpha^{\prime}+\lambda \alpha^{\prime \prime}\right]
$$

for any $\lambda \in(0,1)$.

Consider now the pair $\left(x^{\lambda}, \alpha^{\lambda}\right)$ defined by

$$
x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{\prime \prime} \text { and } \alpha^{\lambda}=(1-\lambda) \alpha^{\prime}+\lambda \alpha^{\prime \prime}
$$

and observe that, in principle, $x^{\lambda} \neq x\left(\alpha^{\lambda}\right)$, that is, $x^{\lambda}$ is not necessarily optimal for $\alpha^{\lambda}$.

We begin by showing that $x^{\lambda}$ is feasible for $\alpha^{\lambda}$. Because $x^{\prime}$ and $x^{\prime \prime}$ are (optimal and therefore necessarily) feasible for $\alpha^{\prime}$ and $\alpha^{\prime \prime}$, we have, for each $j$,

$$
\begin{equation*}
g^{j}\left(x^{\prime}, \alpha^{\prime}\right) \geq 0 \quad \text { and } \quad g^{j}\left(x^{\prime \prime}, \alpha^{\prime \prime}\right) \geq 0 \tag{1}
\end{equation*}
$$

By the quasiconcavity of $g^{j}$ and (1), we have

$$
g^{j}\left(x^{\lambda}, \alpha^{\lambda}\right) \geq \min \left\{g^{j}\left(x^{\prime}, \alpha^{\prime}\right), g^{j}\left(x^{\prime \prime}, \alpha^{\prime \prime}\right)\right\} \geq 0
$$

so $x^{\lambda}$ is feasible for $\alpha^{\lambda}$.

Next, consider the following chain of inequalities:

$$
\begin{aligned}
V\left(\alpha^{\lambda}\right) & =f\left[x\left(\alpha^{\lambda}\right), \alpha^{\lambda}\right] \geq f\left(x^{\lambda}, \alpha^{\lambda}\right) \geq(1-\lambda) f\left[x\left(\alpha^{\prime}\right), \alpha^{\prime}\right]+\lambda f\left[x\left(\alpha^{\prime \prime}\right), \alpha^{\prime \prime}\right] \\
& =(1-\lambda) V\left(\alpha^{\prime}\right)+\lambda V\left(\alpha^{\prime \prime}\right)
\end{aligned}
$$

The first inequality holds by the observation that $x^{\lambda}$ is not necessarily optimal for $\alpha^{\lambda}$, and the second holds by the concavity of $f$. The equalities are all true by definition.

Unfortunately, the objective and constraint functions we find in consumer and producer theory are typically not concave jointly in decision variables and parameters. The next theorem, requiring weaker assumptions, will be more useful in applications.

Theorem 2.13. Convexity of the value function. Consider the following problem and the associated value function:

$$
\mathrm{V}(\alpha)=\max _{\mathrm{x}}\{\mathrm{f}(\mathrm{x} ; \alpha) ; \mathrm{g}(\mathrm{x}) \geq \underline{0}\}
$$

where $\alpha \in \Omega$, a convex set. (Note that the parameters do not enter the constraint function.) If the objective function is convex in the parameters $\alpha$ for any given $x$, then $\mathrm{V}()$ is convex.

## Problem 2.14. Prove Theorem 2.13.

We now consider the effect of a parameter change on the maximum payoff attainable by an optimizing agent. For a start, assume that the agent maximizes $f\left(x ; \alpha^{0}\right)$ with no constraints, and suppose that the assumptions of the preceding section hold. Then the decision rule for the problem is a welldefined and differentiable function $x(\alpha)$ in some neighborhood of $\alpha^{0}$, and substituting this function into $f()$, we obtain the value function

$$
V(\alpha) \equiv f[x(\alpha), \alpha]
$$

Differentiating with respect to $\alpha$,

$$
D V\left(\alpha^{0}\right)=D_{x} f\left(x^{0} ; \alpha^{0}\right) D x\left(\alpha^{0}\right)+D_{\alpha} f\left(x^{0}, \alpha^{0}\right)
$$

That is, a small change in the value of the parameter vector will affect the value of $f$ in two ways: directly, because $f$ is a function of $\alpha$, and indirectly, through the induced change in the optimal values of the choice variables. On the other hand, the first-order conditions for the problem, $D_{x} f\left(x^{0} ; \alpha^{0}\right)=$ $\underline{0}$, ensure that the marginal gain from small changes in the values of the instruments will be zero when we start from an optimum. Hence, (1) reduces to

$$
D V\left(\alpha^{0}\right)=D_{\alpha} f\left(x^{0}, \alpha^{0}\right)
$$

that is, we need consider only the direct effect. We have proved the following result.

Theorem 2.15. Envelope theorem for unconstrained maximization. Let $\mathrm{f}(\mathrm{x}, \alpha)$ be a $\mathrm{C}^{2}$ function, and let $\mathrm{x}^{0}$ be regular maximum of $\mathrm{f}$ for $\alpha^{0}$. Then

$$
V(\alpha)=\max _{x} f(x ; \alpha)=f[x(\alpha), \alpha]
$$

is differentiable at $\alpha^{0}$, and $\mathrm{DV}\left(\alpha^{0}\right)=\mathrm{D}_{\alpha} \mathrm{f}\left(\mathrm{x}^{0}, \alpha^{0}\right)$.

We now show that a similar result holds for the Lagrange problem. The only difference is that in order to take into account the effect on the constraints of the parameter change, we have to differentiate the Lagrangian, rather than just the objective function, with respect to the parameters.

Theorem 2.16. Envelope theorem for the Lagrange problem. Let

$$
\mathrm{V}(\alpha)=\max _{\mathrm{x}}\{\mathrm{f}(\mathrm{x} ; \alpha) ; \mathrm{g}(\mathrm{x}, \alpha)=\underline{0}\}
$$

where $\mathrm{f}$ and $\mathrm{g}$ are $\mathrm{C}^{2}$. If $\mathrm{x}^{0}$ is a regular solution of this problem for $\alpha^{0}$ (i.e., satisfies the sufficient second-order conditions for a strict local maximum), then $\mathrm{V}$ is differentiable at $\alpha^{0}$, and

$$
\mathrm{DV}\left(\alpha^{0}\right)=\mathrm{D}_{\alpha} £\left(\mathrm{x}^{0}, \alpha^{0}\right)=\mathrm{D}_{\alpha} \mathrm{f}\left(\mathrm{x}^{0}, \alpha^{0}\right)+\lambda^{0 \mathrm{~T}} \mathrm{D}_{\alpha} \mathrm{g}\left(\mathrm{x}^{0}, \alpha^{0}\right)
$$

Proof. Differentiating the Lagrangian function

$$
\begin{equation*}
£\left(x^{0}, \alpha^{0}\right)=f\left(x^{0}, \alpha^{0}\right)+\lambda^{T} g\left(x^{0}, \alpha^{0}\right) \tag{1}
\end{equation*}
$$

we obtain the first-order conditions for the problem:

$$
\begin{gather*}
D_{x} £\left(x, \alpha^{0}\right)=D_{x} f\left(x, \alpha^{0}\right)+\lambda^{T} D_{x} g\left(x, \alpha^{0}\right)=\underline{0}  \tag{2}\\
D_{\lambda} £\left(x, \alpha^{0}\right)=g\left(x, \alpha^{0}\right)=\underline{0} \tag{3}
\end{gather*}
$$

Under the assumptions of the theorem, the decision rule for the problem is a well-defined and differentiable function. Substituting it into the objective function, we recover the value function

$$
V(\alpha) \equiv f[x(\alpha), \alpha]
$$

Differentiating $V()$ with respect to the parameters, and using (2),

$$
\begin{align*}
D V\left(\alpha^{0}\right) & =D_{\alpha} f\left(x^{0}, \alpha^{0}\right)+D_{x} f\left(x^{0} ; \alpha^{0}\right) D x\left(\alpha^{0}\right) \\
& =D_{\alpha} f\left(x^{0}, \alpha^{0}\right)-\lambda^{T} D_{x} g\left(x^{0}, \alpha^{0}\right) D x\left(\alpha^{0}\right) \tag{4}
\end{align*}
$$

Substituting the decision rule into (3) and differentiating with respect to $\alpha$,

$$
\begin{equation*}
D_{x} g\left(x^{0}, \alpha^{0}\right) D x\left(\alpha^{0}\right)+D_{\alpha} g\left(x^{0}, \alpha^{0}\right)=\underline{0} \tag{5}
\end{equation*}
$$

Using this expression, (4) reduces to

$$
D V\left(\alpha^{0}\right)=D_{\alpha} f\left(x^{0}, \alpha^{0}\right)+\lambda^{T} D_{\alpha} f\left(x^{0}, \alpha^{0}\right)
$$

As noted in the preceding section, the decision rule for a Kuhn-Tucker problem may not be differentiable at points at which a regime change takes place. The same is true of the value function.

To conclude this section, we will use the envelope theorem to provide a rigorous basis for the intuitive interpretation of the Lagrange multipliers as shadow prices of the constraints advanced in Section 1(b). Consider a version of the Lagrange problem in which the constraints are of the form $g^{j}(x)+\gamma_{j}=0$ for $j=1, \ldots, c$.

$$
V(\gamma)=\max _{x}\{f(x) ; g(x)+\gamma=\underline{0}\}
$$

By the envelope theorem, we have $D V\left(\gamma^{0}\right)=\lambda^{0}$, where $\lambda^{0}$ is the vector of Lagrange multipliers for the problem. Thus the Lagrange multiplier $\lambda_{j}^{0}$ tells us how the maximum value of the program (given by the value function $V$ ) changes with the corresponding constraint constant $\gamma_{j}$. In other words, the multipliers measure the "sensitivity" of the value function to changes in the constraint constants.

## 3. Problems and Applications

Problem 3.1. An agent lives for two periods and has an endowment of one unit of a homogeneous consumption good in the first period, and $\gamma$ units in the second period. His utility function is given by

$$
\ln c_{1}+\ln c_{2}
$$

where $c_{i}$ is consumption in period $i$. The agent can store any feasible quantity of his first-period endowment for consumption at a later time and can get an interest-free loan of up to $\beta$ units of the good (i.e., $s \geq-\beta$, and $R=1$ ).

(i) Calculate the agent's saving function, ignoring the constraint $s \geq-\beta$.

(ii) For what combinations of parameter values will the constraint be binding? In what regions of the $(\beta, \gamma)$ plane will we have an interior solution and a corner solution? Write the agent's savings function, taking into account the constraint.

(iii) Write the maximum-value function for the problem as a function of $\gamma, V(\gamma)$. Verify that $V(\gamma)$ is continuous at the point at which there is a regime change (i.e., as we go from an interior solution to one in which the constraint is binding). Is the value function differentiable at this point?

## (a) Profit Maximization by a Competitive Firm

Consider the problem faced by a competitive firm that produces a single output $y$ using a vector of inputs $x$. The firm takes as given input and output prices $(w, p)$ and maximizes profits, $p y-w x$, subject to the feasibility constraint $y \leq f(x)$, where $f$ is a concave production function that describes the firm's technology. We will require, moreover, that input and output be nonnegative and assume that the input vector $x$ is bounded (e.g., by the overall factor supplies available in the economy). Hence, $\|x\| \leq B$ for some real number $B$ (or, if you prefer, $x \leq e$, where $e$ is the vector of factor endowments). Finally, we will assume that $p>0$ and $w>0$ (i.e., input prices are nonnegative, and at least some of them are strictly positive).

The firm's problem can be written

$$
\begin{equation*}
\pi(p, w)=\max _{x . y}\{p y-w x \text { s.t. } y \leq f(x),(x, y) \geq \underline{0}, \text { and }\|x\| \leq B\} \tag{P}
\end{equation*}
$$

and the problem's value function, $\pi(p, w)$, is the firm's profit function. To simplify notation, let $z=(y,-x)$ and $q=(p, w)$. Then profit is simply $q z$.

Under our assumptions, $q z$ is a continuous function defined on a compact set. Hence, $(\mathrm{P})$ always has a solution. We will now study some properties of the solution and value functions for the firm's problem under some additional assumptions.

Problem 3.2. Show that if $f$ is strictly concave, then $(\mathrm{P})$ has a unique solution for a given price vector $q$.

Hint: By contradiction, assume that there are two distinct optimal production plans, $z^{\prime}$ and $z^{\prime \prime}$, and show that we can construct a feasible plan that will yield a strictly larger profit.

Problem 3.3. Under the assumptions of Problem 3.2, the firm's production plans (i.e., its output level and factor demands) are well-defined functions of the price vector $q$. We will show that these functions are continuous.

Fix a vector $q^{0}$ of prices, and consider a sequence of price vectors $\left\{q_{n}\right\}$ convergent to $q^{0}$ and the corresponding sequence of optimal production plans $\left\{z_{n}\right\}$, with $z_{n}=z\left(q_{n}\right)$ for each $n$. We want to show that $\left\{z_{n}\right\}$ converges to $z\left(q^{0}\right)=z^{\prime}$. To establish this result, we will proceed by contradiction. Suppose that $\left\{z_{n}\right\}$ does not converge to $z^{\prime}$.

(i) Then $\left\{z_{n}\right\}$ has a convergent subsequence $\left\{z_{n_{k}}\right\}$, with limit $z^{0}$ different from $z^{\prime}$. Explain why this is true.

(ii) Let $\left\{q_{n_{k}}\right\}$ be the price subsequence corresponding to $\left\{z_{n_{k}}\right\}$. We have that

$$
\left\{q_{n_{k}}\right\} \rightarrow q^{0} \quad \text { and } \quad\left\{z_{n_{k}}\right\} \rightarrow z^{0} \neq z^{\prime}=z\left(q^{0}\right)
$$

Show that we arrive at the following contradiction: Given any price vector $q_{n_{k}}$ sufficiently close to $q^{0}, z^{\prime}$ is strictly better than the optimal plan $\left\{z_{n_{k}}\right\}$. Hint: Use the fact that $q z$ is a continuous function.

Under assumptions that guarantee the differentiability of the solution function for the firm's problem, we have shown in Problem 2.10 that the supply is increasing in output price, and the demand for each factor is decreasing in its price. The following problem shows that comparativestatics results can sometimes be obtained without differentiability assumptions.

Problem 3.4. Consider two price vectors $q_{1}$ and $q_{0}$ and the corresponding optimal production plans $z_{1}$ and $z_{0}$. Because $z_{1}$ is feasible but not necessarily optimal for $q_{0}$, it must yield a lower profit than $z_{0}$ at this price vector. Using this observation, show that for any $i, \Delta q_{i} \Delta z_{i} \geq 0$ (e.g., for the first component of these vectors we have $\Delta p \Delta y \geq 0$, i.e., an increase in the price of output must yield an increase in supply).

Problem 3.5. Show that the profit function $\pi(q)$ is convex. Can you give an economic interpretation of this property?

Problem 3.6. If the profit function is differentiable, the envelope theorem implies that $D \pi(q)=z(q)$, that is, the derivative of the profit function at a point is simply the optimal production plan (this is Hotelling's lemma). We will show that the profit function is differentiable whenever $f()$ is strictly concave.

Fix a price vector $q$, and consider the behavior of the profit function as we move away from this point. Using the fact that $\pi(q)=q z(q)$, show that for any change $h$ in the price vector,

$$
\begin{gather*}
\pi(q+h) \geq \pi(q)+h z(q)  \tag{1}\\
\pi(q) \geq \pi(q+h)-h z(q+h) \tag{2}
\end{gather*}
$$

Using (1) and (2), show that

$$
\begin{equation*}
h[z(q+h)-z(q)] \geq \pi(q+h)-\pi(q)-h z(q) \geq 0 \tag{3}
\end{equation*}
$$

Using this expression, show that $\pi$ is differentiable at $q$ and $D \pi(q)=$ $z(q)$.

The next problem illustrates how the envelope theorem and the properties of the value function can sometimes be used to obtain comparativestatics results.

Problem 3.7. Suppose the profit function is $C^{2}$. Using the convexity of $\pi(q)$ and the fact that $D \pi(q)=z(q)$, show once more that factor demand functions are downward-sloping.

## (b) Implicit Contracts

Consider the situation faced by a firm and a large number of workers who are "associated" with it. The firm's production technology is of the form

$$
y=x f(L)
$$

where $L$ is the level of labor input, and $x$ is an exogenous productivity shock. We will assume that the production function $f()$ is strictly increasing and strictly concave and that the productivity shock may be either high or low $\left(x \in\left\{x_{H}, x_{L}\right\}\right.$, where $\left.x_{H}>x_{L}\right)$, with probabilities $q_{H}, q_{\mathrm{L}}\left(q_{H}+q_{L}=1\right)$.

For simplicity, we will assume that there is a continuum of unit measure of identical workers, that is, an infinite number of workers, each of them represented by a point in the interval $(0,1)$. Each worker is endowed with a unit of divisible time that he can spend at work or in leisure. His utility is given by

$$
W(c, 1-h)=U(c)+V(1-h)
$$

where $c$ is consumption (= income), $1-h$ is leisure, and the functions $U()$ and $V()$ are strictly increasing and strictly concave.

Before the productivity shock is realized, the firm and its workers negotiate a contract. Notice that there is no reason that the contract should specify wage and employment levels that are independent of the value of $x$. In fact, both workers and firms will find it advantageous to build some flexibility into the contract (to allow them to take advantage of good production opportunities or to share risks optimally among them), and they can do so by conditioning payments and labor hours on contingencies observable by all parties involved. Hence, if the realization of the productivity shock is freely observable by both workers and firms, a contract will be a statecontingent schedule $C(x)$ specifying, for each possible state of nature $x$, the fraction of the labor force that will be employed $(n)$, the number of "hours" each employed individual will work $(h)$, and the compensation to be paid to each employed worker $\left(c^{e}\right)$ and laid-off worker $\left(c^{u}\right)$. Hence,

$$
C\left(x_{i}\right)=\left[c^{e}\left(x_{i}\right), h\left(x_{i}\right), n\left(x_{i}\right), c^{u}\left(x_{i}\right)\right] \text { for } i=H, L
$$

(To simplify the notation, we will use $h\left(x_{i}\right)=h_{i}$, etc.) We will further assume that if layoffs are called for (i.e., if $n_{i}<1$ in some state), the workers to be fired will be selected by lot, so that, ex ante, each worker faces the same probability $1-n_{i}$ of being laid off in state $i$.

It seems reasonable to assume that rational firms and workers should agree on a Pareto-efficient contract (i.e., that they would not settle for a contract if there were some feasible alternative that would make one of the parties better off without making the other worse off). Assuming that the firm is risk-neutral, that is, cares only about expected profits (e.g., because it is owned by well-diversified investors), any such contract can be characterized as the solution to the following problem:

$$
\begin{equation*}
\max E \pi=\sum_{i} q_{i}\left[x_{i} f\left(n_{i} h_{i}\right)-n_{i} c_{i}^{e}-\left(1-n_{i}\right) c_{i}^{u}\right] \tag{P}
\end{equation*}
$$

subject to

$$
E W=\sum_{i} q_{i}\left\{n_{i}\left[U\left(c_{i}^{e}\right)+V\left(1-h_{i}\right)\right]+\left(1-n_{i}\right)\left[U\left(c_{i}^{u}\right)+V(1)\right]\right\} \geq W_{0}
$$

for some given $W_{0}$. That is, we maximize expected profits subject to the constraint that workers' expected utility not fall below some given level. (If there is a competitive market in the background, we can interpret $W_{0}$, the reservation utility of the representative worker, as the utility level guaranteed by the equilibrium contract available in the market, and we can think of $(\mathrm{P})$ as the problem faced by a manager who wants to maximize expected profit subject to the constraint that his contract offer must be acceptable to workers who would otherwise go elsewhere.) Alternatively, we could maximize workers' expected utility subject to the constraint that expected profits not fall below some minimum level, and we would get exactly the same results.

Problem 3.8. Show that the optimal contract involves no layoffs (i.e., $n_{i}=1$ for all $i$ ).

Hint: Suppose we have a contract that specifies some layoffs in certain states of nature. Then workers face a lottery between working and being laid off in each of these states, and, being risk-averse, they do not like it. Show that it is possible to construct another contract with no layoffs that will yield the same profit in each state and will be strictly preferred by workers. A contract featuring slightly lower pay will be acceptable to workers and strictly preferred by firms. Does the argument rely in any way on the firm's risk neutrality?

The preceding result allows us to simplify the optimal-contract problem. Because workers are employed in all states with probability 1 , there is no loss of generality in specifying a contract simply as $C(x)=[c(x), h(x)]$. The optimal-contract problem, then, can be written

$$
\max E \pi=\sum_{i} q_{i}\left[x_{i} f\left(h_{i}\right)-c_{i}\right]
$$

subject to $E W=\Sigma_{i} q_{i}\left\{U\left(c_{i}\right)+V\left(1-h_{i}\right)\right\} \geq W_{0}$.

Problem 3.9. We will now investigate some properties of the optimal contract.

(i) Write the first-order conditions for $\left(\mathrm{P}^{\prime}\right)$, and show that they imply the following conditions:

$$
\begin{array}{ll}
c_{I I}=c_{L} & \text { (efficient risk-sharing) } \\
x_{\imath} f^{\prime}\left(h_{l}\right)=\frac{V^{\prime}\left(1-h_{i}\right)}{U^{\prime}\left(c_{l}\right)} \text { for each } i=H, L & \text { (efficient hours) }
\end{array}
$$

Interpret these two conditions.

(ii) Show that $h_{H} \geq h_{L}$ (i.e., more hours are worked when productivity is high). Hint: Suppose that $h_{I}>h_{H}$, and seek a contradiction using the first-order conditions.

(iii) Show that $h_{H}>h_{L}$. (By contradiction again, suppose $h_{H}=h_{L}$.)

So far, we have assumed that the realization of the productivity shock can be freely observed by both parties. If this is not so, the contract design problem becomes more complicated, and the need to provide incentives to avoid cheating by the party with private information generates distortions that prevent implementation of the first-best contract we have just characterized.

For example, suppose that the shock $x$ can be observed only by the firm. (This may reflect, for example, the fact that firms have better information about market conditions than their workers.) Then, hours and compensation cannot be made contingent directly on the realization of $x$, but only on the firm's announcement of the state $\left(x_{a}\right)$. In this situation, however, the firm may find it advantageous to lie in some states. To prevent this, the contract problem will have to incorporate additional constraints designed to force the firm to tell the truth.

We will now explore the form these constraints must take. Given a contract $C(x)=\left[c\left(x_{i}\right), h\left(x_{i}\right) ; i=H, L\right]$, let $\Pi\left(x_{a} \mid x_{i}\right)$ be the firm's profit when the true state is $x_{i}$ and $x_{a}$ is announced (so $h_{a}$ and $c_{a}$ are implemented). Then

$$
\Pi\left(x_{a} \mid x_{i}\right)=x_{i} f\left(h_{a}\right)-c_{a}
$$

and the optimal strategy for the firm is to announce the state $x_{a}$ that will maximize $\Pi\left(x_{a} \mid x_{i}\right)$. Notice that, given an arbitrary contract, there is no guarantee that the optimal announcement is the true state.

Problem 3.10. Show that under the first-best contract characterized in Problem 3.9, the firm has an incentive to lie in one of the states. Which one? Why?

This result implies that the first-best contract is not implementable when there is private information. The second-best-contract problem (which char-
acterizes the best feasible contract under the circumstances) must incorporate additional constraints to prevent cheating by the firm. This is achieved by making truth-telling the profit-maximizing strategy in all states. Hence, we require

$$
\begin{equation*}
\Pi\left(x_{i} \mid x_{i}\right) \geq \Pi\left(x_{a} \mid x_{i}\right) \forall i \text { and } \forall a \tag{IC}
\end{equation*}
$$

This type of constraint is often called an incentive compatibility (or truthtelling) constraint, for it ensures that the party with private information will have an incentive to reveal it truthfully in all states.

The optimal-contract problem with imperfect information can be written

$$
\max _{c, h} E \Pi(x)=\sum_{i} q_{i}\left[x_{i} f\left(h_{l}\right)-c_{i}\right]
$$

subject to

$$
\begin{gather*}
\sum_{i} q_{i}\left[U\left(c_{i}\right)+V\left(1-h_{i}\right)\right] \geq W_{0} \\
\Pi\left(x_{L} \mid x_{L}\right)=x_{L} f\left(h_{L}\right)-c_{L} \geq x_{L} f\left(h_{H}\right)-c_{H}=\Pi\left(x_{H} \mid x_{L}\right)  \tag{IC.L}\\
\Pi\left(x_{H} \mid x_{H}\right)=x_{H} f\left(h_{H}\right)-c_{H} \geq x_{H} f\left(h_{L}\right)-c_{L}=\Pi\left(x_{L} \mid x_{H}\right) \tag{IC.$H}
\end{gather*}
$$

The following problems explore the implications of the additional constraints and the nature of the distortions they induce. Notice that in our case the incentive compatibility constraints must make it unprofitable for the firm to announce a high state when productivity is actually low. To achieve this, such a strategy must be penalized in some way. One obvious way to do this is to force the firm to pay a higher wage when it announces the high state. This, however, involves an efficiency cost, for full insurance can no longer be offered. As we will see, however, this is not the only inefficiency implied by the incentive constraints.

Problem 3.11. Show that the incentive compatibility constraints, by themselves, imply that $c_{H} \geq c_{L}$ and $h_{H} \geq h_{L}$. Hint: Rearrange, and add the two incentive compatibility constraints.

Problem 3.12. Write the first-order conditions for $\left(\mathrm{P}^{\prime \prime}\right)$. Use them and the preceding results in the following:

(i) Show that $c_{H}>c_{L}$ and $h_{H}>h_{L}$ Hint: Suppose not. Then two of the first-order conditions imply $\lambda_{L}=\lambda_{H}$; use this and the other first-order conditions to obtain a contradiction, $x_{L}>x_{H}$.

(ii) Show that both incentive constraints cannot be binding at the same time. (If they are, $h_{H}=h_{L}$, contradicting the previous result.)

Hence, precisely one incentive compatibility constraint must be binding. Why?
(iii) Show that the active incentive compatibility constraint is the one corresponding to the low-productivity state.

Notice that, by (i), we have $c_{H}>c_{L}$, so the second-best contract does not provide complete insurance for workers.

(iv) Show that the employment level is also distorted, but only in one state, (That is, for the given $c_{i}$, compare the employment level in each state with the one that would be implied by the efficient-hours condition, $x_{l} f^{\prime}\left(h_{l}\right)=V^{\prime}(1-$ $\left.h_{i}\right) / U^{\prime}\left(c_{i}\right)$.

## Bibliography

Arrow, K., and Hahn, F. 1971. General Competitive Analysis. San Francisco: Holden-Day.

Azariadis, C. 1975. Implicit Contracts and Underemployment Equilibria. Journal of Political Economy 83:1183-202.

Baily, M. 1974. Wages and Unemployment with Uncertain Demand. Review of Economic Studies 41:37-50.

Beavis, B., and Dobbs, I. 1990. Optimization and Stability Theory for Economic Analysis. Cambridge University Press.

Berge, C. 1966. Espace Topologiques. Fonctions Multivoques. Paris: Dunod.

Binmore, K. 1982. Mathematical Analysis, a Straightforward Approach, 2nd ed. Cambridge University Press.

Cooper, R. 1987. Wage and Employment Patterns in Labor Contracts: Micro-foundations and Macro-economic Implications. London: Harwood.

Dixit, A. 1990. Optimization in Economic Theory, 2nd ed. Oxford University Press.

de la Fuente, A., and Naranjo, M. T. Continuity of the Constraint Correspondence in Parameterized Kuhn-Tucwer problems with Concave Constraints. Forthcoming in Economics Letters.

Hastenes, M. 1975. Optimization Theory, the Finite Dimensional Case. New York: Wiley.

Intriligator, M. 1971. Mathematical Optimization and Economic Theory. Englewood Cliffs, NJ: Prentice-Hall.

Luenberger, D. 1973. Introduction to Linear and Nonlinear Programming. Reading, MA: Addison-Wesley.

Madden, P. 1986. Concavity and Optimization in Microeconomics. London: Basil Blackwell.

Mangasarian, O. 1982. Nonlinear Programming. Malabar, FL: Krieger.

Silberberg, E. 1978. The Structure of Economics: A Mathematical Analysis. New York: McGraw-Hill.

Simmons, G. 1972. Differential Equations with Applications and Historical Notes. New York: McGraw-Hill.

Stiglitz, J. 1984. Theories of Wage Rigidity. NBER working paper no. 1442.

Stokey, N., and Lucas, R. 1989. Recursive Methods in Economic Dynamics. Harvard University Press.

Sydsaeter, K. 1981. Topics in Mathematical Analysis for Economists. Orlando, FL: Academic Press.

Takayama, A. 1985. Mathematical Economics, 2nd ed. Cambridge University Press.

Vives, X. 1996. Static Oligopoly Pricing: Old Ideas and New Tools. Barcelona: Instituto de Análisis Económico.

Varian, H. 1984. Microeconomic Analysis. New York: Norton.

## Notes

1 In fact, it is a bit stronger. Recall that negative definiteness of the Hessian is sufficient but not necessary for concavity.

2 It can be shown that when we multiply a row of a matrix by a constant, the determinant of the resulting matrix is equal to the constant times the determinant of the original matrix.

3 Notice that the Jacobian of endogenous variables of the system of first-order conditions, $D_{x}^{2} f\left(x^{0}, \alpha^{0}\right)$ is precisely the determinant of the Hessian whose negative definiteness we are assuming. From the appendix to Chapter 6, the negative definiteness of this matrix implies that its determinant will not be zero. In particular, we have that $(-1)^{n}|H|>0$, where $n$ is the dimension of the Hessian matrix.

4 Notice that, in principle, there is no guarantee that $\partial x_{l}^{*} / \partial \alpha_{k}$ will have a "constant sign" for all values of the parameters. Clearly, restrictions on the sign of the cross-partials $D_{x \alpha} f(x, \alpha)$ can be used to guarantee "monotone comparative statics." More general conditions, not requiring differentiability, have been established for programming problems in lattices. The interested reader is referred to the discussion of supermodularity by Vives (1996, ch. 2).

## Some Applications to Microeconomics

The first part of this book has covered most of the mathematical tools required for analysis of static economic models. In this chapter we will discuss some applications of this material to a number of microeconomic models. Our goal will not be to provide a comprehensive treatment of a set of topics generally covered in the standard first-year graduate sequence in microeconomics, but only to illustrate the usefulness of the techniques we have developed and to introduce the reader to the general logic of modelbuilding in economic theory.

We began Chapter 7 with the observation that the "postulate of rationality" - the assumption that individuals have well-defined and consistent preferences and act accordingly - is central in (neoclassical) economics as a source of regularity in individual behavior that makes prediction possible, at least in principle. We then claimed that this postulate led naturally to the modeling of individual decision-making as the outcome of a constrained optimization problem, and we devoted a fair amount of time to studying the "technology" required for solving such problems. Section 1 of this chapter backtracks a little. We consider a standard consumer and discuss how his preferences can be represented by a binary relation and how this relation can be used to construct a utility function. Section 2 then analyzes the behavior of this consumer when he faces market-determined prices for the commodities he wants to purchase with his (exogenously given) income.

The first half of the chapter focuses on modeling the behavior of a single agent under a set of restrictions imposed on him by his environment. To understand the determination of most economic magnitudes, however, we have to go one step beyond such single-agent models and ask what will come out of the interactions of a number of (rational) decision-makers. This takes us to the concept of equilibrium. Given an "economic game" played by a set of agents, many outcomes are possible in principle. The heart of an economic theory is a concept of equilibrium, a criterion that allows us to select a subset
of these outcomes that can be considered to be more plausible, in some reasonable sense.

"Equilibrium" literally means "equal weight," from the condition for balancing a bar on a pivot. The etymology of the word, then, suggests a balance of forces inside the system that results in a state of rest unless some outside force prompts a change. This interpretation carries over to economic models, where an equilibrium typically corresponds to a situation in which no agent has an incentive to change his behavior. The other key idea associated with economic equilibrium is that of the compatibility of the actions of individually optimizing agents.

These two basic strands of the notion of equilibrium can be made operational in many different ways and with varying degrees of "strength." In this chapter we will review some of the standard concepts of equilibrium in economic theory. In Section 3 we consider an exchange economy populated by a large number of price-taking rational consumers who interact with each other through competitive markets, and we establish the existence and some welfare properties of a Walrasian equilibrium in this setting. In Section 4 we introduce some of the basic notions of the theory of games and discuss the concept of Nash equilibrium. Finally, Section 5 will ask the reader to work through some useful models of imperfect competition.

In all cases, our approach will be the same. Given an economic system composed of a set of agents who interact with each other in a specified way (a "game," for short), we will characterize the set of likely outcomes by considering two "subproblems" in turn:

(i) The individual decision problem. Assume that we have a game with welldefined rules, and consider an individual player. Given the particular game, there will be things that the agent controls and things he does not control. As we have already argued, it seems natural to model the behavior of a rational player as a constrained optimization problem. Hence, we will assume that each agent behaves as if he maximizes his objective or payoff function by his choices of the variables he controls, subject to whatever constraints are imposed on him by the rules of the game, and taking as given the things he cannot control. This problem yields as a solution a decision rule specifying the best action for the agent as a function (correspondence) of the things he takes as parameters.

(ii) The equilibrium problem. We still have to check that the optimal responses of the different players are consistent with each other and the overall resources of the system. Whereas the requirement of feasibility is generally straightforward, we have a considerable amount of latitude in specifying what degree of consistency we require among the actions of the players. For example, in a competitive equilibrium, "consistency" translates into market clearing, the requirement that each agent be able to sell or buy as much as he wants of each good at the market price. An alternative notion of equilibrium, however, would allow
for the possibility of rationing (i.e., for the existence of quantity constraints that might prevent agents from buying or selling their desired quantities).

It is important to emphasize that these two "problems" are very closely interrelated. Until we know what kind of game is being played, we cannot say which behaviors are rational, nor can we even write down the individual's problem, because we do not know what he controls, what he must take as given, and what constraints he faces. Similarly, unless we know how individual players are behaving, it is impossible to write down a meaningful equilibrium condition. Hence, the two problems must be written down and solved simultaneously. On the other hand, thinking in terms of these two separate problems is often a useful way to approach the question of what will come out of the interactions of a group of rational individuals.

## 1. Consumer Preferences and Utility

This section discusses the representation of preferences by binary relations and numerical functions. The reader may want to refer to Chapter 1 for some background material on binary relations and ordered sets. Section (a) introduces the concept of preference relation and discusses some properties that such relations are commonly assumed to possess. In particular, the "consistent preferences" half of the postulate of rationality is typically embodied in the assumption that a preference relation is a complete preordering. The other half ("consistent behavior") translates into the assumption that agents choose undominated elements of the set of feasible alternatives. Additional assumptions commonly made concerning preference relations capture ideas like the desirability of commodities and the taste for diversification, or they may be imposed for technical convenience.

Section (b) shows that a preference preorder can be conveniently represented by a numerical function, provided that certain regularity conditions are satisfied. In Section (c) we strengthen these conditions to obtain a differentiable utility function. The resulting model of individual behavior can be analyzed using the methods developed in Chapter 7. This will be the subject of Section 2.

## (a) Preference Relations

Let $X$ be a set, and consider an agent who must choose one of its elements. The most natural way to represent her preferences over such objects is probably in terms of a binary relation. Intuitively, we can imagine selecting two elements at a time from the given set and asking the agent which one she prefers. Such a questionnaire would yield a pairwise ranking of alternatives
that could be used, under certain assumptions, to construct an exhaustive list of possible options ranked by their desirability. We can then imagine her as figuring out which elements are feasible and then choosing the one that is closest to the top of the list.

More formally, our experiment of repeatedly confronting the agent with a choice between two elements of $X$ can be used to construct a binary relation " $\geq$ " in $X \times X$. This relation will be the set of all pairs $(x, y)$ of elements of $X$ such that $x$ is weakly preferred to $y$ by the agent (written $x \geq y$ ). A relation of this kind is called a preference relation.

In principle, then, there is no problem in representing preferences over elements of an arbitrary set by a binary relation " $\geq$ ". The next question is what kinds of properties we may reasonably assume " $\geq$ " to possess. This section reviews a number of assumptions commonly made about preferences and explores their meaning. Roughly, such assumptions come in two different types. Some are meant to capture the idea of rational behavior, and the rest are technical assumptions made so that it is possible to construct models that can be analyzed using standard mathematical techniques. In particular, it is convenient to make assumptions that will ensure that preferences can be represented by a continuous or differentiable quasiconcave numerical function. We shall see in the next section how such a representation can be constructed.

Returning to the preference relation, it is clear that " $\geq$ " will be reflexive, as any agent should be indifferent between $x$ and itself (i.e., $x \geq x$ ). Next, if the agent is "rational," we may expect that her preferences will be "consistent." One way to formalize this is to assume transitivity, that is, if $x$ is preferred to $y$, and $y$ to $z$, then $x$ is preferred to $z$. Notice that if this were not true, the agent might be unable to make up her mind about which element of the set she preferred (she could "cycle" from $x$ to $y$, from $y$ to $z$, and then back to $x$ ), and the decision problem would not have a solution. ${ }^{1}$ Hence, the "consistent preferences" part of the postulate of rationality will be formalized by requiring that " $\geq$ " be reflexive and transitive - that is, the preference relation will always be assumed to be a preordering.

Like any preordering, a preference relation can be decomposed into its symmetric and asymmetric components by defining the following two subrelations:

$$
\begin{array}{ll}
x>y & \text { if and only if } x \geq y \text { and } y \geq x \\
x \sim y & \text { if and only if } x \geq y \text { and } y \geq x
\end{array}
$$

(where $y \geq x$ means "not $y \geq x$ "). We shall refer to " $>$ " as the strict preference relation ( $x>y$ means that $x$ is strictly preferred to $y$ ), and to " $\sim$ " as the indifference relation ( $x \sim y$ means that the agent is indifferent between $x$ and $y$ ).

A further assumption that is often made is that the preference preordering is complete, that is, that given any two elements $x$ and $y$ of $X$, the agent can compare them and know whether she strictly prefers one of the elements or is indifferent between them. This looks innocuous enough, but it implicitly requires some strong assumptions about the information available to the agent. In particular, it presupposes that she knows exactly what alternatives are open to her - and that her knowledge of what each alternative entails is precise enough that she can always tell which is better.

These assumptions have been criticized as being too strong, and weaker alternatives do exist in the literature. For many purposes, however, they seem reasonable enough. We will take the following axiom as the first half of the postulate of rationality and see where it takes us.

Axiom 1.1. The preference relation " $\geq$ " defined on the choice set $\mathrm{X}$ is a complete preordering. This requires

(i) reflexivity: $\forall \mathbf{x} \in \mathbf{X}, \mathbf{x} \geq \mathbf{x}$,

(ii) transitivity: $\forall \mathrm{x}, \mathrm{y}, \mathrm{z} \in \mathrm{X},[\mathrm{x} \geq \mathrm{y}$ and $\mathrm{y} \geq \mathrm{z}] \Rightarrow \mathrm{x} \geq \mathrm{z}$, and

(iii) completeness: $\forall \mathrm{x}, \mathrm{y} \in \mathrm{X}$, either $\mathrm{x} \geq \mathrm{y}$ or $\mathrm{y} \geq \mathrm{x}$ or both.

Intuitively, if this axiom holds, we can picture the agent as having a complete listing of the elements of $X$ ranked by their desirability. If we restrict her choices to some subset of $X$, all she has to do is choose the element of this subset that is closest to the top of the list. That she behaves in this way will complete our description of what we mean by rationality. We formalize this as follows:

Axiom 1.2. Let $\mathrm{X}$ be the choice set, and $\mathrm{C}$ the subset of $\mathrm{X}$ that contains the alternatives available to an agent with a complete preference preordering " $\geq$ " defined over $\mathrm{X}$. The agent chooses a largest element $\mathrm{x} *$ of $\mathrm{C}$. That is, if $\mathrm{x} *$ is chosen, there is no $\mathrm{y} \in \mathrm{C}$ such that $\mathrm{y}>\mathrm{x}^{*}$.

So far we have made no assumptions about the choice set $X$. It is convenient, however, to impose additional structure on this set. For many purposes, assuming that $X$ is a normed vector space is sufficient. This allows us to say, for example, that two alternatives, $x$ and $y$, are similar or close to each other. Once a notion of distance (a metric or, more generally, a topology) is defined on $X$, it seems reasonable to require that similar alternatives not be too far from each other in the consumer's preference ranking. This leads to the following regularity condition.

Definition 1.3. Continuity. Let $(X, d)$ be a metric space. We say that the preferences represented by the preorder " $\geq$ " are continuous if for any $x$ in $X$, the sets

$$
B(x)=\{y \in X: y \geq x\} \text { and } W(x)=\{y \in X: y \leq x\}
$$

are closed in $(X, d)$.

Here $B(x)$ is the set of points of $X$ that are weakly preferred to $x$ by the agent, and $W(x)$ is the set of points that are weakly worse than $x$ given the consumer's preferences. Requiring them to be closed means, for example, that if we consider a convergent sequence $\left\{y_{n}\right\} \rightarrow y$ of points all of which are weakly better than $x$, then the limit of the sequence, $y$, is also weakly better than $x$. It is easy to see that this condition is equivalent to the requirement that the set " $\geq$ " be closed in $X \times X$. Alternatively, the complement of $W(x)$, that is, the set of alternatives that are strictly preferred to $x$, is open. Hence, if $y$ is strictly preferred to $x$, any other alternative $y^{\prime}$ that is sufficiently close to $y$ (in terms of the distance function $d()$ ) will also be strictly preferred to $x$.

It is apparent that at this level of generality, the axioms of rationality do not buy us much. Our two axioms amount to the assumptions (i) that agents have consistent preferences over all available choices and (ii) that they act accordingly. That is, people do what they like best - provided they can. To get any predictions out of this structure, we clearly have to be more specific about agents' preferences and about the constraints they face. In general this can be done only with a more specific situation in mind, but we can list two further assumptions that are useful in many situations. The first one is that people prefer more to less. Hence, we introduce a new concept that roughly captures the "greediness" that economists often assume of their “agents."

Definition 1.4. (Strong) monotonicity. Let the choice space $X$ be a subset of $\mathbb{R}^{\mathrm{n}}$. Preferences are said to be (strongly) monotonic if

$$
x>y \Rightarrow x>y
$$

In the context of standard consumer theory this means that given two bundles $x$ and $y$ that are identical except for the fact that $x$ has more of some good, the consumer always prefers $x$. To some extent this is a matter of definition: If a good is undesirable (a "bad"), we may consider the negative of its quantity as a good, and the axiom holds. Weaker versions of monotonicity are often used and suffice for most purposes. The idea, however, is the same: Assumptions of this type often capture the view that agents pursue their own self-interest. This may be thought of as specializing rationality to selfish behavior, but it need not be so: There is nothing in the model that rules out altruistic preferences.

Given continuity and some sort of monotonicity (possibly weaker than we
are assuming), there is an interesting connection between the topological and order properties of $X$. In particular, the indifference subrelation

$$
I=\{(x, y) \in X \times X ; x \sim y\}
$$

turns out to be the topological boundary of " $\geq$," thought of as a subset of $X \times X$. The strict preference relation " $>$ " is therefore the interior of " $\geq$ ". This result will be useful later in connection with the concept of smooth preferences.

Problem 1.5. Let " $\geq$ " be a continuous and monotonic preference preorder defined on a subset $X$ of $\mathbb{R}^{\mathrm{n}}$. Show that $\partial \geq=I \equiv\{(x, y) \in X \times X ; x \sim y\}$.

The last assumption we introduce is that preferences are convex, in the sense that convex combinations of alternatives are preferred to "pure" choices. In many cases this can be interpreted as capturing a taste for variety or diversification.

Definition 1.6. Convexity. Let the choice space $X$ be a convex subset of $\mathbb{R}^{n}$. Preferences are said to be convex if

$$
x \geq y \Rightarrow \lambda x+(1-\lambda) y \geq y \forall \lambda \in(0,1)
$$

A stronger version of this property (strict convexity) requires that

$$
x \geq y \text { and } x \neq y \Rightarrow \lambda x+(1-\lambda) y>y \forall \lambda \in(0,1)
$$

Notice that in the definitions of monotonicity and convexity we have required $X$ to be a subset of a finite-dimensional Euclidean space. Although more general choice spaces are often used, this is quite adequate for our purposes in this section.

Problem 1.7. Let " $\geq$ " be a convex preference preorder defined on a convex set $X$. Show that the better-than sets induced by these preferences,

$$
B(y)=\{x \in X ; x \geq y\}
$$

are convex.

We close this section with a theorem which shows that it is possible to obtain some results working directly with preference preorderings. On the other hand, this probably is not the easiest way to proceed. The following section will show that it is possible to represent a preference preordering by
a real-valued function. Once this is done, we can use more standard mathematical techniques to analyze models of individual choice.

Theorem 1.8. Let $\mathrm{X}$ be a subset of $\mathbb{R}^{n}$. Let $\mathrm{C}$, the feasible subset of $\mathrm{X}$, be compact and nonempty. Suppose the preference relation " $\geq$ " is a complete and continuous preorder. Then the set of largest elements

$$
x(\geq, C)=\{x \in C: x \geq y \forall y \in C\}
$$

is nonempty. If " $\geq$ " is strictly convex and $\mathrm{C}$ is a convex set, then $\mathrm{x}(\geq, \mathrm{C})$ contains a single element.

Proof. For each $x$, let $B(x, C)=B(x) \cap C=\{y \in C: y \geq x\}$ be the set containing all feasible alternatives that are weakly better than $x$. Because $B(x$, $C$ ) is the intersection of two closed sets, it is closed itself. Let $x_{1}, \ldots, x_{n}$ be a finite collection of elements of $C$. Without loss of generality we can assume that $x_{1} \geq x_{i}$ for all $i=2, \ldots, n$. Hence, $x_{1} \in \cap_{i=1}^{n} B\left(x_{i}, C\right)$, and it follows that the collection of sets $\{B(x, C) ; x \in C\}$ has the finite-intersection property (i.e., any finite subcollection has a nonempty intersection). By assumption, $C$ is compact, so every collection of closed sets with the finite-intersection property has a nonempty intersection (by Theorem 8.13 in Chapter 2). In particular, $\cap_{x \in C} B(x, C) \neq \varnothing$, and because this set must be contained in $x(\geq$, $C)$, the latter is nonempty.

Finally, assume that preferences are strictly convex, and suppose we have two distinct maximizers, $x$ and $x^{\prime}$. Then $x \sim x^{\prime}$, and by the assumption that preferences are strictly convex, any convex combination $\lambda x+(1-\lambda) x^{\prime}$, with $\lambda \in(0,1)$, is preferred to both $x$ and $x^{\prime}$. If $C$ is convex, moreover, such combinations are feasible. But then $x$ and $x^{\prime}$ cannot be maximizers, and we have reached a contradiction.

## (b) Representation by a Utility Function

Definition 1.9. A real-valued function $U^{i}: X^{i} \longrightarrow \mathbb{R}$ is said to represent a preference preordering $\left\{\geq_{i}\right\}$ defined on the choice set $X^{i}$ of agent $i$ if

$$
\forall x, y \in X^{i}, x \geq_{i} y \Leftrightarrow U^{i}(x) \geq U^{i}(y)
$$

That is, $U^{i}$ represents $\left\{\geq_{i}\right\}$ if and only if, given any two alternatives, the function $U^{i}()$ assigns a larger value to the one that is preferred by the agent. We refer to the function $U^{i}()$ as the payoff, objective, or utility function for agent $i$. The subindex $i$ is used in the definition to emphasize that different agents typically will have different preferences, even over a common set of alternatives; from here on, it will be omitted.

A utility function provides a convenient tool for modeling the behavior of a rational agent. Its advantage over the more primitive representation of preferences discussed in the preceding section stems primarily from the fact that functions are generally easier to manipulate than preorders. In particular, there is a well-developed theory of maximization for real-valued functions that can be applied to choice problems once preferences are represented by utility functions.

It is clear that given a numerical function $U$ defined on $X$ we can work back to a preference preorder. The converse statement is harder to prove and requires some restrictions on $X$ and " $\geq_{i}$." A number of representation theorems are available in the literature. We will state without proof a fairly general theorem due to Debreu and then prove a weaker result using monotonicity to simplify the proof.

Theorem 1.10. Representation of preferences by a numerical function (1). A continuous preference preorder $\{\geq\}$ defined on a convex subset $\mathrm{X}$ of a separable normed vector space can be represented by a continuous real-valued function.

In fact, the theorem holds for separable topological spaces. A topological space $Y$ is separable if it contains a countable subset $C$ whose closure is $Y$ itself (i.e., $\bar{C}=Y$ ). Any Euclidean space $E$ is separable, for example, because the set of vectors with rational coordinates is countable and dense in $E$. Convexity of $X$ can be replaced with connectedness. The assumption of connectedness, in turn, can be dispensed with if we assume that $X$ is a perfectly separable topological space (i.e., if it contains a countable class $\mathbb{O}$ of open sets such that every open set in $X$ is the union of sets in the class (O). A separable metric space is perfectly separable. For proofs and further discussion of these results, see Debreu (1983b, pp. 105ff.).

It is easy to see that the utility function that represents a preference preorder is not uniquely defined. Any monotonically increasing transformation $\varphi($ ) of $U($ ) will represent exactly the same preferences, because with $\varphi($ ) strictly increasing, we have

$$
U(x) \geq U(y) \text { if and only if } \varphi[U(x)] \geq \varphi[U(y)]
$$

for all $x, y \in X$. Hence, we say that $U()$ is an ordinal (as opposed to cardinal) utility function. That is, the sign of the difference $U(x)-U(y)$ is important because it tells us which outcome is preferred - but the value of this difference is meaningless, as it will change with any nontrivial increasing transformation $\varphi($ ).

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-339.jpg?height=554&width=673&top_left_y=178&top_left_x=411)

Figure 8.1. A well-behaved indifference map.

Theorem 1.11. Representation theorem (2). Let $\mathrm{X}=\mathbb{R}_{+}^{n}=\left\{\mathrm{x} \in \mathbb{R}^{n} ; \mathrm{x}_{\mathrm{i}} \geq 0 \forall\right.$ $\mathrm{i}=1, \ldots, \mathrm{n}$, and assume that the preference relation " $\geq$ " defined on $\mathrm{X}$ is a complete preordering, continuous and strictly monotone. Then " $\geq$ " can be represented by a real-valued, continuous, and increasing payoff function $\mathrm{U}: \mathrm{X} \longrightarrow \mathbb{R}$. If preferences are convex, $\mathrm{U}$ is quasiconcave.

To see how a utility function can be constructed, it is useful to think of representing the preference preorder " $\geq$ " in terms of its indifference sets. We have seen that a preference preordering can be decomposed into a symmetric part and an asymmetric part. The symmetric part is the indifference relation $\{\sim\}$. It is easy to see that $\{\sim\}$ is an equivalence relation. It follows that the indifference sets

$$
I(x)=\{y \in X ; y \sim x\}
$$

form a partition of $X$. That is, each $x$ in $X$ belongs to precisely one such set. If preferences are continuous and monotonic, we get a picture familiar from basic courses in microeconomics: The indifference sets are indeed indifference "curves" (i.e., connected sets), and each such curve is the common boundary between the (closed) better-than and worse-than sets, $B(x)$ and $W(x)$.

If the picture is "correct," then we can construct a utility function by assigning a number to each indifference curve. For example, if each indifference curve intersects the $45^{\circ}$ line (labeled $D$ in Figure 8.1) exactly once, we can assign to all the $x$ 's on a given indifference curve the distance from their intersection with the diagonal to the origin (we will do something like that later). Intuitively speaking, for this approach to work we need to have the "right number" of "nice" indifference curves. The proof of the following lemma should clarify what we mean by this.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-340.jpg?height=678&width=752&top_left_y=197&top_left_x=351)

Figure 8.2.

Lemma 1.12. Let " $\geq$ " be a continuous and strictly monotone preorder defined on $\mathrm{X}=\mathbb{R}_{+}^{n}$. Then, given any $\mathrm{z} \in \mathrm{X}$, the indifference set $\mathrm{I}(\mathrm{z})=\{\mathrm{x} \in \mathrm{X}$; $\mathrm{x} \sim \mathrm{z}\}$ intersects the "diagonal line" $\mathrm{D}=\left\{\mathrm{x} \in \mathbb{R}_{+}^{n} ; \mathrm{x}_{1}=\ldots=\mathrm{x}_{\mathrm{n}}\right\}$ precisely once.

Proof. The set $D$ of bundles with the same amounts of each commodity (the "diagonal line") can be described by

$$
D=\left\{x \in \mathbb{R}_{+}^{\mathbf{n}} ; x=\gamma e \text { for some } \gamma \in \mathbb{R}_{+}\right\}
$$

where $e=1=(1,1, \ldots, 1)$. Hence, there is a one-to-one correspondence between $D$ and $\mathbb{R}_{+}$. Fix some arbitrary bundle $z$ in $X$, and consider the subsets of $\mathbb{R}_{+}$corresponding to bundles in $D$ that are respectively weakly better and weakly worse than $z$ :

$$
\Gamma_{B}=\left\{\gamma \in \mathbb{R}_{+} ; \gamma e \geq z\right\} \quad \text { and } \Gamma_{w}=\left\{\gamma \in \mathbb{R}_{+} ; \gamma e \leq z\right\}
$$

(refer to Figure 8.2). By strong monotonicity, both of these sets are nonempty. (For example, all $\gamma$ such that $\gamma>\max _{i} z_{i}$ are in $\Gamma_{B}$, and all those with $\gamma<\min _{i} z_{i}$ are in $\left.\Gamma_{w}\right)$. Moreover, the assumed completeness of the preference preorder implies that $\Gamma_{B}$ and $\Gamma_{w}$ must add up to $\mathbb{R}_{+}$(i.e., $\mathbb{R}_{+}=\Gamma_{B} \cup \Gamma_{w}$ ), for any bundle $\gamma e$ must satisfy either $\gamma e \geq z$ or $\gamma e \leq z$ (or both).

Next, we show that continuity implies that both $\Gamma_{B}$ and $\Gamma_{w}$ are closed sets. Let $\left\{\gamma_{n}\right\}$ be a convergent sequence of nonnegative real numbers with limit $\gamma$, and assume that $\gamma_{n} \in \Gamma_{B}$ for all $n$. Then $\left\{x_{n} ; x_{n}=\gamma_{n} e\right\}$ is a sequence of bundles contained in $B(z)$ that converges to $\gamma e$. Because the set $B(z)$ is closed, by the continuity of preferences, the limit of $\left\{x_{n}\right\}$ lies in $B(z)$. That is, $\gamma e \geq z \in$
$B(z)$, which implies that $\gamma \in \Gamma_{B}$ and therefore the closedness of $\Gamma_{B}$. A similar argument will work for $\Gamma_{w}$.

Finally, because $\mathbb{R}_{+}=(0, \infty)$ is connected (i.e., has no "holes"), ${ }^{2}$ and we have $\mathbb{R}_{+}=\Gamma_{B} \cup \Gamma_{w}$, with both $\Gamma_{B}$ and $\Gamma_{w}$ closed, it follows that these sets must have at least one point in common (otherwise they would be separated, and that would contradict the connectedness of $\mathbb{R}_{+}$). Hence, there exists some $\gamma_{z}$ such that $\gamma_{z} e \sim z$. By strong monotonicity, this point of intersection between $I(z)$ and $D$ is unique, for $\gamma e>\gamma_{z} e$ implies $\gamma e>\gamma_{z} e \sim z$, and $\gamma<\gamma_{z}$ implies $\gamma e<z$.

With this result, the proof of the representation theorem is easy. Given some $x$ in $X$, we look for the point where the indifference surface $I(x)$ intersects the diagonal line $D=\left\{x \in \mathbb{R}^{\mathrm{n}} ; x=\gamma e\right.$, with $\left.\gamma \in \mathbb{R}\right\}$ and assign to $x$ the number $\gamma_{x}$ corresponding to this point. Because we have just shown that this number exists and is unique, we have in fact defined a function $U: \mathbb{R}^{\mathrm{m}} \rightarrow \mathbb{R}$, with $U(x)=\gamma_{x}$, where $\gamma_{x}$ is such that $\gamma_{x} \sim x$.

We will now show that $U()$ does represent the given preferences and is increasing. Take two bundles $x$ and $y$, with $x \geq y$. By construction, we have

$$
U(x)=\gamma_{x}, \quad \text { where } \gamma_{x} e \sim x \text { and } U(y)=\gamma_{y}, \quad \text { where } \gamma_{y} e \sim y
$$

Hence,

$$
\gamma_{x} e-x \geqq y \sim \gamma_{y} e
$$

and by monotonicity $U(x)=\gamma_{x} \geq \gamma_{y}=U(y)$ (for otherwise $\gamma_{x} e$ would be dominated by $\gamma_{y} e$ and could not be preferred to it). Hence, $U()$ does represent " $\geq$." Moreover, $U()$ is an increasing function, for if $x \geq y$, then $x \geq y$ by monotonicity, and we have just shown that this implies that $U(x) \geq U(y)$.

Next, we shall show that $U$ is continuous. For this, it is sufficient to show that the inverse image of any closed interval is closed. But note that given any two positive real numbers $\gamma_{y}$ and $\gamma_{z}$,

$$
\begin{aligned}
U^{-1}\left[\gamma_{y}, \gamma_{z}\right] & =\left\{x \in \mathbb{R}^{\mathrm{n}} ; U\left(\gamma_{y} e\right) \leq U(x) \leq U\left(\gamma_{z} e\right)\right\} \\
& =\left\{x \in \mathbb{R}^{\mathrm{n}} ; \gamma_{y} e \leq x \leq \gamma_{z} e\right\}=B\left(\gamma_{y} e\right) \cap W\left(\gamma_{z} e\right)
\end{aligned}
$$

Hence, $U^{-1}\left[\gamma_{x}, \gamma_{y}\right]$ is the intersection of two sets, a better-than set and a worsethan set, that are closed, by the continuity of preferences. It follows that $U^{-1}\left[\gamma_{x}, \gamma_{y}\right]$ is closed, which establishes the continuity of $U()$. Finally, if preferences are convex, the upper contour sets of this function, $\{x \in X$; $U(x) \geq \alpha\}$, are convex sets, because

$$
\{x \in X ; U(x) \geq \alpha\}=\{x \in X ; x \geq \alpha e\}=B(\alpha e)
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-342.jpg?height=642&width=851&top_left_y=192&top_left_x=304)

Figure 8.3. Continuity of the utility function.

and the better-than set $B(\alpha e)$ is convex, by Problem 1.7. This implies that $U($ ) is quasiconcave (by Theorem 3.2 in Chapter 6).

The following problem shows that under our assumptions, indifference sets are indeed nicely behaved indifference curves, with no holes in them.

Problem 1.13. Let " $\geq$ " be a continuous and strictly monotone preference preorder defined on $X=\mathbb{R}_{+}^{\mathrm{n}}$, and let $z$ be an arbitrary point in $X$. We will show that the indifference set $I(z)$ is connected.

A standard way to show that a set $A$ is connected is by showing that the set is homeomorphic to another one $B$ that is known to be connected - that is, by establishing that there exists an invertible continuous function $h()$ with a continuous inverse that maps $A$ onto $B$. Then $A=h^{-1}(B)$ is the continuous image of a connected set and therefore is connected itself (by Theorem 9.3 in Chapter 2).

In this case, let $B$ be the open unit simplex

$$
\Delta=\left\{z \in \mathbb{R}_{++}^{\mathbf{n}} ; z e=1\right\}
$$

where $e=\underline{1}$ and $\mathbb{R}_{++}^{\mathbf{n}}=\left\{x \in \mathbb{R}^{\mathrm{n}} ; x_{i}>0 \forall i=1, \ldots, n\right\}$. Given an indifference set $I(z)$, we "project" it onto $\Delta$ by following a ray through the origin from each point $x$ in $I$ until it intersects the simplex (Figure 8.4). Hence, the function $h()$ is of the form

$$
h(x)=\frac{1}{x e} x=\frac{1}{\sum_{i=1}^{n} x_{i}} x
$$

Show that $h()$ is a homeomorphism.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-343.jpg?height=509&width=724&top_left_y=209&top_left_x=374)

Figure 8.4.

Hint: The only potentially difficult part is establishing the continuity of $h^{-1}()$. Use the sequential characterization of continuity and seek a contradiction. In particular, fix some arbitrary $y^{0}$ in $\Delta$ and assume that $\left\{y_{n}\right\} \rightarrow y^{0}$, but $\left\{x_{n}=h^{-1}\left(y_{n}\right)\right\}$ does not converge to $x^{0}=h^{-1}\left(y^{0}\right)$. Notice that because $y$ and $x=h^{-1}(y)$ lie on the same ray through the origin for any $y$ in $\Delta$, we can write

$$
x_{n}=h^{-1}\left(y_{n}\right)=\lambda_{n} y_{n} \quad \text { and } \quad x^{0}=h^{-1}\left(y^{0}\right)=\lambda^{0} y^{0}
$$

for some positive real numbers $\lambda_{n}$ and $\lambda^{0}$. Observe that $\left\{\lambda_{n}\right\}$ is a sequence of real numbers bounded below by zero. Consider two possibilities in turn: (i) $\left\{\lambda_{n}\right\}$ is bounded above, and (ii) $\left\{\lambda_{n}\right\}$ is not bounded above. Then seek a contradiction.

## (c) Smooth Preferences

This short section shows that, given some additional conditions, a preference relation " $\geq$ " can be represented by a twice continuously differentiable utility function. This is a very convenient result, because it allows us to use calculus techniques both to characterize the solutions to the optimization problems that agents are supposed to solve and to do comparative statics.

Intuitively, differentiability is obtained by strengthening the continuity assumption with the requirement that the indifferent sets be smooth surfaces in $X$ or, more formally, that the indifference relation be a smooth manifold in $X \times X$.

Definition 1.14. Smooth preferences. Let $X$ be an open subset of $\mathbb{R}^{n}$. A monotone preference relation " $\geq$ " defined on $X$ is said to be of class $C^{k}$ $(k \geq 0)$ if the indifference subrelation

$$
\begin{gathered}
\text { Consumer Theory } \\
I=\{(x, y) \in X \times X ; x \sim y\}
\end{gathered}
$$

is a $C^{k}$ manifold.

Recall that a manifold is a set that is locally diffeomorphic to an open set in a Euclidean space. If the diffeomorphism in the definition is of class $C^{k}$, we have a $C^{k}$ manifold. If $k \geq 1$, we speak of smooth manifolds and smooth preferences. (A function is of class $C^{0}$ if it is continuous.)

Theorem 1.15. Let $\mathrm{X}$ be an open subset of $\mathbb{R}^{n}$. A strictly monotone preference preorder " $\geq$ " defined on $\mathrm{X}$ can be represented by a $\mathrm{C}^{\mathrm{k}}$ utility function with no critical points if and only if it is itself of class $\mathrm{C}^{\mathrm{k}}$ (i.e., if the indifference relation $\mathrm{I}$ is a $\mathrm{C}^{\mathrm{k}}$ manifold).

Proof. We prove only the easy part: If " $\geq$ " can be represented by a smooth utility function $U$ with no critical points, then $I$ must be a smooth manifold. To see this, define $v: X \times X \longrightarrow \mathbb{R}$ by

$$
v(x, y)=U(x)-U(y)
$$

By assumption, $U()$ has no critical points, so $D U(x) \neq \underline{0}$, and this in turn implies $D v(x, y)=[D U(x),-D U(y)] \neq \underline{0}$. Hence $v()$ has no critical points, and therefore the set

$$
I=v^{-1}(\underline{0})=\{(x, y) \in X \times X ; U(x)=U(y)\}
$$

is the inverse image of a regular value of $v$. By the regular-value theorem (Theorem 2.3 in Chapter 5), $I$ is a smooth manifold.

The converse can be found in Mas-Colell (1985, pp. 64-6). In fact, he proves a more general result: The theorem holds for locally nonsatiated preferences with connected indifferent sets. Because strong monotonicity trivially implies local nonsatiation and, by Problem 1.13, connectedness of the indifference sets, the theorem follows as stated.

We conclude with the observation that given an appropriate topology on the space of continuous preference relations, the set of smooth preference relations is dense in this space. Intuitively, this means that any continuous preference relation can be approximated "fairly well" by a smooth one - and hence that the assumption of a differentiable utility function is not unreasonable, at least as a first approximation.

## 2. Consumer Theory

Consider an agent (whom we will call the consumer) who has preferences defined over the set $\mathbb{R}_{+}^{G}$ of possible consumption bundles, $x=\left(x^{1}, \ldots, x^{G}\right)$,
where we interpret $x^{i} \geq 0$ as the amount of good $i$ consumed by the agent. We assume that these preferences can be represented by a continuous, increasing, and quasiconcave utility function $U: \mathbb{R}_{+}^{G_{3}} \longrightarrow \mathbb{R}$. Given income $y$ and a vector of commodity prices $p \in \mathbb{R}_{+}^{\mathbb{G}}$, the set of feasible consumption bundles is described by the budget correspondence,

$$
B(p, y)=\left\{x \in \mathbb{R}_{+}^{\mathbb{G}} ; p x \leq y\right\}
$$

which gives, for each price-income pair, the set of bundles whose cost $p x=\Sigma_{i=1}^{G} p_{i} x_{i}$ does not exceed the available income, $y \geq 0$. The consumer will be assumed to maximize utility subject to the constraint imposed by the budget correspondence.

## (a) Utility Maximization and Ordinary Demand Functions

Under the preceding assumptions, the problem faced by the consumer can be written

$$
\begin{equation*}
V(p, y)=\max _{x \in B(p, y)} U(x) \tag{C.U}
\end{equation*}
$$

where $B(p, y)=\left\{x \in \mathbb{R}_{+}^{G} ; y-p x \geq 0\right\}$. The maximum-value function for the consumer's problem, $V(p, y)$, called the indirect utility function, gives the maximum utility attainable by a consumer who faces income $y$ and prices $p$. The solution of the problem is given by a Marshallian or ordinary demand correspondence,

$$
x(p, y)=\arg \max _{x \in B(p, y)} U(x)
$$

which gives for each pair $(p, y)$ the set of optimal consumption bundles. If this correspondence is single-valued, we speak of a demand function. Notice that the indirect utility function and the demand correspondence are related by the expression

$$
V(p, y)=U(x(p, y))
$$

because the maximum attainable utility is the utility provided by any optimal consumption bundle.

In this section we will analyze the properties of the demand correspondence and the indirect utility function. We start with a result that gives sufficient conditions for the continuity of the budget correspondence ${ }^{3}$ (i.e., for the set of feasible options to change continuously with changes in the parameters $p$ and $y$ ).

Theorem 2.1. Continuity of the budget correspondence. Let $\mathrm{B}: \mathbb{R}_{+}^{G+1} \rightarrow \rightarrow \mathbb{R}_{+}^{G}$ be defined by $\mathrm{B}(\mathrm{p}, y)=\left\{\mathrm{x} \in \mathbb{R}_{+}^{\mathbb{G}} ; \mathrm{px} \leq \mathrm{y}\right\}$. Then $\mathrm{B}$ is continuous at any point (p, y), with $\mathrm{p} \gg \underline{0}$ and $\mathrm{y}>0$.

Proof. Notice that the constraint function is linear and therefore concave in $x$ for given $p$ and $y$. Hence, we can apply Theorem 2.2 in Chapter 7, and it suffices to show that $B(p, y)$ is compact and contains an interior point, which is clearly the case under the given assumptions.

Problem 2.2. Give a direct proof of the continuity of the budget correspondence. Hint: Use the sequential characterizations of upper hemicontinuity and lower hemicontinuity. For upper hemicontinuity, consider a sequence $x_{n} \in B\left(p_{n}, y_{n}\right)$ converging to a point $(p, y) \gg \underline{0}$. Show that it is bounded, and apply the Bolzano-Weierstrass theorem. For lower hemicontinuity, construct the sequence as in Problem 2.6 in Chapter 7.

Given the preceding result, we can now use the theorem of the maximum to guarantee the upper hemicontinuity of the demand correspondence and the continuity of the indirect utility function. In addition to these two results, the following theorem establishes some other useful properties of these mappings.

Theorem 2.3. Properties of the demand correspondence and the indirect utility function. Let the utility function $\mathrm{U}: \mathbb{R}_{+}^{G} \longrightarrow \mathbb{R}$ be continuous, increasing, and quasiconcave. Then for each price-income pair ( $\mathrm{p}, \mathrm{y})$, with $\mathrm{p} \gg \underline{0}$ and $\mathrm{y}>0$, there exists at least one solution to the consumer problem (C.U). Moreover, the demand correspondence $\mathrm{x}(\mathrm{p}, \mathrm{y})$ is uhc and homogeneous of degree zero, in the sense that if $\mathrm{z} \in \mathrm{x}(\mathrm{p}, \mathrm{y})$, then $\mathrm{z} \in \mathrm{x}(\mu \mathrm{p}, \mu \mathrm{y})$ for any $\mu>0$. The indirect utility function $\mathrm{V}(\mathrm{p}, \mathrm{y})$ is continuous, quasiconvex, homogeneous of degree zero in ( $\mathrm{p}, \mathrm{y}$ ), increasing in income, and decreasing in prices.

If, in addition, $\mathrm{U}()$ is strictly increasing, then the budget constraint holds with equality, that is, $\mathrm{px}=\mathrm{y}$ for any $\mathrm{x} \in \mathrm{x}(\mathrm{p}, \mathrm{y})$ (the "adding-up" property). If $\mathrm{U}()$ is strictly quasiconcave, then $\mathrm{x}(\mathrm{p}, \mathrm{y})$ is a (single-valued) function and continuous.

## Proof

- Existence of a solution and uniqueness, given strict quasiconcavity. If $p \gg \underline{0}$ and $y>0$, the budget set $B(p, y)=\left\{x \in \mathbb{R}_{+}^{G} ; p x \leq y\right\}$ is a nonempty compact and convex set. Hence the existence of a solution to the consumer problem follows by the extreme-value theorem (Theorem 8.22 in Chapter 2). Given strict quasiconcavity, the solution will be unique, by Theorem 1.11 in Chapter 7.
- Continuity of $V(p, y)$ and $x(p, y)$. Because $B(p, y)$ is compact-valued and continuous for any $(p, y)$, with $p \gg \underline{0}$ and $y>0$, the theorem of the maximum (Theorem 2.1 in Chapter 7) guarantees the continuity of $V(p, y)$ and the upper hemicontinuity of $x(p, y)$. Because a uhc single-valued correspondence is a continuous function (see Section 11 of Chapter 2), moreover, $x(p, y)$ is a continuous function whenever $U$ is strictly quasiconcave.
- Adding up. We will now show that any optimal consumption bundle exhausts the available income when $U()$ is strictly increasing. Suppose this is not the case, that is, that there exists some bundle $z \in x(p, y)$ with $p z<y$. Then there is some consumption bundle that dominates $z$ and is still feasible (i.e., there exists a point $z^{\prime}>z$ such that $p z^{\prime}<y$ ). Because $U()$ is strictly increasing by assumption, we then have $U\left(z^{\prime}\right)>U(z)$, which contradicts the assumption that $z$ is a maximizer.
- Homogeneity of $x(p, y)$ and $V(p, y)$. Notice that any equiproportionate changes in prices and income do not change the budget set. That is, if $p x \leq y$, then $(\mu p) x=$ $\mu(p x) \leq \mu y$ for any $\mu>0$. Hence, $B(p, y)=B(\mu p, \mu y)$ for any $\mu>0$, and the feasible set does not change with $\mu$. Because prices and income do not enter the objective function $U($ ), the consumption choice will not be affected when we multiply all prices and income by the same positive factor, and neither will utility be affected. Hence, this property extends also to the indirect utility function. Notice that $V(p, y)=U(x(p, y))$, where $x(p, y)$ is any optimal consumption bundle. Thus, we can write

$$
V(\mu p, \mu y)=U[x(\mu p, \mu y)]=U[x(p, y)]=V(p, y) \quad \text { for any } \mu>0
$$

- $V()$ is increasing in $y$ and nonincreasing in prices. Take $y^{\prime}$ and $y^{\prime \prime}$, with $y^{\prime \prime}>y^{\prime}$. Then clearly

$$
B\left(p, y^{\prime \prime}\right) \supseteq B\left(p, y^{\prime}\right)
$$

That is, the budget set is (strictly) larger with the higher income. Let $x^{\prime} \in x\left(p, y^{\prime}\right)$ be an optimal consumption bundle for income $y^{\prime}$. Then $x^{\prime}$ is still feasible, but not necessarily optimal for income $y^{\prime \prime}$, so certainly $V\left(p, y^{\prime \prime}\right) \geq V\left(p, y^{\prime}\right)$. In fact, the inequality is strict when $U()$ is strictly increasing, for then $p x^{\prime}=y^{\prime}<y^{\prime \prime}$, so we can find some point $x^{\prime \prime}>x^{\prime}$ that is feasible for income $y^{\prime \prime}$. Then $V\left(p, y^{\prime \prime}\right) \geq U\left(x^{\prime \prime}\right)>$ $U\left(x^{\prime}\right)=V\left(p, y^{\prime}\right)$. Thus, we conclude that $V()$ is strictly increasing in income when $U()$ is strictly increasing. A similar argument will establish monotonicity in prices.

- Quasiconvexity of $V(p, y)$. Given a real number $v$, the lower contour set of $V()$ is the set

$$
L_{v}=\{(p, y) ; V(p, y) \leq v\}
$$

To establish the quasiconvexity of $V()$, we have to show that $L_{v}$ is a convex set for any given $v$. Let $\left(p^{\prime}, y^{\prime}\right)$ and $\left(p^{\prime \prime}, y^{\prime \prime}\right)$ be two arbitrary points in $L_{v}$, that is, with $V\left(p^{\prime}, y^{\prime}\right) \leq v$ and $V\left(p^{\prime \prime}, y^{\prime \prime}\right) \leq v$, and let

$$
\left(p^{\lambda}, y^{\lambda}\right)=\left((1-\lambda) p^{\prime}+\lambda p^{\prime \prime},(1-\lambda) y^{\prime}+\lambda y^{\prime \prime}\right) \quad \text { for } \lambda \in(0,1)
$$

We want to show that $\left(p^{\lambda}, y^{\lambda}\right) \in L_{v}$, that is, that $V\left(p^{\lambda}, y^{\lambda}\right) \leq v$. Notice that it is sufficient to show that for any point $x$ that is feasible for $\left(p^{\lambda}, y^{\lambda}\right)$ (i.e., such that $\left.p^{\lambda} x \leq y^{\lambda}\right)$, we have $U(x) \leq v$, because $V\left(p^{\lambda}, y^{\lambda}\right)$ is the value of one such point.

First, notice that $p^{\lambda} x \leq y^{\lambda}$ implies

$$
p^{\lambda} x=\left[(1-\lambda) p^{\prime}+\lambda p^{\prime \prime}\right] x=(1-\lambda) p^{\prime} x+\lambda p^{\prime \prime} x \leq(1-\lambda) y^{\prime}+\lambda y^{\prime \prime}=y^{\lambda}
$$

Now, because

$$
(1-\lambda) p^{\prime} x+\lambda p^{\prime \prime} x \leq(1-\lambda) y^{\prime}+\lambda y^{\prime \prime}
$$

it must be true that either $p^{\prime} x \leq y^{\prime}$ or $p^{\prime \prime} x \leq y^{\prime \prime}$ or both. If the first inequality holds, then $x$ is feasible, but not necessarily optimal for $\left(p^{\prime}, y^{\prime}\right)$, and we have $U(x) \leq V\left(p^{\prime}\right.$, $\left.y^{\prime}\right) \leq v$. Otherwise, $p^{\prime \prime} x \leq y^{\prime \prime}$ implies $U(x) \leq V\left(p^{\prime \prime}, y^{\prime \prime}\right) \leq v$, by the same argument. In either case, $U(x) \leq v$, and the result follows.

Problem 2.4. Show that if $U()$ is homothetic, then demand is linear in income, that is, $x(p, y)=y x(p, 1)$.

Hint: Recall that a function is said to be homothetic if it is a monotonically increasing transformation of a homogeneous function.

Let us now strengthen our continuity assumptions and require that $U()$ be a twice continuously differentiable function. In this case, both the demand and indirect utility mappings are differentiable functions, and we can obtain some further results. In particular, we assume that $U()$ is a $C^{2}$, strictly quasiconcave, and strictly increasing function that satisfies the second-order sufficient condition for strict quasiconcavity in terms of the bordered Hessian given in Theorem 3.11 in Chapter 6. These assumptions will allow us to use the techniques developed in Chapter 5 and apply the implicit-function theorem to analyze the comparative-statics properties of the ordinary demand functions.

Because we know that the budget constraint will hold as an equality when $U()$ is strictly increasing, we can rewrite (C.U) as a Lagrange problem:

$$
\max _{x}\{U(x) \text { s.t. } y-p x=0\}
$$

where we are implicitly assuming that we have identified a priori those $G$ goods that will be consumed in positive amounts, and we exclude the rest. Differentiating the Lagrangian for the problem,

$$
\mathcal{E}(x, \lambda ; p, y)=U(x)+\lambda(y-p x)
$$

yields the first-order conditions

$$
\begin{gather*}
\frac{\partial £}{\partial x_{i}}=\frac{\partial U}{\partial x_{i}}-\lambda p_{i}=0 \Rightarrow \lambda=\frac{U_{i}(x)}{p_{i}} \forall i=1, \ldots, G  \tag{1}\\
\frac{\partial £}{\partial \lambda}=y-p x=0 \tag{2}
\end{gather*}
$$

where $U_{i}()$ denotes the partial derivative of $U()$ with respect to its $i$ th argument. Given our assumptions, these conditions will characterize a unique optimal solution $x^{*}$. Notice that optimality requires

$$
\frac{U_{k}(x)}{p_{k}}=\lambda=\frac{U_{i}(x)}{p_{i}} \Leftrightarrow \frac{p_{i}}{p_{k}}=\frac{U_{i}\left(x^{*}\right)}{U_{k}\left(x^{*}\right)}
$$

This is the familiar condition requiring that the marginal utility of the last dollar spent on each good must be the same for all of them or, equivalently, that the marginal rate of substitution between any two goods $i$ and $k$ must be equal to the ratio of their prices.

Equations (1) and (2) constitute a system of $G+1$ equations in $G+1$ unknowns that we would like to solve for the ordinary demand functions, $x_{i}^{*}=x_{i}(p, y)$ for $i=1, \ldots, G$, and the multiplier, $\lambda^{*}=\lambda(p, y)$. In some simple cases it is possible to solve (1) and (2) explicitly for $x^{*}$ and $\lambda^{*}$. In general, however, such closed-form solutions are not available, and we have to resort to the implicit-function theorem (IFT) to do comparative statics. To apply this theorem, rewrite the first-order conditions in the form

$$
\begin{gather*}
F^{i}(x, \lambda ; p)=U_{i}(x)-\lambda p_{i}=0 \text { for each } i=1, \ldots, G  \tag{3}\\
F^{G+1}(x, \lambda ; p)=y-p x=0 \tag{4}
\end{gather*}
$$

and observe that the Jacobian of endogenous variables of this system is given by

$$
|J|=\left|D_{(x, \lambda)} F(x, \lambda ; p)\right|=\left|\begin{array}{cccc}
U_{11} & \cdots & U_{1 G} & -p_{1} \\
\cdots & \cdots & \cdots & \cdots \\
U_{G 1} & \cdots & U_{G G} & -p_{G} \\
-p_{1} & \cdots & -p_{G} & 0
\end{array}\right|
$$

Using the first-order conditions $\left(U_{i}=\lambda p_{i}\right)$, and factoring things out, this determinant can be written in terms of the bordered Hessian of the utility function,

$$
|J|=(-1 / \lambda)^{2 n}\left|\begin{array}{cccc}
U_{11} & \cdots & U_{1 G} & U_{1} \\
\cdots & \cdots & \cdots & \cdots \\
U_{G 1} & \cdots & U_{G G} & U_{G} \\
U_{1} & \cdots & U_{G} & 0
\end{array}\right|
$$

which is nonzero by our assumptions on $U()$. Hence, the sufficient conditions for a strict local maximum hold (see Theorem 1.16 in Chapter 7), and the solution to the system of first-order conditions is a regular solution of the consumer's problem. This guarantees that we can use the IFT to compute the partial derivatives of the ordinary demand functions. In particular, we have

$$
\frac{\partial x_{i}(p, y)}{\partial p_{k}}=\frac{\left|J_{i k}\right|}{|J|}
$$

where $J_{i k}$ is the matrix obtained by replacing the $i$ th column of the Jacobian $J$ with the vector $\left(D_{p_{k}} F(x, \lambda ; p)\right)^{T}$.

Unfortunately, it turns out that the sign of $\left|J_{i k}\right|$ cannot be determined unambiguously even when $i=k$. Hence, it is not necessarily true that demands are decreasing in their own price or increasing in income. The one restriction on individual behavior we get from utility maximization is the one given in the following result.

Theorem 2.5. Slutsky. Assume that $\mathrm{U}()$ is $\mathrm{C}^{2}$ and satisfies the sufficient second-order conditions for a local maximum. Then the Slutsky matrix [ $\mathrm{s}_{\mathrm{ik}}$ ], with

$$
\begin{equation*}
s_{i k}=\frac{\partial x_{i}(p, y)}{\partial p_{k}}+x_{k}(p, y) \frac{\partial x_{i}(p, y)}{d_{y}} \tag{5}
\end{equation*}
$$

is symmetric and negative semidefinite.

A proof of this theorem (which can also be established by direct computation using the IFT) and a discussion of its meaning will be given later. For the time being, we just note that the symmetry of the Slutsky matrix requires that

$$
\begin{equation*}
s_{i k}=s_{k i} \Rightarrow \frac{\partial x_{i}(p, y)}{\partial p_{k}}+x_{k}(p, y) \frac{\partial x_{i}(p, y)}{\partial y}=\frac{\partial x_{k}(p, y)}{\partial p_{i}}+x_{i}(p, y) \frac{\partial x_{k}(p, y)}{\partial y} \tag{6}
\end{equation*}
$$

and its negative definiteness implies that the elements in its principal diagonal will be nonpositive, that is,

$$
\begin{equation*}
s_{i i}=\frac{\partial x_{i}(p, y)}{\partial p_{i}}+x_{i}(p, y) \frac{\partial x_{i}(p, y)}{\partial y} \leq 0 \tag{7}
\end{equation*}
$$

This last property can be used to establish what Samuelson calls the "fundamental theorem of demand theory": If a good is not inferior, its ordinary demand curve is downward-sloping. This follows immediately from (7) and
the definition of inferior good. If a good is not inferior, then the income effect is positive, that is, $\partial x_{i}(p, y) / \partial y \geq 0$, and (7) implies

$$
\frac{\partial x_{i}(p, y)}{\partial p_{i}} \leq-x_{i}(p, y) \frac{\partial x_{i}(p, y)}{\partial y} \leq 0
$$

On the other hand, inferior goods may have upward-sloping demands (these are the so-called Giffen goods) if the income effect is negative and strong enough to outweigh the substitution effect.

These results completely exhaust the implications of demand theory. It can be shown that given a set of homogeneous demand functions that add up to income and satisfy the Slutsky conditions, it is possible to "integrate" the demands back to a well-behaved utility function. Hence, we can go not only from utility to demand, but from demand to utility as well. The two sets of properties (those of $U()$ and those of $x())$ are fully equivalent, and this implies that there are no more implications to be had from utility maximization. Note that our results are rather weak: Maximization of a quasiconcave utility function does not impose too many restrictions on ordinary demand functions.

The following problem asks the reader to verify that there exists a simple relationship between the indirect utility function and Marshallian demand. In applied demand analysis it is sometimes more convenient to start out with some specification of the indirect utility function that has reasonable properties and then derive the demand functions from it - rather than starting with the direct utility function.

Problem 2.6. Roy's identity. Assume that the indirect utility function is differentiable. Show that then

$$
x_{i}(p, y)=\frac{-\partial V(p, y) / \partial p_{i}}{\partial V(p, y) / \partial y}
$$

Problem 2.7. Consider the following indirect utility function:

$$
V(p, y)=\frac{y-\sum_{k} p_{k} b_{k}}{\prod_{k} p_{k}^{a_{k}}}, \quad \text { where } \sum_{\mathrm{k}} a_{k}=1
$$

Use Roy's identity to find the ordinary demand functions.

(b) Expenditure Minimization and Compensated Demand

In this section we approach the consumer's decision problem from a slightly different perspective. Rather than taking income as given, we fix an arbitrary
utility level $u$ (i.e., an indifference curve) and solve for the consumption bundle $x^{*}$ that will minimize the expenditure (cost) needed to put the consumer on this particular indifference curve. That is, we will solve the problem

$$
\begin{equation*}
\min _{x}\{p x ; U(x) \geq u\} \tag{C.E}
\end{equation*}
$$

If we write the solution to this expenditure-minimization problem as a function of the parameters, we obtain the optimal consumption bundle as a function $h(p, u)$ of prices and the required utility level

$$
h(p, u)=\arg \min _{x}\{p x ; U(x) \geq u\}
$$

The resulting mapping (with $u$ rather than $y$ as an argument) is known as a compensated or Hicksian demand function or correspondence, because it allows us, by holding utility constant, to abstract from income effects, thus isolating the pure substitution effect of price changes on consumption behavior. The (minimum) value function for the expenditure-minimization problem,

$$
E(p, u)=\min _{x}\{p x ; U(x) \geq u\}=p h(p, u)
$$

is known as the expenditure function and gives the minimum expenditure necessary to achieve a desired level of utility $u$. As usual, we can recover $E(p, u)$ by substituting the optimal solution of the problem (i.e., the Hicksian demands, $h())$ back into the objective function.

In this section we investigate the properties of the compensated demands and the expenditure function. In the next section we will discuss the relationship between the two formulations of the consumer problem and relate the properties of compensated and ordinary demands to each other, proving, in particular, the Slutsky theorem.

Theorem 2.8. Properties of the compensated demand correspondence and the expenditure function. Let the utility function $\mathrm{U}: \mathbb{R}_{+}^{G} \rightarrow \mathbb{R}$ be continuous, strictly increasing, and quasiconcave, and consider the problem

$$
\begin{equation*}
\mathrm{E}(\mathrm{p}, \mathrm{u}) \min _{\mathrm{x}}\{\mathrm{px} ; \mathrm{U}(\mathrm{x}) \geq \mathrm{u}\} \tag{C.E}
\end{equation*}
$$

Let $\underline{\mathrm{u}}=\mathrm{U}(\underline{Q})$ and $(\overline{\mathrm{u}})=\sup \left\{\mathrm{U}(\mathrm{x}) ; \mathrm{x} \in \mathbb{R}_{+}^{n}\right\} \leq \infty$. Then for each $\mathrm{p} \gg \underline{0}$ and $\mathrm{u}$ $\in(\underline{\mathrm{u}}, \overline{\mathrm{u}})$, there exists at least one solution to the consumer problem (C.E), and $\mathrm{h}(\mathrm{p}, \mathrm{u})$ is uhc in this set. Moreover, the compensated demand correspondence $\mathrm{h}(\mathrm{p}, \mathrm{u})$ is homogeneous of degree 0 in $\mathrm{p}$ (in the sense that $\mathrm{h}(\mathrm{p}, \mathrm{u})=\mathrm{h}(\mu \mathrm{p}, \mu \mathrm{y}$ ) for any $\mu>0$ ), and the solution of the problem leaves no excess utility, meaning that for any $\mathrm{x} \in \mathrm{h}(\mathrm{p}, \mathrm{u})$ we have $\mathrm{U}(\mathrm{x})=\mathrm{u}$. If $\mathrm{U}()$ is strictly quasiconcave, then $\mathrm{h}(\mathrm{p}, \mathrm{u})$ is a (single-valued) function and is continuous.

The expenditure function $\mathrm{E}(\mathrm{p}, \mathrm{u})$ is a continuous function, concave and increasing in prices, strictly increasing in $\mathrm{u}$, and homogeneous of degree 1 in prices.

## Proof

- Existence of solutions and uniqueness, given strict quasiconcavity. The feasible set $\Gamma(u)=\left\{x \in \mathbb{R}_{+}^{\mathrm{G}} ; U(x) \geq u\right\}=U^{-1}[u, \infty)$ is closed, by the continuity of $U()$, but is unbounded and therefore not compact. It is not difficult, however, to "compactify" it. Given $p \gg \underline{O}$ and $u \in(\underline{u}, \overline{\mathrm{u}})$, choose a bundle $\overline{\mathrm{x}}$ such that $U(\bar{x})>u$. Such a bundle exists, by the assumption that $u \in(\underline{u}, \overline{\mathrm{u}})$. Then $\overline{\mathrm{x}}$ is feasible for $u$, but not necessarily optimal, and this implies that for any $x \in h(p, u)$ we have $p x \leq p \bar{x}$. Hence the solution to (C.E) will lie in the compact set

$$
\bar{\Gamma}(p, u)=\left\{x \in \mathbb{R}_{+}^{\mathrm{G}} ; U(x) \geq u \text { and } p x \leq p \bar{x}\right\}
$$

Because $U()$ is continuous, the extreme-value theorem guarantees the existence of a solution to (C.E). Moreover, because $U()$ is quasiconcave, $\bar{\Gamma}(p, u)$ is the intersection of two convex sets and therefore is convex itself. If $U()$ is strictly quasiconcave, it follows (by Theorem 1.11 in Chapter 7) that the solution is unique.

- $e(p, u)$ is strictly increasing in $u$. By contradiction. Suppose $e(p, u)=p h(p, u)$ is not strictly increasing in $u$. Then there exist utility levels $u^{\prime}$ and $u^{\prime \prime}$, with $u^{\prime \prime}>u^{\prime}>$ $U(\underline{0})$, and corresponding optimal consumption bundles $x^{\prime}$ and $x^{\prime \prime}$, with $x^{\prime} \in h(p$, $\left.u^{\prime}\right)$ and $x^{\prime \prime} \in h\left(p, u^{\prime \prime}\right)$, such that $0<p x^{\prime \prime} \leq p x^{\prime}$. By the no-excess-utility property, moreover, we have $U\left(x^{\prime \prime}\right)=u^{\prime \prime}>u^{\prime}=U\left(x^{\prime}\right)$. Consider now a consumption bundle of the form $z=\lambda x^{\prime \prime}$, with $\lambda \in(0,1)$. By the continuity of $U()$, we can choose $\lambda$ close enough to unity that $U\left(\lambda x^{\prime \prime}\right)>u^{\prime}=U\left(x^{\prime}\right)$, and because $\lambda<1$ we have $p\left(\lambda x^{\prime \prime}\right)$ $=\lambda\left(p x^{\prime \prime}\right)<p x^{\prime \prime} \leq p x^{\prime}$. This contradicts the assumption that $x^{\prime}$ solves (C.E) with required utility $u^{\prime}$, for we have found a bundle $\lambda x^{\prime \prime}$ that is strictly cheaper than $x^{\prime}$ and yields greater utility.
- $e(p, u)$ is increasing in $p$. Fix some $u$, let $p^{\prime}$ and $p^{\prime \prime}$ be arbitrary price vectors, with $p^{\prime \prime}>p^{\prime}$, and let $x^{\prime \prime}$ be optimal for $\left(p^{\prime \prime}, u\right)$. Then $x^{\prime \prime}$ is feasible for $\left(p^{\prime}, u\right)$ because $U\left(x^{\prime \prime}\right) \geq u$, but it does not necessarily minimize expenditure; hence,

$$
e\left(p^{\prime \prime}, u\right)=p^{\prime \prime} x^{\prime \prime} \geq p^{\prime} x^{\prime \prime} \geq e\left(p^{\prime}, u\right)
$$

- Continuity. First we will show that $h(p, u)$ is compact-valued. As we have shown, $h(p, u)$ is contained in the compact set $\bar{\Gamma}(p, u)$ and therefore is bounded. To see that it is closed, let $m=e(p, u)=p x \equiv P(x)$ for some $x$. Then $\{m\}$ is a closed set in $\mathbb{R}$, and $h(p, u)=P^{-1}(\{m\}) \cap U^{-1}[u, \infty)$ is the intersection of two closed sets, by the continuity of the utility function and the inner product $P()$. Hence, $h()$ is compact-valued, and we can use the sequential characterization of upper hemicontinuity given in Theorem 11.2 in Chapter 2.

Thus, we have to show that given any sequence $\left\{\left(p_{n}, u_{n}\right)\right\}$ converging to $(p, u)$, with $p \gg \underline{Q}$ and $u \in(\underline{u}, \bar{u})$, every companion sequence of demands $\left\{x_{n}\right\}$, with $x_{n} \in h\left(p_{n}, u_{n}\right)$ has a convergent subsequence with limit in $h(p, u)$.

We will show that the sequence $\left\{x_{n}\right\}$ is bounded. Let $z \gg \underline{0}$ be such that $U(z)>u$. Because $\left\{u_{n}\right\} \rightarrow u$, we can assume that (possibly after deleting some initial terms of the sequence)

$$
\begin{equation*}
U(z) \geq u_{n} \forall n \tag{1}
\end{equation*}
$$

Then $z$ is feasible, but not necessarily optimal for all $\left(u_{n}, p_{n}\right)$, and we have

$$
p_{n} z \geq e\left(p_{n}, u_{n}\right)=p_{n} x_{n}
$$

where the last equality holds because $x_{n} \in h\left(p_{n}, u_{n}\right)$. Hence, expenditure in the $i$ th good is bounded by $p_{n} z$ (i.e., $p_{n}^{i} x_{n}^{i} \leq p_{n} z$ ). Because $\left\{p_{n}\right\} \rightarrow p$ (which implies that $\left\{p_{n}^{i}\right\} \rightarrow p^{i}$ for all $i$ ), moreover, we will have

$$
p_{n}^{i}>p^{i} / 2 \text { and } p_{n} z \leq p z+1
$$

for $n$ sufficiently large. Hence,

$$
x_{n}^{i} \leq \frac{p_{n} z}{p_{n}^{i}} \leq \frac{p z+1}{p^{i / 2}}
$$

for all $i$ and sufficiently large $n$.

Because $\left\{x_{n}\right\}$ is bounded, it contains a convergent subsequence, say $\left\{x_{n_{k}}\right\}$, with limit $\tilde{x}$. Because $x_{n_{k}} \in h\left(p_{n_{k}}, u_{n_{k}}\right)$, we have $U\left(x_{n_{k}}\right) \geq u_{n_{k}}$ for all $k$, and the continuity of $U()$ implies that $U(\tilde{x}) \geq u$. Hence $\tilde{x}$ is feasible for $(p, u)$.

To establish that $\tilde{x}$ is also optimal, that is, that $\tilde{x} \in h(p, u)$, we proceed by contradiction. Suppose $\tilde{x} \notin h(p, u)$; then there exists some feasible $x$ that costs less than $\tilde{x}$. That is, there exists some $x$ such that

$$
\begin{align*}
& p x<p \tilde{x}  \tag{2}\\
& U(x) \geq u \tag{3}
\end{align*}
$$

Next, we construct a sequence $\left\{z_{n_{k}}\right\}$ as follows:

$$
z_{n_{k}}= \begin{cases}x & \text { if } u_{n_{k}}<u \\ z_{n_{k}} \in[z, x] \text { s.th. } U\left(z_{n_{k}}\right)=u_{n_{k}} \quad \text { otherwise }\end{cases}
$$

Notice that the required $z_{n_{k}} \in[z, x]$, with $U\left(z_{n_{k}}\right)=u_{n_{k}}$ exists whenever $u_{n_{k}} \geq u$, by the continuity of $U()$ and the fact that $U(z) \geq u_{n_{k}} \geq u=U(x)$. Observe also that $z_{n_{k}}$ is feasible for $\left(p_{n_{k}}, u_{n_{k}}\right)$, by construction, but not necessarily optimal. Hence

$$
\begin{equation*}
p_{n_{k}} z_{n_{k}} \geq e\left(p_{n_{k}}, z_{n_{k}}\right)=p_{n_{k}} x_{n_{k}} \tag{4}
\end{equation*}
$$

because $x_{n_{k}} \in h\left(p_{n_{k}}, u_{n_{k}}\right)$. On the other hand, it can be shown that $\left\{z_{n_{k}}\right\} \rightarrow x$ (see Problem 2.10). Hence, taking limits of both sides of (4), and recalling that $\left\{x_{n_{k}}\right\} \rightarrow \tilde{x}$, we have

$$
\begin{equation*}
p x \geq p \tilde{x} \tag{5}
\end{equation*}
$$

which contradicts (2). This establishes the desired result.

Problem 2.9. To complete the proof of Theorem 2.8, show that under the given assumptions, we have the following:

(i) Compensated demand is homogeneous of degree 0 in prices, and the expenditure function is homogeneous of degree 1 in $p$.

(ii) The solution to the expenditure-minimization problem yields no excess utility. Hint: By contradiction. Show that if the result does not hold, then we can construct a bundle that will yield the required level of utility and will cost less than the optimum.

(iii) The expenditure function is concave in prices. Give an intuitive interpretation of this fact.

Problem 2.10. Show that the sequence $\left\{z_{n_{k}}\right\}$ constructed in the last part of the proof of Theorem 2.8 converges to $x$.

Hint: Notice that we can choose $z$ so that $z \gg x$, use the strict monotonicity of the utility function and the fact that $U(x) \geq u$, and seek a contradiction.

If we assume that $U()$ is $C^{2}$ and strictly quasiconcave, then $h(p, u)$ is a differentiable function, and we can apply the implicit-function theorem to the first-order conditions of the expenditure-minimization problem to study the comparative statics of compensated demands. In this particular case, however, an indirect approach turns out to be much more convenient. The first step is based on the observation that by the linearity of the objective function there is a simple relationship between the expenditure function and the compensated demands.

Theorem 2.11. Shephard's lemma. Assume that $\mathrm{U}()$ is $\mathrm{C}^{1}$. Then the expenditure function is differentiable, and

$$
\mathrm{D}_{\mathrm{p}} \mathrm{E}(\mathrm{p}, \mathrm{u})=\mathrm{h}(\mathrm{p}, \mathrm{u}) ; \quad \text { i.e., } \frac{\partial \mathrm{E}(\mathrm{p}, \mathrm{u})}{\partial \mathrm{p}_{\mathrm{i}}}=\mathrm{h}_{\mathrm{i}}(\mathrm{p}, \mathrm{u}) \forall \mathrm{i}
$$

Proof. By the no-excess-utility property, (C.E) can be written as a standard Lagrange problem (with a single equality constraint). Shephard's lemma then follows immediately by the envelope theorem (Theorem 2.16 in Chapter 7). The Lagrangian for the expenditure-minimization problem is

$$
£(x, \lambda ; p, u)=\sum_{i=1}^{G} p_{i} x_{i}+\lambda[U(x)-u]
$$

Hence the envelope theorem yields

$$
\frac{\partial E(p, u)}{\partial p_{i}}=\frac{\partial £\left(x^{*}, \lambda^{*} ; p, u\right)}{\partial p_{i}}=x_{i}^{*}=h_{i}(p, u)
$$

Using this result, it is easy to derive some important properties of the compensated demand functions from the concavity of the expenditure function. The crucial observation is that by Shephard's lemma, the second partials of the expenditure function are the first partials of the Hicksian demands. That is,

$$
\frac{\partial^{2} E(p, u)}{\partial p_{i} \partial p_{k}}=\frac{\partial h_{i}(p, u)}{\partial p_{k}}
$$

whenever $E()$ is twice differentiable.

Theorem 2.12. Comparative statics of compensated demand. Assume that the expenditure function is $\mathrm{C}^{2}$. Then

(i) the compensated demand functions are decreasing in their own price, that is, $\partial \mathrm{h}_{\mathrm{i}}(\mathrm{p}, \mathrm{u}) / \partial \mathrm{p}_{\mathrm{i}} \leq 0$ for all $\mathrm{i}$, and

(ii) they satisfy the condition $\partial \mathrm{h}_{\mathrm{i}}(\mathrm{p}, \mathrm{u}) / \partial \mathrm{p}_{\mathrm{k}}=\partial \mathrm{h}_{\mathrm{k}}(\mathrm{p}, \mathrm{u}) / \partial \mathrm{p}_{\mathrm{i}}$ for all $\mathrm{i}$ and $\mathrm{k}$.

## Proof

- By the concavity of the expenditure function in prices, the Hessian matrix of second derivatives of $E()$ with respect to prices is negative semidefinite (by Theorem 2.18 in Chapter 6). Because all diagonal elements of a negative semidefinite matrix must be nonnegative (see the appendix to Chapter 6), we have, by Shephard's lemma,

$$
\frac{\partial h_{i}(p, u)}{\partial p_{i}}=\frac{\partial^{2} E(p, u)}{\partial p_{i}^{2}} \leq 0 \forall i=1, \ldots, G
$$

- If $E(p, u)$ is $C^{2}$, we have, by Young's (Schwarz's) theorem (Theorem 2.6 in Chapter 4), that the matrix of second partials is symmetric (the order of differentiation does not matter); hence,

$$
\frac{\partial^{2} E(p, u)}{\partial p_{i} \partial p_{k}}=\frac{\partial^{2} E(p, u)}{\partial p_{k} \partial p_{i}}
$$

and by Shephard's lemma this implies

$$
\frac{\partial h_{i}(p, u)}{\partial p_{k}}=\frac{\partial h_{k}(p, u)}{\partial p_{i}}
$$

The first part of the theorem says that the compensated demand functions are "downward-sloping." The reason for this should be intuitively clear. The sign of the derivative $\partial h_{i}(p, u) / \partial p_{i}$ tells us how a consumer will adjust his purchases of good $i$ in response to an increase in its price when he also receives an income transfer that allows him to stay on the original indifference curve. By holding utility constant, the compensated demand function isolates the pure substitution effect of a price change. Barring income effects, an increase in the price of a good can only make it less attractive relative to other goods, thereby reducing its consumption. The condition given in the second part of the theorem is equivalent, as we will soon see, to the Slutsky symmetry condition asserted in Theorem 2.5.

## (c) Relationship between Compensated and Ordinary Demands: The Slutsky Equation

We have analyzed the consumer's decision problem from two slightly different perspectives. In Section (a) we fixed the allowable expenditure and looked for the highest attainable indifference curve. In Section (b) we selected an arbitrary indifference curve and looked for the lowest isoexpenditure line compatible with it. It is intuitively clear that, provided we are careful to identify the correct indifference curve and expenditure levels, the two problems yield the same optimal bundle (Figure 8.5). The following result makes this equivalence more precise.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-357.jpg?height=549&width=1177&top_left_y=1549&top_left_x=154)

Figure 8.5. Equivalence between utility maximization and expenditure minimization.

Theorem 2.13. Equivalence between utility maximization and expenditure minimization. Let $\mathrm{U}: \mathbb{R}_{+}^{\mathrm{G}} \longrightarrow \mathbb{R}$ be a strictly increasing and continuous utility function, and fix some $\mathrm{p} \gg \underline{0}$.

(i) If $\mathrm{x}_{\mathrm{u}}$ solves (C.U) when income is $\mathrm{y}>0$, then $\mathrm{x}_{\mathrm{u}}$ solves (C.E) when the required utility is $\mathrm{U}\left(\mathrm{x}_{\mathrm{u}}\right)$. Moreover, the minimized expenditure level for the latter problem is $\mathrm{y}$.

(ii) If $\mathrm{x}_{\mathrm{e}}$ solves (C.E) when the required utility level is $\mathrm{u} \in(\underline{\mathrm{u}}, \overline{\mathrm{u}})$, then $\mathrm{x}_{\mathrm{e}}$ solves $(C . U)$ when income is $\mathrm{px}_{\mathrm{e}}$. Moreover, the maximized utility level in the second problem is $\mathrm{u}$.

Problem 2.14. Prove Theorem 2.13. Hint: By contradiction. Assume that $x$ solves one of the problems, but not the other, and show that then it cannot solve the first one either.

Theorem 2.13 allows us to write the following identity:

$$
\begin{equation*}
h(p, u) \equiv x^{*} \equiv x(p, y) \tag{8}
\end{equation*}
$$

where $y$ is the minimum level of expenditure needed to reach the indifference curve indexed by $u$ - and $u$ is the maximum utility attainable with expenditure $y$. More explicitly, we have

$$
\begin{align*}
& h[p, V(p, y)] \equiv x(p, y)  \tag{9}\\
& x[p, E(p, u)] \equiv h(p, u) \tag{10}
\end{align*}
$$

Focusing on the $i$ th component of (10),

$$
h_{i}(p, u) \equiv x_{i}[p, E(p, u)]
$$

and differentiating this expression with respect to an arbitrary price $p_{k}$, we have

$$
\begin{equation*}
\frac{\partial h_{i}(p, u)}{\partial p_{k}}=\frac{\partial x_{i}(p, y)}{\partial p_{k}}+\frac{\partial x_{i}(p, y)}{\partial y} \frac{\partial E(p, u)}{\partial p_{k}} \tag{11}
\end{equation*}
$$

By Shephard's lemma and (8), moreover,

$$
\frac{\partial E(p, u)}{\partial p_{k}}=h_{k}(p, u)=x_{k}(p, y)
$$

Substituting this expression into (11), we obtain an equation that relates the partial derivatives of the compensated and ordinary demand functions:

$$
\begin{equation*}
\frac{\partial h_{i}(p, u)}{\partial p_{k}}=\frac{\partial x_{i}(p, y)}{\partial p_{k}}+x_{k}(p, y) \frac{\partial x_{i}(p, y)}{\partial y} \tag{12}
\end{equation*}
$$

This identity is known as the Slutsky equation.

Comparing (12) with equation (5) in Section (a), we see that the Slutsky terms $s_{i k}$ are in fact the partial derivatives of compensated demand with respect to prices. By Theorem 2.11 we know that

$$
s_{i k}=\frac{\partial h_{i}(p, u)}{\partial p_{k}}=\frac{\partial h_{k}(p, u)}{\partial p_{i}}=s_{k i}
$$

and

$$
s_{i i}=\frac{\partial h_{i}(p, u)}{\partial p_{i}} \leq 0
$$

as asserted in Theorem 2.5. Hence, the properties we attributed in Section (a) to the Slutsky matrix have been derived in Section (b) from the concavity in prices of the expenditure function, using Shephard's lemma.

The Slutsky equation allows us to decompose the effect on demand of a price change into a substitution effect and an income effect. Solving (12) for $\partial x_{i}(p, y) / \partial p_{k}$, we get

$$
\begin{equation*}
\frac{\partial x_{i}(p, y)}{\partial p_{k}}=\frac{\partial h_{i}(p, u)}{\partial p_{k}}-x_{k}\left(p, y^{*}\right) \frac{\partial x_{i}(p, y)}{\partial y} \tag{13}
\end{equation*}
$$

which we can interpret as follows:

total effect of = substitution + income effect, weighted by the importance a price change $=$ effect + of the good whose price has changed

It seems natural to weight the income effect by the consumption of the good whose price has changed. If the expenditure on this particular good is small (e.g., salt), even a large price change will have little effect on the consumer's real income. Finally, consider the decomposition of the effect of a change in a good's own price on its demand:

$$
\begin{equation*}
\frac{\partial x_{i}(p, y)}{\partial p_{i}}=\frac{\partial h_{i}(p, u)}{\partial p_{i}}-x_{i}\left(p, y^{*}\right) \frac{\partial x_{i}(p, y)}{\partial y} \tag{14}
\end{equation*}
$$

By Theorem 2.12, the substitution effect is negative. If the good is normal, $\partial x_{i}() / \partial y$ is positive, and the income and substitution effects work in the same direction, implying that $\partial x_{i}() / \partial p_{i} \leq 0$. This is the "fundamental law of demand."

## 3. Walrasian General Equilibrium in a Pure Exchange Economy

In this section we develop the standard theory of general competitive equilibrium in the context of a pure exchange economy. The adjective "general"
indicates that we explicitly model the interdependence among the different sectors in the economy, as opposed to a partial-equilibrium analysis, where we might focus on a specific market in isolation. The words "competitive" and "Walrasian" indicate reliance on a specific concept of equilibrium which assumes that markets are "perfectly competitive" in a sense to be made precise later.

The economy we study will be populated by a large number of consumers characterized by a well-behaved utility function and endowed with an initial vector of commodity holdings. Each of these consumers will take prices as given and will trade with other agents through a complete set of competitive markets. However, there will be no firms. Ignoring production will simplify matters considerably, while still allowing us to study the basic problem of how markets coordinate the actions of individual economic agents.

We assume that

(i) consumers are rational agents who maximize their utility, taking prices as exogenously given, and constrained only by the requirement that the market value of one's consumption bundle not exceed that of one's endowment, and

(ii) these individuals interact with each other only through a complete set of competitive markets in which prices are determined in such a way that supply always equals demand.

That is, in the Walrasian view, the consistency requirement that we have to impose on individual actions in order to speak of an equilibrium takes the form of market clearing. Notice that individuals are constrained only by prices precisely because markets clear (otherwise some sort of rationing would arise). Individual agents do not feel constrained by the actions of others in any specific way, because they can sell or buy any quantity of any good at the market price. This allows us to formulate and solve the individual's optimization problem as if he were free to choose independently of all other agents. On the other hand, this is not strictly true, as it is the interaction of all agents that determines market prices.

Before we can begin to investigate how prices are determined, we need to define some basic concepts.

Definition 3.1. Exchange economy and allocation. An exchange economy is a couple

$$
\xi=(U, e)=\left\{\left(U^{i}, e^{i}\right) ; i=1, \ldots, n\right\}
$$

where $U^{i}$ is a function $\mathbb{R}_{+}^{\mathcal{G}} \longrightarrow \mathbb{R}$, and $e^{i}=\left(e_{l}^{i}, \ldots, e_{G}^{i}\right)$ is a vector in $\mathbb{R}_{+}^{\mathcal{G}}$. We interpret $U^{i}()$ as the utility function of agent $i$, and $e^{i}$ as his endowment vector (i.e., as his initial holdings of commodities).

An allocation $x=\left(x^{1}, \ldots, x^{n}\right) \in \mathbb{R}_{+}^{\mathrm{n} G}$ is a vector that describes the amount
of each commodity consumed by each of the $n$ agents in the economy. An allocation is feasible if the total consumption of each commodity does not exceed its total endowment (i.e., if $\Sigma_{i=1}^{\mathrm{n}} x^{i} \leq \sum_{i=1}^{\mathrm{n}} e^{i}$ ).

Definition 3.2. Competitive or Walrasian equilibrium. A Walrasian equilibrium is a price-allocation pair $\left(p^{*}, x^{*}\right)$ such that when all agents maximize utility, taking $p^{*}$ as given, markets clear and agents receive the (feasible) allocation $x^{*}=\left(x^{1 *}, \ldots, x^{n *}\right)$.

This definition suggests the following procedure for finding an equilibrium. First, we derive the individual demand functions or correspondences as the solution mappings for the optimization problems faced by the individual traders. Then we aggregate over agents to obtain the total demand for the economy. Finally, we impose market clearing; that is, we require that supply equal demand in the markets for all goods.

This procedure yields a system of $G$ equations (the market-clearing conditions) in $G$ unknowns (the equilibrium prices of the goods). We can exploit the fact that we know how the system is constructed (from individual optimization and an overall equilibrium condition) to establish certain properties of the equilibrium mapping. The basic questions are still the ones we discussed in Chapter 5: First, we need to establish that a solution to the system (i.e., a competitive equilibrium) exists under certain conditions. Then we can ask whether or not the solution is unique, how it varies with changes in the parameters of the model (endowments), and whether or not it has any desirable welfare properties.

Some of these issues will be discussed in detail in the remainder of this section. Section (a) derives some properties of aggregate demand, making use of earlier results on consumer behavior. In Section (b), we provide sufficient conditions for the existence of equilibrium. Finally, Section (c) investigates the welfare properties of competitive equilibrium.

## (a) Aggregate Demand

The optimization problem faced by the traders in our exchange economy is almost identical with the one analyzed in Section 2 . The only difference is that income is now given by the market value of the endowment vector $e^{i}$. Hence, the demand correspondence for agent $i$ is now given by

$$
x^{i}\left(p, p e^{i}\right)=\arg \max _{x^{i}}\left\{\left(U^{i}\left(x^{i}\right) \text { s.t. } p x^{i} \leq p e^{i}\right)\right\}
$$

It is easy to check that this change does not alter the properties of individual demand correspondences. The following theorem lists some of these
properties and derives an additional one (the unboundedness of demand as some prices go to zero).

Theorem 3.3. Properties of the demand correspondence. Let the utility function $\mathrm{U}^{\mathrm{i}}: \mathbb{R}_{+}^{\mathrm{G}} \longrightarrow \mathbb{R}$ be continuous, strictly increasing, and quasiconcave. Then

(i) the demand correspondence $\mathrm{x}^{\mathrm{i}}\left(\mathrm{p}, \mathrm{pe}^{\mathrm{i}}\right)$, is uhc in $\mathrm{p}$ for any $\mathrm{p} \gg 0$,

(ii) compact- and convex-valued for any $\mathrm{p} \gg \underline{0}$, and

(iii) homogeneous of degree 0 , in the sense that if $\mathrm{x} \in \mathrm{x}\left(\mathrm{p}, \mathrm{pe}^{\mathrm{i}}\right.$, then $\mathrm{x} \in \mathbf{x}\left(\mu \mathrm{p}, \mu \mathrm{pe}^{\mathrm{i}}\right)$ for all $\mu>0$.

(iv) The budget constraint holds with equality, that is, $\mathrm{pz}^{\mathrm{i}}=\mathrm{pe}^{\mathrm{i}}$ for any $\mathrm{z}^{\mathrm{i}} \in \mathrm{x}^{\mathrm{i}}\left(\mathrm{p}, \mathrm{pe}^{\mathrm{i}}\right)$ (the "adding-up" property).

(v) If $\mathrm{U}()$ is strictly quasiconcave, then $\mathrm{x}^{\mathrm{i}}\left(\mathrm{p}, \mathrm{pe}^{\mathrm{i}}\right)$ is a (single-valued) function of prices and is continuous.

(vi) Let ( $\mathrm{p}_{\mathrm{n}}$ \} be a convergent price sequence, with $\mathrm{p}_{\mathrm{n}} \gg \underline{0}$ for all $\mathrm{n}$, and assume that its limit $\mathrm{p}$ has some zero component (i.e., $\mathrm{p}_{\mathrm{g}}=0$ for some good $\mathrm{g}$ ) and satisfies $\mathrm{pe}^{\mathrm{i}}>0$. Then the corresponding sequence of demand vectors tends to infinity, in the following sense. Let

$$
\mathrm{m}_{\mathrm{n}}=\inf \left\{\|\mathrm{x}\| ; \mathrm{x} \in \mathrm{x}^{1}\left(\mathrm{p}_{\mathrm{n}}, \mathrm{p}_{\mathrm{n}} \mathrm{e}^{1}\right)\right\}
$$

then $\left\{\mathrm{m}_{\mathrm{n}}\right\} \rightarrow \infty$ as $\mathrm{n} \rightarrow \infty$.

Proof. The results follow immediately from Theorem 2.3, except for (ii) and (vi). To see that $x^{i}\left(p, p e^{i}\right)$ is a convex and compact set, notice that

$$
\begin{align*}
x^{i}\left(p, p e^{i}\right) & =B\left(p, p e^{i}\right) \cap\left\{z \in \mathbb{R}_{+}^{G} ; U^{i}(z) \geq u_{i} \equiv \max _{x \in B\left(p, p e^{l}\right)} U^{i}(x)\right\} \\
& =B\left(p, p e^{i}\right) \cap U_{i}^{-1}\left[u_{i}, \infty\right] \tag{1}
\end{align*}
$$

is the intersection of two convex sets, the budget set $B\left(p, p e^{i}\right)$ and an upper contour set of the quasiconcave function $U^{i}(\cdot)$, and therefore it is convex itself. Similarly, the last expression in (1) shows that $x^{i}\left(p, p e^{i}\right)$ is a closed subset of the compact set $B\left(p, p e^{i}\right)$ and therefore is compact itself (by Theorem 8.14 in Chapter 2). Hence, $x^{i}\left(p, p e^{i}\right)$ is a convex- and compactvalued correspondence.

To establish the boundary property (vi), we proceed by contradiction. Fix some $p$, with some component $p_{g}=0$, and consider a sequence $\left\{p_{n}\right\} \rightarrow p$, with $p_{n} \gg \underline{Q}$ for all $n$. First, observe that the consumer's problem has no solution when some price is zero. Because utility is strictly increasing in all goods, there can be no best consumption bundle, because given any bundle, an alternative that includes more of the free good will be strictly preferred and will always be feasible. Hence, $x^{i}\left(p, p e^{i}\right)=\varnothing$.

Suppose now that the desired result is not true. Then there is a bounded set $B \subseteq \mathbb{R}_{+}^{\mathcal{C}}$ and a subsequence $\left\{p_{n_{k}}\right\}$ of $\left\{p_{n}\right\}$ such that

$$
x^{i}\left(p_{n_{k}}, p_{n_{k}} e^{i}\right) \cap B \neq \varnothing
$$

for all $n_{k}$. Let $z_{k} \in x^{i}\left(p_{n_{k}}, p_{n_{k}} e^{i}\right) \cap B$ for each $k$. Then the sequence $\left\{z_{k}\right\}$ is bounded and therefore contains a convergent subsequence, say $\left\{z_{k_{q}}\right\}$, with limit $z$. We will show that $z \in x^{i}\left(p, p e^{i}\right)$. This contradicts the fact that $x^{i}\left(p, p e^{i}\right)=\varnothing$ and establishes the result.

To conclude the proof, we need to show that $z \in x^{i}\left(p, p e^{i}\right)$, that is, that for every $y$ in $B\left(p, p e^{i}\right)$ we have $U(z) \geq U(y)$. First, notice that because $z_{k_{q}} \in$ $x^{i}\left(p_{n_{k_{q}}}, p_{n_{k_{q}}} e^{i}\right)$, we have $p_{n_{k_{q}}} z_{k_{q}} \leq p_{n_{k_{q}}} e^{i}$ for all $q$. Taking limits of this expression, we see that $p z \leq p e^{i}$, that is, $z \in B\left(p, p e^{i}\right)$. Hence $z$ is feasible for $\left(p, e^{i}\right)$.

We now consider two cases:

(i) Assume that $y$ is such that $p y<p e^{i}$. Then we have $p_{n_{k_{e}}} \mathrm{y}<p_{n_{k_{\alpha}}}{ }^{i}$ for $k_{q}$ large enough. Hence $y$ is feasible for $\left(p_{n_{k_{q}}}, e^{i}\right)$ and because $z_{k_{q}} \in x^{i}\left(p_{n_{k_{q}}} p_{n_{k_{q}}} e^{i}\right)$ is optimal, it follows that $U\left(z_{k_{q}}\right) \geq U(y)$ for all sufficiently large $k_{q}$. Taking limits of this inequality, it follows, by the continuity of $U()$, that $U(z) \geq U(y)$.

(ii) Alternatively, $y$ is such that $p y=p e^{i}>0$. Then we can find a sequence $\left\{y_{k}\right\}$ converging to $y$ such that $p y_{k}<p e^{i}$. By case (i) we have $U(z) \geq U\left(y_{k}\right)$ for all $k$, which implies, by the continuity of $U()$, that $U(z) \geq U(y)$. This concludes the proof of the theorem.

Once we have derived the individual demand functions, the next step is to aggregate them to obtain the "global" demand for all agents. Because all consumers face the same prices, the total quantity of each commodity demanded or supplied at a given price vector is simply the sum of the quantities each individual wants to buy or sell at that price. Hence, we define the aggregate demand correspondence by summing over the $n$ agents,

$$
\begin{equation*}
x(p, e)=\sum_{i=1}^{n} x^{i}\left(p, p e^{i}\right) \tag{1}
\end{equation*}
$$

and the aggregate excess-demand correspondence by

$$
\begin{equation*}
Z(p, e)=\sum_{i=1}^{n}\left[x^{i}\left(p, p e^{i}\right)-e^{i}\right]=x(p, e)-\sum_{i=1}^{n} e^{i} \tag{2}
\end{equation*}
$$

where $e$ is the $n G$ vector $e=\left(e^{1}, \ldots, e^{n}\right)$. Notice that, in general, both $x()$ and $Z$ ( ) will depend not only on total resources but also on the distribution of wealth in the economy.

The aggregate demand correspondence inherits some (but not all) of the properties of individual demand. By Theorem 11.11 in Chapter 2 and Theorem 1.4 in Chapter 6, $x()$ and $Z()$ inherit the upper hemicontinuity and compact- and convex-valuedness of individual demands. It is clear that the unboundedness of individual demand as some price converges to zero carries over to the aggregate. It is also easy to see that aggregation preserves the homogeneity of degree 0 in prices. We know that for each agent $i$,

$$
x^{i}\left(\mu p, \mu p e^{i}\right)=x^{i}\left(p, p e^{i}\right) \forall \mu>0
$$

Summing over agents, we have

$$
x(\mu p, e)=\sum_{i=1}^{n} x^{i}\left(\mu p, \mu p e^{i}\right)=\sum_{i=1}^{n} x^{i}\left(p, p e^{i}\right)=x(p, e)
$$

for all $\mu>0$, so $x()$ is homogeneous of degree 0 . Similarly, we know that all the individual budget constraints hold with equality. Hence,

$$
p x^{i}\left(p, p e^{i}\right)=p e^{i}
$$

for each $i$, and, summing over all consumers,

$$
\sum_{i=1}^{n} p x^{i}\left(p, p e^{i}\right)=\sum_{i=1}^{n} p e^{i}
$$

This expression implies that the value of the aggregate excess-demand vector must be zero, that is,

$$
\begin{equation*}
p \sum_{l=1}^{n}\left[x^{i}\left(p, p e^{i}\right)-e^{i}\right]=p Z(p, e)=0 \tag{W}
\end{equation*}
$$

an equality often referred to as Walras's law. We summarize these results in the following theorem.

Theorem 3.4. Properties of aggregate demand. Suppose $\mathrm{U}^{\mathrm{i}}: \mathbb{R}_{+}^{\mathrm{G}} \longrightarrow \mathbb{R}$ is quasiconcave, strictly increasing, and continuous for all agents. Then the aggregate excess-demand correspondence

$$
\mathrm{Z}(\mathrm{p}, \mathrm{e})=\sum_{\mathrm{i}=l}^{\mathrm{n}}\left[\mathrm{x}^{\mathrm{i}}\left(\mathrm{p}, \mathrm{pe}^{\mathrm{i}}\right)-\mathrm{e}^{\mathrm{i}}\right]=\mathrm{x}(\mathrm{p}, \mathrm{e})-\sum_{\mathrm{i}=1}^{\mathrm{n}} \mathrm{e}^{\mathrm{i}}
$$

is homogeneous of degree 0 in prices, nonempty, compact-and convex-valued, and uhc in prices for given $\mathrm{e}>\underline{0}$ and $\mathrm{p} » \underline{0}$, and it satisfies Walras's law:

$$
\begin{equation*}
\mathrm{pZ}(\mathrm{p}, \mathrm{e})=0 \tag{W}
\end{equation*}
$$

Moreover, given any sequence $\left\{\mathrm{p}_{\mathrm{n}}\right\}$, with $\mathrm{p}_{\mathrm{n}} \gg \underline{0}$ for all $\mathrm{n}$, that converges to a price vector $\mathrm{p}$, with $\mathrm{pe}^{\mathrm{i}}>\underline{0}$ for some $\mathrm{i}$ and some component equal to zero, the sequence $\left\{\mathrm{Z}\left(\mathrm{p}_{\mathrm{n}}, \mathrm{e}\right)\right\}$ is unbounded. Finally, if $\mathrm{U}^{\mathrm{i}}()$ is strictly quasiconcave for all agents, then $\mathrm{Z}($ ) is a continuous (single-valued) function.

Two implications of this result will be useful later. First, notice that Walras's law implies that if all markets except one clear, then the last one must necessarily clear as well. Hence, we need to worry about market clearing for only $G-1$ goods. Second, the homogeneity of degree 0 of $Z()$ in prices means that only relative prices matter. Formally, this allows us to normalize prices and worry about only $G-1$ of them. Among all the possible normalizations, two are very commonly used:
(i) Set the price of one of the goods (called the "numeraire") to 1 . The price vector is then of the form $p=\left(p_{1}, p_{2}, \ldots, p_{G-1}, 1\right)$.

(ii) Assume that the price vector belongs to the unit simplex in $\mathbb{R}_{+}^{\mathbb{G}}$ (i.e., that prices satisfy the relation $\Sigma_{i=1}^{G} p_{g}=1$ ).

It should be noted that our results concerning the properties of the Slutsky matrix for individual demand functions do not, in general, survive aggregation. Because these conditions (together with the properties that aggregate demand does inherit) are, as we have seen, equivalent to utility maximization, it follows that the aggregate demand function is not, generally speaking, utility-generated. That is, most economies do not behave as if we had a single "representative agent" making all consumption decisions. On the other hand, the aggregate excess-demand function will share the properties of individual demands in some special cases. It can be shown that a necessary and sufficient condition for the aggregate excess-demand function to be utility-generated, and hence independent of the distribution of wealth, is that preferences be homothetic and identical for all agents in the economy. The sufficiency part of this result is easily established using the result given in Problem 2.4. With identical and constant marginal propensities to consume in each good, any redistribution of resources will have no effect on aggregate spending patterns. Hence, the aggregate demand function does not depend on the distribution of wealth.

## (b) Existence of Competitive Equilibrium

We have defined a competitive equilibrium as a price-allocation pair ( $p^{*}$, $\left.x^{*}\right)$ such that when all agents optimize, taking $p^{*}$ as given, the markets for all goods clear, and agents receive the allocation $x^{*}$. Because the aggregate demand mapping already embodies the assumption that consumers optimize, taking prices as given, to establish the existence of an equilibrium it is sufficient to show that there exists some price vector $p^{*}>\underline{0}$ that generates a zero aggregate excess demand. If aggregate demand is single-valued, this condition reduces to a system of equations of the form

$$
\begin{equation*}
Z(p, e)=\underline{0} \tag{W.E}
\end{equation*}
$$

which can (hopefully) be solved for $p^{*}$, the equilibrium price vector, for a given vector of endowments. We can then determine the equilibrium allocation by using the individual demand functions to see how much of each commodity will be consumed by each trader at equilibrium prices $p^{*}$, that is, $x^{*}=x\left(p^{*}, e\right) .{ }^{5}$ If aggregate demand is not single-valued, equilibrium will require the existence of some price vector such that the resulting aggregate excess-demand set will contain the zero vector. That is, the equilibrium condition will be of the form

$$
\begin{equation*}
\underline{0} \in Z(p, e) \tag{W.E'}
\end{equation*}
$$

We will focus for the time being on the simpler case in which $Z()$ is a single-valued function. Verifying that a solution of the system (W.E) does exist, at least under some circumstances, is an important test of the consistency of the model we have developed in this section. The mathematical problem we face is that of determining whether or not a given system of equations has a solution. The economic question behind it is whether or not there exist prices that will clear all markets simultaneously, or, to put it slightly differently, whether or not it is possible for all the agents in the model to optimize simultaneously without "running into each other."

As a first check, we start by counting equations and unknowns. We have $G$ of each ( $G$ unknown prices and as many equations, one for each market), so things seem to be O.K. at first sight. On closer inspection, two complications arise, but they just happen to cancel out. The first one is that we have a redundant price. By the homogeneity of degree 0 of the excess-demand function, only relative prices matter, so there are only $G-1$ prices to be determined. Fortunately, we also have a redundant equation, because Walras's law implies that if $G-1$ markets clear, the $G$ th market will automatically clear as well. Hence, the equality of equations and unknowns has been preserved, but this is neither a necessary condition nor a sufficient condition for the system to have a solution.

To proceed further we will analyze a simple example in some detail. We will consider a two-good economy described by an aggregate excess-demand function, with the properties given in Theorem 3.4, and establish the existence of equilibrium for such an economy in two slightly different ways. The first will be more natural, but the second will turn out to be easier to extend to the general case.

Let us normalize the price vector $p=\left(p_{1}, p_{2}\right)$ so that prices lie on the unit simplex (i.e., so that $p_{1}+p_{2}=1$ ). Abusing notation, we can write the aggregate excess-demand function in the form

$$
Z\left(p_{1}\right)=\left[Z_{1}\left(p_{1}\right), Z_{2}\left(p_{1}\right)\right] \equiv\left[Z_{1}\left(p_{1}, 1-p_{1}\right), Z_{2}\left(p_{1}, 1-p_{1}\right)\right]=Z(p)
$$

Walras's law then requires that

$$
\begin{equation*}
p_{1} Z_{1}\left(p_{1}\right)+\left(1-p_{1}\right) Z_{2}\left(p_{1}\right)=0 \tag{1}
\end{equation*}
$$

for all $p_{1}$. By the unboundedness of excess demand as prices go to zero, we know that

$$
\begin{equation*}
Z_{1}\left(p_{1}\right) \rightarrow \infty \quad \text { as } p_{1} \rightarrow 0 \quad \text { and } \quad Z_{2}\left(p_{1}\right) \rightarrow \infty \quad \text { as } p_{2}=1-p_{1} \rightarrow 0 \tag{2}
\end{equation*}
$$

Fix some $B>0$, and observe that, by (2), there exist numbers $\varepsilon$ and $\delta$ in the interval $(0,1)$, with $\varepsilon<1-\delta$, such that

$$
\begin{align*}
& Z_{1}\left(p_{1}\right) \geq B>0 \forall p_{1} \in(0, \varepsilon)  \tag{3}\\
& Z_{2}\left(p_{1}\right) \geq B \forall p_{1} \in(1-\delta, 1) \tag{4}
\end{align*}
$$

Using Walras's law and (4), we have

$$
0=(1-\delta) Z_{1}(1-\delta)+\delta Z_{2}(1-\delta) \geq(1-\delta) Z_{1}(1-\delta)+\delta B
$$

from where

$$
\begin{equation*}
Z_{1}(1-\delta) \leq \frac{-\delta B}{1-\delta}<0 \tag{5}
\end{equation*}
$$

Using (3) and (5), the intermediate-value theorem implies that there exists some price $p_{1}^{*} \in(\varepsilon, 1-\delta)$ such that $Z_{1}\left(p_{1}^{*}\right)=0$. Hence, $p_{1}^{*} Z_{1}\left(p_{1}^{*}\right)=0$, and Walras's law implies that

$$
0+\left(1-p_{1}^{*}\right) Z_{2}\left(p_{1}^{*}\right)=0 \Rightarrow Z_{2}\left(p_{1}^{*}\right)=0
$$

Hence, there exists an equilibrium for this economy, that is, a price vector $p^{*}=\left(p_{1}^{*}, p_{2}^{*}\right)=\left(p_{1}^{*}, 1-p_{1}^{*}\right)>\underline{0}$ that clears both markets simultaneously.

The main problem in extending this argument to the general case is that we cannot rely on the intermediate-value theorem when we work with an arbitrary number of commodities. A strategy that avoids this difficulty involves transforming the problem in such a way that we can use either the Brouwer or the Kakutani fixed-point theorem (see Section 3(b) in Chapter 5). Both of these theorems, however, apply to continuous functions (or hemicontinuous correspondences) that map a compact and convex set into itself. Hence, it will be difficult to work with the aggregate excess-demand correspondence, because $Z: \Delta \rightarrow \rightarrow \mathbb{R}_{+}^{\mathrm{nG}}$ maps the open unit simplex

$$
\Delta=\left\{p \in \mathbb{R}_{++}^{G} ; \sum_{g=1}^{G} p_{g}=1\right\}
$$

into an unbounded set; recall that $Z()$ is not defined when one of the prices is zero, and it becomes unbounded as we approach such a point. There is, however, a workable alternative that involves constructing an appropriate mapping of the price simplex into itself and then invoking a fixed-point theorem.

Let us see how this can be done in our simple example, where it is easy to sidestep some of the difficulties that arise in the general case. The idea will be to construct a continuous function $F: \Delta \longrightarrow \Delta$ that can be loosely interpreted as a set of instructions for a hypothetical auctioneer to adjust prices iteratively until an equilibrium is attained. We can then picture the auctioneer calling out price vectors and asking each agent how much of each commodity he is willing to purchase/sell at those prices, adding up the
quantities over agents, and determining the excess demand in each case. The price-adjustment function will be constructed so that excess demand will lead to an increase in the good's price, and excess supply to a reduction. Clearly, a fixed point of this mapping will be an equilibrium price vector, for a price vector requiring no further adjustment will be one that makes supply equal to demand in all markets.

This description may be misleading, in that it invites us to picture a process of adjustment over time, eventually converging to equilibrium as eager consumers bid up the prices of scarce commodities and suppliers lower the prices of those goods they cannot sell. In fact, nothing of this sort is implied. We are not claiming that the tâtonnement process described by the function $F$ ( ) will eventually converge to an equilibrium, but only that there exists some $p^{*}$ such that if it is, by chance, called out by the auctioneer, no further adjustment will be needed.

One price-adjustment rule that will work in our example is the following. We define the function $F: \Delta \longrightarrow \Delta$ by

$$
\begin{gather*}
q_{1}=F_{1}\left(p_{1}\right)=\frac{p_{1}+\max \left\{0, Z_{1}\left(p_{1}\right)\right\}}{p_{1}+\max \left\{0, Z_{1}\left(p_{1}\right)\right\}+\left(1-p_{1}\right)+\max \left\{0, Z_{2}\left(p_{1}\right)\right\}} \\
q_{2}=F_{2}\left(p_{1}\right)=1-F_{1}\left(p_{1}\right)=\frac{p_{2}+\max \left\{0, Z_{2}\left(p_{1}\right)\right\}}{p_{1}+\max \left\{0, Z_{1}\left(p_{1}\right)\right\}+p_{2}+\max \left\{0, Z_{2}\left(p_{1}\right)\right\}} \tag{6}
\end{gather*}
$$

Notice that $F()$ maps a price vector $p=\left(p_{1}, p_{2}\right)$ in the open unit simplex into another vector $q$ in the same set. The numerator of each fraction in (6) instructs us to form each new price as follows. First, set

$$
p_{g}^{\prime}=p_{g}+\max \left[0, Z_{g}(p)\right]
$$

That is, if excess demand is negative (i.e., if there is an excess supply) or zero, we leave the price as it is, and if there is an excess demand for good $g$, we increase its price by adding the excess demand to the old price. Division by the expression in the denominator (which is the sum of all the adjusted prices) then renormalizes these prices to "bring them back" into the unit simplex.

Figure 8.6 illustrates the functioning of the price-adjustment scheme. We start with an arbitrary price vector $p$ and suppose that it yields an excess demand for good $1, Z_{1}(p)>0$; then, by Walras's law, $Z_{2}(p)<0$. The auctioneer's rule, $F()$, tells us to add $Z_{1}(p)$ to $p_{1}$ and leave $p_{2}$ as it is. This gives us a new price vector $p^{\prime}$, with $p_{1}{ }^{\prime}=p_{1}+Z_{1}(p)$. However, $p^{\prime}$ is not in the unit simplex. The normalization in $F(p)$ amounts to selecting point $q$ in the figure, which does lie on the unit simplex. The net effect, when we consider the final change in normalized prices $(p \rightarrow q)$, is to decrease $p_{2}$ in response to the

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-369.jpg?height=569&width=889&top_left_y=188&top_left_x=298)

Figure 8.6.

original situation of excess supply and to increase $p_{1}$ in response to the excess demand for good 1.

It is easy to show (see Problem 3.5) that a fixed point of $F()$ is an equilibrium price vector for our two-good economy. Hence, proving the existence of equilibrium for our economy reduce to the problem of showing that the function $F()$ has a fixed point. Notice that $F($ ) maps the open unit simplex $\Delta$ into itself (i.e., we are requiring both prices to be strictly positive, because $Z()$ is not defined otherwise). Because $\Delta$ is not a compact set, we cannot use Brouwer's fixed-point theorem. It is easy, however, to establish the existence of a fixed point using the intermediate-value theorem.

Observe that $F_{1}\left(p_{1}\right)$ will have a fixed point if and only if the equation $F_{1}\left(p_{1}\right)-p_{1}=0$ has a solution. The function $F_{1}()$ is continuous on the interval $(0,1)$, because the continuity of each $Z_{g}()$ implies that of $\max \left\{0, Z_{g}(p)\right\}$, and the denominator of $F_{1}()$ never vanishes. Using (3) and (4), we have, moreover,

$$
\begin{aligned}
F_{1}(\varepsilon)-\varepsilon & =\frac{\varepsilon+\max \left\{0, Z_{1}(\varepsilon)\right\}}{\varepsilon+\max \left\{0, Z_{1}(\varepsilon)\right\}+(1-\varepsilon)+\max \left\{0, Z_{2}(\varepsilon)\right\}}-\varepsilon \\
& =\frac{\varepsilon+Z_{1}(\varepsilon)}{\varepsilon+Z_{1}(\varepsilon)+(1-\varepsilon)}-\varepsilon=\frac{(1-\varepsilon) Z_{1}(\varepsilon)}{1+Z_{1}(\varepsilon)}>0
\end{aligned}
$$

and

$$
\begin{aligned}
F_{1}(1-\delta)-(1-\delta) & =\frac{(1-\delta)+\max \left\{0, Z_{1}(1-\delta)\right\}}{(1-\delta)+\max \left\{0, Z_{1}(1-\delta)\right\}+\delta+\max \left\{0, Z_{2}(1-\delta)\right\}}-(1-\delta) \\
& =\frac{(1-\delta)}{1+Z_{2}(1-\delta)}-(1-\delta)<0
\end{aligned}
$$

By the intermediate-value theorem, there exists some point $p_{1}^{*} \in(\varepsilon, 1-\delta)$ such that $p_{1}^{*}=F_{1}\left(p_{1}^{*}\right)$. This, in turn, implies that

$$
p_{2}^{*}=1-p_{1}^{*}=1-F_{1}\left(p_{1}^{*}\right)=F_{2}\left(p_{1}^{*}\right)
$$

so $p^{*}=\left(p_{1}^{*}, p_{2}^{*}\right)$ is a fixed point of $F()$ and therefore a competitiveequilibrium price vector for our two-good economy.

Problem 3.5. Define a mapping $F: \Delta \longrightarrow \Delta$ by

$$
F(p)=\frac{p_{1}+\max \left[0, Z_{1}(p)\right]+\ldots+p_{G}+\max \left[0, Z_{G}(p)\right]}{\sum_{g=1}^{G}\left(p_{g}+\max \left[0, Z_{g}(p)\right]\right)}
$$

where $Z(p)=Z_{1}(p), \ldots, Z_{G}(p)$ is an aggregate-excess-demand function satisfying Walras's law, $p Z(p)=0$ for all $p$. Show that any fixed point of $F()$ is a competitive-equilibrium price vector. That is, if $p^{*}=F\left(p^{*}\right)>\underline{0}$, then

$$
Z_{g}\left(p^{*}\right) \leq 0 \forall g \text { and } Z_{g}\left(p^{*}\right)=0 \quad \text { whenever } p_{g}^{*}>0
$$

Notice that we allow for the possibility of free goods. A good may be in excess supply in equilibrium $\left(Z_{g}\left(p^{*}\right)<0\right)$, but then its price must be zero.

If we are willing to assume that the excess-demand function $Z(p)$ is continuous on the closed price simplex, the preceding argument can be extended to establish the existence of competitive equilibrium in economies with strictly convex preferences. Unfortunately, this assumption is not reasonable in view of the fact that aggregate demand becomes unbounded in the boundary of this set (i.e., for price vectors with some component equal to zero). We will now prove an existence theorem that does not require such an unreasonable assumption. The idea behind the proof is essentially the same as before, but we have to be careful to avoid "boundary problems." The first step involves defining a correspondence $\mu()$ that does essentially the same thing as the function $F()$ we introduced earlier and using Kakutani's fixed-point theorem to establish the following result.

Lemma 3.6. Let $\mathrm{S}$ be a closed and convex subset of the open unit simplex,

$$
\Delta=\left\{\mathrm{p} \in \mathbb{R}_{++}^{\mathrm{G}} ; \sum_{\mathrm{g}=1}^{\mathrm{G}} \mathrm{p}_{\mathrm{g}}=1\right\}
$$

Let $\mathrm{f}: \mathrm{S} \longrightarrow \mathbb{R}^{\mathrm{C}}$ be a continuous function with the property that

$$
\mathrm{pf}(\mathrm{p}) \leq 0 \forall \mathrm{p} \in \mathrm{S}
$$

Then there exists some $\mathrm{p}^{*} \in \mathrm{S}$ such that

$$
\operatorname{pf}\left(\mathrm{p}^{*}\right) \leq 0 \forall \mathrm{p} \in \mathrm{S}
$$

Proof. Define the correspondence $\mu: S \rightarrow \rightarrow S$ by $^{6}$

$$
\begin{equation*}
\mu(p)=\arg \max _{q \in S} q f(p) \tag{1}
\end{equation*}
$$

Because $f()$ is a continuous function, and $S$ a compact set, $f()$ is bounded in the set. It follows that for given $p, q f(p)$ is a continuous function of $q$, and it attains a maximum in the compact set $S$. Hence $\mu(p)$ is nonempty. Moreover, $\mu()$ is convex-valued, because $\mu(p)$ is the set of maximizers of a quasiconcave function, and it is compact-valued and uhc by the theorem of the maximum, because $q f(p)$ is continuous and the constraint set is compact and "constant" and therefore a trivially continuous correspondence.

Thus, we see that the correspondence $\mu()$ satisfies the conditions of Kakutani's fixed-point theorem (Theorem 3.4 in Chapter 5). Therefore, there exists some point $p^{*} \in S$ such that

$$
p^{*} \in \mu\left(p^{*}\right)=\arg \max _{q \in S} q f\left(p^{*}\right)
$$

This implies that

$$
p^{*} f\left(p^{*}\right) \geq p f\left(p^{*}\right)
$$

for any $p \in S$. But because $p f(p) \leq 0$ for all $p \in S$, we have $p^{*} f\left(p^{*}\right) \leq 0$, and it follows that $p^{*}$ is such that

$$
p f\left(p^{*}\right) \leq 0 \forall p \in S
$$

Notice that in a pure exchange economy with strictly convex preferences (and the other properties we have assumed), the excess-demand mapping will be a function that satisfies the conditions of Lemma 3.6 for any compact subset of the open unit simplex. To establish the existence of equilibrium for such an economy, we apply Lemma 3.6 to a sequence $\left\{S_{n}\right\}$ of sets converging to the closed unit simplex and show that the limit of the resulting sequence $\left\{p_{n}^{*}\right\}$ clears all markets.

Theorem 3.7. Existence of competitive equilibrium in an economy with strictly convex preferences. Let $\mathrm{Z}()$ be the excess-demand function characterizing a pure exchange economy with strictly convex preferences. Assume that $\mathrm{Z}()$ is continuous for all $\mathrm{p} \gg \underline{Q}$, that it satisfies Walras's law,

$$
\begin{equation*}
\mathrm{pZ}(\mathrm{p})=0 \tag{W}
\end{equation*}
$$

and that we have the following boundary condition: Given any sequence $\left(\mathrm{p}_{\mathrm{n}}\right)$, with $\mathrm{p}_{\mathrm{n}} \gg Q$ for all $\mathrm{n}$, that converges to a price vector $\mathrm{p}$, with $\mathrm{pe}^{\mathrm{i}}>0$ for some
$\mathrm{i}$, and some component equal to zero, the sequence $\left\{\mathrm{Z}\left(\mathrm{p}_{\mathrm{n}}, \mathrm{e}\right)\right\}$ is unbounded. Then there exists a price vector $\mathrm{p}^{*} \in \Delta$, with $\mathrm{p}^{*} \gg \underline{0}$, such that $\mathrm{Z}\left(\mathrm{p}^{*}\right)=\underline{0}$.

Proof. Consider the increasing sequence of sets $\left\{S_{n}\right\}$, with

$$
S_{n}=\left\{p \in \Delta ; p_{g} \geq 1 / n \forall g=1, \ldots, G\right\}
$$

for $n \geq G$, and notice that $\cup_{n} S_{n}=\bar{\Delta}$. Because the excess-demand function $Z\left(\right.$ ) is continuous in each $S_{n}$ and satisfies Walras's law, Lemma 3.6 implies that for each $n$ there exists some vector $p_{n}^{*}$ such that

$$
\begin{equation*}
p Z\left(p_{n}^{*}\right) \leq 0 \forall p \in S_{n} \tag{1}
\end{equation*}
$$

Because the sequence $\left\{p_{n}^{*}\right\}$ is contained in the compact set $\bar{\Delta}$, it has a convergent subsequence with limit in $\bar{\Delta}$. To simplify the notation, suppose that $\left\{p_{n}^{*}\right\}$ itself converges, and let $p^{*} \in \bar{\Delta}$ be its limit. Next, consider the sequence $\left\{Z\left(p_{n}^{*}\right)\right\}$. This sequence will be bounded, because (i) $\left\{Z\left(p_{n}^{*}\right)\right\}$ is bounded below (e.g., by $\Sigma_{i=1}^{n} e^{i}$ ) because excess supply cannot be unbounded, and (ii) $p Z\left(p_{n}^{*}\right) \leq 0$ for all $n$ and an arbitrary $p \gg \underline{0}$ in some $S_{n}$, by (1), which implies that $Z\left(p_{n}^{*}\right)$ is also bounded above. Hence, $\left\{Z\left(p_{n}^{*}\right)\right\}$ will also have a convergent subsequence, and we can assume without loss of generality that the sequence itself converges to some point $z^{*}$. The boundedness of $\left\{Z\left(p_{n}^{*}\right)\right\}$ also implies that $p^{*} \gg \underline{0}$, for if $\left\{p_{n}^{*}\right\}$ converged to a price vector with some component equal to zero, $\left\{Z\left(p_{n}^{*}\right)\right\}$ would be unbounded, by the boundary condition. Using this fact and the continuity of $Z()$ in the interior of the price simplex, we conclude that

$$
\begin{equation*}
z^{*}=\lim _{n \rightarrow \infty} Z\left(p_{n}^{*}\right)=Z\left(p^{*}\right) \tag{2}
\end{equation*}
$$

Next, we show that $p z^{*} \leq 0$ for all $p \in \bar{\Delta}$. If $p$ lies in the interior of $\bar{\Delta}$ (i.e., if $p \gg 0$ ), then $p \in S_{n}$ for all sufficiently large $n$, and (1) implies $p Z\left(p_{n}^{*}\right) \leq 0$ for all such $n$. Taking limits of this expression as $n \rightarrow \infty$, we conclude that $p z^{*} \leq 0$. If $p$ is a boundary point of $\bar{\Delta}$, we can find a sequence $\left\{q_{n}\right\} \rightarrow p$, with $q_{n} \in S_{n}$. By (1), $q_{n} Z\left(p_{n}^{*}\right) \leq 0$, and, taking limits, $p z^{*} \leq 0$ also in this case.

Now, $p Z\left(p^{*}\right)=p z^{*} \leq 0$ for all $p \in \bar{\Delta}$ implies that $Z\left(p^{*}\right) \leq \underline{0}$ (e.g., letting $p$ $=(1,0, \ldots, 0)$, we see that $Z_{1}\left(p^{*}\right) \leq 0$, and so on). By Walras's law, moreover, we have $p^{*} Z\left(p^{*}\right)=0$, with $p^{*} \gg \underline{0}$. From this we conclude that $Z\left(p^{*}\right)$ $=\underline{0}$, for if $Z\left(p^{*}\right)$ has any strictly negative components, then $p^{*} Z\left(p^{*}\right)=\Sigma_{g=1}^{G}$ $p_{g}^{*} Z_{g}\left(p^{*}\right)<0$, contradicting Walras's law.

The foregoing result can be easily extended to the case in which preferences are convex, but not strictly so. Problem 3.8 asks the reader to extend Lemma 3.6 to the case of a bounded and uhc correspondence. Given
this result, the proof of the existence theorem goes through essentially unchanged when $Z()$ is a uhc correspondence.

Problem 3.8. Let $S$ be a closed and convex subset of the open unit simplex in $\mathbb{R}^{\mathrm{G}}$, and $\phi: S \rightarrow \rightarrow \mathbb{R}^{\mathrm{G}}$ a uhc and convex-valued correspondence with the following properties:

(i) $\phi()$ is bounded i.e., there exists a bounded set $B$ in $\mathbb{R}^{\mathcal{G}}$ such that $\phi(p) \subseteq B$ for all $p \in S$ ), and

(ii) for all $p \in S$ we have $p z \leq 0$ for every $z \in \phi(p)$.

Show that there exists some $p^{*} \in S$ and $z^{*} \in \phi\left(p^{*}\right)$ such that

$$
p z^{*} \leq 0 \forall p \in S
$$

Hint: Adapt the proof of Lemma 3.6. Define the correspondence $\mu()$ on $B$, and consider the product correspondence $\mu(z) \times \phi(p)$.

## (c) Welfare Properties of Competitive Equilibrium

Having established the existence of competitive equilibrium, we can now investigate its welfare properties. After introducing an appropriate concept of social optimality, known as Pareto efficiency, we will prove two important results on the relationship between Pareto efficiency and competitive equilibrium.

Consider the problem of a hypothetical social planner who must decide between two feasible allocations. Early approaches to this problem assumed that individual utilities could be added to obtain a meaningful measure of social welfare. The planner's problem was then reduced to the maximization of social utility. On the other hand, we have seen that in modern consumer theory, utility is an ordinal concept and cannot be meaningfully added across agents. This makes social-welfare comparisons difficult, for given any two feasible allocations, it is very likely that at least some agents will disagree about which is better. If individual preferences cannot be quantified and weighted somehow, there is no way of answering the question of which state is to be preferred.

In this context, the efficiency criterion proposed by Pareto provides not so much a solution as a way to sidestep the problem. Given two allocations $x$ and $y$, we say that $x$ is Pareto-superior to $y$ if and only if nobody prefers $y$ to $x$ and at least one agent strictly prefers $x$ to $y$. An allocation $x$ is said to be Pareto-efficient (-optimal) if there is no other feasible allocation that is Pareto-superior to it. In this way, we avoid the need to make interpersonal utility comparisons. The catch, of course, is that we can make welfare judgments only in cases in which there is no disagreement. To see how restric-
tive this is, observe that if there is a single dissenting individual who prefers $y$ to $x$ against the unanimous opinion of all others, then $x$ and $y$ are not comparable in the Pareto sense. Notice also that an allocation that gives all resources in the economy to a single agent is Pareto-optimal, because presumably he would object to any attempt to confiscate his wealth.

More formally, we have the following definitions.

Definition 3.9. Pareto dominance and Pareto optimality.

(i) An allocation $x=\left(x^{1}, \ldots, x^{n}\right)$ Pareto-dominates another allocation $y=\left(y^{1}, \ldots\right.$, $\left.y^{n}\right)$ if

$$
\forall i=1, \ldots, n, x^{i} \geq_{i} y^{i} \quad \text { and } \quad \exists k \text { s.th. } x^{k}>_{k} y^{k}
$$

(ii) A feasible allocation $x=\left(x^{1}, \ldots, x^{n}\right)$ is Pareto-optimal if there exists no feasible allocation $y$ that Pareto-dominates it.

That is, an allocation is Pareto-optimal if the available resources cannot be redistributed in a way that would make some agents better off without making others worse off.

The following theorems establish that there is a close connection between competitive equilibrium and Pareto optimality.

Theorem 3.10. First welfare theorem. Consider a competitive exchange economy with strictly monotonic preferences. Then any competitive-equilibrium allocation is Pareto-optimal.

Strict monotonicity can be replaced by a weaker non-satiation assumption. On the other hand, some of the implicit assumptions of the theorem should perhaps be made explicit. They include the absence of externalities, asymmetric information, and market power, and the existence of a complete set of markets. Notice that the theorem does not require convexity of preferences. Equilibrium may not exist without convexity, but if it does, it is Pareto-optimal.

A superficial reading of the theorem may skip over the implicit assumptions and conclude that competitive markets are "superior" and that government intervention can only create inefficiencies. A more careful conclusion is that in the absence of some quite common complications, we can expect competitive markets (if they work as they are supposed to) to yield outcomes that are efficient in Pareto's (rather restrictive) sense of the word. The set of (implicit) assumptions of the theorem, moreover, gives us a convenient list of where to look for possible inefficiencies.

Proof. The proof proceeds by contradiction. Let $x=\left(x^{1}, \ldots, x^{n}\right) \in x(p, e)$ be an allocation corresponding to the equilibrium price vector $p$, and let $z=\left(z^{1}, \ldots, z^{n}\right)$ be a feasible allocation that Pareto-dominates $x$, that is, such that (i) $z^{i} \geq_{i} x^{i}$ for all agents $i$, and (ii) there exists at least one agent $k$ such that $z^{k}>_{k} x^{k}$. Because $z$ is feasible by assumption, we have

$$
\begin{equation*}
\sum_{i=1}^{n} z^{i} \leq \sum_{i=1}^{n} e^{i} \tag{1}
\end{equation*}
$$

where $e^{i}$ is the endowment vector of the $i$ th agent.

We will show that $z$ cannot be a feasible allocation. By definition, the equilibrium allocation $x$ maximizes the utility of each agent subject to the budget constraint. By the strict monotonicity of preferences (or some weaker nonsatiation assumption), the budget constraint will hold with equality for each agent (i.e., $p x^{i}=p e^{i}$ for all $i$ ). Next, observe that if $z^{i}$ was preferred, but $x^{i}$ was chosen, it must be that $z^{i}$ was "too expensive." Moreover, because for some agents $z^{k}$ was strictly preferred to $x^{k}$, it must be that the first bundle was strictly too expensive. That is,

$$
\begin{equation*}
p z^{i} \geq p e^{i} \forall i \quad \text { and } \quad p z^{k}>p e^{k} \quad \text { for some } k \tag{2}
\end{equation*}
$$

Adding up over all agents, we obtain

$$
\sum_{i=1}^{n} p z^{i}>\sum_{i=1}^{n} p e^{i} \Rightarrow p \sum_{i=1}^{n} z^{i}>p \sum_{i=1}^{n} e^{i}
$$

Because $p \gg \underline{0}$, this implies that

$$
\sum_{i=1}^{n} z^{i}>\sum_{i=1}^{n} e^{i}
$$

which contradicts (1). Hence, any allocation that is weakly preferred to a competitive equilibrium by all agents and is strictly preferred by some cannot be feasible.

Our second result says that if preferences are convex, any Pareto-optimal allocation can be supported as a competitive equilibrium given an appropriate redistribution of endowments. The implicit assumptions are the same as for the previous theorem.

Theorem 3.11. Second welfare theorem. Let $\mathrm{x} \in \mathbb{R}_{+}^{n G}$ be a Pareto-optimal allocation for a pure exchange economy. Assume that preferences are con$v e x$, continuous, and strictly monotonic. Then there exists a price vector $\mathrm{p} \in$ $\mathbb{R}_{+}^{\mathrm{G}}$ such that $(\mathrm{p}, \mathrm{x})$ is a competitive equilibrium for the economy, with initial endowments $\mathrm{e}^{\mathrm{i}}=\mathrm{x}^{\mathrm{i}}$ for all $\mathrm{i}^{7}$

Proof.

(i) We observe that if $x^{*}$ is Pareto optimal, then there is no way to redistribute initial resources so as to make everybody better off.

Given the Pareto-optimal allocation $x=\left(x^{1}, \ldots, x^{n}\right)$, define for each agent $i$ the set

$$
P_{i}\left(x^{l}\right)=\left\{y^{i} \in \mathbb{R}_{+}^{G} ; y^{i}>_{\iota} x^{i}\right\}
$$

of bundles that are strictly preferred to $x^{i}$. Summing over all consumers, we obtain the set

$$
P(x)=\sum_{i=1}^{n} P_{i}\left(x^{i}\right)=\left\{z ; z=\sum_{i=1}^{n} y^{i}, \text { with } y^{i} \in P_{i}\left(x^{i}\right) \forall i\right\}
$$

of total-resource vectors that would allow us to make all agents strictly better off than under the allocation $x$. Let

$$
\begin{equation*}
E=\sum_{i=1}^{n} x^{i}=\sum_{i=1}^{n} e^{i} \tag{1}
\end{equation*}
$$

(where the equality follows by the monotonicity of preferences) ${ }^{8}$ denote the total resources of the economy (the aggregate-endowment vector). Because $x$ is Pareto-optimal, there is no redistribution of $E$ that would make all the agents better off. Hence, $E \notin P(x)$.

(ii) We shall use a separating-hyperplane theorem to establish the existence of a vector $p$ that will be a candidate for an equilibrium price vector.

Each $P_{i}\left(x^{i}\right)$ is a convex set, by the convexity of preferences. This implies that $P(x)$ is convex, because it is the sum of convex sets (Theorem 1.4 in Chapter 6). Because $E \notin P(x)$, we can apply a separating-hyperplane theorem (Theorem 1.25 in Chapter 6) to conclude that there is a nonzero vector $p$ in $\mathbb{R}^{\mathfrak{G}}$ such that

$$
\begin{equation*}
p E \leq p z \forall z \in P(x) \tag{2}
\end{equation*}
$$

Interpreting $p$ as a price vector, (2) says that the value of the resources needed to make all agents better off (weakly) exceeds the value of the resources available in this economy, both valued at prices $p$.

We still have to show that $p$ can be interpreted as a price vector and that it will support the allocation $x$ as a competitive equilibrium.

(iii) We will show that $p \geq \underline{0}$, that is, that $p$ can be interpreted as a vector of (nonnegative) prices.

Let $u_{g}$ be the $g$ th unit vector in $\mathbb{R}^{G}$ (i.e., $u_{g}$ has a 1 in the $g$ th coordinate, and 0 's in all others). By monotonicity, adding one unit to the total available amount of any commodity will allow us to make all agents better off (e.g., by assigning each agents $1 / n$ extra unit of the good). Hence, $E+u_{g} \in P(x)$ for all $g$, and it follows by (2) that the value of $E+u_{g}$ exceeds that of $E$. That is,

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-377.jpg?height=599&width=794&top_left_y=191&top_left_x=339)

Figure 8.7.

$$
p E \leq p\left(E+u_{g}\right) \forall g=1, \ldots, G
$$

from where

$$
p\left(E+u_{g}\right)-p E=p u_{g}=p_{g} \geq 0 \forall g
$$

(iv) We will show that any bundle strictly preferred to $x^{i}$ costs strictly more than $x^{i}$ at prices $p$ (i.e., that $z^{l}>_{i} x^{l}$ implies $p z^{l}>p x^{i}$ ). This proves the theorem, because it means that any bundle $z^{i}$ strictly preferred to $x^{i}$ would not be affordable for the agent at prices $p$. In an economy with endowments $e^{i}=x^{i}$, no trade would take place at those prices, and we would have an autarkic equilibrium, with each agent consuming his endowment.

Let $k$ be an arbitrary agent, and $z^{k}$ a consumption bundle such that $z^{k}>_{k} x^{k}$. Then the allocation $\left(x^{1}, \ldots, x^{k-1}, z^{k}, x^{k+1}, \ldots, x^{n}\right)$ differs from $x$ only in agent $k$ 's consumption, but contains enough resources to allow us to make all agents better off than under $x$. Starting from this allocation, we will construct a new allocation $\bar{x}$ by taking a little bit of each good away from agent $k$ and allocating it to the other agents in equal shares. That is,

$$
\begin{gathered}
\bar{x}^{k}=z^{k}-\varepsilon \underline{1} \\
\bar{x}^{i}=x^{i}+\frac{\varepsilon}{n-1} \underline{1} \forall i \neq k
\end{gathered}
$$

where 1 is a vector of 1's, and $\varepsilon$ is a positive real number. Because $z^{k}>_{k} x^{k}$, the continuity of preferences implies that we can choose $\varepsilon$ small enough that agent $k$ still will prefer his new bundle to $x^{k}$. Notice also that for
any $\varepsilon>0$, the rest of the agents will always prefer the new allocation to $x^{t}$, by the strict monotonicity of preferences. Hence, there is some $\varepsilon>0$ such that

$$
\bar{x}^{k}=z^{k}-\varepsilon \underline{1}>_{k} x^{k} \quad \text { and } \quad \bar{x}^{i}=x^{i}+\frac{\varepsilon}{n-1} \underline{1}>_{i} x^{i} \forall i \neq k
$$

Because $\bar{x}$ is strictly preferred to $x$ by all agents (by construction), we have $\sum_{i=1}^{n} \bar{x}^{i} \in P(x)$. By (1) and (2), this implies that

$$
p\left(\sum_{i=1}^{n} \bar{x}^{i}\right) \geq p E=\sum_{i=1}^{n} p x^{i}
$$

Expanding this expression and canceling out identical terms,

$$
p\left(z^{k}-\varepsilon \underline{1}+\sum_{i \neq k}\left[x^{i}+(\varepsilon / n-1) \underline{1}\right]\right) \geq p\left(x^{k}+\sum_{i \neq k} x^{i}\right) \Rightarrow p z^{k} \geq p x^{k}
$$

Because $k$ was arbitrary, a similar result holds for all agents, that is,

$$
\begin{equation*}
z^{i}>_{i} x^{i} \Rightarrow p z^{i} \geq p z^{i} \forall i \tag{3}
\end{equation*}
$$

Finally, we show that the inequality in (3) is a strict inequality. We proceed by contradiction. Suppose $z^{i}>_{i} x^{i}$ and $p z^{i}=p x^{i}$. By the continuity of preferences, we can find some scalar $\lambda<1$ such that $\lambda z^{i}>_{i} x^{i}$. Because $\lambda z^{i}$ has strictly less of all commodities than $z^{i}$, it is cheaper than $z^{i}$, and we have $\lambda p z^{i}<p z^{i}=$ $p x^{i}$. This, however, contradicts (3), for $\lambda z^{i}$ is strictly preferred to $x^{i}$ and strictly cheaper.

This theorem has been used to argue that efficiency and fairness can be separated. The market mechanism guarantees efficient outcomes, but it is "ethically neutral." To achieve fairness, however we may want to define it, all we have to do is redistribute (in a lump-sum manner) wealth in some equitable way and then let the market operate freely. This version of the idea that we can have our cake and eat it too has sometimes been called market socialism.

One implication of the second welfare theorem that can sometimes be of practical interest is that competitive equilibria can be characterized as the solutions of appropriate planning problems. In many cases it is easier to solve these problems than to find the equilibrium allocations by equating supply and demand. In a two-agent economy, for example, we can trace out the contract curve (the set of Pareto-efficient allocations) by solving the problem

$$
\max _{x_{1}, x_{2}} U_{1}\left(x_{1}\right) \text { subject to } U_{2}\left(x_{2}\right) \geq u_{2}
$$

and an appropriate feasibility condition, where we treat $u_{2}$ as a parameter. By assigning different values to $u_{2}$, we trace out the entire contract curve.

The first-order conditions for the problem give us a characterization of the set of Pareto-efficient allocations. Because the equilibrium allocations will be in this set, we may be able to infer some of their qualitative properties without actually solving for them. If we have more than two agents, the following generalization of the foregoing problem will work:

$$
\max _{x}\left\{\sum_{i} \lambda_{i} U_{i}\left(x_{i}\right) \text { s.t. feasibility and } \sum_{i} \lambda_{i}=1\right\}
$$

That is, we maximize a weighted average of the utilities of the agents. By changing the weights $\lambda_{i}$, we can trace out the multidimensional analogue of the contract curve.

Problem 3.12. Consider an island economy populated by a representative individual who lives for two periods and has preferences described by the utility function

$$
\begin{equation*}
U(c, x)=\ln c+\beta \ln x \tag{1}
\end{equation*}
$$

where $c$ and $x$ are first- and second-period consumptions. In period 1 , the individual has an endowment of $e$ units of a homogeneous consumption/capital good. He consumes part of it and uses the rest $(k)$ as input for a production technology of the form $y=k^{\alpha}$, with $\alpha<1$. Hence, the consumption-possibilities schedule for the economy is of the form

$$
\begin{equation*}
x \leq k^{\alpha}=(e-c)^{\alpha} \tag{2}
\end{equation*}
$$

(i) Draw the consumption-possibilities frontier and indifference curves on the $(x$, c) plane. Where is the optimum? Solve the planning problem

$$
\begin{equation*}
\max _{c, x}\left\{\ln c+\beta \ln x \text { subject to }(e-c)^{\alpha}-x \geq 0\right\} \tag{P.1}
\end{equation*}
$$

Write the first-order conditions. Is the constraint binding? Why? Or why not? Solve for the optimal values of $c$ and $k=e-c$. (Don't worry about the secondorder conditions. They hold.)

(ii) Next, consider a competitive version of the same economy. The agent now owns all the shares of a competitive firm that has access to the same technology as before, and he can lend part of his endowment to the firm, which maximizes profits, taking as given the market interest factor $R=1+r$ (capital depreciates completely upon use), and then distributes its profits to the shareholder. We shall verify that the competitive allocation coincides with the planning optimum.

Solve the firm's profit-maximization problem,

$$
\begin{equation*}
\max _{k} \pi=k^{\alpha}-R k \tag{P.F}
\end{equation*}
$$

and write the firm's maximized profit as a function of $k$.

Next, write the first-order conditions for the household's utilitymaximization problem,

$$
\begin{equation*}
\max _{s} v(s)=\ln (e-s)+\beta \ln (s R+\pi) \tag{P.H}
\end{equation*}
$$

(the agent takes as given both the market interest rate and the firm's profits), and solve for the optimal levels of saving and consumption.

Finally, in equilibrium the desired savings of the household must be the same as the desired level of capital input by the firm (i.e., $s=k$ ). Solve for the equilibrium values of saving/investment and consumption. They should be the same as in the first part of the problem.

## 4. Games in Normal Form and Nash Equilibrium

The model analyzed in the preceding section assumed that the actions taken by each of our competitive consumers affected other agents only through the impersonal channel of market prices, which determined each agent's consumption opportunities. In many situations of interest, the interdependence between the agents involved is much more direct, with individual actions having a perceptible effect on others' payoffs. In this section we will develop a rather general framework for analysis of games involving a set of rational agents and an appropriate concept of equilibrium due to Nash. Our main purpose is not to provide a systematic introduction to game theory, but to introduce a rather general conceptual framework that will be appropriate for thinking about the "equilibrium problem" in models in which agents interact strategically.

The word "game" evokes a situation in which a number of players engage in some sort of competition, behaving in accordance with certain rules. The actions of the players (along with an element of chance, in most cases) jointly determine the outcome of the game, from which the players derive some sort of payoff, monetary or otherwise. To describe such a game, we need to specify the actions or strategies available to each player and his preferences concerning the outcome of the game. Formally, we have the following definition:

Definition 4.1. Game in normal form. A game in normal form is an $n$-tuple of the form

$$
\Gamma=\left\{\left(U_{i}, A_{i}\right), i=1, \ldots, n\right\}
$$

where $A_{i}$ is a nonempty set, known as the action space or strategy space for player $i$, and $U_{i}$ is a real-valued function, $U_{i}: A_{1} \times A_{2} \times \ldots \times A_{n} \longrightarrow \mathbb{R}$, known as the payoff function for agent $i$.

That is, we have a set $N=\{1, \ldots, n\}$ of players; each one of them is described by his preferences, represented by a payoff function $U_{i}($ ), and by his set $A_{i}$ of available actions. We typically identify the set $A_{i}$ of actions available to the $i$ th agent with a subset of $\mathbb{R}^{\mathrm{m}}$. An element $a_{i}$ of $A_{i}$ is called an action or strategy for agent $i$. The Cartesian product $A=A_{1} \times A_{2} \times \ldots \times A_{n}$ is the action space of the game. An element $a$ of $A$, called an action or strategy profile, is a vector $a=\left(a_{1}, \ldots, a_{n}\right)$ in $\mathbb{R}^{\mathrm{mn}}$ that specifies the strategies chosen by the different players. The actions of all players jointly determine the result of the game and the payoff to each agent, $U_{i}(a)=U_{i}\left(a_{1}, \ldots, a_{n}\right)$, which depends not only on his actions but also on those of all the other agents. For convenience, we will sometimes partition an action profile into two components:

$$
a=\left(a_{i} ; a_{-i}\right), \quad \text { where } a_{-i}=\left(a_{1}, \ldots, a_{i-1}, a_{i+1}, \ldots, a_{n}\right)
$$

Thus, $a_{-i}$ provides us a compact way to refer to "everybody else's" actions.

We now introduce a concept of equilibrium for games in normal form that requires both individual rationality and mutual compatibility among the choices of the different agents.

Definition 4.2. Nash equilibrium. An action profile $a^{*}=\left(a_{1}^{*}, \ldots, a_{n}^{*}\right)$ is a Nash equilibrium if it is feasible (i.e., $a \in A$ ) and if each player's action is a best response to the joint actions of all the other players. That is,

$$
\begin{equation*}
a_{i}^{*} \in \arg \max _{a_{i} \in A_{i}} U_{i}\left(a_{i} ; a_{-i}^{*}\right) \forall i=1, \ldots, n \tag{N}
\end{equation*}
$$

That is, given that other agents play $a_{-i}^{*}$, there is no incentive for the $i$ th player to deviate unilaterally from the equilibrium profile $a^{*}$.

Notice that this definition subsumes both the individual-decision problem and the equilibrium problem. We require that each player $i$ behave as if he is solving a constrained optimization problem, given by $(N)$, in which the actions of the other agents are taken as given. But $(\mathrm{N})$ says more than that: It tells us that this must be true for all agents simultaneously, or that the actions of all the agents are mutually best responses to one another. Loosely, in equilibrium, all agents optimize at the same time.

To establish the existence of Nash equilibrium, it will be convenient to "separate" the two subproblems. We will first describe the behavior of each individual agent through a best-response mapping and then impose a consistency requirement on their joint choices. In this manner, establishing the existence of Nash equilibrium will be reduced to the familiar mathematical problem of showing that a given correspondence has a fixed point.

An action $a_{i}^{*}$ is said to be a best response by player $i$ to actions $a_{-i}$ by the other players if it maximizes agent $i$ 's payoff, given $a_{-i}$. By considering an
agent's best response to all possible combinations of actions of his rivals, we can construct his best-response mapping, $\Phi_{i}: A_{-i} \rightarrow A_{i}$, with

$$
\Psi_{i}\left(a_{-i}\right)=\arg \max _{a_{i} \in A_{i}} U_{i}\left(a_{i} ; a_{-i}\right)
$$

Notice that $\Psi_{i}()$ is analogous to a demand correspondence, except that we now get the set of optimal choices for agent $i$ as a function of the other agents' actions, rather than prices.

Taking the Cartesian product of the best-response mappings for the individual players, we obtain the best-response mapping for the game, $\Psi: A \rightarrow \rightarrow A$, defined by

$$
\Psi(a)=\Psi_{1}\left(a_{-1}\right) \times \Psi_{2}\left(a_{-2}\right) \times \ldots \times \Psi_{n}\left(a_{-n}\right)
$$

We can now redefine a Nash equilibrium as a fixed point of the correspondence $\Psi\left(\right.$ ). Notice that if $a^{*} \in \Psi\left(a^{*}\right)$, then we have

$$
a_{i}^{*} \in \Psi_{i}\left(a_{-i}^{*}\right)=\arg \max _{a_{i} \in A_{i}} U_{i}\left(a_{i} ; a_{-i}^{*}\right) \quad \text { or } \quad U\left(a_{i}^{*} ; a_{-i}^{*}\right) \geq U\left(a_{i} ; a_{-i}^{*}\right) \forall a_{i} \in A_{i}
$$

and for all $i=1,2, \ldots, n$. Hence, $a^{*}$ is indeed a Nash equilibrium (i.e., an action profile such that each player's action is a best response to the actions of the other players).

The proof of the following theorem is now straightforward. It suffices to verify that the best-response mapping for the game satisfies the conditions of Kakutani's fixed-point theorem.

Theorem 4.3. Existence of Nash equilibrium. Let $\Gamma=\left\{\left(\mathrm{U}_{\mathrm{i}}, \mathrm{A}_{\mathrm{i}}\right), \mathrm{i}=1, \ldots, \mathrm{n}\right\}$ be a game in normal form, and assume that

(i) the action space for each player $\mathbf{A}_{\mathrm{i}}$ is a nonempty, compact, and convex subset of $\mathbb{R}^{m}$, and

(ii) the payoff functions $\mathrm{U}_{\mathrm{i}}: \mathrm{A} \longrightarrow \mathbb{R}$ are continuous and quasiconcave in $\mathrm{a}_{\mathrm{i}}$ for given $\mathrm{a}_{-}$.

Then the game $\Gamma$ has at least one Nash equilibrium. That is, there exists some $\mathrm{a}^{*} \in$ A such that $\mathrm{a}^{*} \in \Psi\left(\mathrm{a}^{*}\right)$.

Proof. We have seen that we can define a Nash equilibrium as a fixed point of the best-response correspondence for the game, $\Psi()$. Hence, all we have to do is show that $\Psi$ ( ) satisfies the conditions for Kakutani's theorem, namely, that $\Psi()$ is uhc, nonempty, and compact- and convex-valued, and that $A$ is compact and convex.

First, notice that $A=A_{1} \times A_{2} \times \ldots \times A_{n}$ is compact and convex because it is the Cartesian product of compact and convex sets. Next, consider the bestresponse correspondence for agent $i$,

$$
\Psi_{i}\left(a_{-i}\right)=\arg \max _{a_{i} \in A_{i}} U_{i}\left(a_{i} ; a_{-i}\right)
$$

Because $A_{i}$ is a compact set, and $U_{i}()$ a continuous function, $\Psi_{i}\left(a_{-i}\right)$ is nonempty by the extreme-value theorem. Moreover,

$$
\Psi_{i}\left(a_{-i}\right)=A_{i} \cap\left\{b_{i} ; \mathrm{U}_{\mathrm{i}}\left(b_{i} ; a_{-i}\right) \geq \max _{a_{i} \in A_{i}} U_{i}\left(a_{i} ; a_{-i}\right)\right\}
$$

is the intersection of two convex sets, $A_{i}$ and an upper contour set of the quasiconcave function $U_{i}\left(\cdot ; a_{-i}\right)$, and is therefore convex itself. Hence, $\Psi_{i}()$ is convex-valued. Finally, $\Psi_{i}()$ is uhc and compact-valued, by the theorem of the maximum (because the constraint correspondence is compact-valued and "constant" and therefore continuous).

The correspondence $\Psi(a)$ is defined as the Cartesian product of the individual best-response mappings and therefore inherits the required properties from them. Hence, the conditions of Kakutani's theorem are satisfied, and it follows that $\Psi\left(\right.$ ) has/a fixed point $a^{*}$ in $A$.

Debreu (1983a) has proved an extension of Nash's theorem for the case in which the action space for each player is given by a continuous and convex-valued correspondence $A_{i}=\Gamma_{i}\left(a_{-i}\right)$ of the actions of the other players. This result can be used to establish the existence of competitive equilibrium in an economy like the one analyzed in Section 3. For this, we consider a game played by $n+1$ agents: our $n$ price-taking consumers and a fictional agent we will call the Walrasian auctioneer. Traders choose consumption bundles in order to maximize their utility within their budget sets, taking prices as given. The auctioneer is assumed to set prices so as to maximize the value of excess demand $p Z$, taking the actions of all traders (i.e., the vector $Z$ ) as given. It is easy to show that the equilibrium for this game is a competitive equilibrium in the sense defined in Section 3.

Problem 4.4. Cournot duopoly. Two firms compete in the market for a homogeneous good. The inverse demand function, which gives the price that consumers are willing to pay as a function of the total output of the good, is of the form

$$
\begin{equation*}
P\left(q_{1}+q_{2}\right)=\theta-q_{1}-q_{2} \tag{1}
\end{equation*}
$$

where $\theta>0$ is a given parameter, and $q_{i}$ is the level of output of the $i$ th firm.

Each firm maximizes its profits, taking as given the function (1) and the output level of its competitor. For example, firm 1 solves

$$
\begin{equation*}
\max _{q_{1}} P\left(q_{1}+q_{2}\right) q_{1}-c_{1} q_{1} \tag{2}
\end{equation*}
$$

where $c_{1}$ is its (constant) marginal cost, treating $q_{2}$ as a given constant.
(i) Solve firm 1's problem for its reaction function, that is, a function of the form $q_{1}=\phi_{1}\left(q_{2} ; c_{1}, \theta\right)$ that will give the optimal level of output as a function of its rival's output and the parameters $\left(c_{1}, \theta\right)$.

(ii) Firm 2's reaction function will have the same form as the one you have just derived. In a Nash equilibrium, each firm maximizes its profit, taking as given the other's output level. To find the equilibrium, we solve the system

$$
\begin{equation*}
q_{1}^{*}=\phi_{1}\left(q_{2}^{*} ; c_{1}, \theta\right), \quad q_{2}^{*}=\phi_{2}\left(q_{1}^{*} ; c_{2}, \theta\right) \tag{3}
\end{equation*}
$$

Draw the two reaction functions (their intersection corresponds to the equilibrium). Solve (3) explicitly to obtain the solution mapping for the model,

$$
q^{*}=\left(q_{1}^{*}, q_{2}^{*}\right)=\Psi\left(\theta, c_{1}, c_{2}\right)
$$

What conditions must be imposed on the parameters for the system to have an interior solution (i.e., one in which both firms produce)? Analyze, graphically and analytically, the effect of changes in $\theta$ and $c_{1}$ on equilibrium output levels.

(iii) Compute the equilibrium price and industry output and the equilibrium profit of each firm.

Problem 4.5. Stackelberg duopoly. We will now analyze a market much like the one described in the preceding problem, but in which the timing of actions is slightly different. Instead of assuming that both firms move simultaneously, we now assume that firm 1 moves first. This gives firm 1 a strategic advantage: Because it knows how its rival will behave, it can maximize its own profits, taking as given firm 2's reaction function. Firm 2 then observes firm 1's output choice and behaves accordingly. Solve for the equilibrium of this game, and compare it to the Cournot equilibrium analyzed in Problem 4.4.

## 5. Some Useful Models of Imperfect Competition

In this section we ask the reader to work through the details of two simple models of general equilibrium with imperfect competition. The first model, which builds on the work of Dixit and Stiglitz (1977) and Ethier (1982), formalizes the idea that increasing specialization, as measured by the number of differentiated intermediate goods available, yields efficiency gains that appear as external economies to firms. Different versions of this model have been used by Romer (1987) and Grossman and Helpman (1991), among other authors, as building blocks for models in which growth is fueled by endogenous investment in research-and-development (R\&D) activities
that lead to the development of new product varieties. In Chapter 13 we will analyze one such endogenous growth model.

The second model, based on the work of Dixit and Norman (1980, ch. 9), analyzes a two-good economy in which one sector is imperfectly competitive because of the existence of fixed entry costs. The equilibrium involves two sources of inefficiency: Excess entry leads to the duplication of production facilities and high unit costs, and the existence of market power in one sector distorts relative prices and hence consumer choices. Because in this context an increase in market size will mitigate both types of distortions, the model can be used to illustrate some of the potential advantages of economic integration.

## (a) Increasing Returns to Specialization in a Dixit-Stiglitz Model of Monopolistic Competition

Economists have long argued that an increase in the degree of specialization can increase efficiency. This idea, which goes back to Smith (1961), Marshall (1961), and Young (1928), has recently been revived in both the trade and growth literatures. To formalize it, we shall now develop a version of the Dixit-Stiglitz-Ethier model of monopolistic competition in which there are fixed setup costs in the production of (differentiated) intermediate goods.

Consider an economy in which there are two types of goods, a homogeneous consumption good and a continuum of measure $n$ of differentiated intermediate products $x(s)$, with $0 \leq s \leq n$. The final good $(Y)$ is produced in a competitive industry by assembling intermediate inputs using a constantelasticity-of-substitution production function, ${ }^{9}$

$$
\begin{equation*}
Y=\left(\int_{0}^{n} x_{s}^{\alpha} d s\right)^{1 / \alpha}, \quad \text { where } 0<\alpha<1 \tag{1}
\end{equation*}
$$

and the differentiated components are produced by identical monopolistically competitive firms using labor $(L)$ as an input and a production technology that involves constant marginal costs and decreasing average costs due to a fixed setup cost $(c)$ measured in labor units:

$$
\begin{equation*}
L_{s}=x_{s}+c \tag{2}
\end{equation*}
$$

where $L_{s}$ is the amount of labor required to produce $x_{s}$ units of any intermediate good.

Let us start by observing that the foregoing specification of technology captures Smith's idea that there are increasing returns to specialization. To see this, let $L_{x}$ be the total amount of "variable labor" employed in the production of components. Because all components enter symmetrically in the production function for final goods and are themselves produced using the
same technology, final output will be produced using the same quantity of each input, given by $x=L_{x} / n$. Substituting this expression into (1), final output is given by

$$
\begin{equation*}
\quad Y=\left(\int_{0}^{n} x^{\alpha} d s\right)^{1 / \alpha}=n^{1 / \alpha} x=n^{(1 / \alpha)-1} L_{x} \tag{3}
\end{equation*}
$$

Hence, if the elasticity of substitution among components is low enough (in particular, if $\alpha<1$ ), final output will be an increasing function of the number of component varieties for a given amount of (variable) labor input.

It remains to determine the equilibrium number of product varieties. In this section we assume that entry is limited by a fixed setup cost, but in a later chapter we will want to allow $n$ to grow over time as a result of R\&D investment. Hence, it will be convenient to start by characterizing a "pseudoequilibrium" in which the number of product varieties $(n)$ and the total "variable labor" $\left(L_{x}\right)$ are taken as given. Profit levels and wage rates in such a situation will then give us an indication of the incentive either to directly set up production of a new component or, in a more dynamic context, to invest in R\&D.

Problems 5.1 and 5.2 ask the reader to characterize the optimal behaviors of component producers and final-goods producers.

Problem 5.1. Consider first the behavior of final-goods producers. Although firm size is indeterminate with constant returns and perfect competition, each firm minimizes the cost of producing its desired level of output $y$, taking as given the prices $\mathbf{p}=\{p(s) ; 0 \leq s \leq n\}$ of the different inputs $x(s)$. That is, each firm solves

$$
\min _{x_{s} ; s \in[0, n]} \int_{0}^{n} p_{s} x_{s} d s \text { s.t. } y=\left(\int_{0}^{n} x_{s}^{\alpha} d s\right)^{1 / \alpha}
$$

Using the first-order conditions for this problem, derive the conditional demand for intermediate goods as a function of final output and input prices and the firm's unit-cost function (see Problem 1.21 in Chapter 7). Verify that after aggregating over all final producers, the market demand function is of the form

$$
\begin{equation*}
x_{s}(\mathbf{p}, Y)=\phi p_{s}^{-\varepsilon}, \quad \text { where } \phi=\frac{Y}{\left(\int_{0}^{n} p_{t}^{1-\varepsilon} d t\right)^{1 / \alpha}} \tag{4}
\end{equation*}
$$

and $Y$ is the aggregate output of final goods, with unit costs being given by

$$
\begin{equation*}
c(\mathbf{p})=\left(\int_{0}^{n} p_{s}^{1-\varepsilon} d s\right)^{1 /(1-\varepsilon)} \tag{5}
\end{equation*}
$$

Problem 5.2. Taking the market demand schedule (4), the wage rate (w), and the prices set by its competitors as given, each component producer maximizes operating profits, given by

$$
\begin{equation*}
\Pi_{s}=p_{s} x_{s}-w x_{s}=\phi\left(p_{s}^{1-\varepsilon}-w p_{s}^{-\varepsilon}\right) \tag{6}
\end{equation*}
$$

Solve this problem for the firm's optimal output level and the implied level of profits.

To characterize the equilibrium, let us take as given, for the moment, the number of component varieties $n$ and the total amount of "variable labor" employed in the intermediate sector, $L_{x}$, and consider a symmetric equilibrium in which all component producers set the same price $(p)$ and produce the same output $(x)$. Problem 5.3 asks the reader to solve for profits and wages in such a "pseudoequilibrium."

Problem 5.3. In equilibrium, free entry will ensure that profits will be zero in the perfectly competitive final-goods sector. Hence, the price of final output, which we will normalize to 1 , must be equal to its unit cost. Using this condition, together with previous results, show that equilibrium wages and profits are given by

$$
\begin{equation*}
\pi=\frac{(1-\alpha) Y}{n} \text { and } w=\frac{\alpha Y}{n l_{x}} \tag{7}
\end{equation*}
$$

where $l_{x}=L_{x} / n$ is "variable employment" in a representative component producer. Hence, output is divided between wages and profits. Profits per firm decrease with the number of competitors $n$ and with the difficulty of substituting one input for another, measured by $\alpha$.

We can now solve for the equilibrium number of product varieties in a free-entry equilibrium.

Problem 5.4. We have assumed that anybody willing to pay a fixed cost of $c$ units of labor can set up shop and start producing a new component variety. Compute the total demand for labor, and set it equal to the fixed labor supply $L$. Using this condition and the assumption of free entry into the sector, solve for the equilibrium number of firms $n^{*}$ as a function of $L$ and $c$, and use (3) to derive a reduced-form aggregateproduction function giving output per capita as a function of the same variables. Verify that this function exhibits increasing returns to labor when $\alpha<1$.

## (b) Fixed Costs, Market Power, and Excess Entry in a Cournot Model

Consider an economy populated by $L$ identical individuals, with preferences over two consumption goods described by a utility function of the form

$$
\begin{equation*}
U(c, x)=\alpha \ln x+(1-\alpha) \ln y \tag{1}
\end{equation*}
$$

We take good $y$ as the numeraire and normalize its price to 1. Agents are endowed with a unit of labor time each, and they own shares in firms. They maximize (1) subject to the budget constraint

$$
\begin{equation*}
p x+y=I \tag{2}
\end{equation*}
$$

where $I$ denotes total (wage plus other) income, and $p$ is the price of good $x$. It is easily shown that the assumed preferences imply constant expenditure shares equal to each good's (normalized) weight in the utility function. Hence, consumer optimization implies

$$
\begin{equation*}
p x=\alpha I \text { and } y=(1-\alpha) I \tag{3}
\end{equation*}
$$

We assume that labor is the only factor of production and that the production technologies for $x$ and $y$ are of the form

$$
\begin{equation*}
L_{x}=x+c \text { and } L_{y}=y \tag{4}
\end{equation*}
$$

where $L_{x}$ denotes the amount of labor required to produce $x$ units of the good, and $c$ is a fixed setup cost (in labor units). Hence, marginal costs are constant and equal for the two commodities, but good $x$ is produced at decreasing average cost.

The planning optimum for this economy is easily characterized. To minimize fixed costs, all production of good $x$ should take place in a single plant. The remaining labor $(L-c)$ should be allocated to the production of the two goods in proportion to their weights in the utility function. The first-best per-capita consumption-and-production bundle (FB) corresponds, as shown in Figure 8.8, to a point of tangency between an indifference curve of the representative consumer and a per-capita production-possibilities frontier (PPF) with unit slope (because the marginal costs of both goods are the same).

This allocation, however, will not be attained in equilibrium. Notice that the existence of fixed costs implies that the $x$ sector cannot be competitive. We will assume that firms in this sector compete in a Cournot fashion, taking as given the quantities produced by their rivals, and that free entry drives equilibrium profits to zero. Noncompetitive producers will charge prices in

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-389.jpg?height=594&width=781&top_left_y=189&top_left_x=343)

Figure 8.8. Optimal allocation.

excess of marginal costs, implying that equilibrium $x$ production will be suboptimally low. Free entry will, of course, limit the equilibrium markup, but it also will generate a second inefficiency, as any increase in the number of firms will involve a fixed cost that will reduce overall production possibilities. Problem 5.5 asks the reader to solve for a symmetric free-entry equilibrium. Problem 5.6 then compares this equilibrium with the planning optimum characterized earlier and analyzes the effect of an increase in market size.

Problem 5.5. Consider a free-entry equilibrium in which sector $y$ is competitive, and $x$ producers compete à la Cournot. Zero profits in the competitive sector imply that the salary will be equal to the price of $y$, which we have normalized to 1 . Let us focus on the market for $x$ and characterize a symmetric Cournot equilibrium. Aggregating over consumers, the total demand for $x$ can be written

$$
X=\frac{\alpha Q}{p}
$$

where $Q=L I$ is aggregate income. Inverting this function, and assuming that there are $n+1$ producers in this sector, we can write the inverse demand schedule perceived by a representative producer $i$ in the form

$$
\begin{equation*}
p\left(x_{i}\right)=\frac{\alpha Q}{n x_{-i}+x_{i}} \tag{5}
\end{equation*}
$$

where $x_{i}$ denotes his own output level, and $x_{-i}$ that of an arbitrary competitor.

Producer $i$ maximizes profits,

$$
\Pi_{i}=p\left(x_{i}\right) x_{i}-x_{i}-c=\frac{\alpha Q x_{i}}{n x_{-i}+x_{i}}-x_{i}-c
$$

taking as given the salary $(w=1)$, aggregate income $Q$, and the outputs of his $n$ competitors $\left(x_{-i}\right)$. Using the first-order conditions for this problem, derive a reaction function giving optimal output for the $i$ th producer as a function of those of his rivals. In a symmetric equilibrium, all firms will choose the same output level. Set $x_{i}=x_{-i} \equiv x$, and find (i) the equilibrium level of output, (ii) the equilibrium price of good $x$, and (iii) the equilibrium level of firm profits - all written as functions of aggregate income and the number of firms in the sector.

Now, in a free-entry equilibrium profits are zero, and it follows that aggregate income is given by

$$
\begin{equation*}
Q=L w=L \tag{10}
\end{equation*}
$$

Using this last expression and setting $\pi=0$, find (i) the equilibrium number of $x$ producers (ignoring integer constraints), (ii) the equilibrium price of good $x$, (iii) total $x$ output, (iv) total fixed costs, and (v) total $y$ output - all written as functions of "market size," measured by $\alpha L$, and the fixed cost $c$.

Problem 5.6. Using a diagram similar to Figure 8.8, compare the equilibrium per-capita allocation and the social optimum, illustrating the two sources of inefficiency we have identified. Using your results from Problem 5.5 , discuss how things change as "market size" (measured by $L$ ) increases.

## Bibliography

Arrow, K. 1983a. Economic Equilibrium. In: Collected Papers of Kenneth J. Arrow. Vol. 2: General Equilibrium. Harvard University Press.

Arrow, K. 1983b. An Extension of the Basic Theorems of Classical Welfare Economics. In: Collected Papers of Kenneth J. Arrow. Vol. 2: General Equilibrium. Harvard University Press.

Arrow, K. 1983c. General Economic Equilibrium: Purpose, Analytic Techniques, Collective Choice. In: Collected Papers of Kenneth J. Arrow. Vol. 2: General Equilibrium. Harvard University Press.

Arrow, K. 1989. Economic Theory and the Hypothesis of Rationality. In: The New Palgrave: Utility and Probability, ed. J. Eatwell, M. Milgate, and P. Newman. New York: Norton.

Arrow, K., and Debreu, G. 1983. Existence of an Equilibrium for a Competitive Economy. In: Collected Papers of Kenneth J. Arrow. Vol. 2: General Equilibrium. Harvard University Press.

Arrow, K., and Hahn, F. 1971. General Competitive Analysis. Advanced Textbooks in Economics, Vol. 12, ed. C. Bliss, and M. Intriligator. Amsterdam: North Holland.

Blad, M., and Keiding, H. 1990. Microeconomics. Institutions, Equilibrium and Optimality. Amsterdam: North Holland.

Border, K. 1989. Fixed Point Theorems with Applications to Economics and Game Theory. Cambridge University Press.

Deaton, A., and Muellbauer, J. 1986. Economics and Consumer Behaviour. Cambridge University Press.

Debreu, G. 1959. Theory of Value. An Axiomatic Analysis of Economic Equilibrium. Cowles Foundation Monographs, no. 17. New Haven, CT: Cowles.

Debreu, G. 1976. Economic Theory in the Mathematical Mode. American Economic Review 66:280-7.

Debreu, G. 1982. Existence of Competitive Equilibrium. In: Handbook of Mathematical Economics, Vol. 2, ed. K. Arrow and M. Intriligator, pp. 697-743. Amsterdam: North Holland.

Debreu, G. 1983a. A Social Equilibrium Existence Theorem. In: Mathematical Economics: Twenty Papers of Gerard Debreu, Econometric Society Monographs, no. 4. Cambridge University Press. (Originally published 1952.)

Debreu, G. 1983b. Representation of a Preference Ordering by a Numerical Function. In: Mathematical Economics: Twenty Papers of Gerard Debreu, Econometric Society Monographs, no. 4. Cambridge University Press. (Originally published 1954.)

Dixit, A., and Norman, V. 1980. Theory of International Trade. Cambridge University Press.

Dixit, A., and Stiglitz, J. 1977. Monopolistic Competition and Optimum Product Diversity. American Economic Review 67:297-308.

Ethier, W. 1982. National and International Returns to Scale in the Modern Theory of International Trade. American Economic Review 72:389-405.

Fishburn, P. 1989. Representation of Preferences. In: The New Palgrave: Utility and Probability, ed. J. Eatwell, M. Milgate, and P. Newman. New York: Norton.

Friedman, J. 1986. Game Theory with Applications to Economics. Oxford University Press.

Grossman, G., and Helpman, E. 1991. Innovation and Growth in the Global Economy. Massachusetts Institute of Technology Press.

Hildenbrand, W. 1974. Core and Equilibria of a Large Economy. Princeton University Press.

Hildenbrand, W., and Kirman, A. 1976. Introduction to Equilibrium Analysis. Variations on Themes by Edgeworth and Walras. Amsterdam: North Holland.

Krepps, D. 1990. A Course in Microeconomic Theory. Princeton University Press.

Malinvaud, E. 1985. Lectures on Microeconomic Theory. Amsterdam: North Holland.

Marshall, A. 1961. Principles of Economics, 9th ed., with annotations by C. Guillebaud. London: Macmillan.

Mas-Colell, A. 1985. The Theory of General Economic Equilibrium: $A$ Differentiable Approach. Econometric Society Monographs, no. 9. Cambridge University Press.

Mas-Colell, A., Whinston, M., and Green, J. 1995. Microeconomic Theory. Oxford University Press.

Nash, J. 1950. Equilibrium Points in $N$-Person Games. Proceedings of the National Academy of Sciences, USA 36:48-9.

Nikaido, H. 1972. Introduction to Sets and Mappings in Modern Economics. Amsterdam: North Holland.

Romer, P. 1987. Growth Based on Increasing Returns due to Specialization. American Economic Review, Papers and Proceedings 77:56-62.

Sen, A. 1989. Rational Behaviour. In: The New Palgrave: Utility and Probability, ed. J. Eatwell, M. Milgate, and P. Newman. New York: Norton.

Smith, A. 1961. The Wealth of Nations. London: University Paperbacks. (Originally published 1776.$)$

Varian, H. 1984. Microeconomic Analysis, 2nd ed. New York: Norton.

Young, A. 1928. Increasing Returns and Economic Progress. Economic Journal

38:527-42.

## Notes

1 For many purposes, we can make do with a weaker property, called acyclicity. This requires that the strict preference relation contain no cycles, i.e., that there exist no collection $x_{1}, \ldots, x_{n}$ of alternatives such that $x_{1}>x_{2}>\ldots>x_{n}$ and $x_{n}>x_{1}$. This is both necessary and sufficient for the existence of a nonempty set of undominated alternatives in any finite collection of objects.

2 See Section 9 of Chapter 2 for a discussion of connectedness and some useful results.

3 The reader should refer to Section 11 of Chapter 2 and Section 2(a) of Chapter 7 for a discussion of the continuity of correspondences and the theorem of the maximum.

4 After Léon Walras, the first author who tried to develop a rigorous theory of general equilibrium for a competitive economy.

5 In fact, this has to be generalized a bit. We observe that some goods (e.g., air) are free $\left(p_{g}=0\right)$, and this is compatible with their being in excess supply. To account for this, we can write the equilibrium condition as

$$
p \geq \underline{0}, \quad Z_{g}(p) \leq 0 \quad \text { and } \quad Z_{g}(p)=0 \quad \text { if } p_{g}>0
$$

We will ignore this complication from now on.

6 Notice that if we interpret $f(p)$ as an excess-demand function, the adjustment rule $\mu()$ instructs us to find a price vector $q$ that will maximize the value of the excess-demand vector $f(p)$. This involves setting $p_{g}=0$ for all $g$, such that $f_{g}(p)<0$ and it entails "high" prices for those goods with a positive excess demand. Notice that if $f(p)=\underline{0}$, then any price vector $q$ will do, because then $q f(p)=0$ for all $q$. Hence, if $f(p)=\underline{0}$, we have $p \in$ $\mu(p)$, and $p$ will be a fixed point of $\mu()$.

7 This may sound a bit funny, particularly after you look at the proof and see that no trade takes place in equilibrium. Notice, however, that we could replace the condition that the endowment itself be $x^{i}$ by the assumption that the endowment vector for agent $i$ has the same value as $x^{i}$ at equilibrium prices and that these endowment vectors are collectively feasible. The equilibrium would then generally involve some exchange.

8 If the sum of individual consumptions were strictly less than the total endowment of resources, we could increase the consumption of all agents, making them strictly better off.

9 The additive functional in (1) was introduced by Dixit and Stiglitz (1977) as a utility function. Ethier (1982) reinterpreted it as a production function.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-393.jpg?height=54&width=45&top_left_y=1044&top_left_x=659)

## Dynamical Systems. I: Basic Concepts and Scalar Systems

In many applications in economics and other disciplines we are interested in the evolution of certain systems over time. Suppose the state of the system of interest at a given point in time can be described by a dated vector of real numbers, $x_{t} \in \mathbb{R}^{\mathrm{n}}$, which we call the state vector. To give a precise description of the evolution of $x_{t}$, we introduce a vector-valued function

$$
\phi: \mathbb{R}^{\mathrm{n}+1+p} \supseteq X \times \mathbb{R} \times \Omega \longrightarrow \mathbb{R}^{\mathrm{n}}, \quad \text { with } x_{t}=\phi\left(x_{0}, t ; \alpha\right)
$$

that gives the value of the state vector at time $t$ as a function of its initial value, $x_{0} \in \mathbb{R}^{\mathbf{n}}$ and a vector of parameters $\alpha \in \mathbb{R}^{p}$ that describes the environment in which the system is embedded. Such a function is called a transition function or flow. Notice that $\phi()$ fully describes the behavior of the system: For given initial conditions $x_{0}$ and fixed parameter values $\alpha$, we obtain the time path of the system by giving values to $t$; and by changing $x_{0}$ and $\alpha$ we can determine how this path varies with changes in initial conditions or parameters.

In most cases the flow of a dynamical system is not given to us directly. Instead, we start from a parameterized system of difference or differential equations and must "solve it" to construct its flow. In this chapter and those that follow we will review some of the basic elements of the theory of difference and differential equations and some applications to economics. To abbreviate, we will refer to dynamical systems described by systems of differential equations as "continuous" or "continuous-time" systems (CS), and to those described by systems of difference equations as "discrete" or "discrete-time" systems (DS). When it is not necessary to distinguish between them, we will speak simply of dynamical systems (S).

## 1. Difference and Differential Equations: Basic Concepts

An ordinary differential equation is an equation of the form

$$
\begin{equation*}
x^{(m)}(t)=F\left[t, x(t), \dot{x}(t), \ddot{x}(t), \ldots, x^{(m-1)}(t) ; \alpha\right] \tag{1}
\end{equation*}
$$

where $x(t)=\left[x_{1}(t), x_{2}(t), \ldots, x_{n}(t)\right]$ is a vector-valued function of a real variable that we will interpret as time; $\dot{x}(t)=\left(d x_{1}(t) / d t, d x_{2}(t) / d t, \ldots, d x_{n}(t) / d t\right)$ is the first derivative of $x(t)$ with respect to time, with $\ddot{x}(t)$ its second derivative and $x^{(m)}$ its $m$ th derivative; $\alpha \in \Omega \subseteq \mathbb{R}^{p}$ is a vector of parameters; and $F()$ is a function $\mathbb{R}^{1+\mathrm{n}(\mathrm{m}-1)+\mathrm{p}} \longrightarrow \mathbb{R}^{\mathrm{n}}$ that we will typically assume to be at least $C^{1}$.

Observe that (1) is a functional equation, that is, an equation in which the unknown is a function $x(t)$, rather than a number or a vector. Solving (1) means finding those functions $x(t)$ that, together with their derivatives $\dot{x}, \ldots, x^{(m)}$, will satisfy the equation for given values of the parameters.

In a system of differential equations, time is a continuous variable, that is, $t$ can take any real value. In many cases, however, it is convenient to restrict $t$ to integer values that correspond to some natural period (e.g., a year). In this case, we work with difference equations, that is, equations of the form

$$
\begin{equation*}
x_{t+m}=G\left[t, x_{t}, x_{t+1}, x_{t+2}, \ldots, x_{t+m-1} ; \alpha\right] \tag{2}
\end{equation*}
$$

where $x_{s} \in \mathbb{R}^{\mathrm{n}}$ denotes the state of the system in period $s$. Eike (1), equation (2) is a functional equation, because the unknown is once more a function of $t$ that must satisfy certain properties. On the other hand, given that $t$ is a discrete variable, the solution to (2) will be a sequence rather than a differentiable function of $t$.

A differential equation is linear if $F()$ is linear in $x(t)$ and its derivatives, but not necessarily in $t$ or $\alpha$. Similarly, a difference equation is linear if $G()$ is a linear function of $x_{t}, x_{t+1}, x_{t+2}, \ldots, x_{t+\mathrm{m}-1}$. A dynamical system is autonomous if $t$ does not appear as an independent argument of $F()$ or $G($ ), but enters only through $x(t)$. As we will see later, linear systems are much easier to analyze than nonlinear ones. Because explicit solutions for nonlinear systems cannot be found, except in special cases, we have to settle for qualitative results or numerical solutions for specific functional forms. In the case of autonomous systems of one or two dimensions, qualitative results are easily obtained by graphical methods. For higher-dimensional systems, we have to rely on linear approximations to obtain local results for nonlinear systems.

The order of a differential equation is the order of the highest derivative of $x(t)$ that appears in it; the order of a difference equation is equal to the difference between the highest and lowest time subscripts that appear in the equation. Hence, both (1) and (2) are of order $m$.

It is easy to see that any system of difference or differential equations can be reduced to an equivalent first-order system by introducing additional equations and variables. For example, given the second-order differential equation

$$
\ddot{x}=a \dot{x}+b x
$$

we can define a new variable $y=\dot{x}$ and rewrite the equation in the form of a system of two first-order equations:

$$
\dot{x}=y \quad \text { and } \quad \dot{y}=a y+b x
$$

Hence, we can restrict ourselves, with no loss of generality, to the study of first-order systems of the form

$$
\dot{x}=f(x, t ; \alpha)
$$

or

$$
x_{t+1}=g\left(x_{t}, t ; \alpha\right)
$$

where we indicate in parentheses the arguments of $f()$ or $g()$ other than $x$.

## (a) Geometrical Interpretation

In order to visualize the kind of information contained in a system of equations of the form (CS) or (DS) and to understand what it means to solve such a system, it will be convenient to think of the equations (CS) and (DS) as descriptions of the motion of a particle in $n$-dimensional space. If we interpret $x_{t}$ as the position of the particle at time $t$, the difference equation $x_{t+1}=$ $g\left(x_{t}, t ; \alpha\right)$ tells us that a particle that is in position $x_{t}$ at time $t$ will be at the point $x_{t+1}$ one period later. Subtracting $x_{t}$ from both sides of the equation, we obtain the vector

$$
\Delta x_{t}=x_{t+1}-x_{t}=g\left(x_{t}, t ; \alpha\right)-x_{t}
$$

Graphically, $\Delta x_{t}$ can be represented as an arrow that takes us from the current position of the particle to its next position, as shown in Figure 9.1. Once in $x_{t+1}$, we can construct a new arrow, $\Delta x_{t+1}=g\left(x_{t+1}, t+1\right)-x_{t+1}$, follow it to $x_{t+2}$, and so on.

In summary, a difference equation describes the motion of a particle step by step. If we specify an initial time and position and follow the arrows of motion, we can reconstruct the trajectory or orbit of the system, obtaining a sequence $\left\{x_{t}\right\}$ that is a particular solution to the system. Of course, if we choose a different initial time or position, or if we change the values of the parameters, the same system will generate a different trajectory in the state space $X$. Hence, the difference equation ( $\mathrm{DS}(t, \alpha)$ ) will in general have an infinite number of solutions, indexed by the system's initial time and position and by the parameter vector.

Although it is perhaps easier to visualize the behavior of a discrete-time system, it is often more convenient or more natural to work in continuous time. The analogy with the motion of a particle in space remains valid for systems of differential equations, the only difference being that the particle now moves smoothly rather than in discrete jumps. In fact, a differential

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-397.jpg?height=498&width=655&top_left_y=183&top_left_x=406)

Figure 9.1. Solution trajectories of a discrete system.

equation is simply the limiting case of a difference equation as the length of the period between jumps goes to zero. In the preceding discussion we arbitrarily set the length of the period to 1 , but more generally, we can set it to $h$. Then the change in $x$ between two consecutive periods is given by $\Delta x_{t}=x_{t+h}-x_{t}$. Dividing $\Delta x_{t}$ by $h$ and taking the limit as $h \rightarrow 0$, we obtain the time derivative $\dot{x}(t)$, which can be interpreted as a velocity vector.

Hence, the system $(\operatorname{CS}(t, \alpha)), \dot{x}=f(x, t ; \alpha)$, assigns to each point $x \in X$ an arrow (which we imagine "attached" to $x$ ) whose direction is the instantaneous direction of motion (i.e., the tangent to the body's trajectory at the given point) and whose length is proportional to the speed of movement. In this context, $f$ (or $g$ ) is sometimes referred to as a vector field.

Solving the differential equation (CS) means reconstructing the set of functions $\varphi(t)$ that describe trajectories in state space that are compatible with the given set of velocity vectors. The idea is the same as in the discrete case, with the difference that the orbits of the system will now be smooth curves (differentiable functions of time) rather than discrete sets of points (sequences). Like ( $\operatorname{DS}(t, \alpha)$ ), the continuous system ( $\operatorname{CS}(t, \alpha))$ will in general have an infinite number of solutions, for the particle's trajectory will depend on its initial position and the time at which it is set in motion, as well as on the values of the parameters.

## (b) Initial- and Boundary-Value Problems

As already indicated, a dynamical system $(\mathrm{S}(t))$ will in general have an infinite number of solutions, corresponding to the different trajectories that the state vector may follow in state space depending on its initial position and the time at which the system is set in motion. The set of all such "par-

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-398.jpg?height=691&width=826&top_left_y=190&top_left_x=316)

Figure 9.2. Solution trajectories of a continuous system.

ticular" solutions of the system, $\phi\left(t, x^{0}, t_{0}\right)$, is sometimes called its general solution. In certain cases it is relatively easy to first construct the general solution and then select the particular solution in which we are interested. This process is referred to as definitizing the solution of the system. One way to choose an appropriate particular solution is by imposing an initial condition, that is, a condition of the form

$$
\begin{equation*}
x(0)=x^{0} \tag{0}
\end{equation*}
$$

requiring that the system start out at time zero from some given position $x^{0}$. A system of difference or differential equations and an initial condition together define an initial-value problem, and the solution to this problem is a particular solution of the system.

Imposing an initial condition (in the strict sense of the word) is not the only way to definitize the solution of a dynamical system. More generally, we can use side or boundary conditions of the type

$$
\begin{equation*}
x\left(t_{0}\right)=x^{0} \tag{0}
\end{equation*}
$$

to specify that the state vector $x$ must take on a given value $x^{0}$ at some point in time $t_{0} \in[0,+\infty]$ that need not be equal to zero. We will denote the boundary-value problem defined by a dynamical system $(\mathrm{S}(t, \alpha))$, and the side condition $\left(\mathrm{C}\left(x^{0}, t_{0}\right)\right)$ by $\left(\mathrm{P}\left(x^{0}, t_{0}, \alpha\right)\right)$. We will show later that although the dynamical system $(\mathrm{S}(t, \alpha)$ ) will in general have an infinite number of solutions, the boundary-value problem $\left(\mathrm{P}\left(x^{0}, t_{0}, \alpha\right)\right)$ will have precisely one solution, provided the function $f()$ or $g()$ satisfies certain reasonable conditions.

In the mathematical literature on dynamical systems, the distinction between initial and boundary conditions is seldom made. To return to our interpretation of a dynamical system as the law of motion of a particle in space, the trajectory of the particle is fully determined once we specify that it must go through some point $x^{0}$ at a given time $t_{0}$. For this purpose, it is irrelevant whether $x^{0}$ is the initial position of the particle when it is set in motion "at the beginning of time," its final destination, or any other point in the trajectory.

In many economic applications, however, the difference between initial conditions per se and other types of boundary conditions is important. We often have natural initial conditions associated with variables like the capital stock whose initial values (today) are predetermined by what has happened in the past. On the other hand, there are economic variables, such as asset prices, that are able to "jump" instantaneously and for which there are no obvious initial conditions. In such cases, the choice of an appropriate boundary condition must be made on economic grounds rather than mathematical grounds, and often it will reflect important assumptions concerning the formation of expectations and the choice of equilibrium concept. We will return to this question in Chapter 11 and deal with it in the context of a specific example that will allow for a more precise discussion.

## (c) Some Definitions

In this section we will formalize some of the concepts we have just introduced. Consider, for concreteness, a continuous-time system

$$
\dot{x}=f(x, \alpha, t)
$$

where the function $f()$ maps some set $X \times \Omega \times I$ in $\mathbb{R}^{\mathrm{n}+\mathrm{p}+1}$ into $X \subseteq \mathbb{R}^{\mathrm{n}}$, and $I$ is an interval in the real line.

A (particular) solution of $(\operatorname{CS}(t, \alpha))$ is a differentiable function $\varphi(t)$ : $J_{\varphi} \longrightarrow X$, defined on some interval $J_{\varphi} \subseteq I$ called its interval of definition, and taking values in $X$, that together with its derivative satisfies the differential equation $(\operatorname{CS}(t, \alpha))$ in $J_{\varphi}$, that is, such that

$$
\varphi^{\prime}(t)=f[\varphi(t), \alpha, t] \forall t \in J_{\varphi}
$$

It is important to distinguish between a solution function $\varphi(t)$ and the trajectory it describes in state space. Given a solution $\varphi(t)$ of the differential equation (CS) defined on the interval $J_{\varphi}$, we define the orbit of (CS) induced by $\varphi$ as the set

$$
\gamma(\varphi)=\varphi\left(J_{\varphi}\right)=\left\{x \in X ; x=\varphi(t) \text { for some } t \in J_{\varphi}\right\}
$$

Given a solution $\varphi(t)$ of $(\operatorname{CS}(t, \alpha))$, fix some $t_{0} \in J_{\varphi}$, and let $x^{0}=\varphi\left(t_{0}\right)$. It is then clear that $\varphi(t)$ is a solution of the boundary-value problem

$$
\begin{equation*}
\dot{x}=f(x, \alpha, t), \quad x\left(t_{0}\right)=x^{0} \tag{0}
\end{equation*}
$$

Conversely, we will show later that under appropriate assumptions on $f()$, the problem ( $\left.\mathrm{PC}\left(x^{0}, t_{0}, \alpha\right)\right)$ has precisely one solution defined on a maximal interval $J_{m}\left(x^{0}, t_{0}, \alpha\right)$ that depends on the initial data of the problem and the parameter vector. Clearly, this solution is also a solution of the differential equation $(\operatorname{CS}(t, \alpha))$. Hence, we can identify the set of solutions of $(\operatorname{CS}(t, \alpha))$ with the solutions of the family of boundary-value problems $\left(\mathrm{PC}\left(x^{0}, t_{0}, \alpha\right)\right)$, where we now regard $x^{0}, t_{0}$, and $\alpha$ as "variables." Because any change in these data will generally yield a different solution of $(\operatorname{CS}(t, \alpha))$, we can define a mapping $\phi\left(t ; x^{0}, t_{0}, \alpha\right)$ by setting, for each $t$ in $J_{m}\left(x^{0}, t_{0}, \alpha\right)$,

$$
\phi\left(t ; x^{0}, t_{0}, \alpha\right) \equiv \varphi(t)
$$

where $\varphi()$ is the unique maximal solution of the differential equation (CS $(t, \alpha)$ ) satisfying the boundary condition $\varphi\left(t_{0}\right)=x^{0}$. The resulting function, $\varphi\left(t ; x^{0}, t_{0}, \alpha\right)$, is called the flow of the system $(\operatorname{CS}(t, \alpha))$, or the flow of the vector field $f(x, \alpha, t)$.

By the uniqueness of solutions to boundary-value problems, we can define the orbit of the system $(\operatorname{CS}(t, \alpha))$ through the point $\left(x^{0}, t_{0}\right)$ as the orbit induced by the corresponding solution function, $\varphi(t)=\phi\left(t ; x^{0}, t_{0}, \alpha\right)$. Hence,

$$
\begin{aligned}
\gamma\left(x^{0}, t_{0}\right) & =\gamma\left[\phi\left(t ; x^{0}, t_{0}, \alpha\right)\right]=\varphi\left(J_{m}\left(x^{0}, t_{0}, \alpha\right)\right) \\
& =\left\{x \in X ; x=\varphi(t) \text { for some } t \in J_{m}\left(x^{0}, t_{0}, \alpha\right)\right\}
\end{aligned}
$$

It will be convenient at times to distinguish between the positive and negative orbits through a point. Given a point $\left(x^{0}, t_{0}\right)$, let $J_{m}\left(x^{0}, t_{0}, \alpha\right)=(a, b)$ be the maximal interval of definition of the solution through $\left(x^{0}, t_{0}\right)$, given by the function $\varphi(t)=\phi\left(t ; x^{0}, t_{0}, \alpha\right)$. Then $t_{0} \in J_{m}\left(x^{0}, t_{0}, \alpha\right)$, and we define the positive orbit through $\left(x^{0}, t_{0}\right)$ by

$$
\gamma^{+}\left(x^{0}, t_{0}\right)=\varphi\left(\left[t_{0}, b\right)\right)=\left\{x \in X ; x=\varphi(t) \text { for some } t \in\left[t_{0}, b\right) \subseteq J_{m}\left(x^{0}, t_{0}, \alpha\right)\right\}
$$

and the negative orbit through the same point by

$$
\gamma^{-}\left(x^{0}, t_{0}\right)=\varphi\left(\left(a, t_{0}\right]\right)=\left\{x \in X ; x=\varphi(t) \text { for some } t \in\left(a, t_{0}\right] \subseteq J_{m}\left(x^{0}, t_{0}, \alpha\right)\right\}
$$

Similar concepts can be defined in an analogous way for the discrete system

$$
x_{t+1}=g\left(x_{t}, t ; \alpha\right)
$$

where the function $g\left(\right.$ ) maps some set $X \times I \times \Omega$ in $\mathbb{R}^{\mathrm{n}+\mathrm{i}+\mathrm{p}}$ into $X \subseteq \mathbb{R}^{\mathrm{n}}$. We now assume that $I$ is a set of consecutive integers (we will sometimes refer to such a set as an "interval" for short). A solution of ( $\mathrm{DS}(t, \alpha)$ ) is a sequence (i.e., a function $\varphi(t): J_{\varphi} \longrightarrow X$ ) defined on some "interval" of integers
$J_{\varphi} \subseteq I$ called its "interval" or set of definition. This function takes values in $X$ and satisfies the difference equation ( $\operatorname{DS}(t, \alpha)$ ) in $J_{\varphi}$, that is,

$$
\varphi(t+1)=g[\varphi(t), t ; \alpha] \forall t \in J_{\varphi}
$$

As in the continuous case, each solution of the difference equation (DS( $t$, $\alpha$ ) can be identified with the solution of an appropriate boundary-value problem, and the flow of the system can be defined in the same way as before (at least for all $t \geq t_{0}$, as discussed later). The orbits of the system through any given point $\left(x^{0}, t_{0}\right)$ are also defined in a similar way. Notice, however, that orbits will now be discrete sets of points, rather than differentiable curves in state space.

## (d) Existence, Uniqueness, and Other Properties of Solutions

We will now establish the existence, uniqueness, and other important properties of the solutions to discrete-time boundary-value problems of the form ( $\left.\mathrm{PD}\left(x^{0}, t_{0}, \alpha\right)\right)$. We will also state a theorem that gives similar results for continuous-time systems. The proof of this result, which requires a lot more work than its discrete-time analogue, will be left for Section 6, where we will analyze in some detail the properties of solutions of differential equations.

Consider the boundary-value problem

$$
x_{t+1}=g\left(x_{t}, t ; \alpha\right), \quad x\left(t_{0}\right)=x^{0} \quad\left(\mathrm{PD}\left(x^{0}, t_{0}, \alpha\right)\right)
$$

where the function $g\left(\right.$ ) maps some set $X \times I \times \Omega$ in $\mathbb{R}^{\mathrm{n}+1+p}$ into $X \subseteq \mathbb{R}^{\mathrm{n}}, I$ is an "interval" containing $t_{0}$, and $x^{0}$ is a point in $X$. For convenience, we set $t_{0}=0$ in the following, but the same procedure could be followed for an arbitrary value of $t_{0}$.

The construction of the solution to this problem poses no conceptual difficulty. Intuitively, to recover the system's trajectory it is enough to "follow the arrows" starting from the initial position. Analytically, we can construct the solution sequence $\varphi(t)=\varphi_{t}\left(x^{0}, t_{0}, \alpha\right)$ iteratively by setting $\varphi(0)=x^{0}$ and then using $g()$ to define $\varphi(t)$ recursively by $\varphi(t+1)=g[\varphi(t), t ; \alpha]$. That is,

$$
\begin{align*}
& \phi_{0}\left(x^{0}, 0, \alpha\right)=x^{0} \\
& \phi_{1}\left(x^{0}, 0, \alpha\right)=g\left(x^{0}, \alpha, 0\right)=g\left[\phi_{0}\left(x^{0}, 0, \alpha\right), 0, \alpha\right] \\
& \phi_{2}\left(x^{0}, 0, \alpha\right)=g\left[\phi_{1}\left(x^{0}, 0, \alpha\right), 1, \alpha\right] \\
& \vdots  \tag{1}\\
& \phi_{t}\left(x^{0}, 0, \alpha\right)=g\left[\phi_{t-1}\left(x^{0}, 0, \alpha\right), t-1, \alpha\right]
\end{align*}
$$

If $g()$ is continuous (or $C^{k}$ ), the function $\phi_{t}\left(x^{0}, t_{0}, \alpha\right)$ constructed in (1) is defined as the composition of continuous $\left(C^{k}\right)$ functions and is therefore continuous $\left(C^{k}\right)$ itself in $\left(x^{0}, \alpha\right)$.

Notice that if $g(\cdot, \alpha)$ is defined in the whole space $\mathbb{R}^{\mathbf{n}+1}$, this process can be continued indefinitely, and a solution exists for each $t \geq t_{0}=0$. If $X \times I$ is not the entire space, on the other hand, the solution may cease to exist at some point if $g(\cdot, \alpha)$ maps $\left(x_{t}, t\right)$ into some point $\left(x_{t+1}, t+1\right)$ outside the domain of $g(\cdot, \alpha)$. Hence, the solution sequence $\varphi(t)=\phi_{t}\left(x^{0}, 0, \alpha\right)$ will in general be defined on some maximal set of consecutive integers $J_{\varphi} \subseteq I$ containing zero.

We observe also that the solution sequence $\varphi(t)$ is uniquely defined for $t \geq 0$ (for given $x^{0}$ and $\alpha$ ) provided that $g(\cdot, \alpha)$ is a well-defined function. Under this assumption, any other solution sequence $\Psi(t)$ starting from $x^{0}$ at time zero will adopt exactly the same values and can be continued to the same interval as $\varphi(t)$. Uniqueness does not necessarily survive, however, when we try to extend the solution sequence to negative values of $t$ (or, more generally, for $t<t_{0}$ ).

To construct such an extension, we define the functions $h_{t}()$ by $h_{t}(x)=g(x$, $t ; \alpha)$ for $t<0$ and construct the sequence $\phi_{t}\left(x^{0}, 0, \alpha\right)$ recursively by starting with $\phi_{0}\left(x^{0}, 0, \alpha\right)=x^{0}$ and then setting

$$
\phi_{t}\left(x^{0}, 0, \alpha\right)=h_{t}^{-1}\left(\phi_{t+1}\left(x^{0}, 0, \alpha\right)\right)
$$

for each $t=-1,-2, \ldots$ As before, $\phi_{i}(\cdot)$ may fail to exist after some point. There is no guarantee, moreover, that $h_{t}()$ will be invertible for all $t$, so the inverse mapping $h_{t}^{-1}()$ may well be a correspondence. In this case, the solution to ( $\mathrm{PD}\left(x^{0}, 0, \alpha\right)$ ) will not be unique for $t<0$. On the other hand, if $h_{t}()$ is a homeomorphism for all $t$ (i.e., a continuous function with a continuous inverse), then the solution sequence will be unique, and $\phi_{t}()$ will be a continuous function of $\left(x^{0}, \alpha\right)$ also for $t<0$.

We summarize the discussion in the following theorem.

Theorem 1.1. Existence and uniqueness of solutions for discrete systems and dependence on initial conditions and parameters. Let $\mathrm{g}: \mathrm{X} \times \mathrm{I} \times \Omega \supseteq \mathbb{R}^{\boldsymbol{n}+p+1}$ $\longrightarrow \mathbb{R}^{n}$ be a well-defined function, and $\mathrm{I}$ a set of consecutive integers. Then the boundary-value problem

$$
\mathrm{x}_{\mathrm{t}+1}=\mathrm{g}\left(\mathrm{x}_{\mathrm{t}}, \alpha, \mathrm{t}\right), \quad \mathrm{x}\left(\mathrm{t}_{0}\right)=\mathrm{x}^{0} \quad\left(P D\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)\right)
$$

has a solution sequence $\varphi(\mathrm{t})=\phi_{\mathrm{l}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)$ for each $\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right) \in \mathrm{X} \times \mathrm{I} \times \Omega$. This solution is defined on a maximal set $\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right) \subseteq \mathrm{I}$ containing $\mathrm{t}_{0}$ that depends on the initial data and the parameters of the problem. Moreover, the solution is unique for all $\mathrm{t} \geq \mathrm{t}_{0}$, in the sense that if $\Psi(\mathrm{t})$ is a solution sequence of $\left(P D\left(\mathrm{x}^{0}\right.\right.$, $\left.\mathrm{t}_{0}, \alpha\right)$ ) defined on some set $\mathrm{J}_{\Psi}$, then $\mathrm{J}_{\Psi} \subseteq \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)$, and $\Psi(\mathrm{t})=\varphi(\mathrm{t})$ for all $\mathrm{t} \in \mathrm{J}_{\Psi}$ with $\mathrm{t} \geq \mathrm{t}_{0}$.

Moreover, if $\mathrm{g}()$ is continuous $\left(\mathrm{C}^{\mathrm{k}}\right)$ in $\left(\mathrm{x}_{\mathrm{t}}, \alpha\right)$, then for each $\mathrm{t} \in \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)$, with $\mathrm{t} \geq \mathrm{t}_{0}$, the function $\phi_{\mathrm{t}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)$ is continuous $\left(\mathrm{C}^{\mathrm{k}}\right)$ in $\left(\mathrm{x}^{0}, \alpha\right)$. If, in addition, $\mathrm{h}_{\mathrm{t}}(\mathrm{x})=\mathrm{g}(\mathrm{x}, \mathrm{t} ; \alpha)$ is invertible and has a continuous $\left(\mathrm{C}^{\mathrm{k}}\right)$ inverse for all $\mathrm{t}$, then the solution is unique in all of $\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)$ and $\phi_{\mathrm{t}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)$ is continuous $\left(\mathrm{C}^{\mathrm{k}}\right)$ in $\left(\mathrm{x}^{0}, \alpha\right)$ for all $\mathrm{t}$ in $\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)$.

With continuous-time systems, things are not so simple. However, it is still possible to obtain similar results with slightly stronger assumptions. In Section 6 we will prove a version of the following result.

Theorem 1.2. Existence and uniqueness of solutions for continuous-time systems and dependence on initial conditions and parameters. Let $\mathrm{f}: \mathrm{X} \times \mathrm{I} \times$ $\Omega \supseteq \mathbb{R}^{n+p+1} \longrightarrow \mathbb{R}^{n}$ be $\mathrm{C}^{l}$ on the set $\mathrm{X} \times \mathrm{I} \times \Omega$, where $\mathrm{X}$ and $\Omega$ are open sets, and $\mathrm{I}$ is an open interval in the real line. Then the boundary-value problem

$$
\dot{\mathrm{x}}=\mathrm{f}(\mathrm{x}, \alpha, \mathrm{t}), \quad \mathrm{x}\left(\mathrm{t}_{0}\right)=\mathrm{x}^{0} \quad\left(P C\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)\right)
$$

has a unique solution $\varphi(\mathrm{t})=\phi\left(\mathrm{t}, \mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)$ for each $\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right) \in \mathrm{X} \times \mathrm{I} \times \Omega$ defined on a maximal open interval $\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right) \subseteq \mathrm{I}$ containing $\mathrm{t}_{0}$ that depends on the initial data and parameters of the problem. That is, if $\Psi(\mathrm{t})$ is a solution of $\left(P C\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)\right)$ defined on some interval $\mathrm{J}_{\Psi}$ then $\mathrm{J}_{\Psi} \subseteq \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)$ and $\Psi(\mathrm{t})$ $=\varphi(\mathrm{t})$ for all $\mathrm{t} \in \mathrm{J}_{\psi}$. Moreover, the flow of the system, $\phi\left(\mathrm{t}, \mathrm{x}^{0}, \mathrm{t}_{0}, \alpha\right)$, is $\mathrm{C}^{\prime}$.

One convenient implication of the uniqueness of solutions for boundaryvalue problems is that the solutions of differential or difference equations cannot cross, in the sense that two different solution trajectories cannot go through the same point at the same time and then "separate." The following result makes this precise.

Theorem 1.3. Let $\mathrm{f}$ be $\mathrm{C}^{1}$ on the set $\mathrm{X} \times \mathrm{I}$, where $\mathrm{X}$ is an open set, and $\mathrm{I}$ an open interval in the real line. Let $\phi\left(\mathrm{t}, \mathrm{t}_{0}, \mathrm{x}^{0}\right)$ be the flow of the system $(\mathrm{CS}(\mathrm{t}))$, $\dot{\mathrm{x}}=\mathrm{f}(\mathrm{x}, \mathrm{t})$. Then for each $\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right) \in \mathrm{X} \times \mathrm{I}$ and every $\mathrm{s} \in \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)$ we have $\mathrm{J}_{\mathrm{m}}\left[\phi\left(\mathrm{s}, \mathrm{t}_{0}, \mathrm{x}^{0}\right), \mathrm{s}\right]=\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)$, and

$$
\begin{equation*}
\phi\left(\mathrm{t}, \mathrm{t}_{0}, \mathrm{x}^{0}\right)=\phi\left[\mathrm{t}, \mathrm{s}, \phi\left(\mathrm{s}, \mathrm{t}_{0}, \mathrm{x}^{0}\right)\right] \tag{2}
\end{equation*}
$$

for all $\mathrm{t} \in \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)$.

Let $\varphi(t)=\phi\left(t, t_{0}, x^{0}\right)$ and $\Psi(t)=\phi\left(t, s, x^{s}\right)$ be two solutions of the system $(\mathrm{SC}(t))$ indexed by two arbitrary points in their graphs $\left(t_{0}, x^{0}\right)$ and $\left(s, x^{s}\right)$. The theorem says that if the two graphs have a point in common, that is, if $\varphi(t)$ goes through $x^{s}$ at the same time that $\Psi(t)$ does, then the two solutions are the same in the sense that their maximal intervals of definition coincide, and so do their values for any $t$ in this interval. Equivalently, the result says that
if we follow the solution $\phi\left(t, t_{0}, x^{0}\right)$ to some point $\left(s, x^{s}=\phi\left(s, t_{0}, x^{0}\right)\right)$ and then stop, and then solve the boundary-value problem with initial data $\left(s, x^{s}\right)$ and follow its solution, then we stay on the same path we would follow if we did not stop.

A similar result holds for discrete systems whenever the flow is a welldefined function. In particular, equation (2) will hold for all $t, s \in J_{m}\left(x^{0}, t_{0}\right)$ and greater than $t_{0}$, implying that solutions that at some point come together cannot separate later on. Notice that equation (2) may not hold for $s, t<t_{0}$, for it is possible that $g()$ may map two distinct points into the same one. Hence, different solution sequences may "converge" at some point if $g()$ is not invertible, but they can never "diverge" once they have coincided.

Proof. Let $\varphi(t)=\phi\left(t, t_{0}, x^{0}\right)$ be the unique maximal solution of $(\operatorname{CS}(t))$ going through the point $\left(t_{0}, x^{0}\right)$. Fix some arbitrary $s$ in $J_{m}\left(x^{0}, t_{0}\right)$ and let

$$
\varphi(s)=\phi\left(s, t_{0}, x^{0}\right)=x^{s} \in X
$$

Clearly, $\varphi(t)$ is a solution of the boundary-value problem ( $\left.\mathrm{PC}\left(s, x^{s}\right)\right)$. Let

$$
\Psi(t)=\phi\left(t, s, x^{s}\right)
$$

be the maximal solution of this problem defined on the maximal interval $J_{m}\left(s, x^{s}\right)$. Then, by the uniqueness of solutions (Theorem 1.2), we have $J_{m}\left(x^{0}\right.$, $\left.t_{0}\right) \subseteq J_{m}\left(s, x^{s}\right)$ and

$$
\begin{equation*}
\varphi(t)=\Psi(t) \forall t \in J_{m}\left(x^{0}, t_{0}\right) \tag{1}
\end{equation*}
$$

Moreover, because $\Psi(t)$ is defined at $t_{0}$, we have

$$
\Psi\left(t_{0}\right)=\varphi\left(t_{0}\right)=x^{0}
$$

so $\Psi()$ also goes through the point $\left(t_{0}, x^{0}\right)$. Because $\varphi()$ is the maximal solution through this point, Theorem 1.2 implies that $J_{m}\left(s, x^{s}\right) \subseteq J_{m}\left(x^{0}, t_{0}\right)$, so in fact $J_{m}\left(s, x^{s}\right)=J_{m}\left(x^{0}, t_{0}\right)$.

Using (1) and the definition of $x^{s}$, we now have

$$
\phi\left(t, t_{0}, x^{0}\right)=\varphi(t)=\Psi(t)=\phi\left(t, s, x^{s}\right)=\phi\left[t, s, \phi\left(s, t_{0}, x^{0}\right)\right]
$$

for all $t$ in $J_{m}\left(x^{0}, t_{0}\right)=J_{m}\left(s, x^{s}\right)$.

## 2. Autonomous Systems

A dynamical system is said to be autonomous if time does not enter the function $f()$ or $g()$ as a separate argument, that is, if the system is of the form

$$
\begin{equation*}
\dot{x}=f(x) \tag{CS}
\end{equation*}
$$

or

$$
\begin{equation*}
x_{t+1}=g\left(x_{t}\right) \tag{DS}
\end{equation*}
$$

In this section we will analyze some important properties of autonomous systems and introduce some concepts that will play important roles in the rest of the chapter.

## (a) The Flow of an Autonomous System

We have seen that the uniqueness of solutions for boundary-value problems implies that the solutions of differential or difference equations cannot cross, in the sense that two different solution trajectories cannot go through the same point at the same time and then separate. It is still possible, however, that different solutions may cross a given point at different times and then follow different trajectories. The reason, of course, is that in the general specification of a dynamical system,

$$
\begin{equation*}
\dot{x}=f(x, t) \tag{t}
\end{equation*}
$$

or

$$
\begin{equation*}
x_{t+1}=g\left(x_{t}, t\right) \tag{t}
\end{equation*}
$$

the vector field $f$ or $g$ can be a function of $t$. Graphically, the arrow of motion $\dot{x}$ or $\Delta x$ associated with a point $x$ in the state space can change with time. Hence, the direction of motion of the system depends not only on its current position but also on time.

In the case of the autonomous system

$$
\begin{equation*}
\dot{x}=f(x) \tag{CS}
\end{equation*}
$$

or

$$
\begin{equation*}
x_{t+1}=g\left(x_{t}\right) \tag{DS}
\end{equation*}
$$

however, each point $x$ in $X$ has attached to it a unique, time-invariant arrow, and therefore all particles that at some time reach point $x$ follow exactly the same trajectory in $X$ (from then on, in the case of a discrete system; always, in the case of a continuous system) whenever the assumptions of the corresponding existence and uniqueness theorem are satisfied.

That is, given an autonomous system (S), the solutions satisfying the boundary conditions

$$
x\left(t_{0}\right)=x^{0} \quad \text { and } \quad x\left(t_{1}\right)=x^{0}, \quad \text { with } t_{0} \neq t_{1}
$$

have the same orbit if (S) is a continuous system, and the same positive orbit if (S) is discrete. Hence, solution trajectories never cross. If $X$ is some subset of the real line or the plane, the set of all trajectories can be shown in a figure

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-406.jpg?height=491&width=652&top_left_y=189&top_left_x=104)

Non-autonomous system: several trajectories may go through the same point (at different times).

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-406.jpg?height=478&width=547&top_left_y=191&top_left_x=807)

Autonomous system: only one solution trajectory can go through each point in $X$.

Figure 9.3. Autonomous versus nonautonomous systems.

called a phase diagram, using arrows to indicate the directions of motion. This device is a very useful tool for analysis of the dynamics of lowdimensional autonomous systems (Figure 9.3).

In the remainder of this section we will formally establish this nocrossing property and investigate some other properties of the flow of autonomous systems that are closely related to it.

We start with the discrete case,

$$
\begin{equation*}
x_{t+1}=g\left(x_{t}\right) \tag{DS}
\end{equation*}
$$

Analytically, the flow of (DS) can be obtained by the repeated composition of the time map $g()$ with itself. Letting $\phi_{0}\left(x^{0}\right) \equiv x^{0}$ indicate the position of the system at time zero, we define $\phi_{t}\left(x^{0}\right)$ recursively by

$$
\begin{equation*}
\phi_{t+1}\left(x^{0}\right)=g\left(\phi_{t}\left(x^{0}\right)\right)=g\left[g^{t}\left(x^{0}\right)\right] \equiv g^{t+1}\left(x^{0}\right) \tag{1}
\end{equation*}
$$

where $g^{n}()$ denotes the $n$th iteration of $g()$ (and not its $n$th power). Hence, the flow of (DS) can be written

$$
\phi_{t}\left(x^{0}\right)=g^{t}\left(x^{0}\right) \text { for } t>0
$$

and, by the associativity of the composition of functions, we obtain $g^{t+s}\left(x^{0}\right)=$ $g^{t}\left(g^{s}\left(x^{0}\right)\right)$ or

$$
\begin{equation*}
\phi_{t+s}\left(x^{0}\right)=\phi_{t}\left[\phi_{s}\left(x^{0}\right)\right]=\phi_{s}\left[\phi_{t}\left(x^{0}\right)\right] \tag{2}
\end{equation*}
$$

for all integers $t, s \geq 0$ whenever $s, t$, and $t+s$ lie on the maximal interval of definition of the solution through $x^{0}, J_{m}\left(x^{0}\right)$. If $g()$ is invertible, the same procedure will work backward, with $g^{-n}$ () now denoting the $n$-fold composition of the inverse function $g^{-1}()$ with itself, and then equation (1) holds also for nonpositive integers.

Using equation (2), we can now establish the no-crossing property. Given a point $z$ in $X$, let $\phi_{t}\left(x^{0}\right)$ and $\phi_{t}\left(y^{0}\right)$ be two solutions of (DS) going through $z$ at different times, say $s$ and $r \geq 0$. Then

$$
\phi_{s}\left(x^{0}\right)=z=\phi_{r}\left(y^{0}\right)
$$

and for any $t \geq 0$ in $J_{m}(z)$ we have, using (2),

$$
\phi_{s+t}\left(x^{0}\right)=\phi_{t}\left[\phi_{s}\left(x^{0}\right)\right]=\phi_{t}(z) \quad \text { and } \quad \phi_{r+t}\left(y^{0}\right)=\phi_{t}\left[\phi_{r}\left(y^{0}\right)\right]=\phi_{t}(z)
$$

Hence, we have that $s+t$ and $r+t \in J_{m}(z)$, and

$$
\begin{equation*}
\phi_{s+t}\left(x^{0}\right)=\phi_{r+t}\left(y^{0}\right) \tag{3}
\end{equation*}
$$

for all $t \geq 0$ in $J_{m}(z)$. If two solutions $\phi_{t}\left(x^{0}\right)$ and $\phi_{t}\left(y^{0}\right)$ go through a common point $z$, then they coincide thereafter. Equivalently, we can say that the position of a particle that goes through a given point $z$ depends only on the time spanned since it reached this point, not on the time at which it attained it.

We will now show that a similar property holds for the flows of the continuous-time autonomous system

$$
\begin{equation*}
\dot{x}=f(x) \tag{CS}
\end{equation*}
$$

Lemma 2.1. Let $\varphi(\mathrm{t})$ be a solution of the autonomous system (CS) defined on the maximal interval $\mathrm{J}_{\varphi}$. Then $\varphi(\mathrm{t}+\mathrm{r})$ is also a solution of $(C S)$ for any constant $\mathrm{r}$ and any $\mathrm{t}+\mathrm{r} \in \mathrm{J}_{\varphi}$.

To understand this deceptively simple result, it is probably best to see why it fails to hold in the case of a nonautonomous system. Let $\varphi()$ be a solution of the nonautonomous system

$$
\begin{equation*}
\dot{x}=f(x, t) \tag{t}
\end{equation*}
$$

Then, by definition,

$$
\varphi^{\prime}(s)=f[\varphi(s), s]
$$

for all $s$ in $J_{\varphi}=(a, b)$. Given some fixed constant $r$, define a new function

$$
\Psi(t)=\varphi(t+r)
$$

for all $t$ such that $t+r \in J_{\varphi}=(a, b)$, that is, for $t$ in $J_{\varphi}-r=(a-r, b-r)=J_{\Psi}$. Then

$$
\begin{equation*}
\Psi^{\prime}(t)=\varphi^{\prime}(t+r)=f[\varphi(t+r), t+r]=f[\Psi(t), t+r] \tag{4}
\end{equation*}
$$

so, in general, $\Psi(t)$ is not a solution of $(\operatorname{CS}(t))$ except when $r=0$. In the special case of the autonomous system (CS), however, time is not an argument of $f($ ), and (4) becomes

$$
\Psi^{\prime}(t)=\varphi^{\prime}(t+r)=f[\varphi(t+r)]=f[\Psi(t)]
$$

so $\Psi(t)=r(t+r)$ is indeed a solution of (CS) under the assumptions of the lemma.

Notice that $\varphi(t)$ and $\Psi(t)$ are different solutions of (CS), but they describe the same orbit or solution curve in state space.

Theorem 2.2. Assume that $\mathrm{f}$ is $\mathrm{C}^{\mathrm{l}}$ in some open set $\mathrm{X} \subseteq \mathbb{R}^{n}$, and let $\phi\left(\mathrm{t}, \mathrm{t}_{0}, \mathrm{x}^{0}\right)$ be the flow of the autonomous system (CS). Then, for each $\left(\mathrm{t}_{0}, \mathrm{x}^{0}\right)$ in $\mathrm{X} \times \mathbb{R}$ we have $\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, 0\right)=\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)-\mathrm{t}_{0}$ and

$$
\begin{equation*}
\phi\left(\mathrm{t}, \mathrm{t}_{0}, \mathbf{x}^{0}\right)=\phi\left(\mathrm{t}-\mathrm{t}_{0}, 0, \mathbf{x}^{0}\right) \tag{5}
\end{equation*}
$$

for every $\mathrm{t} \in \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)$, or, equivalently, for every $\mathrm{t}-\mathrm{t}_{0} \in \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, 0\right)$.

Proof. Let $\varphi(s)=\phi\left(s, t_{0}, x^{0}\right)$ be the maximal solution of the boundary-value problem ( $\left.\operatorname{PS}\left(t_{0}, x^{0}\right)\right)$ defined on the maximal interval $J_{m}\left(x^{0}, t_{0}\right)=(a, b)$, and $\Psi(s)=\phi\left(s, 0, x^{0}\right)$ the maximal solution of $\left(\operatorname{PS}\left(0, x^{0}\right)\right)$ defined on the maximal interval $J_{m}\left(x^{0}, 0\right)=(c, d)$.

Define the function $\varphi_{0}(s)$ on $\left(a-t_{0}, b-t_{0}\right)=J_{m}\left(x^{0}, t_{0}\right)-t_{0}$ by

$$
\begin{equation*}
\varphi_{0}(s)=\varphi\left(s+t_{0}\right)=\phi\left(s+t_{0}, t_{0}, x^{0}\right) \tag{1}
\end{equation*}
$$

(notice that if $s \in J_{m}\left(x^{0}, t_{0}\right)-t_{0}$, then $a-t_{0}<s<b-t_{0}$, and therefore $a<s+t_{0}$ $<b$, so $s+t_{0} \in J_{m}\left(x^{0}, t_{0}\right)$; because $\varphi\left(s+t_{0}\right)$ is defined for $s+t_{0} \in J_{m}\left(x^{0}, t_{0}\right), \varphi_{0}(s)$ is defined on $\left.J_{m}\left(x^{0}, t_{0}\right)-t_{0}\right)$. By Lemma 2.1, $\varphi_{0}(s) \equiv \varphi\left(s+t_{0}\right)$ is a solution of the autonomous system (CS). Moreover,

$$
\varphi_{0}(0)=\varphi\left(t_{0}\right)=x^{0}
$$

so $\varphi_{0}(s)$ is a solution of the boundary-value problem ( $\left.\operatorname{PS}\left(0, x^{0}\right)\right)$, just like $\Psi(s)$. Because $\Psi(s)$ is the maximal solution of this problem, Theorem 1.2 implies that $\left(a-t_{0}, b-t_{0}\right)=\left\{J_{m}\left(x^{0}, t_{0}\right)-t_{0}\right\} \subseteq J_{m}\left(x^{0}, 0\right)$ and

$$
\begin{equation*}
\Psi_{0}(s)=\Psi(s) \equiv \phi\left(s, 0, x^{0}\right) \tag{2}
\end{equation*}
$$

for all $s \in\left(a-t_{0}, b-t_{0}\right) \subseteq J_{m}\left(x^{0}, 0\right)$.

Similarly, define $\Psi_{0}(s)$ on $\left(c+t_{0}, d+t_{0}\right)=\left\{J_{m}\left(x^{0}, 0\right)+t_{0}\right\}$ by

$$
\begin{equation*}
\varphi_{0}(s)=\Psi\left(s-t_{0}\right)=\phi\left(s-t_{0}, 0, x^{0}\right) \tag{3}
\end{equation*}
$$

and observe that $\Psi_{0}(s)$ is a solution of $\left(\mathrm{PC}\left(t_{0}, x^{0}\right)\right)$, because

$$
\Psi_{0}\left(t_{0}\right)=\Psi(0)=\phi\left(0,0, x^{0}\right)=x^{0}
$$

Because $\varphi(s)$ is the maximal solution for this problem, it follows by Theorem 1.2 that $\left(c+t_{0}, d+t_{0}\right)=\left\{J_{m}\left(x^{0}, 0\right)+t_{0}\right\} \subseteq J_{m}\left(x^{0}, t_{0}\right)$ and

$$
\begin{equation*}
\Psi_{0}(s)=\varphi(s)=\phi\left(s, t_{0}, x^{0}\right) \tag{4}
\end{equation*}
$$

for all $s \in\left(c+t_{0}, d+t_{0}\right) \subseteq J_{m}\left(x^{0}, t_{0}\right)$.

Notice that we have shown that

$$
J_{m}\left(x^{0}, t_{0}\right)-t_{0}=J_{m}\left(x^{0}, 0\right)
$$

Using (1) and (2), we have

$$
\begin{equation*}
\phi\left(s+t_{0}, t_{0}, x^{0}\right) \equiv \varphi_{0}(s)=\Psi(s) \equiv \phi\left(s, 0, x^{0}\right) \tag{5}
\end{equation*}
$$

for all $s \in\left\{J_{m}\left(x^{0}, t_{0}\right)-t_{0}\right\}=J_{m}\left(x^{0}, 0\right)$. Letting $t=s+t_{0}$, we have, finally,

$$
\phi\left(t, t_{0}, x^{0}\right)=\phi\left(t-t_{0}, 0, x^{0}\right)
$$

for all $t \in J_{m}\left(x^{0}, t_{0}\right)$.

Theorem 2.2 says that the position at time $t$ of an autonomous system depends only on its initial position and the time spanned since the system was set in motion, not on the initial time itself. One convenient implication of the theorem is that we can "normalize" $t_{0}$ to zero and omit the second argument of the flow. When we do this, of course, we have to normalize the maximal interval of existence accordingly. Hence, letting $s=t-t_{0}$, we can rewrite the flow in terms of the normalized time, $s$, as

$$
\begin{equation*}
\phi\left(t, t_{0}, x^{0}\right)=\phi\left(t-t_{0}, 0, x^{0}\right)=\phi\left(s, 0, x^{0}\right) \tag{6}
\end{equation*}
$$

and then $\phi\left(s, 0, x^{0}\right)$ is defined for all $s$ in $J_{m}\left(x^{0}, 0\right)=J_{m}\left(x^{0}, t_{0}\right)-t_{0}$ (i.e., for all $t=s+t_{0}$ in $\left.J_{m}\left(x^{0}, t_{0}\right)\right)$. In most of what follows we will take advantage of this normalization. Except when we need to make explicit reference to the initial time, we will assume that it is equal to zero and write the flow of an autonomous system in the form $\phi\left(t, x^{0}\right)$, denoting the maximal interval of definition of the solution starting (at time zero) from $x^{0}$ by $J_{m}\left(x^{0}\right)$.

Theorem 2.3. Assume that $\mathrm{f}$ is $\mathrm{C}^{l}$ in some open set $\mathrm{X} \subseteq \mathbb{R}^{n}$, and let $\phi\left(\mathrm{t}, \mathrm{x}^{0}\right)$ be the flow of the autonomous system (CS). Let $\mathrm{s} \in \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}\right)$. Then

$$
\mathrm{J}_{\mathrm{m}}\left[\phi\left(\mathrm{s}, \mathrm{x}^{0}\right)\right]=\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}\right)-\mathrm{s}
$$

and

$$
\begin{equation*}
\phi\left(\mathrm{r}+\mathrm{s}, \mathrm{x}^{0}\right)=\phi\left[\mathrm{r}, \phi\left(\mathrm{s}, \mathrm{x}^{0}\right)\right] \tag{7}
\end{equation*}
$$

for any $\mathrm{r} \in \mathrm{J}_{\mathrm{m}}\left[\phi\left(\mathrm{s}, \mathrm{x}^{0}\right)\right]$, or, equivalently, for any $\mathrm{r}+\mathrm{s} \in \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}\right)$.

Proof. Reverting to our former notation for the flow, equation (7) means

$$
\begin{equation*}
\phi\left(r+s, 0, x^{0}\right)=\phi\left[r, 0, \phi\left(s, 0, x^{0}\right)\right] \tag{1}
\end{equation*}
$$

But notice that

$$
\begin{equation*}
\phi\left(r, 0, \phi\left(s, 0, x^{0}\right)\right)=\phi\left[r+s, s, \phi\left(s, 0, x^{0}\right)\right]=\phi\left(r+s, 0, x^{0}\right) \tag{2}
\end{equation*}
$$

where the first equality follows by Theorem 2.2 (use the formula $\phi\left(t-t_{0}, 0\right.$, $\left.x^{0}\right)=\phi\left(t, t_{0}, x^{0}\right)$, with $t_{0}=s, t=r+s$, and $\left.x^{0}=\phi\left(s, 0, x^{0}\right)\right)$, and the second follows from Theorem 1.3 (use the formula $\phi\left[t, s, \phi\left(s, t_{0}, x^{0}\right)\right]=\phi\left(t, t_{0}, x^{0}\right)$, with $t=r+s$ and $t_{0}=0$ ). Hence, (1) holds, and, eliminating the zero arguments, this equality reduces to the desired expression.

Observe also that Theorems 1.3 and 2.2 guarantee that each side is defined if the other is defined. We have, in particular, that if $s \in J_{m}\left(x^{0}\right)$, then

$$
\begin{equation*}
J_{m}\left[\phi\left(s, 0, x^{0}\right), 0\right]=J_{m}\left[\phi\left(s, 0, x^{0}\right), s\right]-s=J_{m}\left(x^{0}, 0\right)-s \tag{3}
\end{equation*}
$$

where, as before, the first equality follows by Theorem 2.2 (using $J_{m}\left(x^{0}, 0\right)=$ $J_{m}\left(x^{0}, t_{0}\right)-t_{0}$, with $t_{0}=s$ and $\left.x^{0}=\phi\left(s, 0, x^{0}\right)\right)$, and the second follows from Theorem 1.3 (using $J_{m}\left[\phi\left(s, t_{0}, x^{0}\right), s\right]=J_{m}\left(x^{0}, t_{0}\right)$, with $t_{0}=0$ ). Assume that the right-hand side of (1) is defined, that is, that $s \in J_{m}\left(x^{0}\right)$ and $r \in J_{m}\left[\phi\left(s, 0, x^{0}\right)\right.$, $0]$. Then we have, by (3), that

$$
r \in J_{m}\left[\phi\left(s, 0, x^{0}\right), 0\right]=J_{m}\left(x^{0}, 0\right)-s
$$

so

$$
s+r \in J_{m}\left(x^{0}, 0\right)
$$

and the left-hand side of (1) is defined. Conversely, if $s, s+r \in J_{m}\left(x^{0}, 0\right)$, then, by (3),

$$
r \in J_{m}\left(x^{0}, 0\right)-s=J_{m}\left[\phi\left(s, 0, x^{0}\right), 0\right]
$$

so the right-hand side of (1) is defined.

It is now easy to show that any two solutions of an autonomous system that cross the same point in phase space (possibly at different times) define the same orbit. The argument is the same as in the discrete case. Let $z$ be a point in $X$, and $\phi\left(t, x^{0}\right)$ and $\phi\left(t, y^{0}\right)$ two solutions of (CS) going through $z$ at different times, say

$$
\phi\left(s, x^{0}\right)=z=\phi\left(r, y^{0}\right)
$$

Then, for any $t$ in $J_{m}(z)=J_{m}\left[\phi\left(s, x^{0}\right)\right]=J_{m}\left(x^{0}\right)-s=J_{m}\left(x^{0}\right)-r$ we have

$$
\phi\left(s+t, x^{0}\right)=\phi\left[t, \phi\left(s, x^{0}\right)\right]=\phi(t, z) \text { and } \phi\left(r+t, y^{0}\right)=\phi\left[t, \phi\left(r, y^{0}\right)\right]=\phi(t, z)
$$

Hence,

$$
\begin{equation*}
\phi\left(s+t, x^{0}\right)=\phi\left(r+t, y^{0}\right) \tag{8}
\end{equation*}
$$

for all $t$ with $s+t, r+t \in J_{m}(z)$. Notice that we do not require $t$ to be a positive number. Hence, if the orbits of the two solutions $\phi\left(t, x^{0}\right)$ and $\phi\left(t, y^{0}\right)$ have a point in common, the two orbits are the same.

## (b) Asymptotic Behavior

Given a dynamical system, we are often interested in determining what happens to its solution as $t \rightarrow \infty$ (provided, of course, the solution is defined for all $t \geq 0$ ). If the solution trajectory approaches some simple configuration (e.g., a single point or a closed curve), we can think of this point or set of points as a long-run equilibrium.

For studying the asymptotic behavior of dynamical systems, we need some definitions. In what follows, $\phi\left(t, x^{0}\right)$ is the flow of a (continuous or discrete) dynamical system.

Definition 2.4. Positive or $\omega$ limit point and limit set. A point $y \in X$ is an $\omega$ limit point of the orbit $\gamma\left(x^{0}\right)$ if there exists a sequence of real numbers $\left\{t_{n}\right\} \rightarrow \infty$ such that $\left\{\phi\left(t_{n}, x^{0}\right)\right\} \rightarrow y$ as $n \rightarrow \infty$. That is, $y$ is a positive limit point of $\gamma\left(x^{0}\right)$ if, given any $\varepsilon>0$, there exists some positive integer $n_{\varepsilon}$ such that $\left\|y-\phi\left(t_{n}, x^{0}\right)\right\|<\varepsilon$ for all $n>n_{\varepsilon}$.

The set of all positive limit points of $\gamma\left(x^{0}\right)$ is the positive limit set of the orbit, denoted by $\omega\left(x^{0}\right)$. The concepts of negative (or $\alpha$ ) limit set and limit point can be defined in the same way by reversing the direction of time.

Intuitively, the positive limit set of an orbit is the set of points to which the orbit tends as $t \rightarrow \infty$. For example, a closed orbit or cycle is its own positive limit set, and also that of any other orbit that approaches it asymptotically. This example shows why the definition of limit point must be formulated in terms of a sequence of $t$ 's even if we work in continuous time. Assume that the solution $\phi\left(t, x^{0}\right)$ describes a spiral trajectory $\gamma\left(x^{0}\right)$ that approaches a closed orbit $\Gamma$, as illustrated in Figure 9.4. Because the solution keeps circling around, we cannot say that any one point $y \in \Gamma$ is the limit of $\phi\left(t, x^{0}\right)$ as $t \rightarrow \infty$. However, the figure shows that it is possible to choose a sequence $\left\{t_{n}\right\}$ of points in time such that $\left\{\phi\left(t_{n}, x^{0}\right)\right\} \rightarrow y$ as $n \rightarrow \infty$.

Some subsets of the state space $X$ have the property that any orbit that enters them never leaves (with time running forward, backward, or both). Such a set is said to be invariant under the flow of the system.

Definition 2.5. Invariant set. A set $S$ in $X$ is positively invariant under the flow of a system if, given any $x^{0}$ in $S$, the positive orbit through $x^{0}, \gamma^{+}\left(x^{0}\right)$, is contained in $S$. Equivalently, $S$ is positively invariant if for all $t \geq 0$ we have $\phi(t, S) \subseteq S$. Similarly, $S$ is negatively invariant if $\phi(t, S) \subseteq S$ for $t \leq 0$, and invariant if it is both positively and negatively invariant.

Intuitively, a set $S$ is (i) positively invariant if any trajectory that enters the set remains in it, (ii) negatively invariant if any orbit that contains a point

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-412.jpg?height=617&width=727&top_left_y=191&top_left_x=370)

Figure 9.4. A limit cycle.

of $S$ must have started in $S$, and (iii) invariant if both things are true at the same time.

(c) Steady States and Stability

Consider a discrete-time autonomous system

$$
\begin{equation*}
x_{t+1}=g\left(x_{t}\right) \tag{DS}
\end{equation*}
$$

where $g$ is a continuous function, and let $\left\{x_{t}\right\}$ be a solution sequence for the system. If $\left\{x_{t}\right\}$ converges to a point $x^{*}$ as $t \rightarrow \infty$, the continuity of $g()$ implies that $x^{*}$ itself must be a solution of (DS); that is, if $g()$ is a continuous function, we have

$$
x^{*}=\lim _{t \rightarrow \infty} x_{t+1}=\lim _{t \rightarrow \infty} g\left(x_{t}\right)=g\left(\lim _{t \rightarrow \infty} x_{t}\right)=g\left(x^{*}\right)
$$

Hence, constant solutions play a special role in analyses of the asymptotic behavior of autonomous systems.

Problem 2.6. Show that this is true also for the continuous-time system (CS), $\dot{x}=f(x)$. That is, if

$$
\lim _{t \rightarrow \infty} \phi\left(t, x^{0}\right)=x^{*}
$$

then $x^{*}$ must be a constant solution of (CS) (i.e., $f\left(x^{*}\right)=\underline{0}$.) Hint: Use Theorem 2.3.

Definition 2.7. Steady or stationary state (fixed point, rest point, or equilibrium). A stationary state of a dynamical system is a constant solution of the system. In the case of a discrete system, $x_{t+1}=g\left(x_{t}\right)$, a point $\bar{x} \in X$ is a steady state if it is a fixed point of $g()$, that is, if $\bar{x}=g(\bar{x})$. For the continuous system $\dot{x}=f(x)$, a steady state is a point $\bar{x} \in X$ such that $f(\bar{x})=\underline{0}$ (i.e., a zero of $f($ ).

A steady state or equilibrium of a dynamical system is a rest point of the system, a value $\bar{x}$ of the state vector that, if ever reached, will be preserved forever unless the system is disturbed in some way. In economic applications, a steady state often can be interpreted as a long-run equilibrium.

Given a steady state $\bar{x}$, the question of its stability naturally arises. Consider a system that is initially at rest at an equilibrium point $\bar{x}$, and imagine that it suffers some shock that causes a small deviation from the rest point. What will happen to the system? Will it return to the equilibrium point, or at least remain close to it, or will it get farther and farther away from it over time?

Definition 2.8. Stability. Let $\bar{x}$ be an isolated steady state of the system (CS), $\dot{x}=f(x)$. We say that $\bar{x}$ is a stable equilibrium of (CS) if, given any $\varepsilon>0$, there exists some real number $\delta \in(0, \varepsilon]$ such that

$$
\left\|x\left(t_{0}\right)-\bar{x}\right\|<\delta \quad \text { for some } t_{0} \Rightarrow\|x(t)-\bar{x}\|<\varepsilon \forall t \geq t_{0}
$$

That is, take a ball of arbitrarily small radius $\varepsilon$ centered at $\bar{x}$. If $\bar{x}$ is stable, we can find some $\delta$ (possibly smaller than $\varepsilon$ ) such that any solution $x(t)$ that at some point enters the ball of radius $\delta$ around $\bar{x}$ remains within the ball of radius $\varepsilon$. Figure 9.5 illustrates the definition.

Definition 2.9. Asymptotic stability. A steady state $\bar{x}$ is asymptotically stable if it is stable, and, moreover, $\delta$ can be chosen (in the preceding definition) in such a way that for any solution $x(t)$ that enters $B_{\delta}(\bar{x})$ at some point we have $\lim _{t \rightarrow \infty} x(t)=\tilde{x}$.

That is, trajectories that get sufficiently close to $\bar{x}$ not only remain nearby but also converge to $\bar{x}$ as $t \rightarrow \infty$. (Observe that $x(t)$ cannot reach $\bar{x}$ in finite time, only asymptotically. Otherwise, the uniqueness of solutions would be violated.)

The largest region such that any solution that enters it converges to $\bar{x}$ is called the basin of attraction of $\bar{x}$. If the basin of attraction is the whole of the state space, that is, if $x(t) \rightarrow \bar{x}$ for every initial position $x^{0}$, we say that $\bar{x}$ is globally asymptotically stable.

An equilibrium that is not stable is unstable. In particular, there exists some $\varepsilon>0$ and some solution that, while passing arbitrarily close to the steady state, does not remain within the ball of radius $\varepsilon$ centered at $\bar{x}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-414.jpg?height=556&width=572&top_left_y=186&top_left_x=443)

Figure 9.5. A stable steady state.

## 3. Autonomous Differential Equations

In this section and the next we will study autonomous systems in one dimension, that is, dynamical systems defined by a single autonomous difference or differential equation. For the case of linear systems, we will show how to compute explicit solutions. For nonlinear systems, we will introduce a simple graphical device that can be used to study the qualitative properties of solutions and establish some results that relate the local behavior of a nonlinear system near a steady state $\bar{x}$ to that of the linear system defined by its derivative at $\bar{x}$. In this section we deal with continuous-time systems, leaving the discrete-time case for Section 4.

Consider the first-order differential equation (CS), $\dot{x}=f(x)$, where $f: \mathbb{R} \supseteq$ $X \rightarrow \mathbb{R}$ is a $C^{1}$ function. In the first part of this section we will show how to construct the general solution of this equation when $f()$ is a linear (affine) function. Part (b) deals with nonlinear equations.

## (a) Linear Equations with Constant Coefficients

To construct the general solution of the first-order linear equation with constant coefficients, we start with the simplest case, that of the homogeneous equation

$$
\begin{equation*}
\dot{x}=a x \tag{CH}
\end{equation*}
$$

where $a$ is a real number, and $x()$ a function from $\mathbb{R}$ to itself. This equation can be solved analytically by the method of separation of variables. Rearranging terms in $(\mathrm{CH})$, we can write

$$
\frac{d x}{d t}=a x \Rightarrow \frac{d x}{x}=a d t
$$

and integrating both sides of this expression,

$$
\int \frac{d x}{x}=\int a d t \Rightarrow \ln x=a t+c_{1}
$$

where $c_{1}$ is an arbitrary constant of integration. Taking antilogs, we arrive at

$$
\begin{equation*}
x(t)=c e^{a t} \tag{1}
\end{equation*}
$$

where $c=e^{c_{1}}$ is also an arbitrary constant. This shows that the solution of $(\mathrm{CH})$ must be a function of the form (1). Moreover, any function of this form is a solution of $(\mathrm{CH})$, as we see by differentiating the function given in (1):

$$
\dot{x}(t)=c a e^{a t}=a x(t)
$$

Hence, we have found the general solution of $(\mathrm{CH})$, a family of exponential functions parameterized by an arbitrary constant $c$ :

$$
\begin{equation*}
x^{h}(t, c)=c e^{a t} \tag{2}
\end{equation*}
$$

We now turn to the more general case of the nonhomogeneous equation

$$
\begin{equation*}
\dot{x}=a x+b \tag{CN}
\end{equation*}
$$

where $b$ is a constant. We will solve $(\mathrm{CN})$ by reducing it to a homogeneous equation through a simple change of variables. We define a new variable, $y$, as the deviation of the state variable, $x$, from its steady-state value, $\bar{x}=-b / a{ }^{1}$ Because $\bar{x}$ is a constant and $y=x-\bar{x}$, we have $\dot{y}=\dot{x}$. The original system can then be rewritten in terms of $y$ and $\dot{y}$ :

$$
\dot{x}=a x+b \Rightarrow \dot{y}=a x+b=a\left(x+\frac{b}{a}\right)=a(x-\bar{x})=a y
$$

Notice that by rewriting the equation in terms of deviations from the steady state we have reduced it to the homogeneous equation $\dot{y}=a y$, with solution $y(t, c)=c e^{a t}$. It is now easy to recover the general solution of the original system; because $x(t)=y(t)+\bar{x}$, we have

$$
\begin{equation*}
x^{g}(t, c)=\bar{x}+c e^{a t} \tag{G.S}
\end{equation*}
$$

Let us rewrite the general solution of $(\mathrm{CN})$ in a slightly different way that may throw some light on the meaning of the arbitrary constant $c$. Evaluating the general solution at time zero, we have

$$
x(0)=\bar{x}+c e^{a 0} \Rightarrow c=x(0)-\bar{x}
$$

Thus, $c$ corresponds to the initial deviation of the state variable from its steady-state value. Substituting this expression back into (G.S), we can write the general solution in the form

$$
\begin{equation*}
x\left(t, x^{0}\right)=\bar{x}+[x(0)-\bar{x}] e^{a t} \tag{G.S'}
\end{equation*}
$$

which gives the value of $x$ at time $t$ as a function of time and the system's initial position. It is clear from this expression that specifying a value of $c$ is equivalent to choosing an initial position for the system. Notice, however, that the value of $x(0)$ remains unknown until we specify a boundary condition. ${ }^{2}$

The conditions for the stability or instability of the steady state can be easily determined using either form of the general solution. Rearranging (G.S'), for example, we can write

$$
x\left(t, x^{0}\right)-\bar{x}=[x(0)-\bar{x}] e^{a t}
$$

This expression shows that the stability of $\bar{x}$ depends on the value of the coefficient $a$. If $a$ is positive, any initial deviation from the steady state will grow over time and approach infinity as $t \rightarrow \infty$. Hence, the system displays explosive behavior, except when it happens to start out at the steady state ( $c=0$ or $x(0)=\vec{x}$ ). On the other hand, if $a<0$, the deviation shrinks over time and goes to zero as $t \rightarrow \infty$. Thus, the steady state of the system is asymptotically stable. Figure 9.6 shows the system's trajectory in each case.

We summarize the results of this section in the following theorem.

Theorem 3.1. The first-order linear equation (CN), $\dot{\mathrm{x}}=\mathrm{ax}+\mathrm{b}(\mathrm{a} \neq 0)$, has $a$ unique steady state $\overline{\mathrm{x}}=-\mathrm{b} / \mathrm{a}$ that is asymptotically stable if $\mathrm{a}<0$, and unstable if $\mathrm{a}>0$. The general solution of $(C N)$ is of the form $\mathrm{x}^{\mathrm{g}}(\mathrm{t}, \mathrm{c})=\overline{\mathrm{x}}+\mathrm{ce}^{\mathrm{at}}$, where $\mathrm{c}$ is an arbitrary constant to be definitized by choice of an appropriate boundary condition.

Problem 3.2. When $a=0$, the nonhomogeneous system is of the form $\dot{x}=b$. Using the method of separation of variables, find the general solution of this equation.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-416.jpg?height=502&width=619&top_left_y=1599&top_left_x=105)

stable system: $a<0$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-416.jpg?height=518&width=601&top_left_y=1605&top_left_x=771)

unstable system: $a>0$

Figure 9.6. Solution trajectories of stable and unstable linear systems.

Problem 3.3. There is no particular reason that we should choose to index the solutions of a system by their values at time zero. Rewrite the general solution of the system $(\mathrm{CN})$ as a function of $x(s)$, the value of $x$ at some arbitrary time $s$.

## (b) Nonlinear Autonomous Equations

When we drop the assumption of linearity, closed-form solutions of differential equations are no longer available, except in special cases. When the system is of dimension 1 , however, it is easy to study the qualitative properties of its solutions with the help of a simple graphical device. To construct the phase diagram of the nonlinear equation

$$
\begin{equation*}
\dot{x}=f(x) \tag{CS}
\end{equation*}
$$

we begin by plotting the function $f()$ that gives the time derivative $\dot{x}$ as a function of $x$. The graph of this function is sometimes called the phase line. Notice that the intersections of the phase line with the horizontal axis correspond to the steady states of the system. The steady states, moreover, divide the horizontal axis into a number of intervals. The next step involves checking whether the function $f()$ lies above or below the axis in each of these regions. If $\dot{x}=f(x)>0$ in a given interval (i.e., if the phase line lies above the axis), then $x$ increases over time in this interval - a fact that can conveniently be indicated by an "arrow of motion" pointing to the right (Figure 9.7). Similarly, if $f()$ lies below the axis, the derivative of $x$ with respect to time is negative. Hence, the variable decreases over time, and the arrow that describes the motion of $x$ points to the left.

Once we have constructed the phase diagram, it is easy to determine the system's trajectory from any given initial point $x(0)$. The idea is simply to follow the arrows of motion from $x(0)$ to the closest steady state, provided there is one in the direction of motion of $x$. Otherwise, $x$ is always increasing or always decreasing. For example, in Figure 9.7 we have the following:

(i) Any trajectory that starts from an initial point below $\bar{x}_{1}$, or lying on the interval between $\bar{x}_{1}$ and $\bar{x}_{2}$, converges to $\bar{x}_{1}$ as $t$ goes to infinity.

(ii) If the starting value of $x$ is larger than $\bar{x}_{2}$, the solution converges to $\bar{x}_{3}$.

The phase diagram can also be used to determine whether or not each of the steady states is stable. If the phase line cuts the horizontal axis from above at $\bar{x}$, then $\bar{x}$ is a stable equilibrium, for the arrows of motion of the system point toward the steady state from both sides. That is, if for all $x$ in some neighborhood of a steady state $\bar{x}$ we have

$$
x<\bar{x} \Rightarrow \dot{x}>0 \text { and } \quad x>\bar{x} \Rightarrow \dot{x}<0
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-418.jpg?height=729&width=1173&top_left_y=180&top_left_x=143)

Figure 9.7. Phase diagram for a scalar continuous system.

then $\bar{x}$ is asymptotically stable: If $x(t)<\bar{x}$, then $\dot{x}(t)>0$, and therefore $x$ increases over time, getting closer to $\bar{x}$. Moreover, because $\dot{x}$ is strictly positive as long as $x<\bar{x}$, the trajectory cannot stop before reaching the stationary point. Similarly, if for all $x$ in some open neighborhood of a stationary point $\bar{x}$ we have

$$
x<\bar{x} \Rightarrow \dot{x}<0 \text { or } \quad x>\bar{x} \Rightarrow \dot{x}>0
$$

then $\bar{x}$ is unstable, for trajectories that start close to the steady state tend to move away from it, at least from one side. Thus, if the phase line cuts the horizontal axis from below, the steady state is unstable, as suggested by Figure 9.7 (compare $\bar{x}_{1}$ and $\bar{x}_{2}$ ).

In summary, we have the following lemma.

Lemma 3.4. A stationary state $\overline{\mathrm{x}}$ of the scalar equation $\dot{\mathrm{x}}=\mathrm{f}(\mathrm{x})$ is stable if and only if there exists some $\delta>0$ such that for all $\mathrm{x} \in \mathrm{B}_{\delta}(\overline{\mathrm{x}})$ we have

$$
(\mathrm{x}-\overline{\mathrm{x}}) \mathrm{f}(\mathrm{x})<0
$$

and unstable if there exists some $\delta>0$ such that

$$
(\mathrm{x}-\overline{\mathrm{x}}) \mathrm{f}(\mathrm{x})>0
$$

for all $\mathrm{x}$ in $(\overline{\mathrm{x}}-\delta, \overline{\mathrm{x}})$ or $(\overline{\mathrm{x}}, \overline{\mathrm{x}}+\delta)$.

Using this result, it is easy to obtain sufficient conditions for the asymptotic stability or instability of a stationary state $\bar{x}$ of a nonlinear equation in
terms of the derivative of $f()$ at $\bar{x}$. Notice that in order to determine whether or not $\bar{x}$ is stable, it is enough to know in what direction $f$ cuts the horizontal axis at this point. If the phase line cuts the horizontal axis transversally, the derivative will tell us. On the other hand, because a zero derivative at the steady state gives no information about the direction of the crossing, nothing can be said about the stability of the system without additional information. We have, then, the following theorem.

Theorem 3.5. Local stability by linearization. Assume that $\mathrm{f}$ is $\mathrm{C}^{l}$, and let $\overline{\mathrm{x}}$ be a stationary solution of the equation (CS), $\dot{\mathrm{x}}=\mathrm{f}(\mathrm{x})$, with $\mathrm{f}^{\prime}(\overline{\mathrm{x}}) \neq 0$. Then $\overline{\mathrm{x}}$ is asymptotically stable if $\mathrm{f}^{\prime}(\overline{\mathrm{x}})<0$, and unstable if $\mathrm{f}^{\prime}(\overline{\mathrm{x}})>0$.

Proof. We star: by rewriting the original system (1), $\dot{x}=f(x)$, in deviations from the steady state. Putting $h=x-\bar{x}$, equation (1) yields (2), $\dot{h}=\dot{x}=f(\bar{x}+$ $h)$. Next, let $\varphi(h)$ be the error committed when we approximate $f()$ by its differential at $\bar{x}$, that is,

$$
\varphi(h)=f(\bar{x}+h)-f^{\prime}(\bar{x}) h, \quad \text { with } \varphi^{\prime}(h)=f^{\prime}(\bar{x}+h)-f^{\prime}(\bar{x})
$$

and observe that $\varphi(0)=0$ and $\varphi^{\prime}(0)=0$ and that $\varphi()$ inherits the continuous differentiability of $f()$. Thus, we can write (2) in the form

$$
\begin{equation*}
\dot{h}=f^{\prime}(\bar{x}) h+\varphi(h) \tag{3}
\end{equation*}
$$

that is, as the sum of a linear system and a perturbation term that, by the differentiability of $f()$, will be "small" close to $\bar{x}$.

Fix some positive $\varepsilon$ such that $\varepsilon<\left|f^{\prime}(\bar{x})\right|$. By the continuous differentiability of $f\left(\right.$ ), there exists some $\delta>0$ such that $\left|\varphi^{\prime}(s)\right|=\left|f^{\prime}(\bar{x}+s)-f^{\prime}(\bar{x})\right|<\varepsilon$ for all $s \in B_{\delta}(0)$. Using the identity

$$
\varphi(h)=\varphi(0)+\int_{0}^{h} \varphi^{\prime}(s) d s=\int_{0}^{h} \varphi^{\prime}(s) d s
$$

we have

$$
|\varphi(h)|=\left|\int_{0}^{h} \varphi^{\prime}(s) d s\right| \leq \int_{0}^{h}\left|\varphi^{\prime}(s)\right| d s \leq \varepsilon|h|<\left|f^{\prime}(\bar{x}) h\right|
$$

for all $h$, with $|h|<\delta$. It follows from this expression and from (3) that for $h$ sufficiently close to zero, the sign of $\dot{h}$ (and hence that of $\dot{x}$ ) is determined by the linear term $f^{\prime}(\bar{x}) h=f^{\prime}(\bar{x})(x-\bar{x})$ and does not depend on the signs of the higher-order terms in the Taylor-series expansion of $f()$, which are captured by the remainder $\varphi(h)$.

Using Lemma 3.2, we see that (2), and hence (1), are stable if and only if $f^{\prime}(\bar{x})<0$. Notice that $f^{\prime}(\bar{x})<0$ implies that $h$ and $\dot{h}$ (and hence $\dot{x}$ ) have opposite signs. For example, if $h$ is positive ( $x$ is above its steady-state value), then
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-420.jpg?height=1128&width=1298&top_left_y=190&top_left_x=86)

Figure 9.8. Nonhyperbolic steady states.

$\dot{x}$ is negative ( $x$ decreases with time). Hence, a strictly negative derivative implies local stability, and by a similar argument, a strictly positive derivative implies that the steady state is unstable.

In conclusion, under the assumptions of the theorem, the original system and its linearization yield the same sign for $\dot{x}$ in some neighborhood of a given stationary point. Hence, we can infer the local stability properties of the original system from those of its linear approximation.

A stationary state $\bar{x}$ is said to be hyperbolic if $f^{\prime}(\bar{x}) \neq 0$, and nonhyperbolic if $f^{\prime}(\bar{x})=0$. The theorem says that linearization (i.e., the approximation of a nonlinear system by the linear system given by its derivative at a steady state) works well around hyperbolic equilibria. Figure 9.8 shows why hyperbolicity is needed: A zero derivative gives no information concerning the way in which the phase line crosses the horizontal axis, and therefore no information concerning stability.

## (c) A Note on Comparative Dynamics

Consider a parameterized dynamical system

$$
\begin{equation*}
\dot{x}=f(x, \alpha) \tag{CS}
\end{equation*}
$$

where $f()$ is a $C^{1}$ function. As we will show in Section 6, a solution $x(t, \alpha)$ of this system is a differentiable function of $t$ and $\alpha$. In this section we will show how to compute the partial derivative of the solution function $x(t, \alpha)$ with respect to the parameter $\alpha$.

The procedure is similar to the one we followed in Chapter 5 to analyze the comparative statics of the solutions to parameterized systems of static equations. Notice that the solution function $x(t, \alpha)$ satisfies identically the original system, that is,

$$
\begin{equation*}
\dot{x}(t, \alpha) \equiv f[x(t, \alpha), \alpha] \tag{1}
\end{equation*}
$$

Because this is an identity, we can differentiate both sides of (1) with respect to the parameter vector, $\alpha$, obtaining

$$
\begin{equation*}
\frac{\partial \dot{x}(t, \alpha)}{\partial \alpha}=f_{x}[x(t, \alpha), \alpha] x_{\alpha}+f_{\alpha}[x(t, \alpha), \alpha] \tag{2}
\end{equation*}
$$

Assume further that the order of differentiation can be inverted in the expression on the left-hand side of (2), so that

$$
\frac{\partial \dot{x}(t, \alpha)}{\partial \alpha} \equiv \frac{\partial^{2} x(t, \alpha)}{\partial t \partial \alpha}=\frac{\partial^{2} x(t, \alpha)}{\partial \alpha \partial t} \equiv \dot{x}_{\alpha}
$$

Then equation (2) yields the differential equation

$$
\begin{equation*}
\dot{x}_{\alpha}=f_{x}() x_{\alpha}+f_{\alpha}() \tag{3}
\end{equation*}
$$

where $f_{x}()$ and $f_{\alpha}()$ are evaluated along the solution trajectory, $x(t, \alpha)$. Hence, the derivative of interest, $x_{\alpha}$, satisfies a linear differential equation. The solution of this equation will give us the trajectory of $x_{\alpha}(t)$, that is, the derivative of $x$ with respect to the parameter at each point in the solution trajectory.

In general, it is difficult to solve (3) along an arbitrary solution trajectory, but there is a special case that can be easily handled. This is the case in which we are initially in a steady state, for then (3) is evaluated along a constant trajectory and is therefore an autonomous linear equation. In this case, the general solution of (3) is of the form

$$
\begin{equation*}
x_{\alpha}(t)=x_{\alpha}(\infty)+\left[x_{\alpha}(0)-x_{\alpha}(\infty)\right] e^{f_{x} t}=x_{\alpha}(0) e^{f_{x} t}+x_{\alpha}(\infty)\left(1-e^{f_{x} t}\right) \tag{4}
\end{equation*}
$$

where $f_{x}$ is a constant and $x_{\alpha}(\infty)$ is the solution of

$$
\dot{x}_{\alpha}=0 \Rightarrow x_{\alpha}(\infty)=\frac{-f_{\alpha}()}{f_{x}()}=\frac{\partial \bar{x}}{\partial \alpha}
$$

Notice that $x_{\alpha}(\infty)$ is also the comparative-statics partial derivative of $x$ across steady states and can therefore be interpreted as the long-run effect of the parameter change when the system converges to a new steady state. Hence, equation (4) tells us that the impact of the parameter change at time $t$ can be written as a weighted average of its immediate or impact effect, $x_{\alpha}(0)$, and its long-run effect, $x_{\alpha}(\infty)$.

It remains to determine the appropriate initial condition for equation (4), and this typically requires thinking about the economics of the problem. For example, if $x$ is a predetermined variable, the impact effect will be zero. If $x$ is a free variable, however, in some cases we can jump directly to the new steady state, that is, $x_{\alpha}(0)=x_{\alpha}(\infty)$. (The reader should refer to Chapter 11 for a discussion of some of these issues in the context of a specific model.)

## 4. Autonomous Difference Equations

We now turn to the scalar system in discrete time (DS), $x_{t+1}=g\left(x_{t}\right)$, where $g: \mathbb{R} \supseteq X \longrightarrow \mathbb{R}$ is a $C^{1}$ function. The discussion closely parallels that of the preceding section. We will first show how the solution can be obtained in the linear case. We shall then discuss two methods, one of them graphical and the other analytic, that can be used to obtain information about the qualitative properties of the solutions of nonlinear equations.

## (a) Linear Equations with Constant Coefficients

The homogeneous equation

$$
\begin{equation*}
x_{t+1}=a x_{t} \tag{DH}
\end{equation*}
$$

where $a, x \in \mathbb{R}$, can be solved by iteration. Because (DH) holds for all periods, we have

$$
x_{t}=a x_{t-1}, \quad x_{t-1}=a x_{t-2}
$$

and so on. Starting at time $t$, and substituting recursively, we have

$$
x_{t}=a x_{t-1}=a\left(a x_{t-2}\right)=a^{2} x_{t-2}=a^{2}\left(a x_{t-3}\right)=a^{3} x_{t-3}=\ldots=a^{t} x_{0}
$$

Because the initial value of the state variable, $x_{0}$, remains undetermined in the absence of a boundary condition, what this expression says is that all solutions of (DH) must be functions of the form $x_{t}=c a^{t}$, where $c$ is an arbitrary constant. Moreover, it is easy to see that any function of the form $x_{t}=c a^{t}$ (where $t$ is an integer) satisfies (DH):

$$
x_{t}=c a^{t}=a\left(c a^{t-1}\right)=a x_{t-1}
$$

Thus, we have identified the general solution of the homogeneous equation (DH), which we write

$$
x_{t}^{h}(c)=c a^{t}
$$

As in the continuous-time case, the general solution of the nonhomogeneous equation,

$$
\begin{equation*}
x_{t+1}=a x_{t}+b \tag{DN}
\end{equation*}
$$

is readily obtained through a change of variable that reduces (DN) to a homogeneous equation in deviations from the steady state, $\bar{x}=b /(1-a) .^{3}$ Subtracting $\bar{x}$ from both sides of (DN),

$$
x_{t+1}-\bar{x}=a x_{t}+b-\frac{b}{1-a}=a x_{t}-\frac{b a}{1-a} \Rightarrow x_{t+1}-\bar{x}=a\left(x_{t}-\bar{x}\right)
$$

Thinking of $x_{t}-\bar{x}$ as a single variable, we now have a homogeneous equation whose solution is given by

$$
x_{t}-\bar{x}=c a^{t}
$$

Rearranging terms, the general solution of the nonhomogeneous equation can be written

$$
\begin{equation*}
x_{t}^{g}(c)=\bar{x}+c a^{t}=\bar{x}+x_{t}^{h}(c) \tag{GS}
\end{equation*}
$$

where $x_{t}^{h}(c)=c a^{t}$ (the so-called complementary function) is the general solution of the homogeneous equation $x_{t+1}=a x_{t}$.

Evaluating (GS) at time zero, we can solve for $c$ as a function of the initial value of the state variable: ${ }^{4}$

$$
x_{0}=\bar{x}+c a^{0} \Rightarrow c=x_{0}-\bar{x}
$$

Substituting this expression into (GS), we get an alternative form of the general solution:

$$
x_{t}^{g}\left(x_{0}\right)=\bar{x}+\left(x_{0}-\bar{x}\right) a^{t}
$$

This expression says that the deviation of $x$ from its steady-state value $\bar{x}$ at time $t$ depends on the initial deviation, the time spanned since the system was set in motion, and the value of $a$. If $x_{t}$ starts out at the steady state ( $x_{0}$ $=\bar{x}$ ), the term $\left(x_{0}-\bar{x}\right) a^{t}$ is always zero, and the system remains at the rest point forever.

If, on the other hand, $x_{0} \neq \vec{x}$, then the system is not initially at rest. What happens then will depend on the absolute value of $a$. If $|a|<1$, the term $\left(x_{0}\right.$ $-\bar{x}) a^{t}$ approaches zero: The initial deviation decreases over time, and the
system gradually returns to its stationary state, which is therefore asymptotically stable. If $|a|>1$, we have $\left|\left(x_{0}-\bar{x}\right) a^{t}\right| \rightarrow \pm \infty$ as $t \rightarrow \infty$, and the steady state is unstable. Hence the stability of the unique steady state of the system depends on the absolute value of the coefficient $a$.

Finally, the sign of $a$ determines whether the path of the system is monotonic or oscillatory. If $a>0$, the term $c a^{t}$ has the same sign for all $t$, and the system converges or diverges monotonically. If $a<0$, on the other hand, $a^{t}$ is positive or negative as $t$ is even or odd, and the system jumps from one side of $\bar{x}$ to the other each period. We summarize in the following theorem.

Theorem 4.1. The first-order linear equation $(D N), \mathrm{x}_{\mathrm{t}+\mathrm{l}}=\mathrm{ax}_{\mathrm{t}}+\mathrm{b}(\mathrm{a} \neq 1)$, has a unique steady state $\overline{\mathrm{x}}=\mathrm{b} /(1-\mathrm{a})$ that is asymptotically stable if $|\mathrm{a}|<1$, and unstable if $|\mathrm{a}|>1$. The general solution of $(N)$ is of the form $\mathrm{x}_{\mathrm{i}}^{\mathrm{s}}(\mathrm{c})=\overline{\mathrm{x}}+\mathrm{ca}^{\mathrm{t}}$, where $\mathrm{c}$ is an arbitrary constant to be definitized by choice of an appropriate boundary condition.

## (b) Nonlinear Equations

We now consider the case of the nonlinear equation

$$
\begin{equation*}
x_{t+1}=g\left(x_{t}\right) \tag{DS}
\end{equation*}
$$

where $g: \mathbb{R} \supseteq X \longrightarrow \mathbb{R}$. The first part of this section deals with the construction of the phase diagram of (DS), and the second introduces the method of linearization.

## (i) Phase Diagrams

To analyze the behavior of difference equations in a single variable we can use a graphical procedure very similar to the one we discussed in the preceding section for the case of differential equations. To construct the phase diagram of the discrete-time system (DS), we plot the function $g()$ in the $\left(x_{t}, x_{t+1}\right)$ plane along with a $45^{\circ}$ line going through the origin. The phase line (the graph of $g()$ ) now gives us next period's value of $x$ as a function of its current value, and the $45^{\circ}$ line can be used to project the value of $x$ from one axis to the other. Combining the two lines, it is easy to reconstruct the time path of $x$. Given an initial value $x_{0}$, we use the graph of $g()$ to obtain the value of $x$ at time $1\left(x_{t+1}=x_{1}=g\left(x_{0}\right)\right)$. Using the $45^{\circ}$ line, we then project $x_{1}$ to the horizontal axis, use $g()$ again to find the next value of $x$, and so on, as illustrated in Figure 9.9.

The steady states of the system now correspond to the intersections of the phase line and the $45^{\circ}$ line. At any such point we have $x_{t+1}=g\left(x_{t}\right)=x_{t}$, implying that $x$ remains constant over time $\left(\Delta x_{t}=x_{t+1}-x_{t}=0\right)$. To determine the
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-425.jpg?height=608&width=1338&top_left_y=192&top_left_x=70)

Figure 9.9. Phase diagram for a discrete-time system.

direction of the arrows of motion, observe that in those regions in which the phase line lies above the $45^{\circ}$ line we have

$$
x_{t+1}=g\left(x_{t}\right)>x_{t} \quad \text { or } \quad \Delta x_{t}=x_{t+1}-x_{t}=g\left(x_{t}\right)-x_{t}>0
$$

Hence, $x_{t}$ increases over time, and the arrows of motion along the horizontal axis point to the right. When the phase line lies below the $45^{\circ}$ line, on the other hand, we have $x_{t+1}=g\left(x_{t}\right)<x_{t}$, so $x_{t}$ decreases over time, and the arrows of motion point to the left.

The procedure is very similar to the one we used in the case of a differential equation, but there are some differences between the two types of systems. In particular, the fact that the variable $x$ now moves in discrete jumps makes it necessary to be a bit careful when it comes to analyzing the stability of the steady states and allows the emergence of some phenomena, such as cyclical behavior patterns, that cannot arise in the case of differential equations in a single variable.

The notion of stability of a steady state is the same as for continuous-time systems. A steady state $\bar{x}$ of (DS) is stable if any solution trajectory that starts sufficiently close to $\bar{x}$ converges to this point, and unstable if there exist trajectories that start arbitrarily close to $\bar{x}$ and eventually get far from it. The only problem is that in the case of a discrete-time system, it is not always possible to determine whether or not a given steady state is stable by checking the direction of the arrows of motion in a neighborhood of this point. In particular, when the phase line is downward-sloping over some interval, $x$ can "jump" from one side of the steady state to the other, and it is possible for a steady state to be unstable even though all the arrows of motion point toward it.

This problem does not arise when the phase line is always upward-sloping. To see this, assume that $g()$ is differentiable. By the mean-value theorem, we can write

$$
g\left(x_{t+1}\right)=g\left(x_{t}\right)+g^{\prime}\left(x^{0}\right)\left(x_{t+1}-x_{t}\right)
$$

where $x^{0}$ is some point lying on the line segment that joins $x_{t}$ and $x_{t+1}$. Subtracting $x_{t+1}$ from both sides of this expression, and recalling that $x_{t+1}=g\left(x_{t}\right)$, we have

$$
g\left(x_{t+1}\right)-x_{t+1}=g\left(x_{t}\right)+g^{\prime}\left(x^{0}\right)\left(x_{t+1}-x_{t}\right)-x_{t+1}=g^{\prime}\left(x^{0}\right)\left[g\left(x_{t}\right)-x_{t}\right]
$$

If $g()$ is always increasing, we have $g^{\prime}\left(x^{0}\right)>0$ for any $t$, and it follows that the terms $\left[g\left(x_{t+1}\right)-x_{t+1}\right]$ and $\left[g\left(x_{t}\right)-x_{t}\right]$ must have the same sign. That is, $g\left(x_{t}\right)$ $>x_{t}$ implies $g\left(x_{t+1}\right)>x_{t+1}$, and $g\left(x_{t}\right)<x_{t}$ implies $g\left(x_{t+1}\right)<x_{t+1}$. Hence, if the phase line is above the $45^{\circ}$ line at time $t$, it will also lie above it at $t+1$. This implies that the trajectories of $x$ cannot "cross" a steady state. Thus, the problems mentioned earlier cannot arise when $g()$ is always increasing.

In conclusion, when the function $g()$ is increasing, we can determine the stability of the steady states by checking the directions of the arrows of motion, just as in the case of a continuous-time system. When this is not the case, we need to be more careful. As an illustration, Figure 9.10 shows the different situations that can arise in the case of a linear equation of the form $x_{t+1}=a x_{t}+b$.

## (ii) Linearization

Given the nonlinear equation

$$
\begin{equation*}
x_{t+1}=g\left(x_{t}\right) \tag{DS}
\end{equation*}
$$

where $g$ is a $C^{1}$ function, we can use Taylor's formula to construct a linear approximation to (DS) in some neighborhood of a fixed point $\bar{x}$ :

$$
\begin{equation*}
x_{t+1} \cong g(\bar{x})+g^{\prime}(\bar{x})\left(x_{t}-\bar{x}\right) \tag{L}
\end{equation*}
$$

Intuitively, it may be expected that the linear equation (L), called the linearization of (DS), will be a "good approximation" to the nonlinear equation (DS) whenever $x$ is close to $\bar{x}$. As we will soon see, this is true in most cases. As a result, the method of linearization allows us to obtain information concerning the local behavior of a nonlinear system by studying the linear approximation given by its derivative at the steady state.

The following result says, in particular, that provided $\left|g^{\prime}(\bar{x})\right| \neq 1$, the nonlinear system (DS) is (locally) stable if and only if its linearization is stable.

Theorem 4.2. Local stability by linearization. Let $\mathrm{g}$ be a $\mathrm{C}^{\prime}$ function. $A$ fixed point $\overline{\mathrm{x}}$ of the equation $(D S), \mathrm{x}_{\mathrm{t}+1}=\mathrm{g}\left(\mathrm{x}_{\mathrm{t}}\right)$, is asymptotically stable if $\left|\mathrm{g}^{\prime}(\overline{\mathrm{x}})\right|<1$, and unstable if $\left|\mathrm{g}^{\prime}(\overline{\mathrm{x}})\right|>1$.
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-427.jpg?height=508&width=1196&top_left_y=164&top_left_x=102)

Case 1: $a \in(0,1)$, Monotone convergence to a stable fixed point
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-427.jpg?height=504&width=1216&top_left_y=741&top_left_x=102)

Case 2: $a \in(-1,0)$, Oscillatory convergence to a stable fixed point
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-427.jpg?height=508&width=1228&top_left_y=1313&top_left_x=90)

Case 3: $a>1$, Unstable fixed point, monotone divergence

Figure 9.10. Phase diagrams and trajectories of $x$ for linear equations.
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-428.jpg?height=592&width=1288&top_left_y=183&top_left_x=86)

Case 4: $a<-1$, Unstable fixed point, oscillatory divergence
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-428.jpg?height=576&width=1300&top_left_y=921&top_left_x=88)

Case 5: $\mathbf{a}=-1$, orbits are two-period cycles

Figure 9.10. Continued

Proof. We can assume, with no loss of generality, that the fixed point $\bar{x}$ is at the origin, that is, $g(0)=0$. (Otherwise, we simply translate the origin to the point ( $\bar{x}, g(\bar{x})$ ) by an appropriate coordinate change.) For any given $\varepsilon>0$, we define $m_{\varepsilon}$ and $M_{\varepsilon}$ by

$$
m_{\varepsilon} \equiv \min \left\{\left|g^{\prime}(x)\right| ;|x| \leq \varepsilon\right\} \quad \text { and } \quad M_{\varepsilon} \equiv \max \left\{\left|g^{\prime}(x)\right| ;|x| \leq \varepsilon\right\}
$$

To prove each part of the theorem we will make use of the following identity:

$$
\begin{equation*}
g(x)=g(0)+\int_{0}^{x} g^{\prime}(s) d s=\int_{0}^{x} g^{\prime}(s) d s \tag{1}
\end{equation*}
$$

(i) Condition for local stability. Assume that $\left|g^{\prime}(0)\right|<1$. By the continuity of $g^{\prime}()$, we can find some $\varepsilon>0$ such that $M_{\varepsilon}<1$. Fix such an $\varepsilon$, and let $x$ be an arbitrary point in $B_{\varepsilon}(0)$. Then we have $\left|g^{\prime}(x)\right| \leq M_{\varepsilon}<1$. We will use this fact to show that the positive orbit through $x$ converges to the steady state $\bar{x}=0$ (i.e., that $g^{n}(x) \rightarrow 0$ as $\left.n \rightarrow \infty\right)$.

Using the identity (1), we have

$$
\begin{equation*}
|g(x)|=\left|\int_{0}^{x} g^{\prime}(s) d s\right| \leq \int_{0}^{x}\left|g^{\prime}(s)\right| d s \leq M_{\varepsilon}|x|<|x| \tag{2}
\end{equation*}
$$

(because $|x| \leq \varepsilon$ ). Hence $g(x)$ also lies in $B_{\varepsilon}(0)$. Next, consider the second iteration of $g, g^{2}(x)=g[g(x)]$. By the chain rule, we have

$$
\frac{d g^{2}(x)}{d x}=g^{\prime}[g(x)] g^{\prime}(x) \leq M_{\varepsilon} M_{\varepsilon}=M_{\varepsilon}^{2}
$$

where the inequality follows from the fact that both $x$ and $g(x)$ lie in $B_{\varepsilon}(0)$.

By the same argument, we see that

$$
\left|g^{2}(x)\right|=\left|\int_{0}^{x} \frac{d g^{2}(s)}{d s} d s\right| \leq M_{\varepsilon}^{2}|x|
$$

and so on, yielding

$$
\left|g^{n}(x)\right| \leq M_{\varepsilon}^{n}|x|
$$

Finally, because $M_{\varepsilon}<1, M_{\varepsilon}^{n} \rightarrow 0$ as $n \rightarrow \infty$. It follows that for every $x \in B_{\varepsilon}(0)$, $g^{n}(x) \rightarrow 0$ as $n \rightarrow \infty$. That is, the fixed point $\bar{x}=0$ is asymptotically stable when $\left|g^{\prime}(0)\right|<1$.

(ii) Condition for local instability. Given any $\varepsilon>0$ and any $x$ in $B_{\varepsilon}(0)$, observe that ${ }^{5}$

$$
|g(x)|=\left|\int_{0}^{x} g^{\prime}(s) d s\right| \geq m_{\varepsilon}|x|
$$

Assume that $\left|g^{\prime}(0)\right|>1$. Then we can choose $\varepsilon>0$ and arbitrarily small in such a way that $m_{\varepsilon}>1+\gamma$, where $\gamma>0$. Fix some $\varepsilon>0$ with this property, and let $x$ be any point of $B_{\varepsilon}(0)$, with $x \neq 0$ (i.e., any point different from the steady state). To show that the positive orbit through $x$ must eventually leave $B_{\varepsilon}(0)$, we will proceed by contradiction. Assume that $g^{n}(x) \in B_{\varepsilon}(0)$ for all $n$. Then we have

$$
\frac{d g^{2}(x)}{d x}=g^{\prime}[g(x)] g^{\prime}(x) \geq m_{\varepsilon}^{2}
$$

and

$$
\left|g^{2}(x)\right|=\left|\int_{0}^{x} \frac{d g^{2}(x)}{d x} d s\right| \geq m_{\varepsilon}^{2}|x|>(1+\gamma)^{2}|x|
$$

By the same argument, we obtain

$$
\left|g^{n}(x)\right| \geq m_{\varepsilon}^{n}|x|>(1+\gamma)^{n}|x|
$$

whenever $g^{n-1}(x) \in B_{\varepsilon}(0)$. Because $(1+\gamma)^{n}|x| \rightarrow \infty$ as $n \rightarrow \infty($ as $x \neq 0)$, and $\varepsilon$ is a fixed number, we arrive at a contradiction, for if $\left|g^{n}(x)\right| \rightarrow \infty$, then it cannot stay within $B_{\varepsilon}(0)$ for all time. Hence the origin is an unstable fixed point, as the orbit through a point $x$ arbitrarily close to it must eventually leave $B_{\varepsilon}(0)$, although it could remain within a larger ball.

Notice that the theorem says nothing about the stability or instability of those fixed points at which the derivative $g^{\prime}(\bar{x})$ is equal to 1 in absolute value. Such steady states are said to be nonhyperbolic, and all the rest are hyperbolic. As in the case of differential equations, the derivative does not give us sufficient information to determine whether or not a nonhyperbolic equilibrium is stable. Figure 9.11 illustrates the point: Both systems have derivative 1 at the steady state, but each of them is stable from a different side, and unstable from the other.

Problem 4.3. Comparative dynamics for discrete systems. Let $x(t, \alpha)$ be the solution function of the parameterized discrete system (DS $(\alpha)$ ), $x_{t+1}=g\left(x_{t}, \alpha\right)$, where $g()$ is a $C^{1}$ function. Proceeding as in Section 3(c), show that the partial derivative of the solution function with respect to the parameter

$$
x_{\alpha}(t, \alpha)=\frac{\partial x(t, \alpha)}{\partial \alpha}
$$

satisfies a linear difference equation. Write the solution of this equation for the special case where $x(t, \alpha)$ is a steady-state solution of $(\operatorname{DS}(\alpha))$.
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-430.jpg?height=650&width=1266&top_left_y=1473&top_left_x=108)

Figure 9.11. Nonhyperbolic steady states of a discrete system.

## 5. Solution of Nonautonomous Linear Equations

We want to compute the solution of the first-order, nonautonomous linear equation

$$
\begin{equation*}
\dot{x}(t)=a(t) x(t)+b(t) \tag{1}
\end{equation*}
$$

where the coefficients $a$ and $b$ are continuous functions of time.

Rewrite (1) in the form

$$
\begin{equation*}
\dot{x}(t)-a(t) x(t)=b(t) \tag{2}
\end{equation*}
$$

and consider the function

$$
\begin{equation*}
e^{-\alpha(t)}, \quad \text { with } \alpha(t)=\int_{0}^{t} a(s) d s \tag{3}
\end{equation*}
$$

where

$$
\begin{equation*}
\frac{d e^{-\alpha(t)}}{d t}=-e^{-\alpha(t)} a(t) \tag{4}
\end{equation*}
$$

Multiplying both sides of (2) by $e^{-\alpha(t)}$,

$$
\begin{equation*}
e^{-\alpha(t)}[\dot{x}(t)-a(t) x(t)]=b(t) e^{-\alpha(t)} \tag{5}
\end{equation*}
$$

Notice that we have defined $e^{-\alpha(t)}$ in such a way that the left-hand side of (5) is the derivative of the product $e^{-\alpha(t)} x(t)$, for

$$
\frac{d}{d t}\left(e^{-\alpha(t)} x(t)\right)=e^{-\alpha(t)} \dot{x}(t)-x(t) a(t) e^{-\alpha(t)}
$$

Hence, we can write (5) in the form

$$
\begin{equation*}
\frac{d}{d t}\left(e^{-\alpha(t)} x(t)\right)=b(t) e^{-\alpha(t)} \tag{6}
\end{equation*}
$$

We will use this expression to derive two (equivalent) forms of the general solution of equation (1). To derive the first form, we integrate both sides of (6) "backward" between zero and $s$, obtaining

$$
\begin{align*}
& \int_{0}^{s} \frac{d}{d t}\left(e^{-\alpha(t)} x(t)\right) d t=\left.\int_{0}^{s} b(t) e^{-\alpha(t)} d t \Rightarrow e^{-\alpha(t)} x(t)\right|_{0} ^{s}=\int_{0}^{s} b(t) e^{-\alpha(t)} d t \\
& \quad \Rightarrow e^{-\alpha(s)} x(s)-1 x(0)=\int_{0}^{s} b(t) e^{-\alpha(t)} d t \\
& \quad \Rightarrow x(s)=x(0) e^{\alpha(s)}+\int_{0}^{s} b(t) e^{\alpha(s)-\alpha(t)} d t \tag{7}
\end{align*}
$$

This expression, sometimes called the backward solution of equation (1), gives us the value of $x(s)$ in terms of its initial value $x(0)$ and a weighted
sum of the past values of the forcing term, $b(t)$. This form of the solution is particularly convenient when the system has a natural initial condition, that is, when $x(0)$ is a predetermined constant. Otherwise the second form of the general solution (the so-called forward solution) may be more useful.

To derive the forward solution, we integrate both sides of (6) forward between $s$ and infinity,

$$
\int_{s}^{\infty} \frac{d}{d t}\left(x(t) e^{-\alpha(t)}\right) d t=\int_{s}^{\infty} b(t) e^{-\alpha(t)} d t
$$

obtaining

$$
\lim _{t \rightarrow \infty} x(t) e^{-\alpha(t)}-x(s) e^{-\alpha(s)}=\int_{s}^{\infty} b(t) e^{-\alpha(t)} d t
$$

or

$$
\begin{equation*}
x(s)=e^{\alpha(s)} \lim _{t \rightarrow \infty} x(t) e^{-\alpha(t)}-\int_{s}^{\infty} b(t) e^{\alpha(s)-\alpha(t)} d t \tag{8}
\end{equation*}
$$

provided the required limits exist.

Define the fundamental solution of (1), denoted by $F(s)$, by

$$
\begin{equation*}
F(s)=-\int_{s}^{\infty} b(t) e^{\alpha(s)-\alpha(t)} d t \tag{9}
\end{equation*}
$$

and assume that this integral converges for all $s$. Using the backward solution (7), and taking limits as $t \rightarrow \infty$, we have

$$
\begin{align*}
\lim _{t \rightarrow \infty} x(t) e^{-\alpha(t)} & =x(0)+\lim _{t \rightarrow \infty} \int_{0}^{t} b(u) e^{-\alpha(u)} d u=x(0)+\int_{0}^{\infty} b(u) e^{-\alpha(u)} d u \\
& =x(0)-F(0) \tag{10}
\end{align*}
$$

Hence, this limit exists by the assumption that $F()$ converges, and substituting (9) and (10) into (8) we can write the forward solution in the form

$$
\begin{equation*}
x(s)=[x(0)-F(0)] e^{\alpha(s)}+F(s) \tag{11}
\end{equation*}
$$

We sometimes refer to the first term on the right-hand side of (11) as the bubble term of the forward solution of (1). ${ }^{6}$

The following problem asks the reader to work out the forward and backward solutions of a discrete-time system.

Problem 5.1. Consider the first-order difference equation

$$
\begin{equation*}
x_{t}=a x_{t-1}+b_{t-1} \tag{1}
\end{equation*}
$$

Iterating (1) backward and forward, derive the discrete-time analogues of equations (7) and (11).

## 6. Solutions of Continuous-Time Systems

In Section 1(d) we stated a theorem on the existence, uniqueness, and other properties of the solutions of continuous-time systems. In this section we will prove this result. As the reader will soon discover, things are considerably more complicated than in the discrete-time case.

Let $f()$ be a function mapping some subset $D=X \times \Omega \times I$ of $\mathbb{R}^{\mathrm{n}+\mathrm{p}+1}$ into $\mathbb{R}^{\mathrm{n}}$. We will investigate the existence, uniqueness, and other properties of the solution to the continuous-time boundary-value problem

$$
\dot{x}=f(x, \alpha, t), \quad x\left(t_{0}\right)=x^{0} \quad\left(\mathrm{PC}\left(x^{0}, t_{0}, \alpha\right)\right)
$$

We will start in Section (a) by establishing the local existence and uniqueness of solutions to (PC) under suitable conditions on the function $f()$ and its domain. Section (b) will show that under essentially the same assumptions, unique "global" solutions of (PC) can be constructed by pasting together local solutions. Finally, in Section (c) we will investigate the continuity of the flow $\phi\left(t, x^{0}, t_{0}, \alpha\right)$ in initial conditions and parameters.

A few technical comments probably are in order before we start. Notice that under our assumptions, both the vector field $f(x, t)$ and any of its solutions $\phi(t)$ are vector-valued functions,

$$
f(x, t)=\left(f^{1}(x, t), \ldots, f^{n}(x, t)\right) \text { and } \phi(t)=\left(\phi^{1}(t), \ldots, \phi^{n}(t)\right)
$$

Hence, the integral of $f()$ should be understood to be a vector of the form

$$
\begin{equation*}
\int_{t 0}^{t} f[\phi(s), s] d s=\left(\int_{t 0}^{t} f^{1}[\phi(s), s] d s, \ldots, \int_{t_{0}}^{t} f^{n}[\phi(s), s] d s\right) \tag{1}
\end{equation*}
$$

In a similar way, we could allow $f()$ and $\phi()$ to be matrix-valued, and then the integral in (1) would be interpreted as a matrix in which each entry would be an ordinary integral.

To aid intuition and to simplify the exposition somewhat, most of the proofs in this section will be written for the special case of a onedimensional system with a single parameter (i.e., under the additional assumption that $x$ and $\alpha$ are real numbers). In many of these proofs we will make use of the important inequality

$$
\begin{equation*}
\left|\int_{a}^{b} g(s) d s\right| \leq \int_{a}^{b}|g(s)| d s \tag{2}
\end{equation*}
$$

where $g():[a, b] \longrightarrow \mathbb{R}$ is a real-valued function of one variable. This inequality is derived by taking the limit of a similar "discrete" inequality for

Riemann sums. We will also make use of the concepts of Lipschitz function and the norm of a linear operator, which were introduced in Chapters 2 and 3 , respectively.

The extension of the proofs to the general case of a vector-valued function is generally straightforward. For such an extension it is sometimes useful to keep in mind that all norms in $\mathbb{R}^{\mathbf{n}}$ are equivalent (see Section 10 of Chapter 2). Hence, we can choose the most convenient norm, and in many cases this turns out to be not the Euclidean norm, but the $\|\cdot\|_{1}$ norm, defined for each $x \in \mathbb{R}^{\mathrm{n}}$ by

$$
\|x\|_{1}=\sum_{i=1}^{n}\left|x_{i}\right|
$$

where $\left|x_{i}\right|$ is the absolute value of the $i$ th component of $x$. If $g(s)$ is now a vector-valued function, we have, using (2) and omitting the subscript of the norm symbol,

$$
\left\|\int_{a}^{b} g(s) d s\right\|=\sum_{i=1}^{n}\left|\int_{a}^{b} g^{i}(s) d s\right| \leq \sum_{i=1}^{n}\left(\int_{a}^{b}\left|g^{i}(s)\right| d s\right)=\int_{a}^{b}\left(\sum_{i=1}^{n}\left|g^{i}(s)\right|\right) d s=\int_{a}^{b}\|g(s)\| d s
$$

Hence, inequality (2) will now be replaced by

$$
\begin{equation*}
\left\|\int_{a}^{b} g(s) d s\right\| \leq \int_{a}^{b}\|g(s)\| d s \tag{3}
\end{equation*}
$$

## (a) Local Existence and Uniqueness

In this section and the next we will establish some properties of the solutions of (PC) for given parameter values. Hence, we suppress the parameter vector $\alpha$ and consider a boundary-value problem of the form

$$
\begin{equation*}
\dot{x}=f(x, t), \quad x\left(t_{0}\right)=x^{0} \tag{0}
\end{equation*}
$$

where $f()$ is a function mapping a set in $\mathbb{R}^{\mathrm{n}+1}$ into $\mathbb{R}^{\mathrm{n}}$. We will make various assumptions about the properties of $f()$ in some set of the form $D=X \times I$, where $I$ is some interval of the real line, but allow for the possibility that $f($ ) may be defined on a larger set where it may not satisfy the required properties. We say that a differentiable function $\phi(t)$ defined on some interval $J \subseteq I$ containing $t_{0}$ is a solution of $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ in $D$ if

(i) $\phi\left(t_{0}\right)=x^{0}$,

(ii) the graph of $\phi(t)$ is contained in $D$, that is,

$$
\left\{(\phi(t), t) \in \mathbb{R}^{\mathrm{n}+1} ; t \in J\right\} \subseteq D
$$

and

(iii) $\phi^{\prime}(t)=f(\phi(t), t)$ for all $t \in J$,
where the derivative in (iii) will be understood to be the appropriate onesided derivative if $t$ is an end point of $J$.

To investigate the existence of local solutions to ( $\mathrm{PC}\left(x^{0}, t_{0}\right)$ ), we start with the observation that the given boundary-value problem can be transformed into an equivalent integral equation that turns out to be easier to work with. This equivalence result will later be used repeatedly.

Lemma 6.1. Let $\mathrm{f}(\mathrm{x}, \mathrm{t})$ be continuous in $\mathrm{D}=\mathrm{X} \times \mathrm{I}$. The function $\phi: \mathrm{J} \longrightarrow \mathbb{R}^{n}$ (where $\mathrm{J} \subseteq \mathrm{I}$ is an interval containing $\mathrm{t}_{0}$ ) is a solution of the boundary-value problem $\left(P C\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)\right)$ if and only if is a continuous solution of the integral equation

$$
\phi(\mathrm{t})=\mathrm{x}^{0}+\int_{\mathrm{t}_{0}}^{\mathrm{t}} \mathrm{f}[\phi(\mathrm{s}), \mathrm{s}] \mathrm{ds} \forall \mathrm{t} \in \mathrm{J} \quad\left(P I\left(\mathrm{x}^{0}, \mathrm{t}^{0}\right)\right)
$$

The proof of the lemma is very simple. If $\phi()$ is a solution of $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ defined in $J$, then it satisfies

$$
\phi^{\prime}(s)=f[\phi(s), s] \forall s \in J
$$

Integrating both sides of this expression from $t_{0}$ to an arbitrary $t$ in $J$, we obtain

$$
\int_{t_{0}}^{t} f[\phi(s), s] d s=\int_{t_{0}}^{t} \phi^{\prime}(s) d s=\phi(t)-\phi\left(t_{0}\right)
$$

by the fundamental theorem of calculus. Imposing the initial condition $\phi\left(t_{0}\right)$ $=x^{0}$, we see that $\phi()$ satisfies the integral equation ( $\left.\mathrm{PI}\left(x^{0}, t_{0}\right)\right)$.

On the other hand, if $\phi()$ is a continuous solution of $\left(\mathrm{PI}\left(x^{0}, t_{0}\right)\right)$, then it is also differentiable, because the function under the integral is continuous. Differentiating both sides of $\left(\mathrm{PI}\left(x^{0}, t_{0}\right)\right)$ with respect to $t$, we obtain, by Leibniz's rule, (see p. 654)

$$
\phi^{\prime}(t)=f[\phi(t), t]
$$

for any $t$ in $J$. Moreover, putting $t=t_{0}$ in $\left(\mathrm{PI}\left(x^{0}, t_{0}\right)\right)$, we see that $\phi\left(t_{0}\right)=x^{0}$. Hence, $\phi(t)$ is indeed a solution of the boundary-value problem $\left(\operatorname{PC}\left(x^{0}, t_{0}\right)\right)$. Notice, incidentally, that because $f()$ is continuous, this last expression implies that $\phi(t)$ is $C^{1}$, because $\phi^{\prime}(t)$ is the composition of two continuous functions.

We can now return to the question of the local existence and uniqueness of solutions to ( $\mathrm{PC}\left(x^{0}, t_{0}\right)$ ). By Lemma 6.1, the problem reduces to that of establishing the existence and uniqueness of a continuous solution to the integral equation ( $\mathrm{PI}\left(x^{0}, t_{0}\right)$ ). We will exploit this equivalence to construct a sequence of increasingly better approximations to the solution of ( $\left.\mathrm{PI}\left(x^{0}, t_{0}\right)\right)$ following Picard's method of successive approximations. Then we will apply
the contraction mapping theorem to conclude that this sequence converges to a function that is the unique solution of the problem.

We start out with what is probably a very poor approximation to $\phi()$ : We guess that the solution function is constant at its only known value, that is,

$$
\phi_{0}(t)=x^{0} \quad \text { for all } t \text { in some subinterval } J \text { of } I \text { containing } t_{0} .
$$

Next, we insert this function on the right-hand side of the integral equation and use the result as a second, and hopefully better, approximation to the solution:

$$
\phi_{1}(t)=x^{0}+\int_{t 0}^{t} f\left[\phi_{0}(s), s\right] d s \quad \text { for each } t \in J
$$

(Refer to Figure 9.12) Repeating this procedure, we construct recursively a sequence of functions $\left\{\phi_{n}\right\}$, with

$$
\phi_{n+1}(t)=x^{0}+\int_{t 0}^{t} f\left[\phi_{n}(s), s\right] d s \quad \text { for each } t \in J
$$

Intuitively, each new term of the sequence $\left\{\phi_{n}\right\}$ should be a better approximation to the solution of $\left(\operatorname{PI}\left(x^{0}, t_{0}\right)\right)$ than the previous term. Hence, it can be expected that the sequence will converge to the exact solution for some appropriate interval $J$. We will now see that this is indeed the case.

Theorem 6.2. Local existence and uniqueness of solutions (Picard). Let $\mathrm{f}(\mathrm{x}, \mathrm{t})$ be a continuous function defined on the closed box

$$
\mathrm{B}\left(\mathbf{x}^{0}, \mathrm{t}_{0}\right)=\mathrm{B}_{\mathrm{x}^{o}} \times \mathrm{I}_{0}=\left\{(\mathrm{x}, \mathrm{t}) ;\left|\mathrm{t}-\mathrm{t}_{0}\right| \leq \mathrm{a},\left\|\mathrm{x}-\mathrm{x}^{0}\right\| \leq \mathrm{b}\right\}
$$

Assume that $\mathrm{f}(\mathrm{x}, \mathrm{t})$ is Lipschitz in $\mathrm{x}$ on $\mathrm{B}$, that is, that there exists a positive constant $\mathrm{K}$ such that

$$
\left\|\mathrm{f}\left(\mathrm{x}_{1}, \mathrm{t}\right)-\mathrm{f}\left(\mathrm{x}_{2}, \mathrm{t}\right)\right\| \leq \mathrm{K}\left\|\mathrm{x}_{1}-\mathrm{x}_{2}\right\| \forall\left(\mathrm{x}_{1}, \mathrm{t}\right) \text { and }\left(\mathrm{x}_{2}, \mathrm{t}\right) \text { in } \mathrm{B}\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)
$$

Then there exists some number $\mathrm{r} \leqslant \mathrm{a}$ such that the boundary-value problem

$$
\begin{equation*}
\dot{\mathrm{x}}=\mathrm{f}(\mathrm{x}, \mathrm{t}), \quad \mathrm{x}\left(\mathrm{t}_{\varrho}\right)=\mathrm{x}^{0} \tag{0}
\end{equation*}
$$

has a unique solution $\phi(\mathrm{t})$ defined on the interval $\mathrm{J}=\left[\mathrm{t}_{0}-\mathrm{r}, \mathrm{t}_{0}+\mathrm{r}\right]$, with $\phi(\mathrm{t}) \in \mathrm{B}_{\mathrm{x}^{0}}$ for all $\mathrm{t} \in \mathrm{J}$.

Observe that the theorem requires continuity and a Lipschitz condition. If $f$ is $C^{1}$, it is continuous and locally Lipschitz (Problem 4.7 in Chapter 4), so it is always possible to find a sufficiently small region $B$ around $\left(x^{0}, t_{0}\right)$ in which the assumptions of the theorem hold.

The proof makes use of the fact that the space $C(I)$ of continuous realvalued functions $g()$ defined on a compact interval $J$ is a complete metric space, with the sup metric defined for $g \in C(J)$ by $\|g\|=\sup \{|g(t)| ; t \in J\}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-437.jpg?height=603&width=853&top_left_y=185&top_left_x=316)

Figure 9.12. Successive approximations to the solution function.

(Notice that because $g()$ is continuous and $J$ is compact, $g()$ is bounded on $J$. The completeness of $C(J)$ then follows by Theorem 7.12 in Chapter 2.)

Proof. As noted earlier, we will prove the result for the scalar case. Hence, $B_{x^{0}}$ is a compact interval in the real line, and the norms can be replaced by absolute values in the Lipschitz condition.

Because $f()$ is continuous on the compact set $B=B\left(x^{0}, t_{0}\right)$, it is bounded; that is, there exists some $M>0$ such that

$$
\begin{equation*}
|f(x, t)| \leq M \forall(x, t) \in B \tag{1}
\end{equation*}
$$

Choose $r$ so that

$$
\begin{equation*}
0<r<\min \left\{a, \frac{1}{K}, \frac{b}{M}\right\} \tag{2}
\end{equation*}
$$

We have to verify that this $r$ will work.

Consider the space $C(J)$ of continuous real-valued functions defined on the interval $J=\left[t_{0}-r, t_{0}+r\right]$, and define the operator T: $C(J) \longrightarrow C(J)$ by

$$
\begin{equation*}
T \varphi(t)=x^{0}+\int_{t_{0}}^{t} f[\varphi(s), s] d s \quad \text { for } t \in J=\left[t_{0}-r, t^{0}+r\right] \tag{3}
\end{equation*}
$$

Using this operator, the successive approximations of Picard are given by the sequence of functions $\left\{\phi_{n}\right\}$ in $C(J)$ defined for each $t \in J$ by

$$
\phi_{0}(t)=x^{0} \quad \text { and } \quad \phi_{n+1}(t)=T \phi_{n}(t) \text { for } n=1,2, \ldots
$$

Observe that a function $\phi$ is a solution of the integral equation $\left(\mathrm{PI}\left(x^{0}, t_{0}\right)\right)$ in Lemma 6.1 if and only if it is a fixed point of $T$ (i.e., if it solves $T \phi=\phi$ ). To establish the existence and uniqueness of such a function, we will show
that $T$ is a contraction that maps a complete space into itself. Given this result, the contraction mapping theorem (Theorem 7.16 in Chapter 2) ensures that $T$ has a unique fixed point $\phi$ that is a continuous solution of the integral equation ( $\left.\mathrm{PI}\left(x^{0}, t_{0}\right)\right)$ and therefore of the initial-value problem (PC $\left.\left(x^{0}, t_{0}\right)\right)$, by Lemma 6.1. Moreover, the sequence of approximations $\left\{\phi_{n}\right\}$ converges to $\phi$, so iteration of $T$ can be used to approximate the solution to any desired level of accuracy. To prove this result, we rely on the completeness of $C(J)$ and on the fact that a closed subset of a complete metric space is itself complete (Theorem 7.9 in Chapter 2).

- Claim (i): The set of continuous real-valued functions $\varphi$ defined on $J$, with the property that $\left|\varphi(t)-\phi_{0}(t)\right| \leq M r$ for all $t \in J=\left[t_{0}-r, t_{0}+r\right]$, is complete.

Observe that this subset of $C(J)$ corresponds to the closed ball $B_{M r}\left[\phi_{0}\right]$ in $C(J)$ equipped with the sup norm. Because a closed subset of a complete metric space is complete, $B_{M r}\left[\phi_{0}\right]$ is complete.

Notice that if $\varphi(t) \in B_{M r}\left[\phi_{0}\right]$, then we have $\left|\varphi(t)-x^{0}\right| \leq M r<M b / M=b$, by (2). Hence, $\varphi(t) \in B_{x} 0$ for all $t$ in $J$, and $(\varphi(t), t)$ lies inside the box $B\left(x^{0}, t_{0}\right)$ for all $t \in J$. This allows us to apply the Lipschitz condition to $f(\varphi(t), t)$.

- Claim (ii): $T$ maps $B_{M_{r}}\left[\phi_{0}\right]$ into itself.

That is, given any suitable function $\varphi$ "close to" $\phi_{0}, T$ yields another function $T \varphi$ that also is not far from $\phi_{0}$. To show that this is true, note that for each $t$ in $J$ $=\left[t_{0}-r, t_{0}+r\right]$ we have, using the boundedness of $f()$,

$$
\begin{aligned}
\left|T \varphi(t)-\phi_{0}(t)\right| & =\left|x^{0}+\int_{t_{0}}^{t} f[\varphi(s), s] d s-x^{0}\right| \\
& =\left|\int_{t_{0}}^{t} f[\varphi(s), s] d s\right| \leq \int_{t_{0}}^{t}|f[\varphi(s), s]| d s \leq M\left|t-t_{0}\right| \leq M r
\end{aligned}
$$

Hence, $M r$ is an upper bound of $\left|T \varphi(t)-\phi_{0}(t)\right|$ in $J$, implying that

$$
\left.\left\|T \varphi-\phi_{0}\right\|=\sup \left\{\mid T \varphi(t)-\phi_{0}(t)\right) ; t \in J\right\} \leq M r
$$

that is, $T \varphi \in B_{M r}\left[\phi_{0}\right]$.

- Claim (iii): $T$ is a contraction on $C(J)$, that is, for all $\varphi_{1}, \varphi_{2} \in C(J),\left\|T \varphi_{1}-T \varphi_{2}\right\|<$ $\left\|\varphi_{1}-\varphi_{2}\right\|$.

Given any two functions $\varphi_{1}()$ and $\varphi_{2}()$ in $C(J)$, we have, for any given $t$ in $J=$ $\left[t_{0}-r, t_{0}+r\right]$

$$
\begin{aligned}
\left|T \varphi_{1}(t)-T \varphi_{2}(t)\right| & =\left|\int_{t_{0}}^{t}\left(f\left[\varphi_{1}(s), s\right]-f\left[\varphi_{2}(s), s\right]\right) d s\right| \\
& \leq \int_{t_{0}}^{t}\left|f\left[\varphi_{1}(s), s\right]-f\left[\varphi_{2}(s), s\right]\right| d s \\
& \leq \int_{t_{0}}^{t} K\left|\varphi_{1}(s)-\varphi_{2}(s)\right| d s \\
& \leq K \int_{t_{0}}^{t} \sup _{s \in J}\left|\varphi_{1}(s)-\varphi_{2}(s)\right| d s=K \int_{t_{0}}^{t}\left\|\varphi_{1}-\varphi_{2}\right\| d s \\
& =K\left|t-t_{0}\right|\left\|\varphi_{1}-\varphi_{2}\right\|<\left\|\varphi_{1}-\varphi_{2}\right\|
\end{aligned}
$$

(by the Lipschitz condition)
because with $t$ in $\left[t_{0}-r, t_{0}+r\right]$ we have $\left|t-t_{0}\right| \leq r$ and, by (2), $K r<1$. Now, this inequality holds for all $t$ in the interval of interest, so $\left\|\varphi_{1}-\varphi_{2}\right\|$ is an upper bound of $\left|T \varphi_{1}(t)-T \varphi_{2}(t)\right|$ for any $t$ in $J$, and it follows that the sup remum over $t \in J$ cannot exceed $\left\|\varphi_{1}-\varphi_{2}\right\|$, implying $\left\|T \varphi_{1}-T \varphi_{2}\right\|<\left\|\varphi_{1}-\varphi_{2}\right\|$.

Hence, $T$ is a contraction from a complete space of continuous functions to itself. By the contraction mapping theorem, $T$ has a unique fixed point in $B_{M r}\left[\phi_{0}\right]$ that we will call $\phi$. This function is continuous and solves $T \phi=\phi$, the integral equation from which we started, and therefore the initial-value problem ( $\operatorname{PC}\left(x^{0}, t_{0}\right)$ ). Because $\phi \in B_{M r}\left[\phi_{1}\right]$, moreover, $\phi(J)$ is contained in $B_{x^{0}}$, as established in (i).

Example 6.3 and Problem 6.4 will show that the solution may not be unique when $f()$ is not a Lipschitz function.

Example 6.3. Consider the initial-value problem

$$
\begin{equation*}
\dot{x}=f(x)=3 x^{2 / 3}, \quad x(0)=0 \tag{P}
\end{equation*}
$$

We will solve the differential equation by the method of separation of variables and then impose the initial condition. Notice that (making improper but convenient use of the notation) we can rewrite the equation $\dot{x}=3 x^{2 / 3}$ in the form

$$
\frac{d x}{d t}=3 x^{2 / 3}
$$

and, rearranging terms,

$$
d t=\frac{x^{-2 / 3}}{3} d x
$$

Integrating both sides of the preceding expression, we have

$$
\int d t=\int \frac{x^{-2 / 3}}{3} d x \Rightarrow c+t=x^{1 / 3}
$$

where $c$ is an arbitrary constant of integration. Hence, the functions of the form

$$
\begin{equation*}
x(t)=(c+t)^{3} \tag{S}
\end{equation*}
$$

are solutions of the given differential equation (as can be easily checked by differentiating (S)). To select the member of this family that solves (P), we impose the initial condition $x(0)=0$. When $t=0$ and $x=0$, we have

$$
0=(c+0)^{3} \Rightarrow c=0
$$

Substituting this expression in (S), one solution of the initial-value problem $(\mathrm{P})$ is the function

$$
x(t)=t^{3}
$$

Notice, however, that the function $y(t)=0$ for all $t$ is also a solution of the initial-value problem, for $y(0)=0$, and $y(t)$ satisfies the differential equation, as

$$
0=\frac{d y}{d t}=3 y(t)^{2 / 3}=0
$$

Notice that the function $f(x)=3 x^{2 / 3}$ is not differentiable at zero, because $f^{\prime}(x)=2 /\left(x^{1 / 3}\right) \rightarrow \infty$ as $x \rightarrow 0$.

Problem 6.4. Show that the function $f(x)=3 x^{2 / 3}$ is not Lipschitz in any neighborhood of zero.

Problem 6.5. Continuous dependence on initial conditions and parameters. Let $f(x, \alpha, t)$ be a continuous function defined on the set $B=B_{x} \times B_{\alpha} \times I$, where $B_{x}, B_{\alpha}$, and $I=[-a, a]$ are closed intervals in the real line. Assume further that $f()$ is Lipschitz in $(x, \alpha)$ on $B$, that is, that there exists some positive constant $K$ such that

$$
\begin{equation*}
|f(y, \beta, t)-f(x, \alpha, t)| \leq K\|(y, \beta)-(x, \alpha)\| \forall(y, \beta, t) \text { and }(x, \alpha, t) \text { in } B \tag{L}
\end{equation*}
$$

Show the following:

(i) For each $\left(x^{0}, \alpha\right)$ in the interior of $B_{x} \times B_{\alpha}$, the initial-value problem

$$
\dot{x}=f(x, \alpha, t), \quad x(0)=x^{0} \quad\left(\mathrm{PC}\left(x^{0}, 0, \alpha\right)\right)
$$

has a unique solution defined on a closed interval $J\left(x^{0}\right) \subseteq I$ containing zero.

(ii) The function $\phi_{t}\left(x^{0}, \alpha\right)$ that gives the solution to ( $\left.\mathrm{PC}\left(x^{0}, 0, \alpha\right)\right)$ as a function of initial conditions and parameters is continuous. Hint: Restrict yourself to a sufficiently small region around $\left(x^{0}, \alpha\right)$, and use Theorem 7.18 in Chapter 2.

## (b) Maximal Solutions

Assume that $f(x, t)$ is continuous and locally Lipschitz in some open region $D=X \times I$ in $\mathbb{R}^{\mathrm{n}+1}$ containing $\left(x^{0}, t_{0}\right)$, and consider the initial-value problem

$$
\begin{equation*}
\dot{x}=f(x, t), \quad x(0)=x^{0} \tag{0}
\end{equation*}
$$

By Theorem 6.2 we know that $\left(\operatorname{PC}\left(x^{0}, 0\right)\right)$ has a unique solution defined on some (possibly small) closed interval around zero, $J_{0}=\left[-r\left(x^{0}\right), r\left(x^{0}\right)\right]$. In this section we will show that this solution can be uniquely extended in $D$ to some maximal interval of existence $J_{m}\left(x^{0}, D\right)$, and we shall investigate the properties of the resulting maximal or global solution as it approaches the end points of its interval of definition. The global solution will be constructed by pasting together local solutions of appropriate boundary problems. We will use the uniqueness of the local solutions to establish the uniqueness of
the global solution and show that this "collation" process can be continued until the graph of the global solution approaches the boundary of the set $D$.

Throughout most of the remainder of this section we will make the following assumption.

Assumption 6.6. The function $f(x, t)$ is continuous and locally Lipschitz in $x$ on some region $D=X \times I$ in $\mathbb{R}^{\mathrm{n}+1}$, where $X$ is an open set in $\mathbb{R}^{\mathrm{n}}$, and $I$ is an open interval on the real line.

Notice that if $f()$ is $C^{1}$ on $D$, then this assumption holds. Hence, all our results extend automatically to the case where $f$ is $C^{1}$.

The first step will be to establish that any two solutions of the boundaryvalue problem $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ coincide in the intersection of their domains. Figure 9.13 illustrates the intuition behind this result: If two solutions of $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$, say $\phi(t)$ and $\varphi(t)$, "separate" at some point $\left(x^{1}, t_{1}\right)$, then the uniqueness of the solutions of $\left(\mathrm{PC}\left(x^{1}, t_{1}\right)\right)$ is violated.

Lemma 6.7. Assume that $\mathrm{f}(\mathrm{x}, \mathrm{t})$ satisfies Assumption 6.6 in the open region $\mathrm{D}=\mathrm{X} \times \mathrm{I}$ in $\mathbb{R}^{n+1}$, and consider the initial-value problem

$$
\dot{\mathrm{x}}=\mathrm{f}(\mathrm{x}, \mathrm{t}), \quad \mathrm{x}\left(\mathrm{t}_{0}\right)=\mathrm{x}^{0}, \quad \text { with }\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right) \in \mathrm{D} \quad\left(P C\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)\right)
$$

Let $\phi(\mathrm{t})$ and $\varphi(\mathrm{t})$ be solutions of $\left(P C\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)\right)$ defined on subintervals $\mathrm{J}_{\phi}$ and $\mathrm{J}_{\varphi}$ of $\mathrm{I}$, respectively, with the property that $\phi(\mathrm{t}) \in \mathrm{X}$ for all $\mathrm{t} \in \mathrm{J}_{\phi}$ and $\varphi(\mathrm{t}) \in \mathrm{X}$ for all $\mathrm{t} \in \mathrm{J}_{\varphi}$. Then $\phi(\mathrm{t})$ and $\varphi(\mathrm{t})$ coincide in the intersection of their domains, that is, $\phi(\mathrm{t})=\varphi(\mathrm{t})$ for all $\mathrm{t} \in \mathrm{J}=\mathrm{J}_{\phi} \cap \mathrm{J}_{\varphi}$.

Problem 6.8. Prove Lemma 6.7. Hint: By the local-existence and uniqueness theorem (Theorem 6.2) we know that $\phi(t)$ and $\varphi(t)$ coincide over some interval containing $t_{0}$. Let $J_{m}$ be the largest subinterval of $J$ over which the two solutions coincide. To show that $J_{m}=J$, assume that $J_{m}$ is strictly contained in $J$, and seek a contradiction.

We can now return to the problem posed at the beginning of this section. Assume that $f(x, t)$ is continuous and locally Lipschitz in some open region $D=X \times I$ in $\mathbb{R}^{\mathrm{n}+1}$ containing $\left(x^{0}, t_{0}\right)$. Then we can find some closed box $B\left(x^{0}\right.$, $\left.t_{0}\right) \subseteq D$ around $\left(x^{0}, t_{0}\right)$ such that $f()$ is bounded and Lipschitz in $B\left(x^{0}, t_{0}\right)$, and it follows by the local existence and uniqueness theorem (Theorem 6.2) that there exists some $r_{0}=r\left(x^{0}\right)>0$ such that the initial-value problem ( $\mathrm{PC}\left(x^{0}\right.$, $\left.t_{0}\right)$ ) has a unique solution $\phi^{0}(t)$ defined on an interval $J_{0}=\left[t_{0}-r_{0}, t_{0}+r_{0}\right]$, with the property that its graph, $\left(J_{0}, \phi^{0}\left(J_{0}\right)\right)$, is contained in $B\left(x^{0}, t_{0}\right) \subseteq D$.

We will now see how this solution can be extended to the right. (A similar argument will yield the continuation of the solution to the left.) Let $t_{1}=t_{0}+$ $r_{0}$ and $x^{1}=\phi^{0}\left(t_{1}\right)$, and consider the initial-value problem

$$
\begin{equation*}
\dot{x}=f(x, t), \quad x\left(t_{1}\right)=x^{1} \tag{1}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-442.jpg?height=554&width=871&top_left_y=187&top_left_x=298)

Figure 9.13. Local uniqueness implies global uniqueness.

Because $\left(x^{1}, t_{1}\right)=\left(\phi^{0}\left(t_{1}\right), t_{1}\right) \in D$, and $D$ is open, the conditions of the local existence and uniqueness theorem are again satisfied in a suitable box around $\left(x^{1}, t_{1}\right)$, and it follows that there exists some positive $r_{1}$ such that $\left(\mathrm{PC}\left(x^{1}, t_{1}\right)\right)$ has a unique solution $\phi^{1}(t)$ defined on the interval $J_{1}=\left[t_{1}-r_{1}\right.$, $\left.t_{1}+r_{1}\right]$.

Now, because $\phi^{0}(t)$ is also a solution of ( $\mathrm{PC}\left(x^{1}, t_{1}\right)$ ), it follows by Lemma 6.7 that $\phi^{0}(t)=\phi^{1}(t)$ for $t \in J_{0} \cap J_{1}$. Define now the function $\phi(t)$ on $J_{0} \cup J_{1}$ by

$$
\phi(t)= \begin{cases}\phi^{0}(t) & \text { for } t \in J_{0} \\ \phi^{1}(t) & \text { for } t \in J_{1} \sim J_{0}\end{cases}
$$

Notice that $\phi(t)$ is a continuous function, because both $\phi^{0}(t)$ and $\phi^{1}(t)$ are continuous, and they coincide over their intersection. Moreover, $\phi(t)$ is a solution of $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ because it satisfies the integral equation ( $\left.\mathrm{PI}\left(x^{0}, t_{0}\right)\right)$ in Lemma 6.1. This is certainly the case in $J_{0}=\left[0, t_{1}\right]$, but also in $J_{1} \sim J_{0}=$ $\left(t_{1}, t_{1}+r_{1}\right]$, because for any $t$ in this interval we have

$$
\begin{aligned}
\phi(t) & =\phi^{1}(t)=x^{1}+\int_{t_{0}}^{t} f\left(\phi^{1}(s), s\right) d s=\phi^{0}\left(t_{1}\right)+\int_{t_{1}}^{t} f\left(\phi^{1}(s), s\right) d s \\
& =x^{0}+\int_{t_{0}}^{t_{1}} f\left(\phi^{0}(s), s\right) d s+\int_{t_{1}}^{t} f\left(\phi^{1}(s), s\right) d s \\
& =x^{0}+\int_{t_{0}}^{t_{1}} f(\phi(s), s) d s+\int_{t_{1}}^{t} f(\phi(s), s) d s=x^{0}+\int_{t_{0}}^{t} f(\phi(s), s) d s
\end{aligned}
$$

where we have made use of the fact that $\phi^{0}(t)$ is a solution of $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ in $J_{0}$, and $\phi^{1}(t)$ is a solution of $\left(\mathrm{PC}\left(x^{1}, t_{1}\right)\right)$ in $J_{1}$. Hence, we have extended the solution to ( $\mathrm{PC}\left(x^{0}, t_{0}\right)$ ) beyond its original domain $J_{0}$. The extension is also unique in the set $J_{0} \cup J_{1}$, because Lemma 6.7 implies that any other solution
defined over any subset of $J_{0} \cup J_{1}$ must coincide with $\phi(t)$ over the intersection of their domains.

Notice that because the right end point of the graph of the extended solution $\left(\phi^{1}\left(t_{1}+r_{1}\right), t_{1}+r_{1}\right)$ still lies in the open set $D$, the continuation process can be repeated in a similar way starting from this point. In fact, because the extended solution obtained in this manner never leaves the open set $D$, the continuation process can be repeated an infinite number of times. Hence, the maximal solution $\phi()$ obtained as the limit of this process will be defined in the union of an infinite number of partially overlapping closed intervals $J_{n}$ constructed as illustrated earlier. The resulting set,

$$
J_{m}\left(x^{0}, t_{0}\right)=\bigcup_{n \geq 0} J_{n} \subseteq I
$$

is called the maximal interval of existence of the solution to $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ in $D$, because it is the largest interval of definition of a solution of $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ whose graph is contained in $D$. Notice that the infinite union of partially overlapping closed intervals will itself be an interval, but not necessarily a closed one. In fact, $J_{m}\left(x^{0}, t_{0}\right)$ must be an open interval, for if $J_{m}\left(x^{0}, t_{0}\right)=[a, b]$, then $(\phi(b), b)$ lies in the open set $D$, and it follows by an already familiar argument that the solution $\phi()$ can be extended within $D$ to a larger interval $[a, b+r]$, thereby contradicting the fact that $[a, b]$ is the maximal interval of existence.

We summarize the preceding discussion in the following theorem.

Theorem 6.9. Let $\mathrm{f}(\mathrm{x}, \mathrm{t})$ satisfy Assumption 6.6 (continuity and existence of a local Lipschitz constant) in the open region $\mathrm{D}=\mathrm{X} \times \mathrm{I}$ in $\mathbb{R}^{n+1}$ containing $\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)$. Then the boundary-value problem $\left(P C\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)\right)$ has a unique maximal solution $\phi(\mathrm{t})$ in $\mathrm{D}$ defined on the open maximal interval $\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)=(\mathrm{a}, \mathrm{b}) \subseteq$ I. That is, if $\varphi(\mathrm{t})$ is any solution of $\left(P C\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)\right)$ in $\mathrm{D}$ defined on some interval $\mathrm{J}_{\varphi}$, then $\mathrm{J}_{\varphi} \subseteq \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{\theta}\right)$ and $\varphi(\mathrm{t})=\phi(\mathrm{t})$ for all $\mathrm{t} \in \mathrm{J}_{\varphi}$.

We will now investigate the behavior of solutions as they approach the end points of their intervals of definition. The following example shows that the maximal interval of existence depends, in general, on the initial conditions of the problem and need not be the entire real line, even when $f()$ is nicely behaved in the whole of $\mathbb{R}^{\mathrm{n}+1}$.

Example 6.10. Consider the initial-value problem

$$
\begin{equation*}
\dot{x}=x^{2}, \quad x(0)=x^{0} \tag{P}
\end{equation*}
$$

As in Example 6.3, we will solve the differential equation by the method of separation of variables and then impose the initial condition. Rearranging terms in the equation $d x / d t=x^{2}$, we have

$$
d t=x^{-2} d x
$$

Integrating both sides of this expression,

$$
\int d t=\int x^{-2} d x \Rightarrow-x^{-1}=c+t
$$

where $c$ is an arbitrary constant of integration. Hence, the solutions of the equation are of the form

$$
\begin{equation*}
x(t)=\frac{-1}{c+t} \tag{S}
\end{equation*}
$$

To select the member of this family that solves $(\mathrm{P})$, we impose the initial condition $x(0)=x^{0}$. When $t=0$ and $x=x^{0}$, we have

$$
x^{0}=\frac{-1}{c+0} \Rightarrow c=-1 / x^{0}
$$

Substituting this condition into (S), the solution of the initial-value problem is given by the function

$$
x(t)=\frac{1}{\left(1 / x^{0}\right)-t}
$$

Notice that $x(t) \rightarrow \infty$ as $t \rightarrow 1 / x^{0}$. Hence, the solution to (P) is defined on $\left(-\infty, 1 / x^{0}\right)$.

The example also illustrates how solutions to ( $\left.\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ may fail to exist for finite $t$. When the conditions of the local existence and uniqueness theorem are satisfied, a solution $\phi(t)$ cannot mysteriously "evaporate." It may, however, "explode" in finite time. If the set $D$ in which $f()$ is well behaved is not the whole of $\mathbb{R}^{n+1}$, the solution can also fail to exist by leaving this set. The following theorems give some more precise results about the limiting behavior of the maximal solutions of $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$.

Lemma 6.11. Assume that $\mathrm{f}(\mathrm{x}, \mathrm{t})$ is bounded in some region $\mathrm{D}=\mathrm{X} \times \mathrm{I}$ in $\mathbb{R}^{n+1}$, and consider the initial-value problem

$$
\dot{\mathrm{x}}=\mathrm{f}(\mathrm{x}, \mathrm{t}), \quad \mathrm{x}\left(\mathrm{t}_{0}\right)=\mathrm{x}^{0}, \quad \text { with }\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right) \in \mathrm{D} \quad\left(P C\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)\right)
$$

Let $\phi(\mathrm{t})$ be a solution of $\left(P C\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)\right)$ defined on a finite interval $(\mathrm{a}, \mathrm{b}) \subseteq \mathrm{I}$ containing $\mathrm{t}_{0}$, with the property that $\phi(\mathrm{t}) \in \mathrm{X}$ for all $\mathrm{t} \in(\mathrm{a}, \mathrm{b})$. Then the limits

$$
\lim _{t \rightarrow a^{+}} \phi(t) \text { and } \quad \lim _{t \rightarrow b^{-}} \phi(t)
$$

exist.

Proof. Let $t_{1}$ and $t_{2}$ be two arbitrary points in $(a, b)$, with $t_{1}<t_{2}$. By Lemma 6.1, we have

$$
\phi\left(t_{1}\right)=x^{0}+\int_{t_{0}}^{t_{1}} f(\phi(s), s) d s \quad \text { and } \quad \phi\left(t_{2}\right)=x^{0}+\int_{t_{0}}^{t_{2}} f(\phi(s), s) d s
$$

Hence,

$$
\begin{equation*}
\phi\left(t_{2}\right)-\phi\left(t_{1}\right)=\int_{t_{1}}^{t_{2}} f(\phi(s), s) d s \tag{1}
\end{equation*}
$$

Because $(\phi(s), s) \in D$ for all $s \in\left[t_{1}, t_{2}\right]$, and $f()$ is bounded in $D$, there is some positive constant $M$ such that $|f(\phi(s), s)| \leq M$. Hence, (1) implies that

$$
\begin{equation*}
\left|\phi\left(t_{2}\right)-\phi\left(t_{1}\right)\right| \leq M\left|t_{2}-t_{1}\right| \tag{2}
\end{equation*}
$$

Now, as $t_{1}, t_{2} \rightarrow b$ from below, we have $\left|t_{2}-t_{1}\right| \rightarrow 0$, implying that $\left|\phi\left(t_{2}\right)-\phi\left(t_{1}\right)\right|$ $\rightarrow 0$. This, in turn, implies, by the completeness ${ }^{7}$ of $\mathbb{R}$ (or $\mathbb{R}^{\mathrm{n}}$ in the general case), that $\phi(t)$ converges to some limit as $t \rightarrow b^{-}$. A similar argument shows that $\phi(t)$ has a limit as $t \rightarrow a^{+}$.

Using this result, we will now show that if a solution $\phi(t)$ is not defined on the entire interval $I$, then it leaves any compact subset of $X$. This implies that as $t$ approaches the right end point of the maximal interval of definition, the solution either tends to the boundary of the domain or "explodes" to infinity, or both. If $I$ is the entire real line, and $X=\mathbb{R}^{\mathrm{n}}$, then the theorem says that if the right end point of the maximal interval of definition is finite (i.e., if $b<\infty$ ), then $\phi(t)$ goes to infinity in finite time. (Notice that if the system is autonomous, then we can assume that $I$ is the entire real line by defining $f(x$, $t)=f(x)$ for all $t$.)

Theorem 6.12. Let $\mathrm{f}(\mathrm{x}, \mathrm{t})$ satisfy Assumption 6.6 in the open region $\mathrm{D}=\mathrm{X} \times$ $\mathrm{I}$ in $\mathbb{R}^{\mathrm{n}+\ell}$ containing $\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)$. Let $\phi(\mathrm{t})$ be the maximal solution of $\left(P C\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)\right)$ in $\mathrm{D}$, defined on the maximal interval $\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)=(\mathrm{a}, \mathrm{b})$. Assume that $\mathrm{b} \in$ int $\mathrm{I}$. Then, given any compact set $\mathrm{K} \subseteq \mathrm{X}$, there exists some $\mathrm{t} \in\left(\mathrm{t}_{0}, \mathrm{~b}\right)$ such that $\phi(\mathrm{t})$ $\notin \mathrm{K}$. Similarly, if $\mathrm{a} \in$ int $\mathrm{I}$, then $\phi(\mathrm{t}) \notin \mathrm{K}$ for some $\mathrm{t} \in\left(\mathrm{b}, \mathrm{t}_{0}\right)$.

Proof. By contradiction. Let $K \subseteq X$ be compact, and assume that $\phi(t) \in K$ for all $t$ in $(a, b)$. Because $f$ is continuous on the compact set $K \times[0, b]$, it is bounded in this set. By Lemma 6.11, $\phi(t)$ has a limit as $t \rightarrow b^{-}$. Let

$$
x^{1}=\lim _{t \rightarrow b^{-}} \phi(t)
$$

be this limit, and define the function $\varphi(t)$ in $(a, b]$ by

$$
\varphi(t)= \begin{cases}\phi(t) & \text { for } t \in(a, b) \\ x^{1} & \text { for } t=b\end{cases}
$$

Then $\varphi(t)$ is continuous in $(a, b]$ (from the left at $b)$ and solves $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ in this interval (by Lemma 2.1), because $\varphi(t)=\phi(t)$ solves $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right.$ ) in $(a, b)$ and

$$
\begin{aligned}
\varphi(b) & =\lim _{t \rightarrow b^{-}} \phi(t)=x^{0}+\lim _{t \rightarrow b^{-}} \int_{0}^{t} f(\phi(s), s) d s \\
& =x^{0}+\int_{0}^{b} f(\phi(s), s) d s=x^{0}+\int_{0}^{b} f(\varphi(s), s)
\end{aligned}
$$

Notice also that because $K$ is compact, with $\varphi(t)$ continuous and $\varphi(t) \in K$ for all $t$ in $(a, b)$, then $x^{1}=\varphi(b)$ (is a closure point of $K$ and therefore) lies also in $K \subseteq X$. Hence, $(\varphi(b), b) \in D$, and it follows that $\varphi(t)$ is a solution of $\left(\operatorname{PC}\left(x^{0}\right.\right.$, $\left.t_{0}\right)$ ) in $D$ defined on $(a, b]$. This contradicts the fact that $(a, b)$ is the maximal interval of existence of the solution of $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ in $\mathrm{D}$.

Corollary 6.13. Under the hypotheses of Theorem 6.12, if $\mathrm{b} \in$ int $\mathrm{I}$ and $\lim _{t \rightarrow b^{-}} \phi(t)$ exists, then

$$
\mathbf{x}^{l}=\lim _{t \rightarrow b^{-}} \phi(t) \in b d y \mathbf{X}
$$

Proof. Assume that $b \in$ int $I$. Let $\varphi(t)$ be the (continuous) extension of $\phi(t)$ to the interval $(a, b]$ defined in the proof of Theorem 6.12. Then the set

$$
K=\varphi[0, b]=\left\{x \in \mathrm{P}^{v} ; x=\varphi(t) \text { for some } t \in[0, b]\right\}
$$

is compact, because it is the continuous image of a compact interval. Assume that $\varphi(b)=x^{1} \in X$. Then, because $\varphi[0, b)=\phi[0, b)$ is certaily contained in $X$, we have $K \subseteq X$, and it follows by Theorem 6.12 that there is some $t \in(0, b)$ such that $\varphi(t) \notin K$. This contradicts the definition of $K$, so $x^{1} \notin X$. But because $\varphi(t) \in X$ for all $t$ in $[0, b)$, it follows by the continuity of $\varphi()$ that $x^{1}=\varphi(b)$ is a closure point of $X$. Hence, $x^{1} \in \operatorname{cl} X \sim X=$ bdy $X$.

The contrapositive of Theorem 6.12 says that if there exists a compact set $K$ in $X$ such that the maximal solution $\phi(t)$ stays within $K$ for all $t$ in $[0, b)$, then $b$ is the right end point of $I$. A similar argument at the other end point yields the following result.

Corollary 6.14. Under the hypotheses of Theorem 6.12, if there exists a compact set $\mathrm{K}$ in $\mathrm{X}$ such that the maximal solution $\phi(\mathrm{t})$ stays within $\mathrm{K}$ for all $\mathrm{t}$ in $\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)=(\mathrm{a}, \mathrm{b})$, then $\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)=\mathrm{I}$.

Of course, if $I=\mathbb{R}$, or the system is autonomous, this implies that any solution that stays within a compact subset of $X$ is defined for all $t$.

Using Theorem 6.12, it is easy to show that if $f$ is a linear function of $x$, that is, if $f(x, t)=A(t) x$, where the function $A(t)$ is continuous on the interval $I$ containing $t_{0}$, then the boundary-value problem $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ has a unique solution defined on the entire interval $I$. Problem 6.15 asks the reader to prove this result for the special case of a scalar system.

Problem 6.15. Let $c(t)$ be a continuous real-valued function defined on an open interval $I=(\alpha, \beta)$ containing $t_{0}$. Consider the initial-value problem defined by the linear system $\dot{x}=c(t) x$ and the initial condition $x\left(t_{0}\right)=x^{0} \in \mathbb{R}$. Show that the solution to this problem is defined on the whole of $I$.

Hint: By contradiction, using Theorem 6.12 and Gronwall's lemma (the following Lemma 6.16).

## (c) Dependence on Initial Conditions and Parameters

In this section we will investigate the dependence on initial conditions of the solutions of the family of boundary-value problems

$$
\begin{equation*}
\dot{x}=f(x, t), \quad x\left(t_{0}\right)=x^{0} \tag{0}
\end{equation*}
$$

where we now regard the initial data $\left(x^{0}, t_{0}\right)$ as variables. As usual, we assume that $f(x, t)$ is continuous and locally Lipschitz in some open region $D=X \times$ $I$ in $\mathbb{R}^{\mathrm{n}+1}$, where $I$ is an open interval (Assumption 6.6). Then Theorem 6.9 assures us that for each $\left(x^{0}, t_{0}\right)$ in $D$ the boundary-value problem $\left(\operatorname{PC}\left(x^{0}, t_{0}\right)\right)$ has a unique solution in $D$. Hence, we can define the flow of $f()$ as the function $\phi\left(t, x^{0}, t_{0}\right): E \rightarrow X$ defined on the set

$$
E=\left\{\left(t, x^{0}, t_{0}\right) \in I \times X \times I ; t \in J_{m}\left(x^{0}, t_{0}\right)\right\} \subseteq D \times I
$$

such that for each fixed $\left(x^{0}, t_{0}\right)$, the function $\phi\left(\cdot, x^{0}, t_{0}\right)$ defined in $J_{m}\left(x^{0}, t_{0}\right)$ is a solution of $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$. Because $\phi\left(\cdot, x^{0}, t_{0}\right)$ is a solution of $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$, we know already that $\phi()$ is $C^{1}$ in its first argument. We will now show that under our maintained assumptions, $E$ is an open set, and $\phi\left(t, x^{0}, t_{0}\right)$ is a continuous function of all its arguments. In fact, if $f()$ is $C^{k}$ in $D$, then so is $\phi($ ). Roughly speaking, then, the flow of a continuous system is as smooth as the vector field itself.

In most of what follows, we will work with a fixed $t_{0}$, suppress the third argument of the flow, writing it $\phi\left(t, x^{0}\right)$, and concentrate on the dependence of the solution on the initial position $x^{0}$. All our results can be easily extended to $\left(x^{0}, t_{0}\right)$.

We will first establish a useful lemma. Using this result, it will then be easy to obtain a bound on the distances between solutions of $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ that start from different initial values.

Lemma 6.16. Gronwall's lemma. Let $\mathrm{u}(\mathrm{t}) \geq 0$ be a continuous real-valued function defined on the interval $\left[\mathrm{t}_{0}, \mathrm{t}_{1}\right]$. Assume that there exist positive constants $\mathrm{C}$ and $\mathrm{K}$ such that

$$
0 \leq \mathrm{u}(\mathrm{t}) \leq \mathrm{C}+\mathrm{K} \int_{\mathrm{t}_{0}}^{\mathrm{t}} \mathrm{u}(\mathrm{s}) \mathrm{ds}
$$

for all $\mathrm{t} \in\left[\mathrm{t}_{0}, \mathrm{t}_{l}\right]$. Then we have

$$
\mathrm{u}(\mathrm{t}) \leq \mathrm{Ce}^{\mathrm{K}\left\|t-\mathrm{t}_{0}\right\|} \forall \mathrm{t} \in\left[\mathrm{t}_{0}, \mathrm{t}_{l}\right]
$$

Proof. For each $t \in\left[t_{0}, t_{1}\right]$, let

$$
U(t)=C+K \int_{t_{0}}^{t} u(s) d s>0
$$

Then $u(t) \leq U(t)$ by assumption. Differentiating $U()$, we have

$$
U^{\prime}(t)=K u(t)
$$

Hence,

$$
\frac{d \ln U(t)}{d t}=\frac{U^{\prime}(t)}{U(t)}=\frac{K u(t)}{U(t)} \leq \frac{K U(t)}{U(t)}=K
$$

Integrating both sides of this expression between $t_{0}$ and $t$,

$$
\ln U(t)-\ln U\left(t_{0}\right) \leq K\left|t-t_{0}\right| \Rightarrow \ln U(t) \leq \ln U\left(t_{0}\right)+K\left|t-t_{0}\right|
$$

Taking exponentials and observing that $U\left(t_{0}\right)=C$, we obtain the desired inequality

$$
U(t) \leq U\left(t_{0}\right) e^{K\left|t-t_{0}\right|}=C e^{K\left|t-t_{0}\right|}
$$

Lemma 6.17. Let $\mathrm{f}(\mathrm{x}, \mathrm{t})$ satisfy Assumption 6.6 in the open set $\mathrm{D}=\mathrm{X} \times \mathrm{I}$ in $\mathbb{R}^{n+1}$. Assume that $\mathrm{f}()$ is Lipschitz in $\mathrm{x}$ on $\mathrm{D}$, with Lipschitz constant $\mathrm{K}$. Given two points $\left(\mathrm{t}_{0}, \mathrm{x}^{0}\right)$ and $\left(\mathrm{t}_{0}, \mathrm{y}^{0}\right)$ in $\mathrm{D}$, let $\phi\left(\mathrm{t}, \mathrm{y}^{0}\right)$ and $\phi\left(\mathrm{t}, \mathrm{x}^{0}\right)$ be the unique solutions in $\mathrm{D}$ of the system $(C S(\mathrm{t})), \dot{\mathrm{x}}=\mathrm{f}(\mathrm{x}, \mathrm{t})$, going through these points, defined respectively in the maximal intervals $\mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}\right)$ and $\mathrm{J}_{\mathrm{m}}\left(\mathrm{y}^{0}\right) \subseteq \mathrm{I}$. Then, for each $\mathrm{t} \in \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}\right) \cap \mathrm{J}_{\mathrm{m}}\left(\mathrm{y}^{0}\right)$ we have

$$
\begin{equation*}
\left\|\phi\left(\mathrm{t}, \mathrm{y}^{0}\right)-\phi\left(\mathrm{t}, \mathrm{x}^{0}\right)\right\| \leq\left\|\mathrm{y}^{0}-\mathrm{x}^{0}\right\| \mathrm{e}^{\mathrm{KIt}-\mathrm{t} d \mathrm{l}} \tag{4}
\end{equation*}
$$

Problem 6.18. Prove Lemma 6.17. Hint: Consider the scalar case and apply Gronwall's lemma to the function $\varphi(t)=\left|\phi\left(t, y^{0}\right)-\phi\left(t, x^{0}\right)\right|$.

The preceding lemma almost implies the continuity of $\phi\left(t, x^{0}\right)$ in $x^{0}$ for given $t$ when $f()$ is (globally) Lipschitz on $D$. If we fix some $t$ in $J_{m}\left(x^{0}\right)$ and let $\left\|y^{0}-x^{0}\right\|$ go to zero, inequality (4) implies that $\left\|\phi\left(t, y^{0}\right)-\phi\left(t, x^{0}\right)\right\| \rightarrow 0-$ provided that $\phi\left(t, y^{0}\right)$ is defined for all $y^{0}$ sufficiently close to $x^{0}$. Our next result takes care of this loose end by showing that for any $t \in J_{m}\left(x^{0}\right), \phi\left(s, y^{0}\right)$ is defined in $[0, t]$ for all $y^{0}$ sufficiently close to $x^{0}$. The proof of the theorem also shows that the graphs of the two solutions $\phi\left(t, y^{0}\right)$ and $\phi\left(t, x^{0}\right)$ in $[a, b]$ stay within a compact subset of $D$. Hence, the inequality in Lemma 6.17 continues to hold for some $K$, and $\phi()$ is continuous in $x^{0}$ for given $t$ provided that $f()$ is locally Lipschitz (because, by Theorem 8.25 in Chapter 2, a func-
tion that is locally Lipschitz on a set $D$ is Lipschitz on any compact subset of $D$ ).

Theorem 6.19. Let $\mathrm{f}(\mathrm{x}, \mathrm{t})$ satisfy Assumption 6.6 in the open set $\mathrm{D}=\mathrm{X} \times \mathrm{I}$ in $\mathbb{R}^{\mathrm{n}+1}$. Given some point $\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right.$ ) in $\mathrm{D}$, let the unique solution $\phi\left(\mathrm{t}, \mathrm{x}^{0}\right)$ of $\left(P C\left(\mathrm{x}^{0}, \mathrm{t}_{0}\right)\right)$ be defined on a closed interval $[\mathrm{a}, \mathrm{b}] \subseteq \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}\right)$. Then there exists some $\delta>0$ and a positive constant $\mathrm{K}$ such that for all $\mathrm{y}^{0} \in \mathrm{B}_{\delta}\left(\mathrm{x}^{0}\right)$ the initialvalue problem $\left(P C\left(\mathrm{y}^{0}, \mathrm{t}_{0}\right)\right)$ has a unique solution $\phi\left(\mathrm{t}, \mathrm{y}^{0}\right)$ defined on $[\mathrm{a}, \mathrm{b}]$ that satisfies

$$
\left\|\phi\left(t, y^{0}\right)-\phi\left(t, x^{0}\right)\right\| \leq\left\|y^{0}-x^{0}\right\| e^{\mathrm{K} I t-t o d}
$$

for all $\mathrm{t}$ in $[\mathrm{a}, \mathrm{b}]$.

Proof. Because $[a, b]$ is compact and $\phi\left(t, x^{0}\right)$ is a continuous function of $t$, the set

$$
A=\phi\left([a, b], x^{0}\right)=\left\{x \in X ; x=\phi\left(t, x^{0}\right) \text { for some } t \in[a, b]\right\}
$$

is a compact subset of $X$. Because $X$ is open, moreover, there exists some $\varepsilon>0$ such that the compact set

$$
B=\bigcup_{x \in A} B_{\varepsilon}[x]=\left\{z \in \mathbb{R}^{\mathrm{n}} ;\left\|z-\phi\left(t, x^{0}\right)\right\| \leq \varepsilon \text { for some } t \in[a, b]\right\}
$$

is a subset of $X$. Moreover, because $f()$ is Lipschitz in $x$ on the open set $D$, and $C=B \times[a, b]$ is a compact subset of $D$, it follows by Theorem 8.25 in Chapter 2 that $f()$ is Lipschitz on $C$, that is, that there exists a positive constant $K$ such that

$$
\begin{equation*}
|f(y, t)-f(x, t)| \leq K|y-x| \tag{1}
\end{equation*}
$$

for all $(y, t)$ and $(x, t)$ in $C$.

Choose some $\delta>0$ such that

$$
\begin{equation*}
\delta \leq \min \left\{\varepsilon, \varepsilon e^{-K(b-a)}\right\} \tag{2}
\end{equation*}
$$

and let $y^{0}$ be a point in $B_{\delta}\left(x^{0}\right)$. Because $\left(y^{0}, t_{0}\right) \in D$, Theorem 6.9 guarantees the existence of a unique solution $\phi\left(t, y^{0}\right)$ going through this point and defined on some maximal interval of existence $J_{m}\left(y^{0}\right)=(\alpha, \beta) \subseteq I$ containing $t_{0}$. We will show that $[a, b] \subseteq(\alpha, \beta)$ and that $\phi\left(t, y^{0}\right)$ satisfies the desired inequality. We start by establishing the following fact:

(i) Claim: If $\phi\left(t, y^{0}\right)$ is defined in $[a, b]$, then $\phi\left(t, y^{0}\right) \in B$ for all $t \in[a, b]$.

Assume that $\phi\left(t, y^{0}\right)$ is defined in $[a, b]$, and observe that because $\phi\left(t_{0}, y^{0}\right)=$ $y^{0} \in B_{\delta}\left(x^{0}\right) \subseteq B_{\varepsilon}\left(x^{0}\right) \subseteq B$, we have $\phi\left(t, y^{0}\right) \in B$ for all $t$ in some interval containing $t_{0}$. We assume that $\phi\left(t, y^{0}\right)$ leaves $B$ at some point in $[a, b]$ to the right of $t_{0}$ and thus obtain a contradiction (a similar argument will work in the other
case). Under this assumption (by the continuity of $\phi()$ in $t$ ) there exists some $t^{*} \in\left(t_{0}, b\right)$ such that $\phi\left(t, y^{0}\right) \in B$ for $t \in\left[t_{0}, t^{*}\right]$, and $\phi\left(t^{*}, y^{0}\right) \in$ bdy B.

Now, because $\phi\left(t, y^{0}\right) \in B$ for all $t$ in $\left[t_{0}, t^{*}\right] \subseteq[a, b]$, the graph of $\phi\left(t, y^{0}\right)$ in $\left[t_{0}, t^{*}\right]$ is contained in the compact set $C=B \times[a, b]$, and it follows that $K$ is a Lipschitz constant for $f()$ in this region. By Lemma 6.17, this implies that

$$
\begin{equation*}
\left|\phi\left(t, y^{0}\right)-\phi\left(t, x^{0}\right)\right| \leq\left|y^{0}-x^{0}\right| e^{K\left(t-t_{0}\right)} \tag{3}
\end{equation*}
$$

for all $t \in\left[t_{0}, t^{*}\right]$. Using (2), this inequality implies, with $t=t^{*} \in[a, b]$, that

$$
\begin{equation*}
\left|\phi\left(t^{*}, y^{0}\right)-\phi\left(t^{*}, x^{0}\right)\right| \leq\left|y^{0}-x^{0}\right| e^{K\left(t^{*}-t_{0}\right)}<\delta e^{K(b-a)}<\varepsilon \tag{4}
\end{equation*}
$$

because $y^{0} \in B_{\delta}\left(x^{0}\right)$. Because $\phi\left(t^{*}, x^{0}\right) \in A$, it follows that $\phi\left(t^{*}, y^{0}\right)$ is an interior point of $B$ (see the definitions of the two sets). This is a contradiction, because $\phi\left(t^{*}, y^{0}\right)$ is a boundary point of $B$. Hence $\phi\left(t, y^{0}\right) \in B$ for all $t \in[a, b]$.

(ii) By the same argument, it follows that if $\beta \leq b$, then $\phi\left(t, y^{0}\right) \in B$ for all $t \in\left[t_{0}\right.$, $\beta$ ). If $\beta \leq b$, then the point $t^{*}$ in (i), with $\phi\left(t^{*}, y^{0}\right) \in$ bdy $B$, must lie in $\left(t_{0}, \beta\right)$, but then (4) holds (because $t^{*}<\beta \leq b$ ), and $\phi\left(t^{*}, y^{0}\right.$ ) is also an interior point of $B$, which is again a contradiction.

(iii) Next, we show that $[a, b] \subseteq(\alpha, \beta)=J_{m}\left(y^{0}\right)$, so that indeed $\phi\left(t, y^{0}\right)$ is defined on the entire interval $[a, b]$ on which we know $\phi\left(t, x^{0}\right)$ to be defined. We assume that $\beta \leq b$ and obtain a contradiction. Under this assumption we have $\phi\left(t, y^{0}\right)$ $\in B$ for all $t \in\left[t_{0}, \beta\right)$, by (ii). But notice that if $\beta \leq b$, then $\left[t_{0}, \beta\right] \subseteq\left[t_{0}, b\right]$, where $b$ is an interior point of the (open) interval $J_{m}\left(x^{0}\right)$ and therefore is an interior point of $I$. Hence, $\beta$ is also an interior point of $I$. But then Theorem 6.12 implies that $\phi\left(t, y^{0}\right)$ must leave any compact subset of $X$ and, in particular, that there exists some $t \in\left(t_{0}, \beta\right)$ such that $\phi\left(t, y^{0}\right) \notin B$, which contradicts (ii). Hence, it must be that $b<\beta$.

A similar argument can be used to establish that if $\alpha \geq a$, then $\phi(t, y) \in B$ for all $t \in\left(\alpha, t_{0}\right]$ and that this also leads to a contradiction. Hence $a>\alpha$, and we conclude that $[a, b]$ is contained in $(\alpha, \beta)$, the maximal interval of existence of $\phi\left(t, y^{0}\right)$. Thus $\phi\left(t, y^{0}\right)$ is defined in the entire interval $[a, b]$, as claimed.

(iv) Once we have shown that $\phi(t, y)$ is defined in the entire interval $[a, b]$, (i) implies that $\phi\left(t, y^{0}\right) \in B$ for all $t$ in $[a, b]$. Hence, the graph of $\phi\left(t, y^{0}\right)$ in $[a, b]$ is contained in the compact set $C=B \times[a, b]$, and it follows that $K$ is a Lipschitz constant for $f$ in this region. Lemma 6.17 then gives

$$
\left|\phi\left(t, y^{0}\right)-\phi\left(t, x^{0}\right)\right| \leq\left|y^{0}-x^{0}\right| e^{K\left|t-t_{0}\right|}
$$

for all $t \in[a, b]$.

Using this result, it is now easy to establish the continuity of the flow.

Theorem 6.20. Continuity of the flow. Assume that $\mathrm{f}(\mathrm{x}, \mathrm{t})$ satisfies Assumption 6.6 (continuity and existence of a local Lipschitz constant) in some open
region $\mathrm{D}=\mathrm{X} \times \mathrm{I}$ in $\mathbb{R}^{\mathrm{n}+}$. Then the flow of the continuous system $(\mathrm{CS}(\mathrm{t}))$, $\phi\left(\mathrm{t}, \mathrm{x}^{0}\right): \mathrm{E} \longrightarrow \mathrm{X}$, is a continuous function, and its domain of definition

$$
\mathrm{E}=\left\{(\mathrm{t}, \mathrm{x}) \in \mathrm{I} \times \mathrm{X} ; \mathrm{t} \in \mathrm{J}_{\mathrm{m}}(\mathrm{x})\right\} \subseteq \mathrm{D}
$$

is an open set.

## Proof

- Openness of $E$. Let $\left(s, x^{0}\right)$ be an arbitrary point of $E$. We want to show that any point $(t, x)$ sufficiently close to $\left(s, x^{0}\right)$ lies in $E$, that is, that $t \in J_{m}(x)$ for any such point.

Assume that $\left(s, x^{0}\right) \in E$ and, for concreteness, that $s>t_{0}$. Then $s \in J_{m}\left(x^{0}\right)$, and it follows that the solution $\phi\left(t, x^{0}\right)$ of the initial-value problem $\left(\mathrm{PC}\left(x^{0}, t_{0}\right)\right)$ is defined on $\left[t_{0}, s\right]$. Because $J_{m}\left(x^{0}\right)$ is open, $s$ is an interior point of $J_{m}\left(x^{0}\right)$, and it follows that $\phi\left(t, x^{0}\right)$ can be extended to the interval $\left[t_{0}, s+\varepsilon\right]$ for some $\varepsilon>0$. Hence $\phi\left(t, x^{0}\right)$ is defined on the closed interval $[s-\varepsilon, s+\varepsilon]$.

It then follows by Theorem 6.18 that there exists some $\delta>0$ such that for any $y^{0} \in B_{\delta}\left(x^{0}\right)$ the solution $\phi\left(t, y^{0}\right)$ of $\left(\mathrm{PC}\left(y^{0}, t_{0}\right)\right)$ is defined for all $t$ in $[s-\varepsilon, s+\varepsilon]$. Hence, $(s-\varepsilon, s+\varepsilon) \times B_{\delta}\left(x^{0}\right) \subseteq E$, and it follows that $E$ is open in $D$.

- Continuity of $\phi\left(\right.$ ). Given some point $\left(s, x^{0}\right) \in E$, let $\varepsilon$ and $\delta$ be as in the first part of the proof, and choose some $\mu$, with $0<\mu<\min \{\varepsilon, \delta\}$. Consider a point $\left(t, y^{0}\right)$ such that $t \in(s-\mu, s+\mu)$ and $y^{0} \in B_{\mu}\left(x^{0}\right)$. Then $\left(t, y^{0}\right) \in E$, so $\phi\left(t, y^{0}\right)$ is defined and satisfies

$$
\left|\phi\left(t, y^{0}\right)-\phi\left(s, x^{0}\right)\right| \leq\left|\phi\left(t, y^{0}\right)-\phi\left(t, x^{0}\right)\right|+\left|\phi\left(t, x^{0}\right)-\phi\left(s, x^{0}\right)\right|
$$

by the triangle inequality. Consider the limit of the right-hand side of this expression as $\left(t, y^{0}\right) \rightarrow\left(s, x^{0}\right)$. By the continuity of $\phi()$ in $x$ for given $t$, the first term goes to zero as $y^{0} \rightarrow x^{0}$. Similarly, the second term goes to zero, by the continuity of $\phi()$ in $t$ for given $x$. Hence, $\phi\left(t, y^{0}\right) \rightarrow \phi\left(s, x^{0}\right)$ as $\left(t, y^{0}\right) \rightarrow\left(s, x^{0}\right)$, which establishes the continuity of $\phi(t, x)$ at an arbitrary point $\left(s, x^{0}\right)$ in $E$, and therefore in the whole set.

## Continuity of the Flow of Parameterized Systems

Let us now introduce the parameters explicitly into the analysis (while still maintaining a fixed $t_{0}$ ) and consider the family of parameterized boundaryvalue problems

$$
\dot{x}=f(x, t, \alpha), \quad x\left(t_{0}\right)=x^{0} \quad\left(\mathrm{PC}\left(x^{0}, t_{0}, \alpha\right)\right)
$$

where $f($ ) will now be assumed to be continuous and locally Lipschitz in $x$ on some region $D \times \Omega=X \times I \times \Omega$ in $\mathbb{R}^{\mathrm{n}+1+\mathrm{p}}$, with $X$ an open set in $\mathbb{R}^{\mathrm{n}}, I$ an open interval in $\mathbb{R}$, and $\Omega$ an open set in $\mathbb{R}^{p}$. For a given value of $\alpha$ we have a nonparameterized system of the type we have studied in this section, and our previous results ensure the existence of a unique and continuous maximal solution of the boundary-value problem. This solution, however,
will generally change with the parameters, as will its maximal interval of existence in $D$. Hence, we will denote the solution of $\left(\mathrm{PC}\left(x^{0}, t_{0}, \alpha\right)\right)$ by $\phi\left(t, x^{0}\right.$, $\alpha$ ), and its maximal interval of definition by $J_{m}\left(x^{0}, \alpha\right)$. Proceeding as before, we can now define the flow of the system as the function $\phi\left(t, x^{0}, \alpha\right): E \longrightarrow$ $X$ defined on the set

$$
\begin{equation*}
E=\left\{\left(t, x^{0}, \alpha\right) \in I \times X \times \Omega ; t \in J_{m}\left(x^{0}, \alpha\right)\right\} \subseteq D \times \Omega \tag{5}
\end{equation*}
$$

such that for each fixed $\left(x^{0}, \alpha\right)$, the function $\phi\left(\cdot, x^{0}, \alpha\right)$ defined in $J_{m}\left(x^{0}, \alpha\right)$ is the unique maximal solution of $\left(\mathrm{PC}\left(x^{0}, t_{0}, \alpha\right)\right)$.

We will use a simple transformation to show that all our previous results on the properties of the flow of nonparameterized systems extend to the present case. Define the vector $y$ and the function $F()$ by

$$
y=(x, \alpha) \text { and } F(y, t)=(f(x, t, \alpha), \underline{0})
$$

and consider the initial-value problem

$$
\begin{equation*}
\dot{y}=F(y, t), \quad y(0)=y^{0}=\left(x^{0}, \alpha\right) \tag{P.y}
\end{equation*}
$$

Notice that (P.y) is simply the system

$$
(\dot{x}=f(x, t, \alpha), \dot{\alpha}=0)
$$

with the initial condition

$$
\left(x(0)=x^{0}, \alpha(0)=\alpha\right)
$$

(i.e., we treat the parameters as additional state variables but set their derivatives to zero so that they remain constant over time).

Then the flow of $F$ is a function of the form

$$
\Phi\left(t, y^{0}\right)=\left(\phi\left(t, x^{0}, \alpha\right), \alpha\right)
$$

where $\phi\left(t, x^{0}, \alpha\right)$ is the flow of $f$. Because (P.y) is a nonparameterized system, our previous results guarantee that its flow will be nicely behaved provided that $F$ is continuous and locally Lipschitz in $y$. And because $\phi\left(t, x^{0}, \alpha\right)$ is just a component of $\Phi\left(t, y^{0}\right)$, this function will be continuous. Hence, we have the following result.

Theorem 6.21. Continuity of the flow of a parameterized system. Assume that $\mathrm{f}(\mathrm{x}, \alpha, \mathrm{t})$ is continuous and locally Lipschitz in $(\mathrm{x}, \alpha)$ on some region $\mathrm{D} \times \Omega$ $=\mathrm{X} \times \mathrm{I} \times \Omega$ in $\mathbb{R}^{n+p+1}$, with $\mathrm{X}$ an open set in $\mathbb{R}^{n}, \mathrm{I}$ an open interval in $\mathbb{R}$, and $\Omega$ an open set in $\mathbb{R}^{p}$. Then the flow of the continuous system $(C S(\alpha, t)), \phi(t$, $\left.\mathrm{x}^{0}, \alpha\right): \mathrm{E} \longrightarrow \mathrm{X}$, is a continuous function, and its domain of definition

$$
E=\left\{\left(t, x^{0}, \alpha\right) \in I \times X \times \Omega ; t \in J_{m}\left(x^{0}, \alpha\right)\right\} \subseteq D \times \Omega
$$

is an open set.

## Differentiability of the Flow

Our final result in this section shows that if $f()$ is a $C^{1}$ function in $D$, then so is the flow $\phi\left(t, x^{0}, \alpha\right)$ in the set $E$ defined in Theorem 6.21. By the discussion in the preceding section, it is sufficient to consider the case of a nonparameterized system, because any results on the dependence on initial conditions extend automatically to the parameters, provided $f()$ is as smooth in $\alpha$ as in $x$.

We have already seen that $\phi()$ is a continuously differentiable function of $t$ for given $x^{0}$. Hence, it suffices to show that $D_{x} \phi\left(t, x^{0}\right)$ exists and is a continuous function of $\left(t, x^{0}\right)$. Assuming for now that $D_{x} \phi\left(t, x^{0}\right)$ is defined, we can begin by guessing what this derivative must look like. Consider the initial-value problem

$$
\begin{equation*}
\dot{x}=f(x, t), \quad x\left(t_{0}\right)=x^{0} \tag{0}
\end{equation*}
$$

where $f()$ is $C^{1}$, and let $\phi\left(t, x^{0}\right)$ be its maximal solution defined on the interval $J_{m}\left(x^{0}, t_{0}\right)$. Substituting the solution function back into the differential equation and using $D_{t}$ and $D_{x}$ to indicate partial derivatives with respect to $t$ and $x$, respectively, we have the identity

$$
D_{t} \phi\left(t, x^{0}\right) \equiv f\left[\phi\left(t, x^{0}\right), t\right]
$$

Differentiating both sides of this identity with respect to $x^{0}$, we have

$$
D_{x} D_{t} \phi\left(t, x^{0}\right)=D_{x} f\left[\phi\left(t, x^{0}\right), t\right] D_{x} \phi\left(t, x^{0}\right)
$$

If we assume further that the order of differentiation can be inverted in the term in the left-hand side of this expression, we have

$$
\begin{equation*}
D_{t} D_{x} \phi\left(t, x^{0}\right)=D_{x} f\left[\phi\left(t, x^{0}\right), t\right] D_{x} \phi\left(t, x^{0}\right) \tag{6}
\end{equation*}
$$

Hence $D_{x} \phi\left(t, x^{0}\right)$ satisfies a linear differential equation. This can be better brought out by letting

$$
z\left(t, x^{0}\right)=D_{x} \phi\left(t, x^{0}\right) \quad \text { and } \quad A\left(t, x^{0}\right)=D_{x} f\left[\phi\left(t, x^{0}\right), t\right]
$$

and rewriting (6) in the form

$$
\begin{equation*}
\dot{z}=A\left(t, x^{0}\right) z \tag{7}
\end{equation*}
$$

Notice, moreover, that at time $t_{0}$ the solution must go through the given initial condition. Hence, $\phi\left(t_{0}, x^{0}\right)=x^{0}$, and therefore

$$
\begin{equation*}
z\left(t_{0}\right)=D_{x} \phi\left(t_{0}, x^{0}\right)=\mathbf{I} \tag{8}
\end{equation*}
$$

where $\mathbf{I}$ is the identity matrix. Hence, our candidate for $D_{x} \phi\left(t, x^{0}\right)$ is the unique solution $z(t)$ of a boundary-value problem involving a parameterized linear system. By Problem 6.15, the solution $z\left(t, x^{0}\right)$ to this linear problem is defined whenever $A\left(t, x^{0}\right)$ is defined, that is, on the whole interval $J_{m}\left(x^{0}, t_{0}\right)$,
and by Theorem 6.21, $z\left(t, x^{0}\right)$ is continuous in $t$ and $x^{0}$. Hence, $D_{x} \phi\left(t, x^{0}\right)=$ $z\left(t, x^{0}\right)$ is continuous, and it follows that $\phi()$ is a continuously differentiable function of $x^{0}$.

Notice that in the general case, where $f$ maps $\mathbb{R}^{\mathrm{n}}$ into $\mathbb{R}^{\mathrm{n}}, z=D_{x} \phi()$ is an $n \times n$ matrix. This poses no particular problem, because we can think of $z$ as a vector in $\mathbb{R}^{\mathrm{n} \times \mathrm{n}}$. Alternatively, we can bring (7) back to a more familiar dimension by working with the differential of $\phi()$, rather than with its derivative. Let $h$ be an arbitrary vector in $\mathbb{R}^{\mathrm{n}}$, and define $y \in \mathbb{R}^{\mathrm{n}}$ by $y=z h$. Then $\dot{y}=\dot{z} h=A z h=A y$, and we obtain a linear system in $n$ variables. Notice that now the initial condition will be $y\left(t_{0}\right)=z\left(t_{0}\right) h=\mathbf{I} h=h$.

We will now show that the solution of the variational problem (7) is indeed the derivative of the flow with respect to $x^{0}$. To simplify things somewhat, we will consider the case of the autonomous system (CS), $\dot{x}=f(x)$.

Theorem 6.22. Differentiability of the flow. Let $\mathrm{f}(\mathrm{x}, \alpha)$ be $\mathrm{C}^{l}$ in the open set $\mathrm{X} \times \Omega$ in $\mathbb{R}^{\mathrm{n}+p}$, and let

$$
\mathrm{E}=\left\{\left(\mathrm{t}, \mathbf{x}^{0}, \boldsymbol{\alpha}\right) \in \mathbb{R} \times \mathrm{X} \times \Omega ; \mathrm{t} \in \mathrm{J}_{\mathrm{m}}\left(\mathrm{x}^{0}, \boldsymbol{\alpha}\right)\right\}
$$

Then the flow of $\mathrm{f}(), \phi\left(\mathrm{t}, \mathrm{x}^{0}, \alpha\right): \mathrm{E} \longrightarrow \mathrm{X}$, is a $\mathrm{C}^{l}$ function.

Proof. We will later make use of the following fact. Let $f()$ be a $C^{1}$ function; then we have

$$
\begin{equation*}
f(y)-f(x)=D f(x)(y-x)+R(y, x) \tag{1}
\end{equation*}
$$

by Taylor's theorem, where

$$
\frac{R(y, x)}{|y-x|} \rightarrow 0 \quad \text { as } \quad y \rightarrow x
$$

This means that given any $\varepsilon>0$, there exists some $\delta>0$ such that

$$
\begin{equation*}
|R(y, x)| \leq \varepsilon|y-x| \tag{2}
\end{equation*}
$$

for all $y$ such that $|y-x| \leq \delta$. Notice that, in general, the value of $\delta$ will depend on $x$. If we restrict $x$ to a compact set $C$, however, given any $\varepsilon$ we can find a $\delta$ that will work for all $x$ in $C$ (by the same argument as in the proof of Theorem 8.24 in Chapter 2). Hence, $R(y, x) /|y-x| \rightarrow 0$ as $y \rightarrow x$ uniformly for $x$ in the compact set $C$.

As noted, it suffices to consider the case of the nonparameterized system (CS), $\dot{x}=f(x)$. Letting $t_{0}=0$ for convenience, let $\phi\left(t, x^{0}\right)$ and $\phi\left(t, x^{0}+h\right)$ be the maximal solutions of (CS) going through the points $x^{0}$ and $x^{0}+h$, respectively, at time zero. Let $J_{m}\left(x^{0}\right)$ be the (maximal) interval of definition of the first of these functions, and fix some compact interval $J_{b}=[0, b]$ contained in $J_{m}\left(x^{0}\right)$. Let $z(t)$ be the solution of the variational problem

$$
\begin{equation*}
\dot{z}=D_{x} \phi\left(t, x^{0}\right) z, \quad z(0)=\frac{\partial \phi\left(0, x^{0}\right)}{\partial x^{0}}=\frac{\partial x^{0}}{\partial x^{0}}=1 \tag{PV}
\end{equation*}
$$

As noted in the discussion prior to the statement of the theorem, $z(t)$ will be defined on the entire set $J_{m}\left(x^{0}\right)$ and therefore in all of $J_{b}$.

By Lemma 6.1, we have, for each $t \in J_{b}$,

$$
\begin{gather*}
\phi\left(t, x^{0}\right)=x^{0}+\int_{0}^{t} f\left(\phi\left(s, x^{0}\right)\right) d s \\
\phi\left(t, x^{0}+h\right)=x^{0}+h+\int_{0}^{t} f\left(\phi\left(s, x^{0}+h\right)\right) d s \\
z(t)=1+\int_{0}^{t} D f\left(x_{s}\right) z(s) d s \tag{3}
\end{gather*}
$$

where, for short, we write $D f\left(x_{s}\right)$ for $D f\left(\phi\left(s, x^{0}\right)\right)$. Using these expressions, we have

$$
\begin{align*}
g(t) \equiv & \left|\phi\left(t, x^{0}+h\right)-\phi\left(t, x^{0}\right)-z(t) h\right| \\
= & \left|\int_{0}^{t}\left[f\left(\phi\left(s, x^{0}+h\right)\right)-f\left(\phi\left(s, x^{0}\right)\right)-D f\left(x_{s}\right) z(s) h\right] d s\right| \\
& \leq \int_{0}^{t}\left|f\left(\phi\left(s, x^{0}+h\right)\right)-f\left(\phi\left(s, x^{0}\right)\right)-D f\left(x_{s}\right) z(s) h\right| d s \\
= & \int_{0}^{t}\left|D f\left(x_{s}\right)\left[\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)-z(s) h\right]\right| d s \\
& +\int_{0}^{t}\left|R\left(\phi\left(s, x^{0}+h\right), \phi\left(s, x^{0}\right)\right)\right| d s \tag{4}
\end{align*}
$$

for each $t \in J_{b}$, where the last equality follows by applying Taylor's theorem to $f\left(\phi\left(s, x^{0}+h\right)\right)-f\left(\phi\left(s, x^{0}\right)\right)$ (see equation (1)), and $R(\cdot, \cdot)$ is the Taylor remainder.

Now, let

$$
N=\max \left\{\left\|D f\left(x_{s}\right)\right\| ; s \in J_{b}\right\}
$$

where $\|\cdot\|$ denotes the norm of the linear operator $D f$ (in fact, this could be replaced by the absolute value, because we are in the scalar case), and $N$ exists because $J_{b}$ is a compact set and $\left\|D f\left(x_{s}\right)\right\|=\left\|D f\left(\phi\left(s, x^{0}\right)\right)\right\|$ is a continuous function of $s$ (because $f()$ is $C^{1}$ and $\phi()$ is continuous). We have, then,

$$
\begin{align*}
& \int_{0}^{t}\left|D f\left(x_{s}\right)\left[\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)-z(s) h\right]\right| d s \\
& \quad \leq \int_{0}^{t}\left\|D f\left(x_{s}\right)\right\|\left|\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)-z(s) h\right| d s \\
& \quad \leq N \int_{0}^{t}\left|\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)-z(s) h\right| d s \leq N \int_{0}^{t} g(s) d s \tag{5}
\end{align*}
$$

Substituting this expression in (4), and recalling the definition of $g()$,

$$
\begin{equation*}
g(t) \leq N \int_{0}^{t} g(s) d s+\int_{0}^{t}\left|R\left(\phi\left(s, x^{0}+h\right), \phi\left(s, x^{0}\right)\right)\right| d s \tag{6}
\end{equation*}
$$

for all $t \in J_{b}$.

To apply Gronwall's lemma to $g($ ), we need to show that the integral of the Taylor error terms is bounded. Fix some arbitrary $\varepsilon>0$ and observe that the set $\phi\left(J_{b}, x^{0}\right)$ is compact because it is the continuous image of a compact interval. Hence,

$$
\frac{R\left[\phi\left(s, x^{0}\right), \phi\left(s, x^{0}+h\right)\right]}{\left|\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)\right|} \rightarrow 0 \quad \text { as }\left|\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)\right| \rightarrow 0
$$

uniformly for $\phi\left(s, x^{0}\right)$ in the compact set $\phi\left(J_{b}, x^{0}\right)$ (i.e., for all $\left.s \in J_{b}\right)$. Hence, there is some number $\delta_{0 \varepsilon}$ (valid for all $s \in J_{b}$ ) such that

$$
\begin{align*}
& \left|R\left[\phi\left(s, x^{0}\right), \phi\left(s, x^{0}+h\right)\right]\right| \leq \varepsilon\left|\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)\right| \text { when } \\
& \left|\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)\right| \leq \delta_{0 \varepsilon} \text { and } s \in J_{b} \tag{7}
\end{align*}
$$

Now, by Theorem 6.19 there exists some $\delta_{1 \varepsilon}>0$ and some positive constant $K$ such that for all $h$, with $|h|<\delta_{1 \varepsilon}$, we have

$$
\left|\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)\right| \leq|h| e^{K s} \leq|h| e^{K b}<\delta_{1 \varepsilon} e^{K b}
$$

for all $s \in J_{b}$. Clearly, we can choose $\delta_{1 \varepsilon}$ small enough that

$$
\begin{equation*}
\left|\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)\right| \leq|h| e^{K b}<\delta_{0 \varepsilon} \tag{8}
\end{equation*}
$$

Assume now that $|h|<\delta_{1 \varepsilon}$. Then, by (8), we have $\left|\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)\right|<$ $\delta_{0 \varepsilon}$, so it follows by (7) and (8) that

$$
\left|R\left[\phi\left(s, x^{0}\right), \phi\left(s, x^{0}+h\right)\right]\right| \leq \varepsilon\left|\phi\left(s, x^{0}+h\right)-\phi\left(s, x^{0}\right)\right| \leq \varepsilon|h| e^{K b}
$$

for all $s \in J_{b}$. Integrating this expression between zero and $t \in J_{b}$,

$$
\int_{0}^{t}\left|R\left(\phi\left(s, x^{0}+h\right), \phi\left(s, x^{0}\right)\right)\right| d s \leq \int_{0}^{t} \varepsilon|h| e^{K b} d s=\varepsilon t|h| e^{K b} \leq \varepsilon b|h| e^{K b}
$$

Substituting this expression into (6),

$$
\begin{equation*}
g(t) \leq N \int_{0}^{t} g(s) d s+\varepsilon b|h| e^{K b} \tag{9}
\end{equation*}
$$

Gronwall's lemma now yields

$$
\begin{equation*}
g(t) \leq \varepsilon b|h| e^{K b} e^{N t} \leq \varepsilon b|h| e^{(K+N) b} \tag{10}
\end{equation*}
$$

for any $t \in J_{b}$. Dividing through by $|h|$ and recalling the definition of $g(t)$ in (4), we have

$$
\frac{g(t)}{|h|}=\frac{\left|\phi\left(t, x^{0}+h\right)-\phi\left(t, x^{0}\right)-z(t) h\right|}{|h|} \leq \varepsilon b e^{(K+N) b}
$$

for all $t \in J_{b}$. Because $\varepsilon$ is an arbitary positive number, it follows that

$$
\lim _{|h| \rightarrow 0} \frac{\left|\phi\left(t, x^{0}+h\right)-\phi\left(t, x^{0}\right)-z(t) h\right|}{|h|}=0
$$

uniformly for $t \in J_{b}$. Hence, we have shown that, as claimed, ${ }^{8}$ the solution of the variational problem ( $\mathrm{PV})$ is the partial derivative of the flow, that is,

$$
z\left(t, x^{0}\right)=D_{x} \phi\left(t, x^{0}\right)
$$

Because $z\left(t, x^{0}\right)$ is a continuous function defined on the entire interval $J_{b}$, moreover, so is $D_{x} \phi\left(t, x^{0}\right)$, and this implies that $\phi()$ is $C^{1}$ on $J_{b}=[0, b]$. Because $b$ is an arbitrary point of $J_{m}\left(x^{0}\right)$, finally, we conclude that $\phi()$ is $\mathrm{C}^{1}$ on its entire domain.

Our next result shows that the flow is as smooth as the vector field $f()$.

Theorem 6.23. Let $\mathrm{f}(\mathrm{x}, \alpha)$ be $\mathrm{C}^{\mathrm{r}}$ (with $1 \leq \mathrm{r} \leq \infty$ ) in the open set $\mathrm{D} \times \Omega$ in $\mathbb{R}^{\mathrm{n}+p}$. Then the flow of $\mathrm{f}(), \phi\left(\mathrm{t}, \mathrm{x}^{0}, \alpha\right): \mathrm{E} \longrightarrow \mathrm{X}$, is a $\mathrm{C}^{\mathrm{r}}$ function.

Proof. As before, it suffices to consider the case of the nonparameterized system (CS), $\dot{x}=f(x)$. We proceed by induction on $r$. By the preceding theorem, the result holds for $r=1$. Assume now that $f$ is $C^{r}$ and that if $F$ is a $C^{r-1}$ function, then the flow of the system $\dot{y}=F(y)$ is $C^{r-1}$. Consider the system formed by (CS) and its variational equation

$$
\begin{equation*}
\dot{z}=D f(x) z \tag{V}
\end{equation*}
$$

Letting $y=(x, z)$ and $F(y)=F(x, z)=(f(x), D f(x) z)$, this system can be written

$$
\begin{equation*}
\dot{y}=F(y) \tag{P.y}
\end{equation*}
$$

Notice that $F$ is a $C^{r-1}$ function, because its first component, $f()$, is $C^{r}$ in $x$, and its second component, $D f(x) z$, is $C^{r-1}$ in $x$ and linear (and therefore $C^{\infty}$ ) in $z$. It follows (by the induction assumption) that the flow of $F, \Phi(t, y)$, is $C^{r-1}$. But notice that $\Phi()$ is of the form

$$
\Phi\left(t, y^{0}\right)=\Phi\left(t, x^{0}, z^{0}\right)=\left(\phi\left(t, x^{0}\right), D_{x} \phi\left(t, x^{0}\right)\right)
$$

because the second component of (P.y) is the variational equation of (CS). Hence, $D_{x} \phi\left(t, x^{0}\right)$ is $C^{r-1}$, and it follows that $\phi\left(t, x^{0}\right)$ is $C^{r}$ in $x$. Moreover, $D_{t} \phi$ $\left(t, x^{0}\right)$ is $C^{r-1}$, because

$$
D_{t} \phi\left(t, x^{0}\right)=f\left(\phi\left(t, x^{0}\right)\right)
$$

and both $f()$ and $\phi(t, x)$ are $C^{r-1}$ or better. Hence, $\phi\left(t, x^{0}\right)$ is $C^{r}$, because both of its partial derivatives are $C^{r-1}$. This proves the theorem.

## Bibliography

Arnold, V. 1990. Ordinary Differential Equations. Massachusetts Institute of Technology Press.

Arrowsmith, D., and Place, C. 1990. An Introduction to Dynamical Systems. Cambridge University Press.

Azariadis, C., and de la Fuente, A. 1993. Discrete Dynamical Systems. Part I. In: Intertemporal Macroeconomics, pp. 1-170. Oxford: Blackwell.

Boyce, W., and DiPrima, R. 1977. Elementary Differential Equations, 3rd ed. New York: Wiley.

Brauer, F., and Nohel, J. 1969. The Qualitative Theory of Ordinary Differential Equations, An Introduction. New York: Dover.

Guzmán, M. 1980. Ecuaciones Diferenciales Ordinarias. Teoría de Estabilidad y Control. Madrid: Alhambra.

Hale, J., and Koçak, H. 1991. Dynamics and Bifurcations. Berlin: Springer-Verlag. Hirsch, M., and Smale, S. 1974. Differential Equations, Dynamical Systems and Linear Algebra. San Diego: Academic Press.

Lang, S. 1983. Undergraduate Analysis. Undergraduate Texts in Mathematics. Berlin: Springer-Verlag.

Lelong-Ferrand, J., and Aurnadies, J. M. 1977. Cours de Mathématiques. Tome 4: Equations Différentielles, Integrales Multiples. Paris: Dunod Université.

Obstfeld, M. 1980. Primer on Differential Equations. Mimeograph, Department of Economics, Columbia University.

Oniki, H. 1973. Comparative Dynamics (Sensitivity Analysis) in Optimal Control Theory. Journal of Economic Theory 6(3):265-83.

Perko, L. 1991. Differential Equations and Dynamical Systems. Texts in Applied Mathematics, no. 7. Berlin: Springer-Verlag.

Simmons, G. 1972. Differential Equations with Applications and Historical Notes. New York: McGraw-Hill.

Sotomayor, J. 1979. Lições de Equações Diferenciais Ordinárias. Rio de Janeiro: Instituto de Matemática Pura e Aplicada.

Sydsaeter, K. 1981 Topics in Mathematical Analysis for Economists. San Diego: Academic Press.

Wiggins, S. 1990. Introduction to Applied Nonlinear Dynamical Systems and Chaos. Texts in Applied Mathematics, no. 2. Berlin: Springer-Verlag.

## Notes

1 To find the steady state of the system, we set $\dot{x}=0$ in $(\mathrm{N})$ and solve for $x$.

2 All that we have done has been to reindex the family of solutions of $(N)$ by $x(0)$, instead of $c$, but we still have to specify which trajectory of the system we want. This can be done by choosing the value of $x(0)$ directly (i.e., by imposing an initial condition in the strict sense of the term) or by specifying some other type of boundary condition, in which case we have to solve for the value of $x(0)$. See Chapter 11 for some examples.

3 To find the steady state of (ND), we suppress the time subindices and solve for $x$ :

$$
(1-a) x=b \Rightarrow \bar{x}=\frac{b}{1-a} \text { provided } a \neq 1
$$

4 This can be done for an arbitrary time $s$. When $t=s$, we have $x_{s}=\bar{x}+c a^{s}$. Solving for $\mathrm{c}$ and substituting in (GS), we obtain $x_{t}=\bar{x}+\left(x_{s}-\bar{x}\right) a^{t-s}$. If $x_{s}$ is known, this expression gives the particular solution that goes through this point at time $s$. Otherwise, $x_{s}$ is undetermined, and we just have another equivalent form of the general solution.

5 Notice that

if $g^{\prime}(s)$ changes sign in the interval, then $m_{\varepsilon}=0$, and therefore $|g(x)| \geq 0=m_{\varepsilon}|x|$

if $g^{\prime}(s)>0$ everywhere in the interval, then $|g(x)|=\int_{0}^{x} g^{\prime}(s) d s \geq m_{\varepsilon}|x|$, and

if $g^{\prime}(s)<0$ everywhere in the interval, then $|g(x)|=\int_{0}^{x}-g^{\prime}(s) d s \geq m_{\varepsilon}|x|$.

6 In Section 2 of Chapter 11 we will make use of the forward solution for an equation that describes the evolution of the price of a share of stock. The reason for the terms "fundamental solution" and "bubble term" will then become clear.

7 Think of $t_{1}$ and $t_{2}$ as terms of a sequence $\left\{t_{n}\right\}$ converging to $b$. Then (2) implies that $\left\{\phi\left(t_{n}\right)\right\}$ is Cauchy, and convergence follows by completeness.

8 See the definition of "derivative" in Section 3 of Chapter 4.

## Dynamical Systems. II: Higher Dimensions

In this chapter we will study dynamical systems of dimension 2 or higher, that is, those defined by systems of two or more differential equations in several variables. Sections 1-3 will deal with linear systems. In the remainder of the chapter we will discuss some techniques for analyzing nonlinear autonomous systems.

## 1. Some General Results on Linear Systems

Our discussion of linear systems will concentrate on the solution of systems with constant coefficients. We begin, however, by listing some important results of the general theory of linear dynamical systems that will be useful later. Consider a first-order homogeneous system of the form

$$
\begin{equation*}
\dot{x}=A(t) x \tag{CH}
\end{equation*}
$$

where the coefficients of the $n \times n$ matrix $A$ can be arbitrary functions of time defined on some interval of the real line. The discussion will be in terms of continuous-time systems, but it is easily shown that the results also hold for discrete systems.

Our first result concerns the algebraic structure of the space of solutions of $(\mathrm{CH})$.

Theorem 1.1. The set

$$
\mathrm{S}^{\mathrm{H}}=\{\mathbf{x}(\mathrm{t}), \mathrm{t} \in \mathrm{I} ; \dot{\mathrm{x}}(\mathrm{t})=\mathbf{A}(\mathrm{t}) x(\mathrm{t}) \forall \mathrm{t} \in \mathrm{I}\}
$$

of solutions of $(\mathrm{CH})$ is a vector space of dimension $\mathrm{n}$.

A set $F=\left\{x^{1}(t), \ldots, x^{n}(t)\right\}$ of $n$ linearly independent solutions of $(\mathrm{CH}),{ }^{1}$ that is, a basis of $S^{H}$, is called a fundamental set of solutions of $(\mathrm{CH})$, and the matrix

$$
\Psi(t)=\left[x^{1}(t), \ldots, x^{n}(t)\right]
$$

is a fundamental matrix for the system.

Because $S^{H}$ is a vector space and $F$ is a basis for it, given an arbitrary solution $y(t)$ of $(\mathrm{CH})$, we can write it precisely in one way as a linear combination of $x^{1}(t), \ldots, x^{n}(t)$; that is, there exist unique scalars $c_{1}, \ldots, c_{n}$ such that

$$
\begin{equation*}
y(t)=\sum_{i=1}^{n} c_{i} x^{i}(t) \tag{1}
\end{equation*}
$$

Assigning different values to the vector $c=\left(c_{1}, \ldots, c_{n}\right)$, we can recover all the solutions of the system. Hence, we can think of (1) as the general solution of $(\mathrm{CH})$. Notice that in order to construct the general solution of the system it suffices to find a fundamental set of solutions, that is, a family of $n$ linearly independent solutions of $(\mathrm{CH})$.

Once we have found a fundamental set of solutions of $(\mathrm{CH})$, the solution of any initial-value problem can be easily obtained. The most compact way to write such solution is in terms of a fundamental matrix. As we have seen, the general solution of $(\mathrm{CH})$ can be written

$$
x^{g}(t)=\sum_{i=1}^{n} c_{i} x^{i}(t)=\Psi(t) c
$$

Next, suppose we are given the boundary condition

$$
x\left(t_{0}\right)=x^{0}
$$

In order to find the value of $c$ that corresponds to this boundary condition, we observe that the solution we seek satisfies

$$
x\left(t_{0}\right)=\Psi\left(t_{0}\right) c=x^{0}
$$

Solving this equation for $c$,

$$
c=\left[\Psi\left(t_{0}\right)\right]^{-1} x^{0}
$$

and substituting the result in the general solution, we obtain the solution of the given boundary-value problem:

$$
x(t)=\Psi(t)\left[\Psi\left(t_{0}\right)\right]^{-1} x^{0}
$$

Next we turn to the nonhomogeneous first-order system

$$
\begin{equation*}
\dot{x}=A(t) x+b(t) \tag{CN}
\end{equation*}
$$

and consider its solution space:

$$
S^{N}=\{x(t), t \in I ; \dot{x}(t)=A(t) x(t)+b(t) \forall t \in I\}
$$

It is easy to show that $S^{N}$ is an affine space of dimension $n$ "parallel" to $S^{H}$. That is, $S^{N}$ is a translation of $S^{H}$, and the translation factor is an arbitrary particular solution $x^{P}(t)$ of $(\mathrm{CN})$. Hence, the general solution of the nonho-
mogeneous continuous system $(\mathrm{CN})$ is the sum of the general solution of the homogeneous system $(\mathrm{CH})$ and an arbitrary particular solution of $(\mathrm{CN})$. We can therefore write

$$
x^{N}(t)=x^{H}(t)+x^{P}(t)
$$

where the general solution of the homogeneous system, $x^{H}(t)$, is sometimes called the complementary function.

## 2. Solution of Linear Systems with Constant Coefficients

In this section we will study linear systems with constant coefficients, that is, systems of the form

$$
\dot{x}=A x+b \Leftrightarrow\left[\begin{array}{c}
\dot{x}_{1}  \tag{CN}\\
\ldots \\
\dot{x}_{n}
\end{array}\right]=\left[\begin{array}{lll}
a_{11} & \ldots \ldots & a_{1 n} \\
\ldots & \ldots \ldots & \ldots \\
a_{n 1} & \ldots \ldots & a_{n n}
\end{array}\right]\left[\begin{array}{c}
x_{1} \\
\ldots \\
x_{n}
\end{array}\right]+\left[\begin{array}{c}
b_{1} \\
\ldots \\
b_{n}
\end{array}\right]
$$

in continuous time, or

$$
x_{t+1}=A x_{t}+b \Leftrightarrow\left[\begin{array}{c}
x_{t+1}^{1}  \tag{DN}\\
\ldots \\
x_{t+1}^{n}
\end{array}\right]=\left[\begin{array}{ccc}
a_{11} & \ldots \ldots & a_{1 n} \\
\ldots & \ldots \ldots & \ldots \\
a_{n 1} & \ldots \ldots & a_{n n}
\end{array}\right]\left[\begin{array}{c}
x_{t}^{1} \\
\ldots \\
x_{t}^{n}
\end{array}\right]+\left[\begin{array}{c}
b_{1} \\
\ldots \\
b_{n}
\end{array}\right]
$$

in discrete time.

We have seen that the general solution of a nonhomogeneous system can be written as the sum of the general solution of the corresponding homogeneous system and any particular solution of the nonhomogeneous system. Hence, we start by solving the homogeneous system

$$
\begin{equation*}
\dot{x}=A x \tag{CH}
\end{equation*}
$$

or

$$
\begin{equation*}
x_{t+1}=A x_{t} \tag{DH}
\end{equation*}
$$

Having done this, the general solution of the nonhomogeneous system is easily completed by computing its stationary solution or steady state.

In the following section we will develop a solution procedure for homogeneous systems that will allow us to exploit our knowledge of the general solution to the scalar linear equation. The method works by reducing $(\mathrm{CH})$ or (DH) to an equivalent diagonal or uncoupled system through an appropriate change of variables. A diagonal system is simply a set of independent first-order linear equations that we already know how to solve. Given its solution, it is easy to recover that of the original system by applying the inverse of the diagonalizing transformation. In Sections 2(b) and 2(c) we will discuss the complications that arise when the coefficient matrix $A$ has complex eigenvalues or cannot be diagonalized. In the remainder of Section

2 we will analyze the nonhomogeneous case and discuss the stability of linear systems.

## (a) Solution by Diagonalization

Consider the discrete-time homogeneous system

$$
\begin{equation*}
x_{t+1}=A x_{t} \tag{DH}
\end{equation*}
$$

where $A$ is an $n \times n$ matrix of real numbers, and $x$ is a vector in $\mathbb{R}^{\mathrm{n}}$. For concreteness, we will often work with the two-dimensional or "planar" system:

$$
\left[\begin{array}{l}
x_{t+1}^{1}  \tag{DH2}\\
x_{t+1}^{2}
\end{array}\right]=\left[\begin{array}{ll}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{array}\right]\left[\begin{array}{l}
x_{t}^{1} \\
x_{t}^{2}
\end{array}\right]
$$

Notice that there is a special case of (DH2) that we already know how to solve. If $A$ is a diagonal matrix, that is, if $a_{12}=a_{21}=0$, then (DH2) is simply a set of two independent equations in one variable,

$$
x_{t+1}^{1}=a_{11} x_{t}^{1} \quad \text { and } \quad x_{t+1}^{2}=a_{22} x_{t}^{2}
$$

and their general solutions are of the form

$$
x_{t}^{1}=c_{1} a_{11}^{t} \quad \text { and } \quad x_{t}^{2}=c_{2} a_{22}^{t}
$$

where $c_{1}$ and $c_{2}$ are arbitrary constants.

In the general case, $A$ is not a diagonal matrix. In many cases, however, we can find a change of coordinates that will diagonalize or "uncouple" the system. In particular, recall from Chapter 3 that if $A$ has no repeated eigenvalues, then its eigenvectors $e_{1}, \ldots, e_{n}$ are all linearly independent, and the matrix $E=\left[e_{1}, \ldots, e_{n}\right]$ can be used to diagonalize $A$. That is, $E^{-1} A E=\Lambda$, where $\Lambda=\operatorname{diag}\left(\lambda_{1}, \ldots, \lambda_{n}\right)$ is the matrix with the eigenvalues of $A$ in the principal, diagonal, and zeros elsewhere.

Using this result, we can now derive a formula for the general solution of (DH) when the coefficient matrix $A$ has no repeated eigenvalues. Premultiplying both sides of

$$
\begin{equation*}
x_{t+1}=A x_{t} \tag{DH}
\end{equation*}
$$

by the inverse of the matrix of eigenvectors, $E$ (observe that $E E^{-1}=I$ ),

$$
E^{-1} x_{t+1}=E^{-1} A\left(E E^{-1}\right) x_{t}=\left(E^{-1} A E\right)\left(E^{-1} x_{t}\right)
$$

Using the fact that $E^{-1} A E=\Lambda$, we have

$$
E^{-1} x_{t+1}=\Lambda\left(E^{-1} x_{t}\right)
$$

Finally, defining the transformed variables

$$
y_{t}=E^{-1} x_{t}
$$

we can rewrite the equation in the form

$$
y_{t+1}=\Lambda y_{t}
$$

In this way, we obtain a diagonal or uncoupled system in the transformed variables $y_{t}$ whose coefficients are the eigenvalues of the coefficient matrix of the original system. The general solution of this system, denoted by $y_{t}^{h}$, is easy to calculate, as we will soon see. Given $y_{t}^{h}(c)$, we can recover the general solution of the original system simply by applying the inverse of the diagonalizing transformation, that is, by premultiplying $y_{t}^{h}$ by the matrix formed by the eigenvectors of $A$ :

$$
x_{t}^{h}=E y_{t}^{h}
$$

For example, the planar system

$$
\left[\begin{array}{l}
x_{t+1}^{1}  \tag{DH2}\\
x_{t+1}^{2}
\end{array}\right]=\left[\begin{array}{ll}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{array}\right]\left[\begin{array}{l}
x_{t}^{1} \\
x_{t}^{2}
\end{array}\right]
$$

reduces, after diagonalization, to two independent equations,

$$
\begin{equation*}
y_{t+1}^{1}=\lambda_{1} y_{t}^{1} \quad \text { and } \quad y_{t+1}^{2}=\lambda_{2} y_{t}^{2} \tag{1}
\end{equation*}
$$

where

$$
y=\left(y^{1}, y^{2}\right)=E^{-1} x
$$

The general solution of (1) can be written

$$
y_{t}^{h}(c)=\left[\begin{array}{l}
y_{t}^{1}  \tag{2}\\
y_{t}^{2}
\end{array}\right]=\left[\begin{array}{l}
c_{1} \lambda_{1}^{t} \\
c_{2} \lambda_{2}^{t}
\end{array}\right]
$$

in terms of the transformed variables, and

$$
\left[\begin{array}{l}
x_{t}^{1} \\
x_{t}^{2}
\end{array}\right]=x_{t}^{h}(c)=E y_{t}^{h}(c)=\left[\begin{array}{ll}
e_{11} & e_{21} \\
e_{12} & e_{22}
\end{array}\right]\left[\begin{array}{l}
c_{1} \lambda_{1}^{t} \\
c_{2} \lambda_{2}^{t}
\end{array}\right]=\left[\begin{array}{l}
c_{1} e_{11} \lambda_{1}^{t}+c_{2} e_{21} \lambda_{2}^{t} \\
c_{1} e_{12} \lambda_{1}^{t}+c_{2} e_{22} \lambda_{2}^{t}
\end{array}\right]
$$

in terms of the original variables. As usual, $c=\left(c_{1}, c_{2}\right)^{T}$ is a vector of arbitrary constants, and the choice of a value for $c$ is equivalent to the specification of a boundary condition.

The generalization for systems of arbitrary dimension $n$ is straightforward. The general solution of $y_{t+1}=\Lambda y_{t}$ is of the form

$$
y_{t}=\Lambda^{t} c
$$

where $\Lambda^{t}=\operatorname{diag}\left(\lambda_{1}^{t}, \ldots, \lambda_{n}^{t}\right)$, and $c$ is a column vector of arbitrary constants. Premultiplying by $E$, the general solution of the original system is given by

$$
\begin{equation*}
x_{t}^{h}(c)=E y_{t}^{h}(c)=E \Lambda^{t} c \tag{3}
\end{equation*}
$$

Operating in (3), the general solution can be written as shown in the following theorem, which summarizes our results.

Theorem 2.1. Let $\mathrm{A}$ be a real $\mathrm{n} \times \mathrm{n}$ matrix with no repeated eigenvalues. Then the $\mathrm{j}$ th component of the general solution of the system $\mathbf{x}_{\mathrm{t}+1}=\mathbf{A x}_{\mathrm{t}}$ can be written

$$
\mathrm{x}_{\mathrm{jt}}^{\mathrm{h}}(\mathrm{c})=\sum_{\mathrm{i}=I}^{\mathrm{n}} \mathrm{c}_{\mathrm{i}} \mathrm{e}_{\mathrm{ij}} \lambda_{\mathrm{i}}^{\mathrm{t}}
$$

where $\mathrm{e}_{\mathrm{ij}}$ is the $\mathrm{j}$ th component of the eigenvector $\mathrm{e}_{\mathrm{i}}$ associated with the eigenvalue $\lambda_{i}$.

Proceeding in a similar fashion, we obtain an analogous result for the homogeneous linear system in continuous time,

$$
\begin{equation*}
\dot{x}=A x \tag{CH}
\end{equation*}
$$

The general solution of $(\mathrm{CH})$ is of the form

$$
\begin{equation*}
x^{h}(t ; c)=E e^{\Lambda t} c \tag{4}
\end{equation*}
$$

where

$$
e^{\Lambda t}=\left[\begin{array}{ccc}
\exp \left(\lambda_{1} t\right) & \ldots \ldots & 0 \\
\ldots & \ldots \ldots & \ldots \\
0 & \ldots \ldots & \exp \left(\lambda_{n} t\right)
\end{array}\right]
$$

Theorem 2.2. Let $\mathrm{A}$ be a real $\mathrm{n} \times \mathrm{n}$ matrix with no repeated eigenvalues. Then the $\mathrm{j}$ th component of the general solution of the system $(\mathrm{CH}), \dot{\mathrm{x}}=\mathrm{Ax}$, can be written

$$
\mathrm{x}_{\mathrm{j}}^{\mathrm{h}}(\mathrm{t} ; \mathrm{c})=\sum_{\mathrm{i}=I}^{\mathrm{n}} \mathrm{c}_{\mathrm{i}} \mathrm{e}_{\mathrm{ij}} \exp \left(\lambda_{\mathrm{i}} \mathrm{t}\right)
$$

where $\mathrm{e}_{\mathrm{ij}}$ is the jth component of the eigenvector $\mathrm{e}_{\mathrm{i}}$ associated with the eigenvalue $\lambda_{i}$.

Problem 2.3 will ask the reader to derive this result using a diagonalization procedure. But first we give an alternative proof of the theorem that may be instructive.

Proof. We seek solutions of the system $(\mathrm{CH}), \dot{x}=A x$, of the form

$$
\begin{equation*}
x(t)=e^{\alpha t} z \tag{1}
\end{equation*}
$$

where $z$ is a vector, and $\alpha$ a scalar. For a function of the form (1) to be a solution of the system, we will have to impose certain restrictions on $z$ and $\alpha$. In particular, we want (1) to satisfy equation $(\mathrm{CH})$, that is,

$$
[\dot{x}(t)=] \alpha e^{\alpha t} z=e^{\alpha t} A z[=A x(t)]
$$

Dividing both sides by $e^{\alpha x} \neq 0$ and rearranging, we have

$$
(A-\alpha I) z=\underline{0}
$$

where $I$ is the identity matrix. Observe that this is precisely the condition that must be satisfied by the eigenvalues and eigenvectors of $A$. Hence, the vector-valued function $x(t)=z e^{\alpha t}$ is a solution of $(\mathrm{CH})$ if $\alpha$ is an eigenvalue of $A$ and $z$ is a corresponding eigenvector. Occasionally we will refer to solutions of this form as elementary solutions of $(\mathrm{CH})$.

Hence, the functions of the form

$$
\begin{equation*}
x^{i}(t)=\left[x_{1}^{i}(t), \ldots, x_{n}^{i}(t)\right]^{T}=\exp \left(\lambda_{l} t\right) e_{i} \tag{2}
\end{equation*}
$$

are solutions of $(\mathrm{CH})$. Moreover, we have assumed that the eigenvalues $\lambda_{1}$, $\ldots, \lambda_{n}$ are all distinct. Because this guarantees the linear independence of the eigenvectors, the functions $\left\{x^{i}(t) ; i=1, \ldots, n\right\}$ are linearly independent and therefore constitute a fundamental set of solutions. Thus, we can write the general solution of $(\mathrm{CH})$ in the form given in the theorem,

$$
x^{h}(t ; c)=\sum_{i=1}^{n} c_{i} \exp \left(\lambda_{t} t\right) e_{l}
$$

Problem 2.3. Derive equation (4) by diagonalizing the coefficient matrix of $(\mathrm{CH})$.

## (b) Imaginary Eigenvalues

Let $A$ be a real matrix with no repeated eigenvalues. We have just seen that the functions of the form $x^{i}(t)=\exp \left(\lambda_{i} t\right) e_{i}$ form a basis for the solution space of the homogeneous system

$$
\begin{equation*}
\dot{x}=A x \tag{CH}
\end{equation*}
$$

Hence, the general solution of $(\mathrm{CH})$ can be written in the form

$$
\begin{equation*}
x^{h}(t ; c)=\sum_{i=1}^{n} c_{i} \exp \left(\lambda_{i} t\right) e_{i} \tag{G.S}
\end{equation*}
$$

If $A$ has only real eigenvalues, its eigenvectors will have real components, and by assigning real values to the constants $c_{i}$ in (G.S), we can obtain all the real-valued solutions of the system. If the system has some complex roots, (G.S) remains valid, but its usefulness is limited, as this expression now describes a family of complex-valued functions. Although all these functions are indeed solutions of the system, typically we are interested only in those that are real-valued. Hence, we would like to construct a different basis for the solution space, one that will allow us to recover the real solutions of the system by assigning real values to the arbitrary constants.

This turns out to be fairly easy to do. If $A$ is a matrix with real entries, its complex eigenvalues and eigenvectors come in conjugate pairs, and, therefore, so do the functions $x^{i}(t)=\exp \left(\lambda_{i} t\right) e_{i}$ that are still solutions of (1). That is, if $x^{i}(t)=u(t)+i v(t)$ is a solution of $(\mathrm{CH})$, then so is the function
$x^{j}(t)=u(t)-i v(t)$. It is possible to show, moreover, that the real functions $u(t)$ and $v(t)$ are themselves solutions of $(\mathrm{CH})$ and that they can be used, together with any real-valued elementary solutions of the system, $\exp \left(\lambda_{i} t\right) e_{i}$, to form a real-valued basis for the solution space of the system.

For the sake of concreteness, let us assume that the first two eigenvalues of the coefficient matrix, $\lambda_{1}$ and $\lambda_{2}$, are complex, and the rest, $\lambda_{3}, \ldots, \lambda_{n}$, are real numbers. If $A$ has only real coefficients, then $\lambda_{1}$ and $\lambda_{2}$ are conjugates, that is,

$$
\lambda_{1}=\alpha+i \mu \quad \text { and } \quad \lambda_{2}=\alpha-i \mu
$$

and the same is true of the corresponding eigenvectors, which can be written

$$
e_{1}=d+i f \text { and } e_{2}=d-i f
$$

where $d$ and $f$ are vectors in $\mathbb{R}^{\mathrm{n}}$. The corresponding elementary solutions are the functions

$$
x^{1}(t)=\exp \left(\lambda_{1} t\right) e_{1} \quad \text { and } \quad x^{2}(t)=\exp \left(\lambda_{2} t\right) e_{2}
$$

Let us rewrite $x^{1}(t)$ in a more convenient form. ${ }^{2}$ We have

$$
\begin{aligned}
x^{1}(t) & =\exp \left(\lambda_{1} t\right) e_{1}=e^{(\alpha+i \mu) t}(d+i f)=e^{\alpha t}(\cos \mu t+i \sin \mu t)(d+i f) \\
& =e^{\alpha t}\left\{d \cos \mu t+i f \cos \mu t+i d \sin \mu t+i^{2} f \sin \mu t\right\} \\
& =e^{\alpha t}(d \cos \mu t-f \sin \mu t)+i e^{\alpha t}(f \cos \mu t+d \sin \mu t)
\end{aligned}
$$

Proceeding in the same way,

$$
x^{2}(t)=\exp \left(\lambda_{2} t\right) e_{2}=e^{\alpha t}(d \cos \mu t-f \sin \mu t)-i e^{\alpha t}(f \cos \mu t+d \sin \mu t)
$$

We now define the functions

$$
u(t)=e^{\alpha t}(d \cos \mu t-f \sin \mu t) \quad \text { and } \quad v(t)=e^{\alpha t}(f \cos \mu t+d \sin \mu t)
$$

and write the elementary solutions in the form

$$
x^{1}(t)=u(t)+i v(t) \text { and } \quad x^{2}(t)=u(t)-i v(t)
$$

We know that any linear combination of solutions of $(\mathrm{CH})$ is also a solution of $(\mathrm{CH})$. Therefore,

$$
\begin{aligned}
y\left(t ; \kappa_{1}, \kappa_{2}\right) & =\kappa_{1} x^{1}(t)+\kappa_{2} x^{2}(t)=\kappa_{1}[u(t)+i v(t)]+\kappa_{2}[u(t)-i v(t)] \\
& =\left(\kappa_{1}+\kappa_{2}\right) u(t)+i\left(\kappa_{1}-\kappa_{2}\right) v(t)
\end{aligned}
$$

is also a solution for any (complex) scalars $\kappa_{1}$ and $\kappa_{2}$. In particular, we can put

$$
y(t ; 1 / 2,1 / 2)=u(t) \text { and } \quad y(t ;-i / 2, i / 2)=v(t)
$$

to conclude that $u(t)$ and $v(t)$ are also solutions of $(\mathrm{CH})$. Moreover, it can be shown that $u()$ and $v()$ are linearly independent of each other and the other elementary solutions. Hence, instead of $x^{1}(t)$ and $x^{2}(t)$, we can use $u(t)$ and $v(t)$ to complete the fundamental set of solutions. Then we can write the general solution of the system in the form

$$
\begin{align*}
x^{h}(t ; c) & =c_{1} u(t)+c_{2} v(t)+\sum_{i=3}^{n} c_{i} \exp \left(\lambda_{i} t\right) e_{i} \\
& =c_{1} e^{\alpha t}(d \cos \mu t-f \sin \mu t)+c_{2} e^{\alpha t}(f \cos \mu t+d \sin \mu t)+\sum_{i=3}^{n} c_{i} \exp \left(\lambda_{i} t\right) e_{i} \tag{5}
\end{align*}
$$

For the case of the discrete system $x_{t+1}=A x_{t}$, a similar procedure can be used. Assume that the first eigenvalues $\lambda_{1}$ and $\lambda_{2}$ of the coefficient matrix are complex,

$$
\lambda_{1}=\alpha+i \mu=r(\cos \theta+i \sin \theta), \quad \lambda_{2}=\alpha-i \mu=r(\cos \theta-i \sin \theta)
$$

where $r$ is the common modulus of $\lambda_{1}$ and $\lambda_{2}, \theta$ is the angle formed by the vector $\lambda_{1}$ in the complex plane and the horizontal axis (see Section 7 of Chapter 1), and the rest, $\lambda_{3}, \ldots, \lambda_{n}$, are real. Then the general solution can be written in terms of a real basis, as follows:

$$
\begin{align*}
x_{t}^{h}(c) & =c_{1} u(t)+c_{2} v(t)+\sum_{i=3}^{n} c_{i} \lambda_{i}^{t} e_{i} \\
& =c_{1} r^{t}(d \cos \theta t-f \sin \theta t)+c_{2} r^{t}(f \cos \theta t+d \sin \theta t)+\sum_{i=3}^{n} c_{i} \lambda_{i}^{t} e_{i} \tag{6}
\end{align*}
$$

Problem 2.4. Derive equation (6).

## (c) Repeated Eigenvalues

We now consider what happens when the coefficient matrix of the homogeneous linear system has some repeated eigenvalues. If $\xi$ is an eigenvalue of multiplicity $m$ (i.e., it is repeated $m$ times), then associated with it there is a set of up to $m$ (but possibly fewer) linearly independent eigenvectors. If we cannot find a full set of $m$ linearly independent characteristic vectors, the coefficient matrix will not be diagonalizable, and the procedure we have used thus far will not work.

From a slightly different perspective, the problem is that we may not have enough linearly independent elementary solutions of the form $\exp \left(\lambda_{i} t\right) e_{i}$ to complete a basis of the solution space. To complete a fundamental set of solutions, we will have to search for functions of a different form. It turns out that the additional solutions we need can be found among a family of functions of a relatively simple form, each containing the product of a polynomial in $t$ and an exponential.

In particular, assume that the coefficient matrix $A$ has $k$ distinct roots $\mu_{1}, \ldots, \mu_{k}$, with multiplicities $m_{1}, \ldots, m_{k}$, respectively. Then the solutions of the system $(\mathrm{CH}), \dot{x}=A x$, will be of the form

$$
\begin{equation*}
x(t)=\sum_{i=1}^{k} P_{i}(t) \exp \left(\mu_{i} t\right)=\sum_{i=1}^{k} \sum_{j=1}^{m_{i}} p_{i j} t^{j-1} \exp \left(\mu_{i} t\right) \tag{7}
\end{equation*}
$$

where $P_{i}(t)$ is a polynomial in $t$ of order $k-1$ (with vector-valued coefficients). We observe, however, that not all functions of the form (7) are solutions of $(\mathrm{CH})$. Additional restrictions must be placed on the coefficients $p_{i j}$ in order for $x(t)$ to be a solution of the system, as shown in the following problem.

Problem 2.5. Given the linear system $(\mathrm{CH}), \dot{x}=A x$, assume that there is one eigenvalue $\xi$ of multiplicity $2\left(\lambda_{1}=\lambda_{2}=\xi\right)$, and the rest of the eigenvalues $\lambda_{3}, \ldots, \lambda_{n}$ of $A$ are all different from each other. Associated with the repeated eigenvalue we have two elementary solutions:

$$
x^{1}(t)=\exp \left(\lambda_{1} t\right) e_{1}=e^{\xi t} e_{1} \quad \text { and } \quad x^{2}(t)=\exp \left(\lambda_{2} t\right) e_{2}=e^{\xi t} e_{2}
$$

Clearly, if $e_{1}$ and $e_{2}$ are linearly independent eigenvectors associated with $\xi$, the elementary solutions $x^{1}(t)$ and $x^{2}(t)$ are also independent from each other and from the rest of the elementary solutions $x^{3}(t), \ldots, x^{n}(t)$. Hence the set of elementary solutions is still a basis for the solution space of the homogeneous system, and we can write the general solution as before:

$$
\begin{equation*}
x^{g}(t)=c_{1} x^{1}(t)+\ldots+c_{n} x^{n}(t) \tag{G.S}
\end{equation*}
$$

If $e_{1}$ and $e_{2}$ are linearly dependent, however, so are $x^{1}(t)$ and $x^{2}(t)$, and we do not have enough independent elementary solutions to span the solution space. To complete a basis for the solution space that will allow us to write the general solution, we need to find an additional solution to $(\mathrm{CH})$ that will be linearly independent from the elementary solutions. We will seek a solution of the form

$$
\begin{equation*}
\phi(t)=(a+b t) e^{\xi t}=a e^{\xi t}+b t e^{\xi t} \tag{1}
\end{equation*}
$$

that is, the product of a polynomial of order 1 (1 less than the multiplicity of $\xi$ ) in $t$ and the exponential term in the eigenvalue $\xi$. What restrictions must be placed on the vectors $a$ and $b$ so that $\phi(t)$ will indeed be a solution of the system, that is, will satisfy the equation $\phi^{\prime}(t)=A \phi(t)$ ? Write the general solution of the system.

(d) Nonhomogeneous Systems and Stability Conditions

We now turn to nonhomogeneous linear systems of the form

$$
\begin{equation*}
\dot{x}=A x+b \tag{CN}
\end{equation*}
$$

or

$$
\begin{equation*}
x_{t+1}=A x_{t}+b \tag{DN}
\end{equation*}
$$

We have seen that the general solution of such a system can be written

$$
\begin{equation*}
x^{N}(t)=x^{H}(t)+x^{P}(t) \tag{G.S}
\end{equation*}
$$

where the complementary function $x^{H}(t)$ is the general solution of the corresponding homogeneous system, and $x^{P}(t)$ is an arbitrary particular solution of the nonhomogeneous system.

In the preceding sections we have shown how to compute $x^{H}(t)$. Hence, it suffices to find one particular solution of (CN) or (DN) to be able to write its general solution. An obvious choice is the stationary solution of the system, $\bar{x}$, whenever it exists. To find it, in the discrete case we put $x_{t+1}=x_{t}$, eliminating the time subscripts, and solve for $x$ to obtain

$$
\begin{align*}
x= & A x+b \Rightarrow(A-I) x=-b \\
& \Rightarrow \bar{x}=-(A-I)^{-1} b \tag{8}
\end{align*}
$$

whenever $A-I$ is invertible. In the continuous case, we set $\dot{x}$ to zero:

$$
\begin{align*}
\dot{x}= & A x+b=\underline{0} \Rightarrow A x=-b \\
& \Rightarrow \bar{x}=-A^{-1} b \tag{9}
\end{align*}
$$

provided $A$ is invertible. ${ }^{3}$

Using the results from the preceding section, we can write the general solutions of the given systems directly. ${ }^{4}$ Then the conditions for stability or instability follow immediately by inspection.

Theorem 2.6. Let $\mathrm{A}$ be a real $\mathrm{n} \times \mathrm{n}$ matrix with no repeated eigenvalues, all different from zero. Then the general solution of the system $(C N), \dot{x}=\mathrm{Ax}+\mathrm{b}$, is given by

$$
\begin{equation*}
\mathrm{x}^{\mathrm{g}}(\mathrm{t} ; \mathrm{c})=\overline{\mathrm{x}}+\sum_{\mathrm{i}=l}^{\mathrm{n}} \mathrm{c}_{\mathrm{i}} \exp \left(\lambda_{\mathrm{i}} \mathrm{t}\right) \mathrm{e}_{\mathrm{i}} \tag{G.S.C}
\end{equation*}
$$

where $\vec{x}=-\mathrm{A}^{-I} \mathrm{~b}$ is the unique stationary state of the system, $\mathrm{c}_{1}, \ldots, \mathrm{c}_{\mathrm{n}}$ are arbitrary constants to be definitized by choice of a boundary condition, $\lambda_{\mathrm{i}}$ is the $\mathrm{i}$ th characteristic root of the coefficient matrix $\mathrm{A}$, and $\mathrm{e}_{\mathrm{i}}$ is the corresponding characteristic vector.

Given (G.S), it is easily determined whether the steady state $\bar{x}$ is stable or unstable. Suppose first that all roots of the system are real numbers. Then the $j$ th component of the general solution is given by

$$
\begin{equation*}
x_{j}^{g}(t ; c)=\bar{x}_{j}+\sum_{i=1}^{n} c_{i} e_{i j} \exp \left(\lambda_{i} t\right) \tag{10}
\end{equation*}
$$

The stability of the steady state depends on the signs of the system's eigenvalues. If all roots are negative, then all terms of the form $\exp \left(\lambda_{i} t\right)$ go to zero
as $t \rightarrow \infty$, and the solution converges asymptotically 'to the steady state $\bar{x}$ for any value of the constants $c_{i}$ - that is, from any initial position. On the other hand, if any of the roots of the system are strictly positive, the corresponding exponential terms $\exp \left(\lambda_{i} t\right)$ go to infinity as $t \rightarrow \infty$. Hence the system is unstable and diverges from the steady state, unless we "kill" the explosive roots by assigning a zero value to the corresponding constants.

If any of the characteristic roots are complex, the general solution can be written in the form derived in the preceding section. In particular, if $\lambda_{1}=\alpha+i \mu$ and $\lambda_{2}=\alpha-i \mu$ are the only complex eigenvalues, with eigenvectors $e_{1}=d+$ if and $e_{2}=d$-if, we have

$$
\begin{align*}
x^{g}(t ; c)= & \bar{x}+c_{1} e^{\alpha t}(d \cos \mu t-f \sin \mu t)+c_{2} e^{\alpha t}(f \cos \mu t+d \sin \mu t) \\
& +\sum_{i=3}^{n} c_{i} \exp \left(\lambda_{i} t\right) e_{i} \tag{11}
\end{align*}
$$

This expression shows that the crucial determinants of the stability of the steady state are the signs of the real parts of the eigenvalues of the system, $\alpha$. The existence of a nonzero imaginary component $\mu$ introduces a cyclical element into the solution through the functions $\sin \mu t$ and $\cos \mu t$, but what determines the convergence or divergence of the system is the behavior of the term $e^{o t}$. Observe also that if the eigenvalues of $A$ are all pure imaginary numbers, the solutions of the system are cyclical and describe closed trajectories around the steady state.

Finally, if the system has repeated roots, the general solution is of the form

$$
\begin{equation*}
x(t)=\sum_{i=1}^{k} P_{i}(t) \exp \left(\mu_{i} t\right)=\sum_{i=1}^{k} \sum_{j=1}^{m_{i}} p_{i j} t^{j-1} \exp \left(\mu_{i} t\right) \tag{12}
\end{equation*}
$$

This expression implies that even with repeated roots, the stability of the system depends on the signs of the real parts of its eigenvalues. If $\mu_{i}$ is real and negative, for example, the terms of the form $t e^{\mu t}$ also tend to zero as $t \rightarrow \infty$, because the exponential term prevails. By L'Hôpital's rule, we have

$$
\lim _{t \rightarrow \infty} t e^{\mu t}=\lim _{t \rightarrow \infty} \frac{t}{e^{-\mu t}}=\lim _{t \rightarrow \infty} \frac{1}{-\mu e^{-\mu t}} \sim \frac{1}{\infty}=0
$$

In summary, the stability of the continuous-time autonomous linear system depends on the signs of the real parts of the eigenvalues of its coefficient matrix. We summarize as follows:

Theorem 2.7. Let $\mathrm{A}$ be a real $\mathrm{n} \times \mathrm{n}$ matrix with nonzero eigenvalues. Then the unique steady state of the system (CS), $\overline{\mathrm{x}}=-\mathrm{A}^{-1} \mathrm{~b}$, is (globally) asymptotically stable if and only if all the eigenvalues of the coefficient matrix A have strictly negative real parts, and it is unstable if at least one of the eigenvalues is strictly positive.

A steady state that satisfies the conditions of the theorem (i.e., has nonzero characteristic roots) is said to be hyperbolic.

For discrete-time systems, we have a very similar situation.

Theorem 2.8. Let $\mathrm{A}$ be a real $\mathrm{n} \times \mathrm{n}$ matrix with eigenvalues all distinct and different from 1.5 Then the general solution of the system (DN), $\mathbf{x}_{\mathrm{t}+\mathrm{I}}=\mathrm{Ax}_{\mathrm{t}}+\mathrm{b}$, is given by

$$
\begin{equation*}
\mathrm{x}_{\mathrm{t}}^{\mathrm{g}}(\mathrm{c})=\overline{\mathrm{x}}+\sum_{\mathrm{i}=I}^{\pi} \mathrm{c}_{\mathrm{i}} \lambda_{\mathrm{i}}^{\mathrm{t}} \mathrm{e}_{\mathrm{l}} \tag{G.S.D}
\end{equation*}
$$

where $\overline{\mathrm{x}}=-(\mathrm{A}-\mathrm{I})^{-1} \mathrm{~b}$ is the unique steady state of the system, $\mathrm{c}_{l}, \ldots, \mathrm{c}_{\mathrm{n}}$ are arbitrary constants whose values will be determined by the choice of an appropriate boundary condition, $\lambda_{\mathrm{i}}$ is the $\mathrm{i}$ th eigenvalue of $\mathrm{A}$, and $\mathrm{e}_{\mathrm{i}}$ is the corresponding eigenvector.

This expression shows that what determines the convergence or divergence of the system is whether or not the absolute values of its roots are smaller than 1 . If we have complex roots, we have

$$
x_{i}^{g}(c)=c_{1} r^{t}(d \cos \theta t-f \sin \theta t)+c_{2} r^{t}(f \cos \theta t+d \sin \theta t)+\sum_{i=3}^{n} c_{i} \lambda_{i}^{t} e_{i}
$$

where we observe that the stability of the system depends on the value of $r$, the modulus of its complex roots. In the case of systems with repeated roots, the situation is similar to the one that arises in continuous-time systems. We have, then, the following:

Theorem 2.9. Let A be a real $\mathrm{n} \times \mathrm{n}$ matrix whose eigenvalues all have moduli different from 1. Then the unique steady state of the system (DN), given by $\overline{\mathrm{x}}=-(\mathrm{A}-\mathrm{I})^{-1} \mathrm{~b}$, is (globally) asymptotically stable if and only if all the eigenvalues of the coefficient matrix A have moduli strictly smaller than 1, and unstable if at least one eigenvalue has modulus strictly larger than 1 .

## A Class of Nonautonomous Systems

The diagonalization procedure discussed in Section 2(a) can be extended to deal with nonautonomous systems of the form

$$
\begin{equation*}
\dot{x}=A x+b(t) \quad \text { or } \quad x_{t+1}=A x_{t}+b_{t} \tag{13}
\end{equation*}
$$

where the coefficient matrix $A$ is constant, but the forcing term $b$ is a function of time.

Assume that $A$ is diagonalizable, and consider, for concreteness, the discrete case. Proceeding as before, we premultiply both sides of (13) by the inverse of the eigenvector matrix, $E^{-1}$, to get

$$
E^{-1} x_{t+1}=E^{-1} A\left(E E^{-1}\right) x_{t}+E^{-1} b_{t}=\Lambda E^{-1} x_{t}+E^{-1} b_{t}
$$

If we now define the transformed variables

$$
y_{t}=E^{-1} x_{t} \quad \text { and } \quad d_{t}=E^{-1} b_{t}
$$

we can rewrite the earlier expression as

$$
y_{t+1}=\Lambda y_{t}+d_{t}
$$

Because $\Lambda=\operatorname{diag}\left(\lambda_{1}, \ldots, \lambda_{n}\right)$ is diagonal, the transformed system reduces to a set of independent equations of the form

$$
y_{t+1}^{i}=\lambda_{i} y_{t}^{i}+d_{t}^{i}
$$

Following the procedure discussed in Section 5 of Chapter 9, we can solve each of these equations separately. To recover the solution of the original system, it suffices to apply the inverse of the original transformation, that is, to use the relation $x_{t}=E y_{t}$.

## (e) Stable and Unstable Spaces

We have seen that the stability of a linear system depends on the values of its characteristic roots. In the case of the continuous-time system $\dot{x}=A x+b$, for example, if all the eigenvalues of $A$ have negative real parts, the solution converges asymptotically to the stationary state $\bar{x}$ from any initial position. In this case, we say that $\bar{x}$ is a sink. If all the characteristic roots of $A$ have positive real parts, the system is "completely unstable" and "explodes" from any initial position other than the steady state itself. In this case, we speak of a source. The situation is similar in the case of discrete-time systems, except that now we are concerned with the moduli of the eigenvalues, rather than with the signs of their real parts.

When the system has roots with positive real parts and roots with negative real parts (or roots inside and roots outside the unit circle in the complex plane, in the discrete-time case), we say that its steady state is a saddle point. A saddle point is an unstable equilibrium, according to the definition given in Chapter 9, for there exist solution trajectories that, starting arbitrarily close to the steady state, get arbitrarily far from it as time passes. There are, however, other trajectories that converge asymptotically to the steady state. In fact, there is a possibly large region of the state space with the property that any trajectory originating in it converges to the steady state. This region is what we call the stable space or stable manifold of the system.

Suppose, for concreteness, that we have a homogeneous system in continuous time, $(\mathrm{CH}), \dot{x}=A x$, with $n$ distinct eigenvalues, all real and different from zero. Partition the eigenvalues of $A,\left\{\lambda_{i} ; i=1, \ldots, n\right\}$, into two sets, $S$ and $U$, with $i \in S$ if $\lambda_{i}<0$ and $i \in U$ if $\lambda_{i}>0$, and write the general solution of the system in the form

$$
\begin{equation*}
x^{g}\left(t ; c_{u}, c_{s}\right)=\sum_{i=1}^{n} c_{i} \exp \left(\lambda_{i} t\right) e_{i}=\sum_{i \in S} c_{i} \exp \left(\lambda_{i} t\right) e_{i}+\sum_{i \in U} c_{i} \exp \left(\lambda_{i} t\right) e_{i} \tag{14}
\end{equation*}
$$

where, as usual, $c=\left(c_{1}, \ldots, c_{n}\right)^{T}$ is a vector of arbitrary constants. Clearly, if we set the constants $c_{u}$ corresponding to the unstable roots equal to zero, then, the solution of the system, which reduces to

$$
x^{g}\left(t ; \underline{0} c_{s}\right)=\sum_{i \in S} c_{i} \exp \left(\lambda_{i} t\right) e_{i}
$$

converges to the steady state $\bar{x}=\underline{0}$ for any value of the vector $c_{s}$.

Setting some of the arbitrary constants equal to zero is equivalent to choosing a subset of the state space $\mathbb{R}^{n}$. We will show that the subset of $\mathbb{R}^{\mathrm{n}}$ corresponding to the boundary condition $c_{u}=\underline{0}$ is the subspace of $\mathbb{R}^{\mathrm{n}}$ spanned by the eigenvectors associated with the stable roots. Recall that the absence of repeated roots guarantees the linear independence of the eigenvectors of the coefficient matrix $A$. Hence, under our assumptions, $A$ has a full set of $n$ linearly independent eigenvectors, $~ e=\left\{e_{i} \in \mathbb{R}^{\mathrm{n}} ; i=1, \ldots, n\right\}$, and this family of vectors is a basis for the state space $\mathbb{R}^{\mathrm{n}}$. Let $x^{0}$ be the initial position of the system at time zero. Because e is a basis of $\mathbb{R}^{\mathrm{n}}$, the vector $x^{0}$ can be written in precisely one way as a linear combination of the eigenvalues of $A$. That is, there exist real numbers $\beta_{1}, \ldots, \beta_{n}$, not all zero, such that

$$
\begin{equation*}
x^{0}=\sum_{i=1}^{n} \beta_{i} e_{i} \tag{15}
\end{equation*}
$$

Moreover, evaluating the general solution of the system at time zero,

$$
\begin{equation*}
x^{g}(0, c)=\sum_{i=1}^{n} c_{i} \exp \left(\lambda_{i} 0\right) e_{i}=\sum_{i=1}^{n} c_{i} e_{i}=x^{0} \tag{16}
\end{equation*}
$$

and combining (15) and (16),

$$
\begin{equation*}
\sum_{i=1}^{0}\left(c_{i}-\beta_{i}\right) e_{i}=\underline{0} \tag{17}
\end{equation*}
$$

Finally, by the linear independence of the eigenvectors, (17) implies that

$$
c_{i}=\beta_{i} \forall i=1, \ldots, n
$$

That is, the arbitrary constants $c_{i}$ in the general solution correspond to the coordinates of the system's initial position in the coordinate system defined by the eigenvectors of the coefficient matrix.

Now, the convergent space of the system is the set of points for which $c_{u}=\underline{0}$, that is, the set of $n$-vectors that can be written as linear combinations of the stable eigenvectors, or the subspace of $\mathbb{R}^{\mathrm{n}}$ generated by $\left\{e_{i} \in \mathbb{R}^{\mathrm{n}} ; i \in\right.$ $S\}$. Call this set $W^{s}(\underline{0})$, where $\underline{0}$ is the steady state of the given homogeneous system. Given any point $x^{0}$ in $W^{s}(\underline{0})$, the particular solution of the system through this point is given by

$$
x\left(t ; x^{0}\right)=\sum_{i \in S} \beta_{i} \exp \left(\lambda_{i} t\right) e_{i}
$$

Hence, $x\left(t ; x^{0}\right) \rightarrow \underline{0}$ as $t \rightarrow \infty$. Moreover, $W^{s}(\underline{0})$ is invariant under the flow of the system, for if $x^{0}$ is a linear combination of the stable eigenvectors, so is $x\left(t ; x^{0}\right)$ for any $t$. Similarly, if $y^{0}=\sum_{i \in \mathrm{U}} \gamma_{i} e_{t}$ is a point in the unstable subspace of the system $W^{u}(\underline{0})=\operatorname{span}\left\{e_{i} ; i \in U\right\}$, the solution through $y^{0}$ is given by

$$
x\left(t ; y^{0}\right)=\sum_{i \in U} \gamma_{i} \exp \left(\lambda_{i} t\right) e_{i}
$$

and we have

$$
\left\|x\left(t ; y^{0}\right)\right\| \rightarrow \infty \quad \text { as } t \rightarrow \infty \quad \text { and } \quad x\left(t ; y^{0}\right) \rightarrow \underline{0} \quad \text { as } t \rightarrow-\infty
$$

So far, we have assumed that all the characteristic roots of the system are real-valued, but the situation is not very different if some eigenvalues are complex. Suppose $A$ has $n$ distinct but possibly complex roots,

$$
\lambda_{i}=\alpha_{j}+i \mu_{j} \quad(j=1, \ldots, n)
$$

with corresponding eigenvectors

$$
e_{j}=u_{j}+i v_{j}
$$

(Recall that complex eigenvalues and eigenvectors come in conjugate pairs. Hence, if $\mu_{k} \neq 0$ for some $k$, then $\bar{\lambda}_{k}=\alpha_{k}-i \mu_{k}$ is also an eigenvalue, and its corresponding eigenvector is of the form $\bar{e}_{k}=u_{k}-i v_{k}$.) For each pair of complex eigenvalues, we can replace the eigenvectors $e_{k}$ and $\bar{e}_{k}$ by the real vectors $u_{k}$ and $v_{k}$ and proceed as before. Hence, the stable and unstable subspaces of the homogeneous system $\dot{x}=A x$ are now given by

$$
\begin{equation*}
W^{s}(\underline{0})=\operatorname{span}\left\{u_{j}, v_{j} ; \alpha_{j}<0\right\} \quad \text { and } \quad W^{u}(\underline{0})=\operatorname{span}\left\{u_{j}, v_{j} ; \alpha_{j}>0\right\} \tag{18}
\end{equation*}
$$

Finally, in the case of the nonhomogeneous system $\dot{x}=A x+b$, with steady state $\bar{x}$, the stable and unstable spaces $W^{s}(\bar{x})$ and $W^{u}(\bar{x})$ are obtained by "displacing" the stable and unstable subspaces of the homogeneous system so that they "go through" the steady state $\bar{x}$. That is, $W^{s}(\bar{x})$ and $W^{u}(\bar{x})$ are the affine (rather than linear) subspaces of $\mathbb{R}^{\mathrm{n}}$ given by

$$
\begin{equation*}
W^{s}(\bar{x})=\bar{x}+W^{s}(\underline{0}) \text { and } W^{u}(\bar{x})=\bar{x}+W^{u}(\underline{0}) \tag{19}
\end{equation*}
$$

We summarize the discussion in the following theorem.

Theorem 2.10. Stable and unstable manifold for linear systems. Consider the linear system $\dot{\mathrm{x}}=\mathrm{Ax}+\mathrm{b}$, with steady state $\overline{\mathrm{x}}$ and suppose that $\mathrm{A}$ has no repeated roots. Then the sets $\mathrm{W}^{\mathrm{s}}(\overline{\mathrm{x}})$ and $\mathrm{W}^{\mathrm{u}}(\overline{\mathrm{x}})$ defined in (19) are invariant under the flow of the system. Moreover, given any point $\mathrm{x}^{0}$ in $\mathrm{W}^{\mathrm{s}}(\overline{\mathrm{x}})$, the solution of the system through this point, $\mathrm{x}\left(\mathrm{t} ; \mathrm{x}^{0}\right)$, converges to $\overline{\mathrm{x}}$ as $\mathrm{t} \rightarrow \infty$. Given any point $\mathrm{y}^{0}$ in $\mathrm{W}^{\mathrm{u}}(\overline{\mathrm{x}})$, the corresponding solution, $\mathrm{x}\left(\mathrm{t} ; \mathrm{y}^{0}\right)$, satisfies

$$
\left\|\mathrm{x}\left(\mathrm{t} ; \mathrm{y}^{0}\right)\right\| \rightarrow \infty \quad \text { as } \mathrm{t} \rightarrow \infty \quad \text { and } \quad \mathrm{x}\left(\mathrm{t} ; \mathrm{y}^{0}\right) \rightarrow \overline{\mathrm{x}} \quad \text { as } \mathrm{t} \rightarrow-\infty
$$

A similar result holds for discrete-time systems. In this case, however, the stable (unstable) space is defined by the eigenvectors corresponding to eigenvalues inside (outside) the unit circle in the complex plane, that is,

$$
\begin{equation*}
W^{s}(\underline{0})=\operatorname{span}\left\{u_{j}, v_{j} ;\left|\lambda_{j}\right|<1\right\} \quad \text { and } \quad W^{u}(\underline{0})=\operatorname{span}\left\{u_{j}, v_{j} ;\left|\lambda_{j}\right|>1\right\} \tag{20}
\end{equation*}
$$

## (f) Linear Systems on the Plane

In this section we analyze in detail the dynamics of autonomous linear systems in the plane, that is, systems of the form

$$
\begin{equation*}
\dot{x}=A x+b \tag{CS2}
\end{equation*}
$$

or

$$
\begin{equation*}
x_{t+1}=A x_{t}+b \tag{DS2}
\end{equation*}
$$

where $A$ is a real $2 \times 2$ matrix.

Practically all the information we need to describe the dynamics of (CS2) or (DS2) is summarized by the eigenvalues of the coefficient matrix $A$. Depending on whether the characteristic roots of $A$ are real or complex, have positive or negative real parts, or lie inside or outside the unit circle in the complex plane, the steady state of the system will be stable or unstable, and the solution trajectories will behave differently. We will examine the different possibilities that can arise in the continuous- and discrete-time cases. To summarize our results, we will construct two figures (one for discrete systems and the other for continuous systems) drawn on a Cartesian plane, with $\operatorname{det} A$ on the vertical axis and $\operatorname{tr} A$ on the horizontal axis. For each type of system we will divide this plane into a number of regions, each corresponding to a different type of steady state.

Recall from Chapter 3 (Section 6) that the eigenvalues of $A\left(\lambda_{1}\right.$ and $\left.\lambda_{2}\right)$ satisfy the relations

$$
\begin{align*}
& \operatorname{tr} A=\lambda_{1}+\lambda_{2}  \tag{21}\\
& \operatorname{det} A=\lambda_{1} \lambda_{2} \tag{22}
\end{align*}
$$

and are the solutions of the characteristic equation

$$
\begin{equation*}
p(\lambda)=|A-\lambda \mathbf{I}|=\lambda^{2}-(\operatorname{tr} A) \lambda+\operatorname{det} A=0 \tag{23}
\end{equation*}
$$

Hence, by the quadratic formula, $\lambda_{1}$ and $\lambda_{2}$ are given by

$$
\begin{equation*}
\lambda_{1}, \lambda_{2}=\frac{\operatorname{tr} \pm \sqrt{\operatorname{tr}^{2}-4 \mathrm{det}}}{2} \tag{24}
\end{equation*}
$$

Equation (24) shows that the eigenvalues of $A$ are real or complex depending on the sign of the discriminant of the characteristic equation,

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-477.jpg?height=709&width=1002&top_left_y=181&top_left_x=246)

Figure 10.1. Regions of real and complex eigenvalues.

$$
\Delta=\operatorname{tr}^{2}-4 \mathrm{det}
$$

Setting $\Delta$ equal to zero and solving for the determinant,

$$
\begin{equation*}
\Delta=\operatorname{tr}^{2}-4 \operatorname{det}=0 \Rightarrow \operatorname{det}=\operatorname{tr}^{2} / 4 \tag{25}
\end{equation*}
$$

we obtain the equation for a parabola with a minimum at the origin. This curve divides the plane into two regions, as shown in Figure 10.1. In the region above the parabola we have $\Delta<0$, that is, $\operatorname{tr}^{2}<4$ det, indicating that the roots of the system are complex numbers, whereas the region below the curve corresponds to the case of real eigenvalues $(\Delta>0)$.

Equation (24) also shows that complex eigenvalues come in conjugate pairs. Hence, if $\lambda_{1}=\alpha+i \mu$ is an eigenvalue, then so is $\lambda_{2}=\alpha-i \mu$, and equations (21) and (22) imply that

$$
\begin{equation*}
\operatorname{tr} A=\lambda_{1}+\lambda_{2}=(\alpha+i \mu)+(\alpha-i \mu)=2 \alpha \tag{26}
\end{equation*}
$$

$\operatorname{det} A=\lambda_{1} \lambda_{2}=(\alpha+i \mu)+(\alpha-i \mu)=\alpha^{2}+i \mu \alpha-i \mu \alpha-i^{2} \mu^{2}=\alpha^{2}+\mu^{2}=\left|\lambda_{1}\right|^{2}=\left|\lambda_{2}\right|^{2}$

Hence, when the eigenvalues are complex, the trace of the coefficient matrix is equal to twice the (common) real part of the eigenvalues, and the determinant is the square of their (common) modulus.

$$
\text { (i) Continuous Time }
$$

Consider the planar system in continuous time,

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-478.jpg?height=392&width=612&top_left_y=182&top_left_x=108)

Case a.1: stable node $\left(\lambda_{1}, \lambda_{2}<0\right)$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-478.jpg?height=390&width=615&top_left_y=183&top_left_x=755)

Case a.2: unstable node $\left(\lambda_{1}, \lambda_{2}>0\right)$

Figure 10.2. Nodes.

$$
\begin{equation*}
\dot{x}=A x+b \tag{CS2}
\end{equation*}
$$

and recall the general discussion of stability in Section 2(d).

Suppose first that $\Delta=\operatorname{tr}^{2}-4$ det $>0$ (i.e., we are in the region below the parabola). Then the characteristic roots of the system are real numbers, and its general solution can be written

$$
\begin{aligned}
& x_{1}^{g}(t, c)=\bar{x}_{1}+c_{1} e_{11} \exp \left(\lambda_{1} t\right)+c_{2} e_{21} \exp \left(\lambda_{2} t\right) \\
& x_{2}^{g}(t, c)=\bar{x}_{2}+c_{1} e_{12} \exp \left(\lambda_{1} t\right)+c_{2} e_{22} \exp \left(\lambda_{2} t\right)
\end{aligned}
$$

The stability of the system depends on the signs of the eigenvalues. The possible cases are the following.

## - Case (a). Real roots of the same sign: nodes

If $\operatorname{det} A=\lambda_{1} \lambda_{2}>0$, then both roots are real numbers with the same sign. In this case, the steady state $\bar{x}$ is called a node, because all the trajectories point directly "into" or "out of" the steady state. Given that the eigenvalues of $A$ must have the same sign, the sign of the trace of this matrix will tell us whether the system is stable or unstable. If $\operatorname{tr} A=\lambda_{1}+\lambda_{2}<0$, both eigenvalues are negative, and all trajectories converge smoothly to the steady state, yielding an (asymptotically) stable node. If the trace is positive, so are both eigenvalues, and the node is unstable, as illustrated in Figure 10.2.

A similar situation arises if $(\operatorname{tr} A)^{2}-4(\operatorname{det} A)=0$. Then the system has a repeated real root $\left(\lambda_{1}=\lambda_{2}=\xi\right)$, and its general solution is of the form

$$
\begin{aligned}
& x_{1}^{g}(t, c)=\bar{x}_{1}+c_{1} e_{11} \exp (\xi t)+c_{2} b_{1} t \exp (\xi t) \\
& x_{2}^{g}(t, c)=\bar{x}_{2}+c_{1} e_{12} \exp (\xi t)+c_{2} b_{2} t \exp (\xi t)
\end{aligned}
$$

where $e_{1}=\left(e_{11}, e_{12}\right)^{T}$ is an eigenvector of $A$ associated with the repeated root, and $b=\left(b_{1}, b_{2}\right)^{T}$ is a 2-vector. Note that the solution trajectories converge if $\xi<0$, and diverge when $\xi>0$.

- Case (b). Real roots of different signs: saddle points

If $\operatorname{det} A=\lambda_{1} \lambda_{2}<0$, the roots of the system are real numbers, of opposite signs, and the steady state is a saddle point. As we saw in Section 2(e), in this case the solutions of the system converge from some initial positions and diverge from others.

For concreteness, suppose that $\lambda_{1}>0$ and $\lambda_{2}<0$, and consider the general solution of the system:

$$
\begin{aligned}
& x_{1}^{g}(t, c)=\bar{x}_{1}+c_{1} e_{11} \exp \left(\lambda_{1} t\right)+c_{2} e_{21} \exp \left(\lambda_{2} t\right) \\
& x_{2}^{g}(t, c)=\bar{x}_{2}+c_{1} e_{12} \exp \left(\lambda_{1} t\right)+c_{2} e_{22} \exp \left(\lambda_{2} t\right)
\end{aligned}
$$

It is clear that if $c_{1} \neq 0$, the system's behavior will ultimately be dominated by its positive root $\lambda_{1}>0$. As $t \rightarrow \infty,\left|c_{1} \exp \left(\lambda_{1} t\right)\right| \rightarrow \infty$, and the system displays explosive behavior, moving farther and farther from the steady state as time passes. On the other hand, if we impose the boundary condition $c_{1}=0$, the system's behavior is determined by its negative root alone, and it converges to the steady state $\bar{x}$ as $t \rightarrow \infty$.

Note that in order to "kill off" the explosive root we have to assign a value of zero to one of the arbitrary constants, $c_{1}$, while the other remains "free." We have seen that assigning values to the two constants is equivalent to picking an initial point for the system, and that assigning a value to only one of them is equivalent to selecting a subspace of the phase plane. Hence, the system will converge to the steady state if and only if it starts out from a point in some subset of the $\left(x_{1}, x_{2}\right)$ plane characterized by the condition that the arbitrary constant associated with the explosive root is equal to zero.

To see what the stable subspace looks like, set $c_{1}=0$ in the general solution to get

$$
\begin{align*}
& x_{1}(t)-\bar{x}_{1}=c_{2} e_{21} \exp \left(\lambda_{2} t\right) \\
& x_{2}(t)-\bar{x}_{2}=c_{2} e_{22} \exp \left(\lambda_{2} t\right) \tag{28}
\end{align*}
$$

Using the second equation to eliminate $c_{2} \exp \left(\lambda_{2} t\right)$ from the first one,

$$
\begin{align*}
{\left[x_{1}(t)-\bar{x}_{1}\right] } & =\frac{e_{21}}{e_{22}}\left[x_{2}(t)-\bar{x}_{2}\right] \\
\Rightarrow x_{1}(t) & =\bar{x}_{1}+\frac{e_{21}}{e_{22}}\left[x_{2}(t)-\bar{x}_{2}\right] \tag{29}
\end{align*}
$$

which is the equation of the straight line labeled $S$ in Figure 10.3. This line, known as the saddle path, is the convergent subspace of the $\left(x_{1}, x_{2}\right)$ plane. If the system does not start out from a point on $S$, it will embark on an explosive path, as shown in the figure.

Notice that the slope of the saddle path is determined by the eigenvector $e_{2}$ associated with the stable root $\lambda_{2}<0$. If we take the steady state as its origin, the stable eigenvector points in the direction of the saddle path. The other eigenvector (associated with $\lambda_{1}>0$ ) also defines an interesting direction in the state plane,

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-480.jpg?height=580&width=943&top_left_y=194&top_left_x=262)

Figure 10.3. Case (b): saddle point $\left(\lambda_{1}>0, \lambda_{2}<0\right)$.

that of a divergent path, the "anti-saddle path" or unstable subspace, labeled $U$ in the figure. (Note that the two eigenvectors need not be orthogonal to each other.)

- Case (c). Complex roots: spiral points

Next, suppose that the discriminant $\Delta=\operatorname{tr}^{2}-4 d e t$ is negative. Then the eigenvalues of the system are complex numbers, $\lambda_{1}=\alpha+i \mu$ and $\lambda_{2}=\alpha-i \mu$, and, following the discussion in Section 2(b), the general solution can be written

$$
\begin{equation*}
x^{g}(t, c)=\bar{x}+c_{1} u(t)+c_{2} v(t) \tag{30}
\end{equation*}
$$

where

$$
u(t)=e^{\alpha t}(d \cos \mu t-f \sin \mu t) \quad \text { and } \quad v(t)=e^{\alpha t}(f \cos \mu t+d \sin \mu t)
$$

When the characteristic roots of the system are complex, the steady state is said to be a spiral point, because the circular functions $\sin \mu t$ and $\cos \mu t$ in the solution induce a spiral-like pattern in the orbits of the system. As nodes, spiral points can be either stable or unstable. This can be determined by checking the sign of the trace, which in this case reduces to

$$
\operatorname{tr} A=\lambda_{1}+\lambda_{2}=\alpha+i \mu+\alpha-i \mu=2 \alpha
$$

Hence, if $\operatorname{tr} A<0$, the eigenvalues have a negative real part $\alpha$, and (30) describes a family of spiral trajectories converging to the steady state $\vec{x}$, if $\operatorname{tr} A>0$, then $\alpha>0$, and the spirals diverge away from $\bar{x}$.

- Case (d). Pure imaginary roots: centers

If $\operatorname{tr} A=0$ and $\operatorname{det} A>0$, the discriminant is negative, and the eigenvalues of the system are pure imaginary numbers with a zero real part $\alpha$. Hence, the scale factor $e^{\alpha t}$ that multiplies the circular functions $u(t)$ and $v(t)$ in the general solu-

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-481.jpg?height=520&width=581&top_left_y=181&top_left_x=142)

Case c.1: stable spiral point $(\alpha<0)$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-481.jpg?height=516&width=581&top_left_y=183&top_left_x=754)

Case c.2: unstable spiral point $(\alpha>0)$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-481.jpg?height=544&width=756&top_left_y=858&top_left_x=360)

Case d: Center $(\alpha=0)$

Figure 10.4. Spiral points and centers.

tion (30) becomes a constant, and the trajectories of the system are closed curves around a steady state that is called a center. This is the only case in which the continuous linear system (CS2), $\dot{x}=A x+b$, has cyclical solutions. Note that a center is stable, because nearby solutions remain nearby, but not asymptotically so, because they do not converge to the steady state.

- Summary

We have seen that the nature and stability of the steady state of the $2 \times 2$ autonomous linear system depend on the values of its characteristic roots, given by

$$
\begin{equation*}
\lambda_{1}, \lambda_{2}=\frac{\operatorname{tr} \pm \sqrt{\operatorname{tr}^{2}-4 \mathrm{det}}}{2} \tag{24}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-482.jpg?height=698&width=1101&top_left_y=189&top_left_x=179)

Figure 10.5. Stability map for continuous linear systems in the plane.

By keeping in mind (24) and

$$
\begin{gather*}
\operatorname{tr} A=\lambda_{1}+\lambda_{2}  \tag{21}\\
\operatorname{det} A=\lambda_{1} \lambda_{2} \tag{22}
\end{gather*}
$$

it is easy to determine the nature of the system's steady state and orbits just by looking at the coefficient matrix. In particular, we have seen the following:

(i) If $\operatorname{det} A=\lambda_{1} \lambda_{2}<0$, the eigenvalues of the system are real numbers of opposite signs; hence, we have a saddle point.

(ii) If $\operatorname{det} A=\lambda_{1} \lambda_{2}>0$, the roots are either complex numbers or real numbers of the same sign. In this case there are two possibilities:

(a) If $\operatorname{tr} A=\lambda_{1}+\lambda_{2}<0$, the two eigenvalues are negative (if real) or have negative real parts; in either case the system is stable.

(b) If $\operatorname{tr} A=\lambda_{1}+\lambda_{2}>0$, both roots are positive or have positive real parts; in both cases, the system is unstable.

## (ii) Discrete Time

In the discrete-time case, stability is determined by the moduli of the eigenvalues of the coefficient matrix. When the characteristic roots of the system are real, the question reduces to whether or not they fall inside the interval $(-1,1)$. A convenient way to determine when this is the case is based on the following observation.
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-483.jpg?height=590&width=1238&top_left_y=191&top_left_x=119)

Figure 10.6.

Let $\lambda_{1}$ and $\lambda_{2}$ be the eigenvalues of $A$. We can factor the characteristic polynomial of the matrix and write it in the form

$$
p(\lambda)=\left(\lambda-\lambda_{1}\right)\left(\lambda-\lambda_{2}\right)
$$

Suppose for the time being that both eigenvalues are real, and imagine that we want to determine whether or not both of them fall on the same side of a given constant $a$. Evaluating $p()$ at $a$, we have

$$
p(a)=\left(a-\lambda_{1}\right)\left(a-\lambda_{2}\right)
$$

Clearly, $p(a)>0$ if and only if the two factors on the right-hand side have the same sign, that is, if $\lambda_{1}$ and $\lambda_{2}$ fall on the same side of $a$.

In our case, we are interested in determining whether or not the (real) eigenvalues of $A$ fall on the same sides of 1 and -1 . Thus, we will draw the lines $p(1)=0$ and $p(-1)=0$. Recalling that

$$
p(\lambda)=\lambda^{2}-(\operatorname{tr} A) \lambda+\operatorname{det} A
$$

we have

$$
\begin{align*}
& p(1)=1-\operatorname{tr}+\operatorname{det} \geq 0 \\
& \quad \Rightarrow \operatorname{det} \geq \operatorname{tr}-1 \tag{31}
\end{align*}
$$

Hence, the set of points in the (tr, det) plane that satisfies $p(1)=0$ is a straight line through the points $(0,-1)$ and $(1,0)$ that divides the plane into two regions, as shown in Figure 10.6. In the region above the line, we have $p(1)>0$, indicating that both roots lie on the same side of 1 , whereas the opposite inequality holds in the region below the $p(1)=0$ line, indicating that the eigenvalues fall on opposite sides of 1 on the real line.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-484.jpg?height=659&width=867&top_left_y=188&top_left_x=305)

Figure 10.7.

Similarly, we have

$$
\begin{align*}
& p(-1)=1+\operatorname{tr}+\operatorname{det} \geq 0 \\
& \quad \Rightarrow \operatorname{det} \geq-1-\operatorname{tr} \tag{32}
\end{align*}
$$

The line $p(-1)=0$ goes through the points $(-1,0)$ and $(0,-1)$. In the region above the line, we have $p(-1)>0$, and both roots are on the same side of -1 . Combining the two graphs, the plane is divided into four regions, as shown in Figure 10.7.

Next, we add to this graph the line

$$
\begin{align*}
\Delta & =\operatorname{tr}^{2}-4 \operatorname{det}=0 \\
& \Rightarrow \operatorname{det}=\frac{\operatorname{tr}^{2}}{4} \tag{33}
\end{align*}
$$

As we know, points above the parabola described by (33) correspond to systems with complex eigenvalues. It is easy to check that the line $\Delta=0$ is tangent to $p(-1)=0$ at the point $(-2,1)$ and to $p(1)=0$ at $(2,1)$. The parabola is therefore entirely contained in the "upper quadrant" of the plane, as partitioned by the two straight lines.

Figure 10.8 shows that the plane can be divided into eight regions by the three reference lines described earlier and a horizontal line at det $=1$. For each of these regions, we can now determine the stability type of the steady state.

First, we concentrate on the regions of the plane that correspond to real eigenvalues $(1,2,3,4,7$, and 8$)$. The steady state is a sink if both roots are

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-485.jpg?height=831&width=1288&top_left_y=188&top_left_x=99)

Figure 10.8.

in the interval $(-1,1)$, a source if neither eigenvalue falls in this region, and a saddle point if one root is within this interval and the other is not. Taking each region in turn, we have the following:

Region 1: $p(1)<0$ and $p(-1)>0$. The two eigenvalues fall on the same side of -1 and on different sides of 1 . The only possibility is shown here: There is one eigenvalue in $(-1,1)$, and the other is larger than 1 . The steady state is a saddle point.

Region 2: $p(1)<0$ and $p(-1)<0$. The steady state is a source.

Region 3: $p(1)>0$ and $p(-1)<0$. The steady state is a saddle point.

Region 4: $p(1)>0$ and $p(-1)>0$. The two eigenvalues are on the same sides of 1 and -1 . Moreover, we have det $>0$, so both eigenvalues have the same sign, and $\mathrm{tr}<-2$, so they are both negative. Hence, both roots are smaller than -1 . The steady state is a source.
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-485.jpg?height=652&width=602&top_left_y=1346&top_left_x=770)

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-486.jpg?height=840&width=1249&top_left_y=192&top_left_x=118)

Figure 10.9. Stability map for the discrete planar system.

Region 8: $p(1)>0$ and $p(-1)>0$. Now det $>0$ and $t r>2$, so the two roots are positive and fall on the same

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-486.jpg?height=112&width=597&top_left_y=1182&top_left_x=773)
sides of both 1 and -1 . Hence, they must be larger than 1 , and the steady state is a source.

Region 7: $p(1)>0$ and $p(-1)>0$. Now we have $-2<\operatorname{tr}<2$ and $-1<\operatorname{det}<1$. Both eigenvalues must lie in $(-1,1)$,

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-486.jpg?height=113&width=601&top_left_y=1454&top_left_x=771)
and we have a sink.

In regions 5 and 6, the eigenvalues are complex numbers,

$$
\lambda_{1}=\alpha+i \mu \quad \text { and } \quad \lambda_{2}=\alpha-i \mu
$$

Recalling that

$$
\begin{gathered}
\operatorname{tr} A=\lambda_{1}+\lambda_{2}=2 \alpha \\
\operatorname{det} A=\lambda_{1} \lambda_{2}=\alpha^{2}+\mu^{2}=\left|\lambda_{1}\right|^{2}=\left|\lambda_{2}\right|^{2}
\end{gathered}
$$

it is easy to determine the stability of the system. In region 5, we have det $>1$, implying that $\left|\lambda_{1}\right|=\left|\lambda_{2}\right|>1$. Hence, the steady state is a source, whereas in region 6 the opposite inequality holds, indicating that we have a sink. Our conclusions are summarized in Figure 10.9.

## 3. Autonomous Nonlinear Systems

In this section we will study autonomous nonlinear systems of the form

$$
\begin{equation*}
\dot{x}=f(x) \tag{CS}
\end{equation*}
$$

or

$$
\begin{equation*}
x_{t+1}=g\left(x_{t}\right) \tag{DS}
\end{equation*}
$$

where $f, g: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}^{\mathrm{n}}$ are $C^{1}$ functions. Because explicit solutions for nonlinear systems are, in general, not available, we will have to rely on more indirect methods to analyze the behavior of such systems. We start by developing a graphical method that will allow us to obtain qualitative information about the behavior of planar dynamical systems and present it in a convenient and intuitive manner. We then show that a considerable amount of information regarding the behavior of a nonlinear system near an equilibrium can be obtained by studying its linearization, that is, the linear system defined by the derivative of $f()$ or $g()$ at the steady state.

## (a) Phase Diagrams for Planar Systems

In Chapter 9 we introduced the phase diagram as a useful tool for studying nonlinear systems in one dimension. In this section we will see that this technique can be extended to the case of dynamical systems in two variables. The basic idea is the same in both cases: We project onto the state space the graphs of the solutions of the system as a way to visualize their behavior. In two dimensions, the result is a diagram showing the system's trajectories on the plane.

Given a system of differential equations in the plane,

$$
\begin{align*}
\dot{x} & =f(x, y)  \tag{1}\\
\dot{y} & =g(x, y) \tag{2}
\end{align*}
$$

where $f$ and $g$ are $C^{1}$ functions, the first step is to set $\dot{x}$ and $\dot{y}$ equal to zero in (1) and (2) to obtain the equations of the phase lines:

$$
\begin{align*}
& \dot{x}=0 \Rightarrow f(x, y)=0  \tag{3}\\
& \dot{y}=0 \Rightarrow g(x, y)=0 \tag{4}
\end{align*}
$$

Each of these equations describes a curve in the $(x, y)$ plane. $^{6}$

Consider these lines one at a time. The phase line $\dot{x}=0$ divides the $(x, y)$ plane into two regions. In one of them, we have $\dot{x}>0$, indicating that $x$ increases over time ( $x \uparrow$ ), whereas in the other, $\dot{x}<0$, and $x$ decreases over
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-488.jpg?height=502&width=1194&top_left_y=183&top_left_x=143)

Figure 10.10. Phase lines and arrows of motion.

time. To determine which is which (if it is not obvious from inspection of the equations), we can evaluate either of the derivatives ${ }^{7}$

$$
\frac{\partial \dot{x}}{\partial x}=\frac{\partial f(x, y)}{\partial x} \quad \frac{\partial \dot{x}}{\partial y}=\frac{\partial f(x, y)}{\partial y}
$$

at a convenient point in the $\dot{x}=0$ line (typically at the steady state). For example, suppose that $\partial \dot{x} / \partial x>0$, as assumed in Figure 10.10. This tells us that, starting from the $\dot{x}=0$ line, a small movement to the right will increase the value of $\dot{x}$, making it strictly positive. Hence, $\dot{x}>0$ in the region to the right of the phase line. We indicate this in the graph through a horizontal "arrow of motion" pointing to the right along the $x$ axis.

Doing the same thing with the $\dot{y}=0$ phase line, we obtain the second panel of Figure 10.10. The next step is to combine the two phase lines into a single diagram. Intersections of the phase lines correspond to steady states of the system (at such points, we have $\dot{x}=0$ and $\dot{y}=0$, so both variables remain constant over time). The $(x, y)$ plane is now divided into a number of regions by the phase lines (four if they intersect only once). Combining the information summarized by the two panels of Figure 10.10, we can draw, for each region of the plane, a set of arrows of motion describing the direction of motion of the system along each of the axes, as shown in Figure 10.11.

The pattern of the arrows of motion will give us valuable information about the behavior of the system. In this case, for example, they suggest the existence of a convergent saddle path through the upper and lower quadrants. Arrows alone are not enough, however, to provide a complete description of the trajectories of the system. We may, for example, find configurations that are compatible with a closed cycle or a (convergent or divergent) spiral path; hence, we may need further information to determine the actual pattern of the solution trajectories.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-489.jpg?height=662&width=876&top_left_y=187&top_left_x=298)

Figure 10.11. Phase diagram.

For the case of discrete-time systems, the procedure is very similar. Given a system of the form

$$
\begin{align*}
& x_{t+1}=f\left(x_{t}, y_{t}\right) \text { or } \Delta x_{t}=x_{t+1}-x_{t}=f\left(x_{t}, y_{t}\right)-x_{t}  \tag{5}\\
& y_{t+1}=g\left(x_{t}, y_{t}\right) \text { or } \Delta y_{t}=y_{t+1}-y_{t}=g\left(x_{t}, y_{t}\right)-y_{t} \tag{6}
\end{align*}
$$

we obtain the phase lines by setting $\Delta x_{t}$ and $\Delta y_{t}$ equal to zero (i.e., by deleting the time subscripts and setting $x_{t+1}=x_{t}=x$ ):

$$
\begin{aligned}
& \Delta x_{t}=0 \Rightarrow x=f(x, y) \\
& \Delta y_{t}=0 \Rightarrow y=g(x, y)
\end{aligned}
$$

As in the continuous case, the $\Delta x_{t}=0$ phase line divides the phase plane into two regions. In one of them, $\Delta x_{t}>0$, and $x$ increases over time, whereas in the other, $\Delta x_{t}<0$, and $x$ decreases. To determine the pattern of the arrows of motion in each region, we differentiate (5) with respect to one of the variables and evaluate one of the derivatives

$$
\frac{\partial \Delta x_{t}}{\partial x_{t}}=\frac{\partial f\left(x_{t}, y_{t}\right)}{\partial x_{t}}-1 \quad \text { or } \quad \frac{\partial \Delta x_{t}}{\partial y_{t}}=\frac{\partial f\left(x_{t}, y_{t}\right)}{\partial y_{t}}
$$

at a convenient point in the $\Delta x_{t}=0$ line. We then proceed as discussed earlier.

Although phase diagrams can be extremely useful tools, they do not yield sufficient information to analyze all aspects of interest in a system's behavior, and they can be used to study systems in only one or two dimensions. In the remainder of this section, we will review some results that yield more precise (but only local) information about the behavior of nonlinear systems
of any dimension. The basic idea is to approximate a nonlinear system in the neighborhood of a steady state by the linear system defined by its derivative. As we will see, the local behaviors of the two systems are very similar in most cases.

## (b) Local Analysis by Linearization

Let $f: \mathbb{R}^{\mathrm{n}} \supseteq X \rightarrow \mathbb{R}^{\mathrm{n}}$ be a $C^{1}$ function, and $x^{0}$ a point in its domain. As we saw in Chapter 4, we can write

$$
\begin{equation*}
f(x)=f\left(x^{0}\right)+D f\left(x^{0}\right)\left(x-x^{0}\right)+E_{f}\left(x-x^{0}\right) \tag{7}
\end{equation*}
$$

and the differentiability of $f$ implies that the error term $E_{f}\left(x-x^{0}\right)$ will be small for $x$ close to $x^{0}$, in the sense that

$$
\begin{equation*}
\lim _{x \rightarrow x^{0}} \frac{\left\|E_{f}\left(x-x^{0}\right)\right\|}{\left\|x-x^{0}\right\|}=0 \tag{8}
\end{equation*}
$$

With this in mind, consider a nonlinear autonomous system of the form

$$
\begin{equation*}
\dot{x}=f(x) \tag{NC}
\end{equation*}
$$

or

$$
\begin{equation*}
x_{t+1}=g\left(x_{t}\right) \tag{ND}
\end{equation*}
$$

where $f, g: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}^{\mathrm{n}}$ are $C^{1}$ functions, and let $\bar{x}$ be a steady state of (N). Then the linear system ${ }^{8}$

$$
\begin{equation*}
\dot{x}=D f(\bar{x})(x-\bar{x}) \tag{LC}
\end{equation*}
$$

or

$$
\begin{equation*}
x_{t+1}=\bar{x}+D g(\bar{x})\left(x_{t}-\bar{x}\right) \tag{LD}
\end{equation*}
$$

can be expected to be a reasonable approximation to $(\mathrm{N})$ around the equilibrium point $\bar{x}$, for the only difference between the two systems is the error term $E_{f}(x-\bar{x})$. Because expression (8) guarantees that this term will be small in the neighborhood of $\bar{x}$, we can expect it to have little influence on the behavior of the system. For a large class of systems this is indeed the case, and as a result we can obtain a fair amount of information about the behavior of the nonlinear system $(\mathrm{N})$ near an equilibrium by studying its linearization (i.e., the linear system defined by the derivative of $f$ or $g$ at the steady state).

To make this result more precise, we need to introduce some additional concepts. Two systems are topologically equivalent if they have similar orbit structures. More formally, two systems are topologically equivalent if their
solution trajectories are the same after a continuous "change of coordinates."

Definition 3.1. Topological or flow equivalence. Given two dynamical systems $f$ and $g$, we say that they are topologically equivalent if there exists a homeomorphism $h$ (a continuous change of coordinates) that maps $f$ orbits into $g$ orbits while preserving the sense of direction in time.

The concept of flow equivalence allows us to make precise the idea that two systems behave "very similarly." The central result of this section says that most nonlinear systems are topologically equivalent to their linearizations near an equilibrium point. There are, however, some exceptions. Equilibria for which linearization is guaranteed to work well are said to be hyperbolic.

Definition 3.2. Hyperbolic equilibrium. Let $\bar{x}$ be a steady state of the nonlinear system (N), $\dot{x}=f(x)$ [or $x_{t+1}=g\left(x_{t}\right)$ ]. We say that $\bar{x}$ is a hyperbolic equilibrium if the derivative of $f$ evaluated at $\bar{x}, D f(\bar{x})$, has no eigenvalues with zero real parts $[D g(\bar{x})$ has no eigenvalues with moduli equal to 1$]$.

Theorem 3.3. Grobman-Hartman. Let $\overline{\mathrm{x}}$ be a hyperbolic equilibrium of $(N C), \dot{\mathrm{x}}=\mathrm{f}(\mathrm{x})$. Then there is a neighborhood $\mathrm{U}$ of $\overline{\mathrm{x}}$ such that $(N C)$ is topologically equivalent to the linear system

$$
\begin{equation*}
\dot{\mathrm{x}}=\mathrm{Df}(\overline{\mathrm{x}})(\mathrm{x}-\overline{\mathrm{x}}) \tag{LC}
\end{equation*}
$$

in U. Similarly, given the discrete system $(N D), \mathrm{x}_{\mathrm{t}+I}=\mathrm{g}\left(\mathrm{x}_{\mathrm{t}}\right)$, if $\overline{\mathrm{x}}$ is hyperbolic and $\operatorname{Dg}(\overline{\mathrm{x}})$ is invertible, then there is a neighborhood $\mathrm{U}$ of $\overline{\mathrm{x}}$ such that (ND) is topologically equivalent to the linear system

$$
\begin{equation*}
\mathbf{x}_{\mathrm{t}+1}=\overline{\mathbf{x}}+\operatorname{Dg}(\overline{\mathbf{x}})\left(\mathbf{x}_{\mathrm{t}}-\overline{\mathbf{x}}\right) \tag{LD}
\end{equation*}
$$

Hence, linearization works well around hyperbolic equilibria. ${ }^{9}$ In the discrete case, we require $g()$ to be locally invertible, so that the negative orbit is defined.

Our next two results provide more precise information about the behavior of the nonlinear system. The first theorem tells us that around hyperbolic equilibria, the stability type of the equilibrium is the same for the nonlinear system and for its linearization. The second one says that if the linearized system has a saddle point, so does the nonlinear system. Moreover, the nonlinear system has a saddle path of the same dimension as and tangent to the stable space of the linearized system at the steady state.

Theorem 3.4. Local stability for nonlinear systems. Consider the system $(N C), \dot{\mathrm{x}}=\mathrm{f}(\mathrm{x})$, where $\mathrm{f}: \mathbb{R}^{\mathrm{n}} \supseteq \mathrm{X} \longrightarrow \mathbb{R}^{\mathrm{n}}$ is a $\mathrm{C}^{l}$ function, and let $\overline{\mathrm{x}}$ be an equilibrium point of $(N C)$. Then we have the following:

- If all eigenvalues of $\mathrm{Df}(\overline{\mathrm{X}})$ have strictly negative real parts, then $\overline{\mathrm{X}}$ is asymptotically stable.
- If at least one eigenvalue of $\mathrm{Df}(\overline{\mathrm{x}})$ has a positive real part, then $\overline{\mathrm{x}}$ is (locally) unstable.
- If at least one eigenvalue of $\operatorname{Df}(\overline{\mathrm{x}})$ has a zero real part, and all other eigenvalues have negative real parts, then the equilibrium $\overline{\mathrm{x}}$ may be stable, asymptotically stable, or unstable.

Similarly, let $\overline{\mathrm{x}}$ be a steady state of the discrete system $(N D), \mathrm{x}_{\mathrm{t}+1}=\mathrm{g}\left(\mathrm{x}_{\mathrm{t}}\right)$. Then we have the following:

- If all eigenvalues of $\operatorname{Dg}(\overline{\mathrm{x}})$ have moduli strictly less than $1, \overline{\mathrm{x}}$ is asymptotically stable (a $\sin k$ ).
- If at least one eigenvalue has modulus greater than 1, then $\overline{\mathrm{x}}$ is unstable (a source).
- If the eigenvalues of the Jacobian are all inside the unit circle, but at least one is on the boundary (has modulus 1), then $\overline{\mathrm{x}}$ may be stable, asymptotically stable, or unstable.

Theorem 3.5. Stable manifold. Let $\overline{\mathrm{x}}$ be a steady state of the system (NC), $\dot{\mathrm{x}}=\mathrm{f}(\mathrm{x})$ [or $(N D), \mathrm{x}_{\mathrm{t}+1}=\mathrm{g}\left(\mathrm{x}_{\mathrm{t}}\right)$ ], where $\mathrm{f}, \mathrm{g}: \mathbb{R}^{n} \longrightarrow \mathbb{R}^{n i}$ is a $\mathrm{C}^{l}$ function. Suppose the matrix $\mathrm{Df}(\overline{\mathrm{x}})[\mathrm{Dg}(\overline{\mathrm{x}})]$ has $\mathrm{k}$ eigenvalues with negative real parts [inside the unit circle in the complex plane] and $\mathrm{n}-\mathrm{k}$ eigenvalues with positive real parts [outside the unit circle]. Then there exists a k-dimensional differentiable manifold $\mathrm{S}$, tangent to the stable space of the linearization of $(N C)[(N D)]$ at $\overline{\mathrm{x}}$, that is invariant under the flow of the system and such that for any $\mathrm{x}^{0}$ in $\mathrm{S}$, the solution through $\mathrm{x}^{0}$ converges to the steady state, that is,

$$
\lim _{t \rightarrow-\infty} \mathbf{x}\left(\mathbf{t}, \mathbf{x}^{0}\right)=\overline{\mathbf{x}}
$$

Similarly, there is an ( $\mathrm{n}-\mathrm{k})$-dimensional differentiable manifold $\mathrm{U}$, tangent to the unstable space of the linearized system at $\overline{\mathrm{x}}$, that is invariant under the flow of $(N)$. For any point $\mathrm{y}^{0}$ in $\mathrm{U}$, moreover,

$$
\lim _{t \rightarrow-\infty} x\left(t, x^{0}\right)=\bar{x}
$$

The proofs of these results would take us too far afield. The interested reader can consult Perko (1991, ch. 2) and Ruelle (1989) and the references cited therein.

## 4. Problems

Problem 4.1. Polar coordinates. When working with planar systems it is sometimes convenient to work in polar coordinates. Consider a point with Cartesian (ordinary) coordinates $(x, y)$. Its polar coordinates are $(r, \theta)$, where $r$ is the Euclidean distance from the origin to the point $(x, y)$, and $\theta$
is the angle formed by the line segment going from the origin to the point $(x, y)$ and the horizontal axis. Hence, $r$ and $\theta$ are defined by

$$
\begin{gather*}
r^{2}=x^{2}+y^{2}  \tag{1}\\
\theta=\arctan (y / x) \tag{2}
\end{gather*}
$$

and $\theta$ is such that

$$
\begin{equation*}
\cos \theta=x / r \quad \text { and } \sin \theta=y / r \tag{3}
\end{equation*}
$$

Differentiating (1) and (2) implicitly with respect to time, show that

$$
\begin{align*}
r \dot{r} & =x \dot{x}+y \dot{y}  \tag{4}\\
r^{2} \dot{\theta} & =x \dot{y}-y \dot{x} \tag{5}
\end{align*}
$$

Hint: Recall that if $y=\arctan u$, then $y^{\prime}=u^{\prime} /\left(1+u^{2}\right)$.

To rewrite a system of the form

$$
\begin{equation*}
\dot{x}=f(x, y), \quad \dot{y}=g(x, y) \tag{6}
\end{equation*}
$$

in polar coordinates, we substitute (6) into (4) and (5) and see whether or not the resulting expressions can be written entirely in terms of $r$ and $\theta$. If this can be done, and the resulting system can be solved explicitly, the solution functions for the original system, $x(t)$ and $y(t)$, can be recovered using the following relation, derived from (3):

$$
\begin{equation*}
x=r \cos \theta \text { and } y=r \sin \theta \tag{7}
\end{equation*}
$$

Problem 4.2. Let $A$ be a $2 \times 2$ real matrix with complex eigenvalues $\lambda_{1}$, $\lambda_{2}=\alpha \pm i \mu$ and corresponding complex eigenvectors $e_{1}, e_{2}=u \pm i v$. It can be shown that the real vectors $u$ and $v$ are linearly independent, so the matrix $P=[u, v]$ is invertible.

(i) Show that

$$
P^{-1} A P=R=\left[\begin{array}{cc}
\alpha & -\mu  \tag{8}\\
\mu & \alpha
\end{array}\right]
$$

Equation (8) shows that if $A$ has complex eigenvalues, then the planar system $\dot{z}=A z$ can be written (after a coordinate change) in the form

$$
\left[\begin{array}{c}
\dot{x} \\
\dot{y}
\end{array}\right]=\left[\begin{array}{cc}
\alpha & -\mu \\
\mu & \alpha
\end{array}\right]\left[\begin{array}{l}
x \\
y
\end{array}\right]
$$

or, equivalently,

$$
\begin{equation*}
\dot{x}=\alpha x-\mu y \tag{9}
\end{equation*}
$$

$$
\begin{equation*}
\dot{y}=\mu x-\alpha y \tag{10}
\end{equation*}
$$

(Think of using $P$, rather than the eigenvector matrix $E$, to "diagonalize" $A$. The resulting matrix is not diagonal, but, as we will soon see, is quite convenient.)

(ii) Rewrite the system (9)-(10) in polar coordinates and solve it, leaving the solution $(r(t), \theta(t))$ as a function of the initial values $r(0)$ and $\theta(0)$.

(iii) Using the trigonometric identities

$$
\begin{align*}
& \sin (a+b)=(\sin a)(\cos b)+(\cos a)(\sin b)  \tag{11}\\
& \cos (a+b)=(\cos a)(\cos b)-(\sin a)(\sin b) \tag{12}
\end{align*}
$$

recover the solution $(x(t), y(t))$ of the original system, written as a function of the initial values $x(0)$ and $y(0)$.

Problem 4.3. Consider the following system of differential equations:

$$
\begin{gather*}
\dot{x}=f(x, y)=y+x\left(c-x^{2}-y^{2}\right)  \tag{17}\\
\dot{y}=g(x, y)=-x+y\left(c-x^{2}-y^{2}\right) \tag{18}
\end{gather*}
$$

(i) Show that the point $(0,0)$ is the only steady state of the system for any value of $c$.

(ii) Linearize the system around the steady state and compute its eigenvalues. What can we say about the stability and type of the steady state? (There are three possible cases, depending on the value of $c$.)

(iii) Show that the original system can be written in polar coordinates as

$$
\begin{gather*}
\dot{r}=r\left(c-r^{2}\right)  \tag{19}\\
\dot{\theta}=-1 \tag{20}
\end{gather*}
$$

Using these expressions, describe the behavior of the system, and compare the results with those obtained in (ii). Linearization should give accurate local results in two cases, but we can now "see" more things. What happens in the third case?

## Bibliography

Arnold, V. 1990. Ordinary Differential Equations. Massachusetts Institute of Technology Press.

Arrowsmith, D., and Place, C. 1990. An Introduction to Dynamical Systems. Cambridge University Press.

Azariadis, C., and de la Fuente, A. 1993. Discrete Dynamical Systems. Part I. In: Intertemporal Macroeconomics, pp. 1-170. Oxford: Blackwell.

Beavis, B., and Dobbs, I. 1990. Optimization and Stability Theory for Economic Analysis. Cambridge University Press.

Beltrami, E. 1987. Mathematics for Dynamic Modelling. Orlando, FL: Academic Press.

Boyce, W., and DiPrima, R. 1977. Elementary Differential Equations, 3rd ed. New York: Wiley.

Brauer, F., and Nohel, J. 1969. The Qualitative Theory of Ordinary Differential Equations, An Introduction. New York: Dover.

Brock, W., and Malliaris, A. 1989. Differential Equations, Stability and Chaos in Dynamic Economics. Amsterdom: North Holland.

Coddington, E. 1961. An Introduction to Ordinary Differential Equations. Englewood Cliffs, NJ: Prentice-Hall.

Guckenheimer, J., and Holmes, P. 1983. Nonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields. Berlin: Springer-Verlag.

Guzmán, M. 1980. Ecuaciones Diferenciales Ordinarias. Teoría de Estabilidad y Control. Madrid: Alhambra.

Hale, J., and Koçak, H. 1991. Dynamics and Bifurcations. Berlin: Springer-Verlag.

Hirsch, M., and Smale, S. 1974. Differential Equations, Dynamical Systems and Linear Algebra. New York: Academic Press.

Lelong-Ferrand, J., and Aurnadies, J. M. 1977. Cours de Mathématiques. Tome 4: Equations Différentielles, Integrales Multiples. Paris: Dunod Université.

Luenberger, D. 1979. Introduction to Dynamic Systems. New York: Wiley.

Obstfeld, M. 1980. Primer on Differential Equations. Mimeograph, Department of Economics, Columbia University.

Perko, L. 1991. Differential Equations and Dynamical Systems. Berlin: SpringerVerlag.

Ruelle, D. 1989. Elements of Differentiable Dynamics and Bifurcation Theory. Orlando, FL: Academic Press.

Sanchez, D. 1968. Ordinary Differential Equations and Stability Theory: An Introduction. San Francisco: Freeman.

Simmons, G. 1972. Differential Equations with Applications and Historical Notes. New York: McGraw-Hill.

Sydsaeter, K. 1981. Topics in Mathematical Analysis for Economists. Orlando, FL: Academic Press.

Tu, P. 1994. Dynamical Systems. An Introduction with Applications in Economics and Biology. Berlin: Springer-Verlag.

## Notes

1 Note that each solution $x^{i}(t)$ is a vector-valued function.

2 By Euler's formula: $e^{i \theta}=\cos \theta+i \sin \theta$. See Section 7 of Chapter 1 .

3 That is, provided $\operatorname{det} A \neq 0$. Because the determinant is equal to the product of the eigenvalues, what we need is that $A$ have no zero roots.

4 We can also transform the given systems into equivalent homogeneous ones, simply by rewriting them in deviations from the steady state. That was what we did in our discussion of scalar systems in Chapter 9.

5 The characteristic roots of the matrix $B=A-\mathbf{I}$ are the solutions of the system $\operatorname{det}(B-\lambda \mathbf{I})=\operatorname{det}[A-(\lambda+1) \mathbf{I}]=0$, and those of $A$ solve $\operatorname{det}(A-\lambda \mathbf{I})=0$. Hence, the characteristic values of the two matrices satisfy the relation $\lambda_{B}+1=\lambda_{A}$. For $B$ to be invertible (thus guaranteeing the existence of a unique steady state), we need its determinant to be different from zero, or, equivalently, its eigenvalues all to be different from zero. But $\lambda_{B} \neq 0$ is equivalent to $\lambda_{A} \neq 1$; hence the assumptions of the theorem.

6 If equation (3) or (4) cannot be solved explicitly, we can use the implicit-function theorem to determine the slopes of the curves they define.

7 Either one will do, as long as we are careful with how we interpret the sign of the derivative. Essentially, what we are doing is checking the sign of $\dot{x}$ at an arbitrary point in one of the subplanes into which the phase line divides the plane. All the points in a given subplane should yield the same sign for $\dot{x}$; but note that "below" and "to the right"
of an upward-sloping line are one and the same thing, so in the preceding graph it does not matter whether we check at $A(\partial \dot{x} / \partial x)$ or at $B(\partial \dot{x} / \partial y)$.

It may be easy to remember that $\partial \dot{x}_{i} / \partial x_{l}>0$ implies that the arrow of motion for $x_{i}$ points away from the corresponding $\left(\dot{x}_{t}=0\right)$ phase line. An increase in $x_{t}$ makes $\dot{x}_{i}$ positive, and hence causes $x_{1}$ to increase even more.

8 To get (L) from (7), notice that $f(\bar{x})=\underline{0}$ and $g(\bar{x})=\bar{x}$ by definition of steady state.

9 It can be shown that "most" equilibria are hyperbolic. Intuitively, nonhyperbolicity is a fragile property, for the following reason. Note that the real parts of the eigenvalues of $D f(\bar{x})$ are continuous functions of the entries of the Jacobian matrix. If a given eigenvalue has a zero real part, any small change in the values of these entries will make it nonzero, turning the equilibrium into a hyperbolic steady state.

This chapter discusses some examples of dynamic economic models in order to illustrate the use in economic theory of some of the techniques and results discussed earlier.

We will first study in detail the dynamics of an IS-LM model with adaptive expectations and sticky prices. This exercise will illustrate the construction of phase diagrams and the use of a system's eigenvalues to determine its stability properties. We will then turn to a simple perfect-foresight model that illustrates how the choice of boundary conditions embodies important economic assumptions. A similar issue arises in regard to Dornbusch's celebrated overshooting model, which will be discussed next. The last part of the chapter contains an introduction to neoclassical growth theory and a discussion of some techniques that are useful in dealing with nonlinear systems.

## 1. A Dynamic IS-LM Model

Introductory texts in macroeconomics often rely on Keynesian-style static IS-LM models like the one we analyzed in Chapter 5 (Problem 4.1). A simple version of this model can be written as follows:

$$
\begin{align*}
& y=\beta y-\gamma r  \tag{1}\\
& m=\kappa y-\alpha\left(r+\pi^{e}\right) \tag{2}
\end{align*}
$$

where the Greek letters are positive parameters, $y$ is the log of real output, $r$ is the real interest rate, $\pi^{e}$ is the expected rate of inflation, and $m=\ln (M / P)$ is the logarithm of real money balances, that is, the nominal money supply $(M)$ divided by the price level $(P)$. Equation (1), often called the $I S$ schedule, can be interpreted as an equilibrium condition for the goods market. It says that the demand for output, which is an increasing function of income and a decreasing function of the interest rate, should be equal to the supply of output. Equation (2), the $L M$ schedule, is an equilibrium condition for the money market. It requires that the demand for real balances, which is
increasing in income and decreasing in the nominal interest rate $\left(r+\pi^{e}\right)$, be equal to the real money supply.

If we take the real money supply and the expected rate of inflation as given, equations (1) and (2) can be solved for the equilibrium values of income and the interest rate $\left(y^{*}\right.$ and $\left.r^{*}\right)$ as functions of $m$ and $\pi^{e}$. It is easy to check that

$$
\begin{align*}
& y^{*}=y\left(m, \pi^{e}\right)=\frac{m+\alpha \pi^{e}}{c}, \quad \text { where } c \equiv \kappa+\frac{\alpha(1-\beta)}{\gamma}>0  \tag{3}\\
& r^{*}=r\left(m, \pi^{e}\right)=\frac{-\left(m+\alpha \pi^{e}\right)}{d}, \quad \text { where } d \equiv \alpha+\frac{\kappa \gamma}{1-\beta}>0 \tag{4}
\end{align*}
$$

To turn the preceding model into a dynamic model, we make some simple assumptions about the evolution of the money supply, the formation of expectations, and price dynamics. First, we assume that the nominal money supply $M$ grows over time at a constant rate $\mu$. Hence:

$$
\begin{equation*}
\frac{\dot{M}}{M}=\mu \tag{5}
\end{equation*}
$$

Second, we assume that actual inflation at each point in time $(\pi=\dot{P} / P)$ is a function of expected inflation and the difference between current output and a "natural" rate of output $\bar{y}$. Hence, if demand is very high, and that pushes the economy to operate at more than normal capacity, prices will rise faster than expected, as described by the following Phillips relation: ${ }^{1}$

$$
\begin{equation*}
\left(\frac{\dot{P}}{P}=\right) \pi=\pi^{e}+\theta(y-\bar{y}) \tag{6}
\end{equation*}
$$

Finally, we assume that expectations are adaptive, with inflation forecasts updated each period by a fraction of the current forecast error:

$$
\begin{equation*}
\dot{\pi}^{e}=\delta\left(\pi-\pi^{e}\right) \tag{7}
\end{equation*}
$$

To analyze the dynamics of the model, we reduce the preceding equations to a system of differential equations in $m$ and $\pi^{e}$. To obtain the law of motion describing expected inflation, we substitute (6) into (7) and use (3) to get

$$
\begin{equation*}
\dot{\pi}^{e}=\delta \theta\left[y\left(m, \pi^{e}\right)-\bar{y}\right]=\delta \theta\left(\frac{m+\alpha \pi^{e}}{c}-\bar{y}\right)=\frac{\delta \theta \alpha}{c} \pi^{e}+\frac{\delta \theta}{c} m-\delta \theta \bar{y} \tag{e}
\end{equation*}
$$

To get the second equation that we need, notice that by definition $m=\ln (M / P)=\ln M-\ln P$. Differentiating this expression with respect to time, we have

$$
\dot{m}=\frac{\dot{M}}{M}-\frac{\dot{P}}{P}=\mu-\pi
$$

Substituting (6) into this last expression, and using (3), we obtain

$$
\begin{equation*}
\dot{m}=\mu-\pi^{e}-\theta(y-\bar{y})=\mu-\pi^{e}+\theta \bar{y}-\theta \frac{m+\alpha \pi^{e}}{c}=-\left(1+\frac{\theta \alpha}{c}\right) \pi^{e}-\frac{\theta}{c} m+\mu+\theta \bar{y} \tag{L.m}
\end{equation*}
$$

Hence, the model reduces to a system of two linear and autonomous differential equations. ${ }^{2}$ We will construct its phase diagram and compute the eigenvalues of the coefficient matrix to check the stability of the steady state.

In what follows, we treat $\pi^{e}$ and $P$ (and therefore $m=M / P$ ) as predetermined variables. That is, we assume that the time paths of actual prices and expected inflation are continuous and therefore do not display sudden jumps. Economically, we are saying that both prices and expectations respond with some sluggishness to changing circumstances. This assumption, common in old-fashioned Keynesian-type models, is not necessarily the most reasonable one that can be made. In later sections we will study other models in which prices are allowed to adjust instantaneously, even if this involves a discrete jump in their level.

## (a) Phase Diagram and Stability Analysis

The evolution of our model economy is described by a first-order system of differential equations:

$$
\begin{gather*}
\dot{\pi}^{e}=\delta \theta\left(\frac{m+\alpha \pi^{e}}{c}-\bar{y}\right)=\frac{\delta \theta \alpha}{c} \pi^{e}+\frac{\delta \theta}{c} m-\delta \theta \bar{y}  \tag{e}\\
\dot{m}=\mu-\pi^{e}+\theta\left(\bar{y}-\frac{m+\alpha \pi^{e}}{c}\right)=-\left(1+\frac{\theta \alpha}{c}\right) \pi^{e}-\frac{\theta}{c} m+\mu+\theta \bar{y} \tag{L.m}
\end{gather*}
$$

As a first step in our analysis of this system we compute its steady state and construct its phase diagram. Setting $\dot{\pi}^{e}=0$ and $\dot{m}=0$ in the laws of motion describing expected inflation and the real money supply, we obtain the equations of the phase lines:

$$
\begin{gather*}
\dot{\pi}^{e}=0 \Rightarrow \frac{m+\alpha \pi^{e}}{c}=\bar{y} \Rightarrow m=c \bar{y}-\alpha \pi^{e}  \tag{e}\\
\dot{m}=0 \Rightarrow \pi^{e}=\mu+\theta\left(\bar{y}-\frac{m+\alpha \pi^{e}}{c}\right) \tag{P.m}
\end{gather*}
$$

This system of equations can be solved for the steady-state values of $m$ and $\pi^{e}$. Using (P. $\left.\pi^{e}\right)$ in (P.m), we see that

$$
\begin{equation*}
\bar{\pi}^{e}=\mu \tag{8}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-500.jpg?height=601&width=832&top_left_y=195&top_left_x=320)

Figure 11.1. The $\dot{\pi}^{e}=0$ phase line.

Next, substituting (8) into (P. $\pi^{e}$ ),

$$
\begin{equation*}
\bar{m}=c \bar{y}-\alpha \mu \tag{9}
\end{equation*}
$$

Given $\bar{m}$ and $\bar{\pi}^{e}$, we can use (3) and (4) to solve for the steady-state values of output and the interest rate:

$$
\begin{gathered}
y^{*}\left(\bar{m}, \bar{\pi}^{e}\right)=\frac{\bar{m}+\alpha \bar{\pi}^{e}}{c}=\frac{c \bar{y}-\alpha \mu+\alpha \mu}{c}=\bar{y} \\
r\left(\bar{m}, \bar{\pi}^{e}\right)=\frac{-\left(\bar{m}+\alpha \bar{\pi}^{e}\right)}{d}=\frac{-(c \bar{y}-\alpha \mu+\alpha \mu)}{d}=-(c / d) \bar{y}
\end{gathered}
$$

We can think of the steady state as a long-run equilibrium position. In such an equilibrium, both anticipated inflation and actual inflation (see equation (7)) are equal to the rate of money creation $\mu$, and because there are no inflationary surprises, output is at its natural rate. The equilibrium money supply is positively related to (the natural rate of) output and negatively related to $\mu$ - because monetary growth induces inflation, which lowers the demand for real balances.

Turning now to the dynamics of the model, the next step is to plot each of the phase lines with the corresponding arrows of motion. From

$$
\begin{equation*}
m=c \bar{y}-\alpha \pi^{e} \tag{e}
\end{equation*}
$$

we see that the $\dot{\pi}^{e}=0$ phase line defines a downward-sloping function in the $\left(\pi^{e}, m\right)$ plane, as shown in Figure 11.1. This line divides the plane into two regions: one in which $\dot{\pi}^{e}>0$ (i.e., expected inflation increases over time), and a second one in which the reverse is true. To determine which is which, consider the following experiment: Imagine that, starting out from a point in the

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-501.jpg?height=633&width=851&top_left_y=201&top_left_x=320)

Figure 11.2. The $\dot{m}=0$ phase line.

$\dot{\pi}^{e}=0$ phase line (say the steady state), we increase the value of $m$ slightly and see what happens to the value of $\dot{\pi}^{e}$. More formally, we use (L. $\left.\pi^{e}\right)$ to compute the derivative of $\dot{\pi}^{e}$ with respect to $m$, and (if this derivative is not a constant) we evaluate it at the starting point:

$$
\frac{\partial \dot{\pi}^{e}}{\partial m}=\delta \theta / c>0
$$

Because the derivative is positive and the initial value of $\dot{\pi}^{e}$ was zero, we conclude that moving "north" of the phase line puts us in the region in which $\dot{\pi}^{e}>0$. Hence, $\pi^{e}$ increases over time in the region above the phase line, and the corresponding arrows of motion along the $\pi^{e}$ axis point to the right. ${ }^{3}$

For the $\dot{m}=0$ phase line we proceed in similar fashion (Figure 11.2). Solving for $m$ as a function of $\pi^{e}$ in (P.m), we see that the phase line is downward-sloping:

$$
\begin{equation*}
m=\frac{c}{\theta}(\mu+\theta \bar{y})-\frac{c}{\theta}\left(1+\frac{\theta \alpha}{c}\right) \pi^{e} \tag{10}
\end{equation*}
$$

Differentiating (L.m), we see that the partial derivative of $\dot{m}$ with respect to $m$,

$$
\frac{\partial \dot{m}}{\partial m}=-(\theta / c)<0
$$

is negative. Thus, $\dot{m}$ decreases (from an initial value of zero at the steady state) and becomes negative as we move into the region above the phase line. Hence, $m$ decreases over time in this area of the phase plane, and we indicate this fact with an arrow of motion pointing down along the $m$ axis.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-502.jpg?height=657&width=835&top_left_y=187&top_left_x=316)

Figure 11.3. Phase diagram.

Combining the two phase lines and the corresponding arrows of motion, we can now construct the phase diagram. Because both lines are downwardsloping, the first step is to determine which is steeper. Using (P.m) and (10), we see that

$$
\left|\left(\frac{d m}{d \pi^{e}}\right)_{\pi}\right|=\alpha<(c / \theta)+\alpha=\left|\left(\frac{d m}{d \pi^{e}}\right)_{m}\right|
$$

so the phase line (P.m), $\dot{m}=0$, is steeper, as shown in Figure 11.3. Notice that the pattern of arrows of motion is compatible with (convergent or divergent) spiral trajectories or with a saddle path, depending on the values of the parameters. To be more precise, we have to look at the eigenvalues of the system.

To determine the local stability properties of the steady state, we compute the eigenvalues of the coefficient matrix of the system,

$$
A=\left[\begin{array}{cc}
-\frac{\theta}{c} & -\left(1+\frac{\alpha \theta}{c}\right) \\
\frac{\delta \theta}{c} & \frac{\alpha \delta \theta}{c}
\end{array}\right]
$$

As we saw in Chapter 3 (Section 6), the characteristic roots of $A$ are given by

$$
\lambda_{1}, \lambda_{2}=\frac{\operatorname{tr} \pm \sqrt{\operatorname{tr}^{2}-4 \mathrm{det}}}{2}
$$

where

$$
\begin{gathered}
\operatorname{tr} A=\lambda_{1}+\lambda_{2}=-\frac{\theta}{c}+\frac{\alpha \delta \theta}{c}=\frac{\theta}{c}(\alpha \delta-1) \\
\operatorname{det} A=\lambda_{1} \lambda_{2}=-\frac{\theta}{c} \frac{\alpha \delta \theta}{c}+\left(1+\frac{\theta \alpha}{c}\right) \frac{\delta \theta}{c}=-\frac{\alpha \delta \theta^{2}}{c^{2}}+\frac{\delta \theta}{c}+\frac{\alpha \delta \theta^{2}}{c^{2}}=\frac{\delta \theta}{c}>0
\end{gathered}
$$

Hence, the determinant of the coefficient matrix is positive, and the trace may be either positive or negative depending on parameter values. Similarly, the discriminant $\Delta=\operatorname{tr}^{2}-4 d e t$ may be either positive or negative, and as a result the eigenvalues of the system may be either real numbers or complex numbers.

Suppose first that the eigenvalues are real numbers (i.e., that $\Delta>0$ ). In that case the positive sign of the determinant (which, as we know, is equal to the product of the eigenvalues) implies that $\lambda_{1}$ and $\lambda_{2}$ have the same sign. The stability of the system then depends on the sign of the trace (whose value is equal to the sum of the eigenvalues). In particular, the steady state will be stable if

$$
\operatorname{tr} A=\lambda_{1}+\lambda_{2}<0 \Leftrightarrow \delta<1 / \alpha
$$

as both eigenvalues will then be negative real numbers. ${ }^{4}$

If the discriminant is negative, on the other hand, the eigenvalues of the system will be complex conjugates of the form $\lambda_{1}=a+i b$ and $\lambda_{2}=a-i b$. Hence,

$$
\operatorname{tr}=\lambda_{1}+\lambda_{2}=2 a
$$

so the sign of the real parts of the eigenvalues is the same as the sign of the trace. If $\delta<1 / \alpha$, the trace and therefore the real parts of the eigenvalues are negative, and the system is stable.

Hence, the stability condition is the same in both cases and depends crucially on the size of the expectations adjustment parameter $\delta$. This parameter tells us how quickly expectations are revised in response to forecast errors. If $\delta$ is small, there is an element of sluggishness built into the model. Inflationary expectations take a while to catch up with actual inflation. They do eventually catch up, however, and equilibrium is restored, but this may take some time. Thus, with low $\delta$, the model is stable and slow to adjust. If, on the other hand, $\delta$ is "too large," the model becomes unstable, because price expectations "overreact," and because expected inflation becomes a component of actual inflation, there is no way to restore equilibrium.

In the remainder of this section we will assume that parameter values are such that the eigenvalues are both real and negative. This gives us a "wellbehaved system" that converges asymptotically to the steady state without cyclical oscillations.

## (b) Effects of Monetary Policy

We can now use the phase diagram and the stability assumption we have just made to analyze the response of the system to a change in the value of one of its parameters. In particular, we focus on the effect of a once-and-forall change in the rate of money creation $\mu$.

Assume that we are initially at the steady state $S_{0}$ that corresponds to a constant rate of monetary growth $\mu_{0}$. Next, imagine that the government increases the rate of growth of the nominal money supply from $\mu_{0}$ to $\mu_{1}$ and promises never to change it again, and people believe it. What happens?

Because we have assumed the system is stable, it will converge asymptotically to a new steady state $S_{1}$ that corresponds to the new value of $\mu$. There are two different questions to consider: First, we have to see what happens to the steady state when the parameter changes. This is an exercise in comparative statics. Second, we would like to determine the path the system follows from its initial position (the steady state associated with $\mu_{0}$ ) to the new long-run equilibrium.

Let us start with the long-run effects of the proposed policy change. Recall that the steady state of the system lies at the intersection of the phase lines

$$
\begin{gather*}
m=\frac{c}{\theta}(\mu+\theta \bar{y})-\frac{c}{\theta}\left(1+\frac{\theta \alpha}{c}\right) \pi^{e}  \tag{P.m}\\
m=c \bar{y}-\alpha \pi^{e} \tag{e}
\end{gather*}
$$

Inspection of these equations shows that an increase in $\mu$ shifts the $\dot{m}=0$ phase line upward, but has no effect on the $\dot{\pi}^{e}=0$ locus. The new steady state $S_{1}$ will therefore lie to the southeast of the old one, as illustrated in Figure 11.4. Hence, the long-run effect of an increase in the rate of money growth is to increase expected inflation and reduce real money holdings.

Recalling equation (8), $\bar{\pi}^{e}=\mu$, we see that an increase in the rate of monetary growth leads in the long run to a proportional increase in the rate of expected (and actual) inflation and to a reduction in the stock of real balances. We also know that

$$
y^{*}\left(\bar{m}, \bar{\pi}^{e}\right)=\bar{y} \quad \text { and } \quad r^{*}\left(\bar{m}, \bar{\pi}^{e}\right)=-(c / d) \bar{y}
$$

so steady-state output and real interest rates are independent of monetary policy. Hence, monetary policy is neutral in the long run, because it has no effect on output ${ }^{5}$ or interest rates. Its only effect is a proportional increase in the rate of inflation that reduces the demand for real balances.

In the short run, however, a change in the rate of money creation will have real effects. Figure 11.5 describes the transition to the new long-run equilibrium. At time zero, the system is at point $S_{0}$. This point is the steady state

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-505.jpg?height=658&width=835&top_left_y=191&top_left_x=316)

Figure 11.4. Long-run effect of an increase in the rate of money creation.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-505.jpg?height=682&width=832&top_left_y=1010&top_left_x=320)

Figure 11.5. Adjustment to an increase in the rate of money creation.

corresponding to $\mu_{0}$, but it is no longer a steady state when the increase in the rate of money creation shifts the $\dot{m}=0$ phase line to the right. Under the new policy, the arrows of motion of the system point to the northeast at $S_{0}$. Hence, money balances and expected inflation increase along the first part of the adjustment trajectory, labeled (1) in Figure 11.5. Eventually, however, the system enters into a different quadrant in which the arrows of motion point to the southeast, the segment of the system's trajectory labeled

(2). During this second stage of the adjustment process, expected inflation continues to increase, but real money holdings now decrease, eventually falling below their initial value.

Given the trajectories of $\pi^{e}$ and $m$, we can derive the time paths of output and the real interest rate. We have seen that

$$
y^{*}\left(m, \pi^{e}\right)=\frac{m+\alpha \pi^{e}}{c} \quad \text { and } \quad r^{*}\left(m, \pi^{e}\right)=-\frac{m+\alpha \pi^{e}}{d}
$$

where $c$ and $d$ are positive numbers. In part (1) of the adjustment trajectory, both $m$ and $\pi^{e}$ are increasing, so $y^{*}$ is rising, and $r^{*}$ is falling. This is the standard Keynesian result concerning the expansionary effects of a loosening of monetary policy. These responses, however, are reversed later, with both income and the real interest rate returning to their original levels in the new steady state $S_{1}$.

## 2. An Introduction to Perfect-Foresight Models

In Chapters 9 and 10 we warned the reader that the selection of appropriate boundary conditions often is not as straightforward in economic models as in the case of physical systems. In this section we study two examples that will serve to illustrate this point and to introduce the reader to the logic of perfect-foresight models. The first is a simple model of stock prices based on the no-arbitrage principle, and the second is a model of exchange-rate determination. In both cases we seek the equilibrium path of some asset price. Because this variable is not tied down by previous history, we have to rely on economic considerations to determine which of the infinitely many solutions of a certain dynamical system should be considered the equilibrium trajectory.

## (a) A Model of Stock Prices

Suppose investors in financial markets have a choice between two assets: government bonds, which pay a fixed interest rate $r$, and shares of stock, which pay a constant stream of dividends $d$. We take $r$ and $d$ as given and develop a model of the evolution of share prices $(v)$.

To derive the asset-pricing equation, we start out from the postulate that no obvious profit opportunities should remain unexploited in equilibrium. The instantaneous return earned by an agent who invests $v$ dollars in bonds is $r v$. Alternatively, if he buys a share of stock, his expected return is the sum of the dividend $d$ and the expected increase in the value of the share $\dot{v}_{e}=d v_{e} / d t$. In equilibrium, the expected returns on the two assets must be the same, yielding the condition

$$
\begin{equation*}
r v=d+\dot{v}_{e} \tag{1}
\end{equation*}
$$

If this condition did not hold, we could not be in equilibrium, because no investor would want to hold the asset with the lower return. Prices would have to adjust until somebody was willing to hold all existing assets.

It remains to specify how expectations are formed. We will consider two possibilities. The first is that agents have adaptive expectations, formed in accordance with the equation

$$
\begin{equation*}
\dot{v}_{e}=\alpha\left(v-v_{e}\right) \tag{2}
\end{equation*}
$$

That is, if the actual price of the share $v$ exceeds its expected price $v_{e}$, agents revise their expectations upward. The size of the correction depends on the "forecast error" and on the value of the parameter $\alpha$, which can be interpreted as a measure of the speed of learning. To ensure that the model behaves sensibly, we assume that $0<\alpha<r$. The second possibility is that agents have perfect foresight (i.e., that they forecast share prices correctly). In this case, $v_{e}(t)=v(t)$ for all $t$ (and hence $\dot{v}_{e}=\dot{v}$ ).

In what follows, we refer to the present value of the stream of dividends,

$$
v^{*}=\int_{0}^{\infty} d e^{-r t} d t=\frac{d}{r}
$$

as the fundamental value of the stock.

## (i) Adaptive Expectations

In this section we will assume that expectations are adaptive. Under this assumption, the evolutions of actual and expected share prices are described by equations (1) and (2). To solve the model, we start by finding the time path of expected share prices. Solving for $v$ in (1),

$$
\begin{equation*}
v=\frac{d}{r}+\frac{\dot{v}_{e}}{r} \tag{3}
\end{equation*}
$$

and substituting this expression in (2), we obtain a differential equation in $v_{e}$ :

$$
\begin{align*}
\dot{v}_{e} & =\alpha v-\alpha v_{e}=\alpha\left(\frac{d}{r}+\frac{\dot{v}_{e}}{r}\right)-\alpha v_{e} \Rightarrow \dot{v}_{e}\left(1-\frac{\alpha}{r}\right)=-\alpha v_{e}+\frac{\alpha d}{r} \\
& \Rightarrow \dot{v}_{e}=-\gamma v_{e}+\frac{\alpha d}{r-\alpha}, \quad \text { where } \gamma \equiv \frac{\alpha r}{r-\alpha} \tag{4}
\end{align*}
$$

Setting $\dot{v}_{e}=0$ in (4), we can solve for the steady-state value of $v_{e}$ :

$$
\begin{array}{r}
\frac{\alpha r}{r-\alpha} v_{e}=\frac{\alpha d}{r-\alpha} \\
\Rightarrow \bar{v}_{e}=v^{*}=\frac{d}{r} \tag{5}
\end{array}
$$

The solution of (4) is then given by

$$
\begin{equation*}
v_{e}(t)=v^{*}+\left[v_{e}(0)-v^{*}\right] e^{-\gamma t} \tag{5}
\end{equation*}
$$

Under the assumption that $\alpha<r$, we have $\gamma>0$, and the system is stable. Any initial discrepancy between the expected share price and its fundamental value decreases over time and disappears asymptotically. In the long run, the expected price of a share of stock is equal to the present value of its dividends.

Next, we solve for the time path of $v$. Substituting

$$
\begin{equation*}
\dot{v}_{e}=\alpha\left(v-v_{e}\right) \tag{2}
\end{equation*}
$$

in (3), we have

$$
v=v^{*}+\frac{\alpha}{r}\left(v-v_{e}\right) \Rightarrow v\left(1-\frac{\alpha}{r}\right)=v^{*}-\frac{\alpha}{r} v_{e}
$$

Substituting equation (5) into this expression and solving for $v$, we obtain, after some algebra,

$$
\begin{equation*}
v(t)=v^{*}-\frac{\alpha}{r-\alpha}\left[v_{e}(0)-v^{*}\right] e^{-\gamma t} \tag{6}
\end{equation*}
$$

Under our assumptions, $e^{-\gamma t} \rightarrow 0$ as $t \rightarrow \infty$. Hence, asymptotically, the market price of the stock also converges to its fundamental value $v^{*}$.

The long-run predictions of the model are both intuitive and reasonable: In the steady state, the market price of the share is equal to the discounted value of its dividend stream, and expectations are correct $\left(\bar{v}=\bar{v}_{e}=v^{*}\right)$. This is no longer the case in the short run, as we will soon see. During the transition to the steady state, actual and expected prices need not be equal, and both can deviate from the stock's fundamental value. Comparing (5) and (6), we see, moreover, that $v(t)$ and $v_{c}(t)$ lie on opposite sides of $v^{*}$ and must be moving in opposite directions (Figure 11.6). That is, when actual prices are "too high" relative to the fundamental value, the expected price is below $v^{*}$, and when share prices are rising, expected share prices are falling.

Another disturbing feature of the model is that the forecast error is predictable. Combining (5) and (6), we can solve explicitly for the time path of the forecast error,

$$
\begin{align*}
v_{e}(t)-v(t) & =\left(v^{*}+\left[v_{e}(0)-v^{*}\right] e^{-\gamma t}\right)-\left(v^{*}-\frac{\alpha}{r-\alpha}\left[v_{e}(0)-v^{*}\right] e^{-\gamma t}\right) \\
& =\frac{r}{r-\alpha}\left[v_{e}(0)-v^{*}\right] e^{-\gamma t} \tag{7}
\end{align*}
$$

Setting $t=0$ in equation (7),

$$
v_{e}(0)-v(0)=\frac{r}{r-\alpha}\left[v_{e}(0)-v^{*}\right]
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-509.jpg?height=558&width=783&top_left_y=198&top_left_x=340)

Figure 11.6. Time paths of actual and expected stock prices with adaptive expectations.

we obtain a relation between the actual and expected prices of the stock at time zero:

$$
\begin{equation*}
\frac{r-\alpha}{r} v(0)+\frac{\alpha}{r} v_{e}(0)=v^{*} \tag{8}
\end{equation*}
$$

Notice that equations (1) and (2) describe the time paths of $v$ and $v_{e}$, but do not tie down their initial values. For both equations to hold simultaneously, these initial values must satisfy condition (8), but what does this mean? If we take the initial expected price as given, then (8) gives the equilibrium price of the stock at time zero. Alternatively, if we take $v(0)$ as given, we can solve (8) for $v_{e}(0)$, but it is hard to see why agents would choose to make just such a forecast. In any event, if initial expected prices are correct $\left(v_{e}(0)=v(0)\right)$, then both actual and expected prices must be equal to the fundamental value of the stock $v^{*}$; but if the expected price at time zero is different from $v^{*}$, the initial equilibrium price must be on the opposite side of $\nu^{*}$, and the forecast error disappears only gradually.

Perhaps the most unsatisfactory implication of the model we have just developed is that (except when $v_{e}(0)=v(0)=v^{*}$ ) agents commit, each period, a perfectly predictable forecast error that costs them money. As a result, an agent who knows the structure of the model will have an incentive to deviate from the predicted behavior, thereby invalidating the theory. For example, if you know that expected prices tomorrow will be below market prices, you can write a contract today offering to buy tomorrow at the expected price. If expectations are formed as we have assumed, somebody will be willing to buy such a contract - but when tomorrow comes you will immediately be able to resell the stock at a profit. Hence, the predictable
discrepancy between actual and expected prices involves an opportunity for quick profits. Agents would have an incentive to compute the actual trajectory of prices, but the model assumes that they do not do so (i.e., that they form expectations according to (2)).

This is hard to reconcile with the hypothesis that individuals are rational and maximize utility or wealth. In the context of a model as simple as the present one, without uncertainty or asymmetric information, the easiest way to model the idea that individuals are rational is to assume that they know the model and all the relevant data, such as the time path of dividends. But then each agent could compute the solution, just as we have done, and it makes little sense to assume that forecast errors would be eliminated only gradually when it would be possible (and profitable) to avoid them completely.

## (ii) Perfect Foresight

In conclusion, in a world without uncertainty, adaptive expectations are not consistent with the assumption of rationality. The theory works only as long as agents do not understand what is happening. To avoid this problem, we will postulate that agents form expectations that are consistent with the structure of the model. In particular, we assume that the agents know the model and use it, along with all the relevant information they have, to predict the evolution of share prices. Because there is no stochastic element in the model, the time path of prices will be correctly anticipated. Hence, we replace equation (2) with the assumption of perfect foresight:

$$
\begin{equation*}
v_{e}(t)=v(t) \forall t \tag{9}
\end{equation*}
$$

Let us see where this assumption takes us. Given (9), $\dot{v}_{e}=\dot{v}$ for all $t$, and the equation describing the time path of asset prices becomes

$$
\begin{align*}
& r v=d+\dot{v} \\
& \quad \Rightarrow \dot{v}=r v-d \tag{10}
\end{align*}
$$

Like equation (4), equation (10) has a unique stationary solution,

$$
v^{*}=d / r
$$

in which share prices reflect the discounted value of the dividend stream. The dynamics of the two systems are, however, very different. In particular, whereas (4) is stable, the stationary state of (10) is unstable, because $r>0$. The general solution of (10) is given by

$$
\begin{equation*}
v^{g}(t, c)=v^{*}+c e^{r t}=v^{*}+\left[v(0)-v^{*}\right] e^{r t} \tag{11}
\end{equation*}
$$

where we emphasize that assigning a value to the arbitrary constant $c$ is equivalent to choosing an initial value for the share price.

At first sight, this does not look very promising. Because the "bubble term" $c e^{r t}$ goes to plus or minus infinity as $t \rightarrow \infty$, equation (11) predicts that share prices will explode, except in the case in which $v(0)=v^{*}$. If we take the initial value of $v$ as given, then the model predicts an unreasonablelooking path of share prices, except by chance. This difficulty, common in asset-pricing models, almost led to the abandonment of perfect-foresight models. However, researchers like Sargent and Wallace (1973) and Calvo (1977) soon realized that taking initial asset prices as given was not always the most reasonable alternative. Because asset prices are free to move, and even "jump" at each point in time, at least half the problem is determining their initial value.

In more general terms, the important point is that it is not always legitimate from the point of view of economic theory to take the initial value of a variable as a parameter fixed by previous history. The choice of an appropriate boundary condition often requires a little thought about the economics of the problem. What equation (10) says is that the solution of the model must be one of the family of functions described by $v^{g}(t, c)$. The economic problem is that of determining which of these trajectories corresponds to an equilibrium. The answer then determines the appropriate boundary condition and therefore the initial value of $v$.

For the sake of the argument, let us take an arbitrary value of $v(0)$ as given. The instability of the system implies that if the initial price is incorrect (in the sense of not reflecting the fundamental value of the asset), then things can only get worse. To see why, let us return to (10) and rewrite it in the form

$$
\begin{equation*}
\frac{\dot{v}+d}{v}=r \quad \text { or } \quad \dot{v}=r v-d=r\left(v-v^{*}\right) \tag{12}
\end{equation*}
$$

Suppose that $v(0)>v^{*}$ (i.e., that share prices are higher than what would be reasonable in terms of the present value of the underlying dividend flow). Then, in order for (12) to hold, the price of the share must be increasing at a rate such that the capital gains are just enough to make up for a dividend that is low relative to the price. Today's price increase, on the other hand, makes tomorrow's price even less reasonable, and therefore requires an even higher rate of appreciation in the future.

It is not clear what mechanism would make tomorrow's share prices rise by enough to justify, ex post, today's unreasonably high price. In fact, the only sensible way to interpret such an explosive path of share prices is as a "bubble" in which unreasonable expectations become self-fulfilling. Although such phenomena are not unknown, it may be reasonable to rule out such behavior under "normal" circumstances. This leaves us with only the constant solution $(c=0)$ given by the fundamental value of the asset, in
which share prices accurately reflect the present value of dividends. In equilibrium, the value of the share, $v$, jumps immediately to $v^{*}$ and remains constant forever - unless the system is disturbed in some way.

It is worth noting that the assumption of perfect foresight eliminates the inconsistency we found in the adaptive expectations model. An individual who knows the structure of the economy and knows that all other agents use an adaptive forecasting rule has every incentive to deviate from the predicted behavior (i.e., to forecast prices correctly, and get rich along the way). But because the same is true of each and every agent, the model cannot be correct. With perfect foresight, by contrast, everybody uses the correct model to predict prices, and nobody has an incentive to behave differently. Although the ability to predict prices exactly does not generate extraordinary returns, any other alternative will lose money, on average.

Next, we will see how the model can be used to analyze the response of share prices to a change in the tax rate on dividends. The exercise will also serve to check the "reasonableness" of the model.

Assume that dividends are taxed at a flat rate $\tau$ that remains constant over time. Then equation (10) becomes

$$
\begin{equation*}
\dot{v}=r v-(1-\tau) d \tag{13}
\end{equation*}
$$

where $(1-\tau) d$ is the net-of-tax dividend. The general solution of this equation is given by

$$
v^{g}(t, c ; \tau)=v^{*}(\tau)+c e^{r t}=v^{*}(\tau)+\left[v(0)-v^{*}(\tau)\right] e^{r t}
$$

where the stationary solution

$$
v^{*}(\tau)=\frac{(1-\tau) d}{r}
$$

now reflects the present value of after-tax dividends.

The policy change we will analyze involves an increase in the tax rate from $\tau_{0}$ to some higher value $\tau_{1}$. To start, let us suppose that the tax increase is unexpected and that the agents believe that the new rate will remain in effect forever. As shown in Figure 11.7, the change in the tax parameter shifts the phase line upward, yielding a new stationary solution

$$
v^{*}\left(\tau_{1}\right)=\frac{\left(1-\tau_{1}\right) d}{r}<\frac{\left(1-\tau_{0}\right) d}{r}=v^{*}\left(\tau_{0}\right)
$$

If we rule out explosive paths, the value of $v$ jumps down immediately after the policy change to its new fundamental value $v^{*}\left(\tau_{1}\right)$. The model predicts, reasonably enough, that a tax increase will result in an immediate drop in prices equal to the reduction in the present value of the after-tax dividend stream.
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-513.jpg?height=494&width=1270&top_left_y=198&top_left_x=101)

Figure 11.7. Response of stock prices to an unanticipated increase in dividend taxes.

Next, imagine that today (at time zero) the government announces (and everybody believes it) that the tax rate will be raised to $\tau_{1}$ at some time $T$ in the future and will remain constant thereafter. To determine the equilibrium path of the system following the announcement, we work backward in time. If we rule out explosive paths, at time $T$ the system must be at the new fundamental solution $v^{*}\left(\tau_{1}\right)$. For $t<T$, the initial tax rate $\left(\tau_{0}\right)$ still applies, and the system must therefore obey the "old" law of motion:

$$
\begin{equation*}
\dot{v}=r v-\left(1-\tau_{0}\right) d \tag{14}
\end{equation*}
$$

Hence, the equilibrium path of the system during the transition period $[0, T)$ must be one of the family of functions described by the general solution of the "old" system:

$$
\begin{equation*}
v^{g}\left(t, c ; \tau_{0}\right)=v^{*}\left(\tau_{0}\right)+c e^{r t}=v^{*}\left(\tau_{0}\right)+\left[v(0)-v^{*}\left(\tau_{0}\right)\right] e^{r t} \tag{15}
\end{equation*}
$$

The equilibrium solution is the one that puts us at the new fundamental price $v^{*}\left(\tau_{1}\right)$ precisely at the time $T$ at which the policy change takes effect. Formally, the appropriate boundary condition is

$$
v\left(T ; \tau_{0}\right)=v^{*}\left(\tau_{1}\right) \Rightarrow v^{*}\left(\tau_{0}\right)+\left[v(0)-v^{*}\left(\tau_{0}\right)\right] e^{r T}=v^{*}\left(\tau_{1}\right)
$$

Notice that the only unknown in this expression is the price of the stock at time zero (i.e., at the moment of the announcement). Solving for $v(0)$,

$$
\begin{equation*}
v(0)=v^{*}\left(\tau_{0}\right)-\left[v^{*}\left(\tau_{0}\right)-v^{*}\left(\tau_{1}\right)\right] e^{-r T} \tag{16}
\end{equation*}
$$

the initial drop in share prices is given by

$$
\begin{equation*}
v^{*}\left(\tau_{0}\right)-v(0)=\left[v^{*}\left(\tau_{0}\right)-v^{*}\left(\tau_{1}\right)\right] e^{-r T} \tag{17}
\end{equation*}
$$

Substituting this expression into the general solution, we obtain the trajectory of stock prices during the transition to the new steady state:

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-514.jpg?height=578&width=884&top_left_y=188&top_left_x=285)

Figure 11.8. Response of stock prices to an anticipated increase in dividend taxes.

$$
\begin{equation*}
v(t)=v^{*}\left(\tau_{0}\right)-\left[v^{*}\left(\tau_{0}\right)-v^{*}\left(\tau_{1}\right)\right] e^{r(t-T)} \tag{18}
\end{equation*}
$$

Hence, stock prices fall immediately as a result of the announcement, and they continue to fall until they reach the new fundamental price precisely at the time of the tax change. Observe also that the size of the immediate capital loss is equal to the discounted value (at time zero) of the change in the stock's fundamental value. In some sense, this is what we should expect.

Figure 11.8 displays the time path of share prices. During the transition period, prices follow what looks like (but is not) an explosive path of the "old" system. In fact, the equilibrium path is the only solution of the system that yields a continuous trajectory from time zero on and ends up at the new fundamental value of the stock at time $T$. This continuity property has an intuitive economic interpretation: If share prices were to remain constant at $v^{*}\left(\tau_{0}\right)$ until the time of the actual policy change, agents would be anticipating a capital loss of $v^{*}\left(\tau_{0}\right)-v^{*}\left(\tau_{1}\right)$ at time $T$. To avoid such loss, each agent would try to sell his shares just an instant before $T$. Hence, prices would fall, pushing $v(T-\varepsilon)$ below $v^{*}\left(\tau_{0}\right)$. In fact, the adjustment must start even earlier, for the same logic implies that the price cannot be $v^{*}\left(\tau_{0}\right)$ at time $T-2 \varepsilon$ if agents anticipate a capital loss at $T-\varepsilon$, and so on. In fact, there cannot be an equilibrium in which agents anticipate a rate of return on the stock lower than $r$ at any point in the future. Hence, the full burden of the adjustment must fall on the initial shareholders, who, taken by surprise by the announcement, cannot do anything to avoid a capital loss.

Problem 2.1 asks the reader to verify that the solution trajectory we have just derived can be obtained directly by solving a nonautonomous version of the stock-pricing equation.

Problem 2.1. When the tax rate on dividends varies over time, our stockpricing equation can be written in the form

$$
\begin{equation*}
\dot{v}=r v-b(t) \tag{1}
\end{equation*}
$$

where

$$
b(t)=\left(1-\tau_{t}\right) d
$$

Equation (1) is a nonautonomous linear equation of the type we studied in Section 5 of Chapter 9. Its solution can be written in the ("forward") form

$$
\begin{equation*}
v(t)=[v(0)-F(0)] e^{r t}+F(t) \tag{2}
\end{equation*}
$$

where

$$
\begin{equation*}
F(t)=\int_{t}^{\infty} b(s) e^{r(t-s)} d s \tag{3}
\end{equation*}
$$

the fundamental solution of (1), is the discounted value of the stream of future after-tax dividends, and $[v(0)-F(0)] e^{r t}$ is a bubble term capturing possible deviations from the fundamental value of the stock. By the same logic as in our earlier discussion, we will rule out bubbles and assume that $v(t)=F(t)$ for all $t$. Hence, the value of the stock at each point in time will be given by (3). We will now show that this fundamental solution gives the same time path of stock prices in response to a preannounced future increase in dividend taxes as the procedure we followed earlier.

(i) Show that

$$
\begin{equation*}
\int_{t}^{b} e^{r(t-s)} d s=\frac{1}{r}\left(1-e^{r(t-b)}\right) \tag{4}
\end{equation*}
$$

(ii) As before, assume that an announcement is made at time zero that dividend taxes will increase at time $T$ from $\tau_{0}$ to $\tau_{1}$. Then

$$
\begin{align*}
b(t) & =\left(1-\tau_{0}\right) d & & \text { for } t \in[0, T) \\
& =\left(1-\tau_{1}\right) d & & \text { for } t \in[T, \infty) \tag{5}
\end{align*}
$$

Using (3) and (4), compute the trajectory of stock prices following the announcement.

Problem 2.2. Cagan's model with perfect foresight. Consider the following specification of equilibrium in the money market:

$$
\begin{equation*}
m(t)-p(t)=-\lambda \pi(t), \quad \text { with } \lambda>0 \tag{1}
\end{equation*}
$$

where $m$ is the $\log$ of the nominal money supply, $p$ is the log of the price level, and $\pi=\dot{p}$ is the (both actual and expected) inflation rate (i.e., we are assuming perfect foresight). If we are willing to assume away real-side com-
plications (e.g., assume that output is fixed at the natural rate), then the full equilibrium of the economy is determined by this equation.

Assume that the nominal money supply grows at a constant rate $\dot{m}=\mu$. Differentiating (1) with respect to time, we can obtain a differential equation in the inflation rate,

$$
\begin{align*}
& \mu-\pi=\dot{m}-\dot{p}=-\lambda \dot{\pi} \\
& \quad \Rightarrow \dot{\pi}=\theta(\pi-\mu), \quad \text { where } \theta \equiv 1 / \lambda \tag{2}
\end{align*}
$$

(i) Find the steady state of this equation, and write its general solution.

(ii) Assume that $\mu$ remains constant forever. From an economic point of view, which is the most reasonable particular solution of this equation? Why?

(iii) Assume that we are at time zero and that $\mu$ has always been constant at some value $\mu_{0}$. Suddenly the government announces that at some time $T$ in the future the rate of money creation will increase to $\mu_{1}>\mu_{0}$ and will remain constant forever thereafter (and people believe the announcement). Describe the evolution of the inflation rate following the announcement and your reasons for selecting this particular adjustment path. Write the particular solution corresponding to this behavior, and use it to solve for the jump in the price level at the time of the announcement. What factors determine the size of this jump?

## (b) Dornbusch's Overshooting Model

The model we study in this section is an open-economy IS-LM model with perfect foresight and sticky output prices. It is designed to study how price rigidity in goods markets affects the short-run responses of exchange rates to policy shifts and other exogenous disturbances. Because the focus is on short-run dynamics, we assume that the level of output is fixed. We will find that the sticky-price assumption yields a model that mimics the observed tendency of exchange rates to exhibit considerably more volatility than the underlying "fundamentals."

As in Section 1, Greek letters will denote positive parameters, and variables denoted by lowercase letters will be the natural logarithms of the corresponding variables denoted by uppercase letters. Asterisks will be used to denote foreign variables. For example, $p=\ln P$ is the $\log$ of the domestic price level, and hence $\dot{p}=\dot{P} / P$ is the domestic rate of inflation. We will use $s$ to denote (the log of) the nominal exchange rate, defined as the price of one unit of foreign money in domestic currency units. Hence, an increase in $s$ represents a loss of value of the home currency, and $\dot{s}$ is its rate of depreciation.

Starting with the market for domestic output, the basic equations of the model are the following. Output supply is fixed at some constant, exogenous level

$$
\begin{equation*}
y^{s}=y \tag{1}
\end{equation*}
$$

Demand for domestic output, on the other hand, depends positively on the ratio of foreign to domestic output prices expressed in a common currency unit $\left(s+p^{*}-p\right)$. Aggregate demand is also positively related to government expenditures $g$ and negatively related to the real interest rate $R-\dot{p}$, where $R$ is the nominal interest rate, and $\dot{p}$ is the (actual and expected) rate of inflation:

$$
\begin{equation*}
y^{d}=\delta\left(s+p^{*}-p\right)-\sigma(R-\dot{p})+g \tag{2}
\end{equation*}
$$

If demand exceeds supply, inventories are drawn down, and prices increase in proportion to excess demand, as described by the following "Phillips curve":

$$
\begin{equation*}
\dot{p}=\alpha\left(y^{d}-y\right) \tag{3}
\end{equation*}
$$

The last two equations of the model,

$$
\begin{gather*}
m-p=\phi y-\lambda R  \tag{4}\\
R=R^{*}+\dot{s} \tag{5}
\end{gather*}
$$

are asset-market equilibrium conditions. Equation (4) is a standard LM schedule, relating the demand for real balances $(m-p)$ to income and the nominal interest rate, and (5) is an uncovered interest parity relation, telling us that the interest-rate differential between domestic and foreign bonds must be just enough to offset the depreciation $(\dot{s})$ of the domestic currency.

We will make the standard "small-economy" assumption and treat the world interest rate $R^{*}$ as an exogenous constant. To simplify things, we will also assume that the nominal money supply $(m)$, government expenditures $(g)$, and the foreign price level $\left(p^{*}\right)$ remain constant over time. This leaves us with three time-dependent state variables: $s, p$, and $R$.

Working with equations (2)-(5), it is easy to solve for the steady state of the model. Setting $\dot{s}$ equal to zero in (5), we have

$$
\begin{equation*}
\bar{R}=R^{*} \tag{ss.$R}
\end{equation*}
$$

That is, the domestic interest rate must be equal to the world rate in a longrun equilibrium, for otherwise the domestic currency would have to appreciate or depreciate in order to compensate investors for the interest-rate differential between domestic and foreign bonds.

Using $\bar{R}=R^{*}$, we can solve (4) for the steady-state price level:

$$
\begin{gather*}
(4) \Rightarrow m-\bar{p}=\phi y-\lambda R^{*} \\
\Rightarrow \bar{p}=m-\phi y+\lambda R^{*} \tag{ss.p}
\end{gather*}
$$

Setting $\dot{p}=0$ in equation (3), we obtain $y^{d}=y$. Using this expression, equation (2) can be solved for the steady-state exchange rate:

$$
\begin{align*}
& (2) \Rightarrow y=\delta\left(\bar{s}+p^{*}-\bar{p}\right)-\sigma\left(R^{*}-0\right)+g \\
& \quad \Rightarrow \bar{s}=\bar{p}-p^{*}+(1 / \delta)\left(y+\sigma R^{*}-g\right) \tag{ss.s}
\end{align*}
$$

The steady-state exchange rate depends on the relative price levels of the two countries, $\bar{p}-p^{*}$, but notice that there is an additional term. From equation (2), $\delta$ is the real-exchange-rate elasticity of the demand for domestic output. If domestic and foreign goods were perfect substitutes, we would have $\delta \rightarrow \infty$ and (ss.s) would reduce to $\bar{s}=\bar{p}-p^{*}$, which would be the (longrun) purchasing-power-parity relation (one unit of domestic currency buys the same output in both countries).

Equations (1)-(5) can be reduced to a system of two differential equations in $p$ and $s$ that summarize, respectively, the behaviors of asset markets and goods markets. First, we solve (4) for $R$,

$$
\begin{equation*}
R=\frac{\phi y-m+p}{\lambda} \tag{6}
\end{equation*}
$$

and substitute the result into (5) to get the law of motion describing the evolution of the exchange rate,

$$
\begin{equation*}
\dot{s}=R-R^{*}=\frac{\phi y-m+p}{\lambda}-R^{*} \tag{L.s}
\end{equation*}
$$

Next, substituting (2) into (3),

$$
\dot{p}=\alpha\left[\delta\left(s+p^{*}-p\right)-\sigma(R-\dot{p})+g-y\right]
$$

and solving for $\dot{p}$, we have

$$
\begin{equation*}
\dot{p}=\frac{\alpha}{1-\alpha \sigma}\left[\delta\left(s+p^{*}-p\right)-\sigma R+g-y\right] \tag{7}
\end{equation*}
$$

Finally, we substitute (6) into (7) to get

$$
\begin{equation*}
\dot{p}=\frac{\alpha}{1-\alpha \sigma}\left(\delta\left(s+p^{*}-p\right)-\sigma \frac{\phi y-m+p}{\lambda}+g-y\right) \tag{8}
\end{equation*}
$$

and, grouping terms,

$$
\begin{equation*}
\dot{p}=\frac{\alpha}{1-\alpha \sigma}\left(\delta\left(s+p^{*}\right)-[\delta+(\sigma / \lambda)] p-\sigma \frac{\phi y-m}{\lambda}+g-y\right) \tag{L.p}
\end{equation*}
$$

The next two problems ask the reader to investigate the dynamic behavior of this system of differential equations and to identify the solution trajectory that corresponds to the equilibrium of the model. The first step is to construct the phase diagram.

Problem 2.3. Construct the phase diagram for the system (L.s)-(L.p). Assume that $1-\alpha \sigma>0$. What does this assumption mean?

Next, the reader is asked to verify that the steady state of the system is a saddle point. As we saw in Chapter 10, this implies that the system converges to the steady state provided its initial position lies on a straight line through this point, called the convergent subspace of the system or saddle path. For a given initial value of the domestic price level (which we take to be a predetermined variable) there is a unique value of the exchange rate that will put us on this convergent trajectory. Because any other solution of the system would "explode," generating a rather unreasonable trajectory of domestic prices and exchange rates, we will take the saddle path as the equilibrium solution of the model. The reader is asked to solve explicitly for the appropiate particular solution of the dynamical system.

## Problem 2.4. Solution of Dornbusch's model.

(i) Compute the eigenvalues and eigenvectors of the system (L.s)-(L.p), and verify that the steady state is a saddle point.

(ii) Write the general solution of the system. Find the particular solution of the system that corresponds to the saddle path, and discuss the equilibrium trajectory of the system from an arbitrary initial price level. Find the equation that describes the saddle path, and show that it has negative slope.

We will now use the model to analyze the effects of different monetarypolicy and fiscal-policy measures on price levels and exchange rates. The first two policy changes are unanticipated changes in government expenditures and in the money supply. To analyze their impact, the reader can proceed essentially as we have done in previous exercises of a similar nature. The first step is to determine the effect of the policy change on the steady state of the system. Then we select the solution of the system that, given the initial price level, will take us eventually to the new steady state. This solution is required to be continuous at all points, except possibly at time zero, when the exchange rate (which is assumed to be a "free variable") is allowed to jump as required in order to put us on the convergent trajectory.

Problem 2.5. Assume that the economy is initially (at time zero) at the steady state $S_{0}=\left(\bar{p}_{0}, \bar{s}_{0}\right)$ corresponding to values $m_{0}$ and $g_{0}$ of the money supply and government expenditures.

(i) Suppose the government announces an immediate and unanticipated permanent increase in its expenditure level on domestic goods to $g_{1}>g_{0}$. Discuss the impact on the steady state of the system, and describe the adjustment trajectory from the initial position to the new equilibrium.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-520.jpg?height=659&width=979&top_left_y=193&top_left_x=249)

Figure 11.9. Adjustment to an anticipated increase in the money supply.

(ii) Analyze the effect of an immediate, unanticipated, and permanent increase in the nominal money supply to $m_{1}>m_{0}$. It will be seen that the exchange rate temporarily "overshoots" its new long-run equilibrium value. Explain in what sense this is true, and discuss the economic mechanism that generates this result. What determines the degree of overshooting?

The final policy experiment we will consider is a preannounced future increase in the money supply. The logic of the analysis is still the same. We want to identify a trajectory that will eventually take us to a new steady state and that will be continuous at all points, except possibly at the time of the announcement. In constructing such a path, the reader should keep in mind that the system must obey the "old" law of motion (corresponding to the initial parameter values) until the policy change actually takes place.

Problem 2.6. As before, assume that the economy is initially (at time zero) at the steady state $S_{0}=\left(\bar{p}_{0}, \bar{s}_{0}\right)$ corresponding to a value $m_{0}$ of the money supply. Now imagine that at time zero the government announces that at some time $T$ in the future the money supply will be permanently increased from the current level of $m_{0}$ to $m_{1}=m_{0}+\Delta m$. The change in the steady state will be as in the preceding problem, with the long-run equilibrium levels of $p$ and $m$ increasing proportionately to $\Delta m$. The adjustment path is sketched in Figure 11.9. Explain how this path is constructed, and explain how you would go about finding the coordinates of points $A$ and $B$ in Figure 11.9 using the general solution of the system (derived earlier) and appropriate boundary conditions.

## 3. Neoclassical Growth Models

This section reviews some simple models of growth in a one-sector neoclassical economy. These models have become the standard framework for much work in macroeconomics, as well as in growth theory. We begin by setting down some common assumptions concerning the technology and characterizing equilibrium factor prices in a one-sector neoclassical setting. We then develop Solow's classic model (1956) and an extension of it due to Diamond (1965) that endogenizes the savings behavior of finitely-lived individuals.

## (a) Technology and Factor Prices in a Neoclassical World

The predictions of a growth model regarding the time path of output and the evolution of the international distribution of income depend, essentially, on its technological assumptions concerning the existence of constant or increasing returns to scale in capital and the nature and determinants of technical progress. In this section we will review the central technological assumptions of the basic neoclassical models. Some of their implications will be explored later within the framework of the Solow model.

Consider a world with two factors and a single good. Capital $(K)$ and labor $(L)$ are used to produce a homogeneous output that can be consumed directly or used as capital in the production process. We will assume that the technology can be described by an aggregate production function

$$
\begin{equation*}
Y=F(K, L) \tag{1}
\end{equation*}
$$

where $Y$ is aggregate output. We will typically assume that $F()$ is a smooth and concave function that exhibits constant returns to scale and positive and decreasing marginal products $\left(F_{K}, F_{L}>0\right.$, and $F_{K K}, F_{L L}<0$ ). In most cases, we will also assume that both capital and labor are essential for production $(F(0, L)=F(K, 0)=0)$ and that the following Inada conditions hold:

$$
\begin{aligned}
& F_{K} \rightarrow 0 \quad \text { as } K \rightarrow \infty, \quad F_{K} \rightarrow \infty \quad \text { as } K \rightarrow 0, \\
& F_{L} \rightarrow 0 \quad \text { as } L \rightarrow \infty, \quad F_{L} \rightarrow \infty \quad \text { as } L \rightarrow 0
\end{aligned}
$$

We will often use as an example the Cobb-Douglas specification

$$
\begin{equation*}
Y=A K^{\alpha} L^{\beta} \tag{3}
\end{equation*}
$$

where $A$ is an index of "total factor productivity" that summarizes the current state of technical know-how. The coefficients $\alpha$ and $\beta$ measure the elasticity of output with respect to the stocks of the two factors: If the stock of capital increases by $1 \%$, holding the labor force constant, national output will increase by $\alpha \%$.

Before discussing the neoclassical specification of the production function, we need to introduce the notion of returns to scale. We will say that the production function $F()$ exhibits increasing returns to scale (in $K$ and $L$ ) if increases in the stocks of both factors in the same proportion yield a more-than-proportional increase in output, that is, if for all $\lambda>1$ we have

$$
F(\lambda K, \lambda L)>\lambda F(K, L)
$$

Similarly, $F($ ) exhibits constant returns when $F(\lambda K, \lambda L)=\lambda F(K, L)$, and decreasing returns when $F(\lambda K, \lambda L)<\lambda F(K, L)$ for all $\lambda>1$. In the case of a Cobb-Douglas function, we have

$$
F(\lambda K, \lambda L)=A(\lambda K)^{\alpha}(\lambda L)^{\beta}=\lambda^{\alpha+\beta} A K^{\alpha} L^{\beta}=\lambda^{\alpha+\beta} F(K, L)
$$

Hence, $F($ ) presents increasing returns if and only if $\alpha+\beta>1$, decreasing returns if and only if $\alpha+\beta<1$, and constant returns when $\beta=1-\alpha$.

In the simplest version of the neoclassical model, technology exhibits constant returns in $K$ and $L$. This hypothesis is usually justified in part by a replication argument: If the stocks of all inputs were to double, we could simply replicate all productive processes at the existing scale, thus ensuring that output would also double. If $K$ and $L$ are the only relevant factors, this argument implies that the technology would present nondecreasing returns, but it does not rule out, in principle, the possibility of strictly increasing returns, for we might be able to increase efficiency by expanding the scale of certain processes. The neoclassical literature, however, has tended to ignore this possibility, largely because increasing returns are difficult to reconcile with the traditional assumption of perfect competition and therefore tend to make modeling more complicated. ${ }^{6}$

The assumption of constant returns to scale turns out to be very convenient. One of the main reasons is that it allows us to write factor prices in a competitive equilibrium as simple functions of a single state variable, the capital/labor ratio in the economy. To see this, let us start by introducing a per-capita production function. Exploiting the linear homogeneity of the production function, and letting $\lambda=1 / L$, we can write

$$
\begin{aligned}
& F(K / L, 1)=(1 / L) F(K, L) \Rightarrow Y=F(K, L)=L F(K / L, 1) \\
& \quad \Rightarrow Y / L=F(K / L, 1)
\end{aligned}
$$

Thus, per-capita output is a function of the capital stock per worker. Letting $Z$ and $Q$ denote the capital stock and output per worker, respectively $(Z=K / L$ and $Q=Y / L$ ), we define the per-capita production function by

$$
\begin{equation*}
Q=f(Z) \equiv F(K / L, 1) \tag{4}
\end{equation*}
$$

The relationship between the per-capita and aggregate production functions is therefore given by

$$
F(K, L) \equiv L f(Z)=L f(K / L)
$$

Differentiating this expression with respect to $K$ and $L$, the corresponding marginal products can be written as functions of $Z$ :

$$
\begin{gathered}
F_{K}(K, L)=L f^{\prime}(Z)(1 / L)=f^{\prime}(Z) \\
F_{L}(K, L)=L f^{\prime}(Z)\left(-K / L^{2}\right)+f(Z)=f(Z)-f^{\prime}(Z) Z
\end{gathered}
$$

Finally, using the homogeneity of degree zero of the partial derivatives of $F(),{ }^{7}$ we have

$$
f^{\prime}(Z)=F_{K}(K, L)=F_{1}(K / L, 1)
$$

from where

$$
f^{\prime \prime}(Z)=F_{11}(K / L, 1)<0
$$

Thus, under the standard assumption that the marginal product of capital falls with $K$, the per-capita production function is an increasing and concave function of capital intensity.

Consider now an economy endowed with a constant-returns technology in which all agents behave competitively. Firms maximize profits, taking factor prices as given. Workers have no utility for leisure and therefore supply their entire endowment of labor time at the market-determined wage rate. The economy is always in competitive equilibrium, with full employment of labor, and factor prices are given by the corresponding marginal products.

A competitive firm hires labor at the market-determined wage $w$ and rents capital at a net rental rate $r$ - meaning that it must return to lenders $1+r$ units of output (principal plus interest) per unit of borrowed capital. If capital depreciates at a rate $\delta$, the gross rental rate of capital is $\rho=r+\delta$, and profits are given by

$$
F(K, L)-w L-\rho K
$$

Using the per-capita production function, total profits can be written as the product of profits per worker and the size of the labor force. The firm's problem,

$$
\begin{equation*}
\max _{Z, L} L[f(Z)-\rho Z-w] \tag{P}
\end{equation*}
$$

can be approached in two steps. First, $Z$ will be chosen to maximize profits per worker, yielding the necessary condition

$$
f^{\prime}(Z)=\rho
$$

which defines the optimal capital/labor ratio $Z$ as a function of the rental rate. The linearity of the objective function in $L$ implies that the optimal choice of scale depends on factor prices in a discontinuous way. If $w$ and $\rho$ are such that maximum profits per worker are negative, the optimal decision is to shut down $(L=0)$ in order to minimize losses. If profits per worker are positive, however, the thing to do is to set $L=\infty$. This choice, however, is incompatible with equilibrium. If there is free entry into the industry, new firms will come in until profits are eliminated, that is, until

$$
w=f(Z)-\rho Z=f(Z)-Z f^{\prime}(Z) \equiv w(Z)
$$

Now, with zero profits per worker, the size of individual firms is indeterminate (they are indifferent among sizes, because they earn zero profits anyway). Equilibrium factor prices, however, are easily determined. If we take as given the aggregate stock of capital $K$ and the size of the labor force $L$, then the aggregate capital/labor ratio $Z=K / L$ is determined, and because in equilibrium all firms (facing the same technology and factor prices) use inputs in the same proportion, equilibrium factor prices can be conveniently written as simple functions of $Z$ :

$$
\begin{equation*}
\rho=f^{\prime}(Z) \text { and } \quad w=w(Z)=f(Z)-Z f^{\prime}(Z) \tag{5}
\end{equation*}
$$

In some models, factor productivity increases over time as a result of technological progress. A common way to model this process is to write the production function in the form

$$
\begin{equation*}
Y_{t}=F\left(B_{t} K_{t}, A_{t} L_{t}\right) \tag{6}
\end{equation*}
$$

where $A_{t}$ and $B_{t}$ are indices of labor productivity and capital productivity. If we define $Z$ as the capital/labor ratio in "effective units,"

$$
Z=B K / A L
$$

we can proceed as before. Output per efficiency unit of labor is now given by

$$
f(Z) \equiv F(B K / A L, 1)
$$

and total output is

$$
Y=F(B K, A L)=A L f(Z)
$$

In a competitive equilibrium, the wage is

$$
w(Z)=f(Z)-Z f^{\prime}(Z)
$$

per efficiency unit of labor, or $W(Z)=A w(Z)$ per worker, and the rental rate is $f^{\prime}(Z)$ per efficiency unit, or $B f^{\prime}(Z)$ per physical unit of capital.

## (b) The Solow Model

In this section we will study a simple model of a dynamic economy developed by Solow (1956) in one of the papers that marked the beginning of modern growth theory. ${ }^{8}$

Suppose technology is described by a neoclassical production function $Y=F(K, A L)$, with constant returns to scale and labor-augmenting technical progress at a constant exogenous rate $g=\dot{A} / A$. We assume that a constant fraction $s$ of the current flow of output is invested at each point in time. If capital depreciates at a constant rate $\delta$, the evolution of the capital stock over time is described by the equation

$$
\begin{equation*}
\dot{K}=s Y-\delta K=s A L f(Z)-\delta K \tag{7}
\end{equation*}
$$

where $\dot{K}=d K / d t$ can be interpreted as the increase in the aggregate stock of capital during a period of time of infinitesimal length, and $Z=K / A L$ is the capital/labor ratio in efficiency units. Dividing both sides of (7) by $K$,

$$
\begin{equation*}
\frac{\dot{K}}{K}=s \frac{f(Z)}{Z}-\delta \tag{8}
\end{equation*}
$$

we see that the growth rate of the aggregate capital stock $(\dot{K} / K)$ is the difference between investment per unit of capital and the rate of depreciation. If investment exceeds depreciation, $K$ increases over time, and vice versa. Given that $Z=K / A L$, we can take logs of both sides of this expression,

$$
\ln Z=\ln K-\ln A-\ln L
$$

and differentiate with respect to time, obtaining

$$
\frac{\dot{Z}}{Z}=\frac{\dot{K}}{K}-\frac{\dot{L}}{L}-\frac{\dot{A}}{A}=\frac{\dot{K}}{K}-(n+g)
$$

where $\dot{L} L=n$ is the (constant) rate of population growth. That is, the rate of growth of the stock of capital per effective unit of labor is the difference between the rates of growth of the aggregate capital stock and the labor force, measured in efficiency units. Substituting (8) into the foregoing expression, we arrive at

$$
\begin{equation*}
\frac{\dot{Z}}{Z}=\frac{\dot{K}}{K}-\frac{\dot{L}}{L}-\frac{\dot{A}}{A}=\frac{s L A f(Z)-\delta K}{K}-(n+g)=s \frac{f(Z)}{Z}-(\delta+n+g) \tag{9}
\end{equation*}
$$

Equation (9) shows that, given a constant investment ratio, the rate of growth of $Z$ depends crucially on the behavior of the average product of capital $f(Z) / Z$, which is itself a function of the capital/labor ratio. What can we say about the shape of this function? Recall that $f(Z)=F(Z, 1)$, where $F($ ) is linearly homogeneous in both its arguments. Hence, for any $\lambda>1$, we have

$$
f(\lambda Z)=F(\lambda Z, 1)<F(\lambda Z, \lambda)=\lambda f(Z)
$$

whenever $F()$ is strictly increasing in its second argument. Constant returns in capital and labor imply diminishing returns in capital alone and therefore in the per-capita production function. As we combine more and more capital with a unit of labor, output increases less than proportionately. Dividing both sides of the foregoing expression by $Z$ and rearranging, we see that

$$
\frac{f(\lambda Z)}{\lambda Z}<\frac{f(Z)}{Z}
$$

for any $\lambda>1$. Hence, the average product of capital decreases with $Z$.

An important implication of this feature of the technology is that the growth rate will tend to fall as investment flows into decreasingly productive activities. Plotting both terms from the right-hand side of (9) as functions of $Z$, the rate of growth of $Z(\dot{Z} / Z)$ is given by the vertical distance between these lines, as shown in Figure 11.10. The negative slope of $s f(Z) / Z$ therefore implies that the growth rate of $Z$ (and therefore that of income per efficiency unit of labor) will be a decreasing function of capital intensity. Moreover, if the productivity of investment falls sufficiently that $s f(Z) / Z$ drops below the horizontal line $n+g+\delta$, growth (in output per efficiency unit of labor) will eventually stop. This condition will be satisfied whenever ${ }^{9}$

$$
\begin{equation*}
\lim _{Z \rightarrow \infty} \frac{f(Z)}{Z}=\lim _{Z \rightarrow \infty} f^{\prime}(Z)=f^{\prime}(\infty)<n+g+\delta \tag{10}
\end{equation*}
$$

This outcome, however, does not necessarily follow from the linear homogeneity of the aggregate production function, and thus it requires stronger assumptions. For example, if we assume a linear technology, $F(K, A L)=a K+b A L$, we have $f(Z) / Z=a+(b / Z)$, and growth will continue indefinitely, provided that $a>n+g+\delta$. Hence, constant returns per se do not rule out the possibility of sustained growth in output per efficiency unit of labor. One common assumption that does imply (10) is the Inada condition, $f^{\prime}(\infty)=0$, which implies that labor is an essential factor in production $(F(K, 0)=0)$. Observe that by the homogeneity of $F()$ we can write

$$
\frac{f(Z)}{Z}=\frac{1}{Z} F(Z, 1)=F(1,1 / Z)
$$

and taking limits,

$$
f^{\prime}(\infty)=\lim _{Z \rightarrow \infty} \frac{f(Z)}{Z}=\lim _{Z \rightarrow \infty} F(1,1 / Z)=F(1,0)
$$

In short, the problem is that labor is fixed in supply and is essential. If capital increases without bound, "labor per machine" goes to zero, driving down the productivity of capital to the point where it can no longer reproduce itself.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-527.jpg?height=633&width=734&top_left_y=192&top_left_x=369)

Figure 11.10. Dynamics of the Solow model under strongly decreasing returns.

Figure 11.10 shows the dynamics of the Solow model under the standard assumption of strongly decreasing returns implied by the Inada condition. The decreasing function $s f(Z) / Z$ intersects the horizontal line $\delta+n+g$ at the point $\bar{Z}$ that solves the equation $\dot{Z} \mid Z=0$. The negative slope of the curve also implies that $Z$ converges toward its stationary value $\bar{Z}$. As the figure shows, $\dot{Z} / Z$ is positive (i.e., $Z$ is increasing over time) when the stock of capital per worker is low (and therefore the return on investment is high), and negative when $Z$ is "high" (higher than $\bar{Z}$ ), for in this case the low return on investment implies that saving will not be enough to cover depreciation and equip newborn workers with the preexisting average stock of capital.

In the long run the system converges to a stationary equilibrium in which the capital/labor ratio $Z$ is constant. Output per worker along such a balanced-growth path is given by

$$
\begin{equation*}
\bar{Q}_{t}=A_{t} f(\bar{Z}) \tag{11}
\end{equation*}
$$

Taking logarithms of this expression, and using the fact that $A$ grows exponentially over time at a constant rate $g$ (i.e., $A_{t}=A_{0} e^{g t}$ ), we have

$$
\ln \bar{Q}_{t}=\ln \left(A_{0} f(\bar{Z})\right)+g t
$$

Hence, the time path of the system is as shown in Figure 11.11. An economy that starts out with a capital/labor ratio below its steady-state value will initially grow at a rate exceeding $g$, but will gradually approach the balancedgrowth path given by (8). Asymptotically, output per worker grows at the (exogenous) rate of technical progress, $g$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-528.jpg?height=579&width=912&top_left_y=192&top_left_x=282)

Figure 11.11. Time path of output in the Solow model.

This result has some strong implications. First, notice that in the absence of technological progress $(g=0)$, growth in per capita income eventually stops. Standard neoclassical assumptions allow for "extensive" growth: If capital and labor grow at the same rate, output will increase proportionately. However, the technological assumptions we have made severely limit the possibility of growth in income per capita, for the technology exhibits strongly decreasing returns in the only reproducible factor, $K$, whose marginal product falls to zero in the limit.

Second, the model predicts that policy changes will have only level effects. That is, changes in economic policy (or other parameters of the model) can affect the level of the path of output, but will have no effect on its long-run growth rate, which is determined only by the exogenous rate of technical progress. As an example, Figures 11.12 and 11.13 illustrate the effect of an increase in the investment ratio. A higher $s$ shifts the curve $s f(Z) / Z$ upward, yielding a higher steady-state capital/labor ratio. This, in turn, shifts the intercept of the balanced-growth trajectory upward, but does not change its slope. During the transition period, higher investment does yield a temporarily higher growth rate, but this effect disappears gradually over time as the economy approaches its new balanced-growth path. Thinking in crosssectional terms, the model implies that in the long run, countries that invest more (or have lower rates of population growth) will have higher income levels but the same growth rates as those that invest less (or have fastergrowing populations). On the other hand, countries that are similar in these respects will eventually end up with the same per capita income, even if they start out with very different endowments of capital per worker.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-529.jpg?height=707&width=738&top_left_y=189&top_left_x=376)

Figure 11.12. Effect of an increase in the investment rate on steady-state capital intensity.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-529.jpg?height=576&width=923&top_left_y=1112&top_left_x=270)

Figure 11.13. Time path of output following an increase in the investment rate.

Problem 3.1. The Solow model with a Cobb-Douglas production function. Assume that the aggregate production function is Cobb-Douglas, with laboraugmenting technical progress

$$
\begin{equation*}
Y=K^{\alpha}(A L)^{1-\alpha} \tag{1}
\end{equation*}
$$

with $\dot{A} / A=g$. Write the intensive-production function $f(Z)$, giving output per efficiency unit of labor as a function of the capital/labor ratio in effi-
ciency units, $Z=K / A L$. Derive the law of motion for $Z$ under Solow's assumptions, and solve explicitly for the steady state of the system. What factors determine a country's long-term level of income?

Problem 3.2. Suppose the production function is of the form (1): $Y_{t}=$ $\left(B_{t} K_{t}\right)^{\alpha}\left(A_{t} L_{t}\right)^{1-\alpha}$, with both capital- and labor-augmenting technical progress at rates $\dot{B} / B=g_{B}$ and $\dot{A} / A=g_{A}$. Derive the equation of motion for the capital/labor ratio in effective units, $Z=B K / A L$, under the assumptions of the Solow model. Show that the system has a balanced-growth path (i.e., a constant- $Z$ solution) if and only if $g_{B}=0$ (i.e., if technical progress is only labor-augmenting).

## (c) An Overlapping-Generations Model (Diamond)

Although Solow's model is extremely simple, at the time it was written it brought real progress. The reason is that, unlike static formulations of the Keynesian type, it explicitly brought out the role of investment in increasing the economy's productive capacity and highlighted the trade-off between present consumption and future consumption. One obvious limitation of the model, however, is its assumption of an exogenous savings rate. Back in the 1950s, that was seen as a perfectly reasonable simplification. Since then, however, economists have come to insist that the behavior of agents should be derived from some sort of optimization problem. To remedy this shortcoming, the Solow-Swan model was soon extended by authors who derived savings behavior from the maximization of lifetime utility. Two specifications have become standard in the literature. The main difference between them is their demographic structure. One of them, first developed by Cass (1965) and Koopmans (1965), building on earlier work by Ramsey (1928), features a representative household that lives forever; the other, due to Diamond (1965), assumes, rather more sensibly, finite lifetimes. In this section we will study the second of these models, which is simpler in some ways, leaving the Cass-Koopmans model for a later chapter.

An interesting feature of the Diamond (1965) model is its demographic structure. The economy is populated by successive generations of finitelylived workers. In the simplest version of the model, agents live for two periods and "have children" at the end of the first one. At any given point in time, then, members of two generations coexist on the earth (hence the name overlapping generations) and interact with each other and with firms through competitive markets for labor and output/capital. Young agents sell their labor, eat part of the proceeds, and save the rest for old age by lending unconsumed output to firms for use as capital in the next period's production. Old individuals do not work, but simply consume their savings, includ-
ing interest earnings. Firms hire labor and borrow capital to produce output using a constant-returns-to-scale production technology.

## (i) Household Behavior

The utility of an agent born in period $t$ (belonging to the $t$ th generation) is an increasing function of consumption in the first and second periods of his life ( $c$ and $x$, respectively):

$$
\begin{equation*}
U_{t}=U\left(c_{t}, x_{t+1}\right) \tag{1}
\end{equation*}
$$

We will assume that $U$ is strictly increasing in both arguments, smooth, and strictly quasiconcave. Having no taste for leisure, households sell their entire endowment of labor time (one unit in youth) in the labor market in exchange for a real wage of $w_{t}$ units of output. Part of this income goes to current consumption, $c_{t}$, and the rest $\left(s_{t}\right)$ is lent to firms for use as capital in next period's production at an interest rate $r_{t+1}$. Old agents, therefore, have a total wealth of $s_{t} R_{t+1}=s_{t}\left(1+r_{t+1}\right)$ units of output and, not caring about their children, consume all of it.

Households, then, maximize (1) subject to the constraints

$$
w_{t}=c_{t}+s_{t} \quad \text { and } \quad s_{t} R_{t+1}=x_{t+1}
$$

For future reference, it will be convenient to study a slightly more general version of this problem. We will allow for the possibility that agents may have some income in the second period of their lives and solve

$$
\begin{equation*}
\max _{c, x}\left\{U(c, x) \text { s.t. } y_{1}=c+s \text { and } x=y_{2}+s R\right\} \tag{P}
\end{equation*}
$$

where $y_{1}$ and $y_{2}$ denote first- and second-period incomes, respectively. We will make the following assumptions:

$$
\begin{gather*}
U_{c}, U_{x}>0  \tag{A.1}\\
U_{c c}, U_{x x}<0 \text { and } U_{c x}=U_{x c} \geq 0  \tag{A.2}\\
U_{c}(c, x) \rightarrow \infty \quad \text { as } c \rightarrow 0 \text { and } U_{x}(c, x) \rightarrow \infty \quad \text { as } x \rightarrow 0 \tag{A.3}
\end{gather*}
$$

Assumption (A.2) is plausible and allows us easily to sign certain partial derivatives of interest. We will show later that it can be replaced by the assumption that consumption is a normal good in both periods. The third assumption is made to avoid the possibility of corner solutions. Because the marginal utility of consumption in either period goes to infinity as consumption approaches zero, agents will consume positive amounts in both periods whenever they have any income at all. Hence, the natural nonnegativity constraints on $c$ and $x$ will not be binding at an optimum and can be ignored in the formulation of the problem.

Substituting the constraints into the utility function $U()$, we can rewrite (P) as

$$
\max U\left(y_{1}-s, y_{2}+s R\right)
$$

Differentiating $U$ with respect to $s$, we obtain the first-order condition

$$
\begin{equation*}
\frac{\partial U}{\partial s}=U_{c}\left(y_{1}-s, y_{2}+s R\right)(-1)+U_{x}\left(y_{1}-s, y_{2}+s R\right) R=0 \Rightarrow R=\frac{U_{c}(c, x)}{U_{x}(c, x)} \tag{2}
\end{equation*}
$$

As usual, the agent sets the marginal rate of substitution between present consumption and future consumption (i.e., the rate at which he would be willing to trade present consumption for future consumption) equal to the rate at which he can do so, which is given by the interest factor. Because $U$ is a concave function of $s$, equation (2) does characterize an optimum.

The solution to this problem gives us the optimal level of savings as a function of first- and second-period incomes and the interest factor, that is, a savings function of the form

$$
s^{*}=s\left(y_{1}, y_{2}, R\right)
$$

which conveniently describes the optimal behavior of the household. The following proposition summarizes the properties of the function $s()$.

Proposition 3.3. Properties of the savings function. Consider the function

$$
\mathrm{s}\left(\mathrm{y}_{1}, \mathrm{y}_{2}, \mathrm{R}\right)=\arg \max _{\mathrm{s}} \mathrm{U}\left(\mathrm{y}_{1}-\mathrm{s}, \mathrm{y}_{2}+\mathrm{s} \mathrm{R}\right)
$$

Under the assumption that (i) first- and second-period consumptions are normal goods (i.e., the demand for them is increasing in income), or (ii) $\mathrm{U}_{\mathrm{co}}$ $\mathrm{U}_{\mathrm{xx}}<0$ and $\mathrm{U}_{\mathrm{cx}} \geq 0$, we have that

$$
\frac{\partial \mathrm{s}^{*}}{\partial \mathrm{y}_{1}} \in(0,1), \frac{\partial \mathrm{s}^{*}}{\partial \mathrm{y}_{2}}<0, \text { and } \frac{\partial \mathrm{s}^{*}}{\partial \mathrm{R}}>0 \text { for } \mathrm{s}^{*} \leq 0
$$

If, in addition, $\mathrm{c}$ and $\mathrm{x}$ are strict substitutes (i.e., if an increase in the relative price of one, measured by the interest factor, leads to an increase in the demand for the other), then

$$
\frac{\partial s^{*}}{\partial R}>0
$$

also for net savers ( $\mathrm{s}>0$ ).

Problem 3.4. Prove Proposition 3.3.

To conclude, note that the problem faced by a worker in Diamond's model is exactly the one in the proposition, with

$$
y_{1}=w_{t}, \quad y_{2}=0, \quad \text { and } \quad R=R_{t+1}
$$

Hence, we can write the savings function

$$
s^{*}=s\left(w_{t}, R_{t+1}\right)
$$

and under the assumptions of Proposition 3.3 we can sign the partial derivatives $s_{W}()$ and $s_{R}()$.

## (ii) Equilibrium and Dynamics

We will assume that population grows at a constant rate $n$ (i.e., $L_{t+1}=$ $\left.(1+n) L_{t}\right)$ and that capital depreciates at a rate $\delta$. Each period young agents sell their labor, eat part of the proceeds, and lend the remainder to firms. Older workers simply consume their savings. Firms are of the standard neoclassical variety. In equilibrium, factor prices are equal to their marginal products, and factor markets clear. Hence (see Section 3(a)),

$$
\begin{gathered}
w_{t}=w\left(Z_{t}\right)=f\left(Z_{t}\right)-Z_{t} f^{\prime}\left(Z_{t}\right) \quad \text { and } \\
R_{t+1}=1+r_{t+1}=1+\rho_{t+1}-\delta=f^{\prime}\left(Z_{t+1}\right)+(1-\delta)
\end{gathered}
$$

Labor-market clearing means simply that all young workers are employed. Capital-market clearing requires that next period's capital stock be equal to current savings by the young: ${ }^{10}$

$$
\begin{equation*}
K_{t+1}=L_{t} s_{t} \tag{3}
\end{equation*}
$$

Dividing both sides of this expression by $L_{t+1}=(1+n) L_{t}$, and letting $Z=K / L$, we have ${ }^{11}$

$$
\begin{align*}
& \frac{K_{t+1}}{L_{t+1}}=\frac{L_{t} s_{t}}{(1+n) L_{t}} \\
& \quad \Rightarrow(1+n) Z_{t+1}=s_{t} \tag{4}
\end{align*}
$$

Substituting the savings function, evaluated at equilibrium factor prices, into (4), we arrive finally at

$$
\begin{equation*}
(1+n) Z_{t+1}=s\left[w\left(Z_{t}\right), f^{\prime}\left(Z_{t+1}\right)+(1-\delta)\right] \tag{5}
\end{equation*}
$$

To simplify the exposition somewhat, in the remainder of this section we will assume that the population is constant $(n=0)$ and that capital depreciates completely upon use $(\delta=1)$. With these assumptions, equation (5) reduces to

$$
\begin{equation*}
Z_{t+1}=s\left[w\left(Z_{t}\right), f^{\prime}\left(Z_{t+1}\right)\right] \tag{6}
\end{equation*}
$$

Equation (6) implicitly defines a function of the form $Z_{t+1}=\phi\left(Z_{t}\right)$, that is, a first-order difference equation (notice that $Z_{t+1}$ appears on both sides of this expression).

Without knowing the specific forms of $U()$ and $f()$ we cannot solve for $\phi($ ) explicitly, but we can get some qualitative information about it. We are particularly interested in two questions. The first has to do with the existence of steady states for the dynamical system described by (6). Second, if steady states exist, we would like to determine under what conditions they are stable. To answer these questions, we need some information about the properties of $\phi($ ). Steady states of the system are just fixed points of $\phi$, and their stability depends on the value of $\phi^{\prime}(Z)$.

Differentiating (6) implicitly with respect to $Z_{t}$, we obtain the slope of the phase line, $\phi^{\prime}\left(Z_{t}\right)=d Z_{t+1} / d Z_{t}$ :

$$
\begin{align*}
& \frac{d Z_{t+1}}{d Z_{t}}=s_{w}() w^{\prime}\left(Z_{t}\right)+s_{R}() f^{\prime \prime}\left(Z_{t+1}\right) \frac{d Z_{t+1}}{d Z_{t}} \\
& \quad \Rightarrow \phi^{\prime}\left(Z_{t}\right)=\frac{d Z_{t+1}}{d Z_{t}}=\frac{s_{W}() w^{\prime}\left(Z_{t}\right)}{1-s_{R}() f^{\prime \prime}\left(Z_{t+1}\right)} \tag{7}
\end{align*}
$$

Notice that the denominator of this expression is always positive. Because $f^{\prime}()<0$, the whole expression will be positive provided that $s_{R}()>0$ or $s_{R}()<0$ and is "small" in absolute value. To determine whether or not a given steady state $\bar{Z}$ is stable, we only have to check whether or $\left|\phi^{\prime}(\bar{Z})\right|$ is smaller than 1. There is, however, no guarantee of stability, or even of the existence of any interior steady states.

The function $\phi()$ summarizes the effect of the capital stock on savings, as mediated by both preferences and technology through separate interest and wage channels. Standard assumptions are not sufficient to ensure that (6) will be as well-behaved as the Solow model we analyzed in the preceding section. They are, however, sufficient to show that $\phi(0)=0$ and $\phi(Z)<Z$ for sufficiently large $Z$. Hence, $\phi()$ goes through the origin and eventually falls below the $45^{\circ}$ line, making indefinitely sustained growth impossible. The origin is always a steady state, but the system may have no interior steady states, or any odd number of them, with alternating stability properties, as suggested in Figure 11.14.

Clearly, a sufficient condition for the existence of a nontrivial steady state is that $\phi^{\prime}(0)>1$, and a sufficient condition for uniqueness is that, in addition, $\phi($ ) be concave. The following proposition summarizes the key properties of the model.

Proposition 3.5. Existence of steady states in the Diamond model. Assume that the intensive production function $\mathrm{f}()$ is concave, with $\mathrm{f}(0)=0$ and

$$
\mathrm{f}^{\prime}(\mathrm{Z}) \rightarrow 0 \quad \text { as } \mathrm{Z} \rightarrow \infty \quad \text { and } \quad \mathrm{f}^{\prime}(\mathrm{Z}) \rightarrow \infty \quad \text { as } \mathrm{Z} \rightarrow 0
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-535.jpg?height=428&width=1200&top_left_y=191&top_left_x=138)

Figure 11.14. Possible phase diagrams for the Diamond model.

Then $\phi(0)=0$, and for $Z_{\mathrm{t}}$ sufficiently large, $\mathrm{Z}_{\mathrm{t}+1} / \mathrm{Z}_{\mathrm{t}}=\phi\left(\mathrm{Z}_{\mathrm{t}}\right) / \mathrm{Z}_{\mathrm{t}}<1$. Hence, 0 is always a steady state of the system, and indefinite growth is not possible. Moreover, if

$$
\lim _{Z \rightarrow 0} \phi^{\prime}(Z)>1
$$

then there exists at least one additional steady state with $Z>0$. If this last condition is satisfied and $\phi$ is increasing and concave, there is a unique nontrivial and globally stable steady state. ${ }^{12}$

## Proof

- First, we note that $Z=0$ is always a steady state for the system, that is, $\phi(0)=0$. With zero capital, no production is possible $(f(0)=0)$, and hence $w(0)=0$. With zero wages, no savings are possible $[s(0, R)=0]$, and therefore there can be no capital accumulation.
- Next, we show that $\left(Z_{t+1} / Z_{t}\right) \rightarrow 0$ as $Z_{t} \rightarrow \infty$. It follows that for sufficiently large $Z$ we have $Z_{t+1} / Z_{t}=\phi\left(Z_{t}\right) / Z_{t}<1 \Rightarrow Z_{t+1}=\phi\left(Z_{t}\right)<Z_{t}$, and hence the graph of $\phi$ is below the $45^{\circ}$ line. This implies that capital accumulation cannot continue forever, for if $Z$ is large enough, it must be decreasing.

To derive this result, note that

$$
0 \leq \frac{Z_{t+1}}{Z_{t}}=\frac{s\left(w_{t}, R_{t+1}\right)}{Z_{t}} \leq \frac{w\left(Z_{t}\right)}{Z_{t}}=\frac{f\left(Z_{t}\right)}{Z_{t}}-f^{\prime}\left(Z_{t}\right) \leq \frac{f\left(Z_{t}\right)}{Z_{t}}
$$

Taking limits as $Z \rightarrow \infty$, we have, by L'Hôpital's rule,

$$
0 \leq \lim _{Z \rightarrow \infty} \frac{Z_{t+1}}{Z_{t}} \leq \lim _{Z \rightarrow \infty} \frac{f\left(Z_{t}\right)}{Z_{t}}=\lim _{Z \rightarrow \infty} f^{\prime}(Z)=0
$$

whenever $f()$ is unbounded; otherwise, we can omit the penultimate term in the foregoing expression, and the inequalities will still hold.

- The function $\phi$, then, goes through the origin and is below the $45^{\circ}$ line for $Z$ large enough. Clearly, whether or not additional steady states (with $Z>0$ ) exist will depend on the slope of $\phi$ at the origin. There are two possibilities: If the slope of
$\phi$ is greater than 1 at the origin, then $\phi$ starts above the $45^{\circ}$ line; because it must eventually end up below it, continuity implies that it must cross it an odd number of times, and at least one additional steady state exists. On the other hand, if $\phi$ starts below the $45^{\circ}$ line, we will have an even number of such equilibria, possibly zero. Note that because $\phi(0)=0$,

$$
\lim _{Z \rightarrow 0} \phi^{\prime}(Z)=\lim _{Z \rightarrow 0} \frac{\phi(Z)}{Z} \leq \lim _{Z \rightarrow 0} \frac{w(Z)}{Z}=\lim _{Z \rightarrow 0} w^{\prime}(Z)
$$

so a necessary condition for $\phi^{\prime}(0)>1$ is $w^{\prime}(0)>1$. The last part of the proposition is obvious.

Example 3.6. Cobb-Douglas technology and log preferences. Assume that the population grows at a constant rate $n$, and the production and utility functions are of the form

$$
\begin{gather*}
U(c, x)=\beta \ln c+(1-\beta) \ln x, \quad \text { where } \beta \in(0,1)  \tag{U}\\
F(K, L)=K^{\alpha} L^{1-\alpha}, \quad \text { where } \alpha \in(0,1) \tag{P}
\end{gather*}
$$

Under these assumptions we have

$$
w=(1-\alpha) Z^{\alpha}, \quad R=\alpha Z^{\alpha-1}, \quad \text { and } \quad s(w, R)=(1-\beta) w
$$

and the law of motion for the stock of capital per worker is given by

$$
\begin{align*}
& (1+n) Z_{t+1}=(1-\beta)(1-\alpha) Z_{t}^{\alpha} \\
& \quad \Rightarrow Z_{t+1}=\phi\left(Z_{t}\right)=\frac{(1-\beta)(1-\alpha)}{(1+n)} Z_{t}^{\alpha} \tag{L.Z}
\end{align*}
$$

Note that

$$
\begin{aligned}
& \phi^{\prime}\left(Z_{t}\right)=\frac{(1-\beta)(1-\alpha)}{(1+n)} \alpha Z_{t}^{\alpha-1}>0 \text { and } \\
& \phi^{\prime \prime}\left(Z_{t}\right)=\frac{(1-\beta)(1-\alpha)}{(1+n)} \alpha(\alpha-1) Z_{t}^{\alpha-2}<0
\end{aligned}
$$

Thus, the phase line goes through the origin and is monotonically increasing and strictly concave. Notice also that $\phi^{\prime}(Z) \rightarrow \infty$ as $Z \rightarrow 0$, and $\phi^{\prime}(Z) \rightarrow 0$ as $Z \rightarrow \infty$. Hence, the phase line $\phi()$ starts out above the $45^{\circ}$ line, but eventually becomes flatter and must therefore eventually go below it. This implies the existence of an interior steady state, $\bar{Z}>0$. In fact, we can solve for $\bar{Z}$ explicitly. Eliminating the time subscripts in (L.Z),

$$
\phi(Z)=Z \Rightarrow Z=\frac{(1-\beta)(1-\alpha)}{(1+n)} Z^{\alpha}
$$

which holds for $Z=0$. For $Z \neq 0$, we can divide through by $Z^{\alpha}$ to get

$$
Z^{1-\alpha}=\frac{(1-\beta)(1-\alpha)}{(1+n)} \Rightarrow \bar{Z}=\left(\frac{(1-\beta)(1-\alpha)}{(1+n)}\right)^{1 /(1-\alpha)}>0
$$

Because $\phi^{\prime}(0)>1$, the steady state at the origin is an unstable node. To check the stability of $\bar{Z}$, note that

$$
\phi^{\prime}(\bar{Z})=\frac{(1-\beta)(1-\alpha)}{(1+n)} \alpha \bar{Z}^{\alpha-1}=\frac{(1-\beta)(1-\alpha)}{(1+n)} \alpha\left(\frac{(1-\beta)(1-\alpha)}{(1+n)}\right)^{-1}=\alpha \in(0,1)
$$

so the interior steady state is a stable node.

## 4. Some Useful Techniques

Nonlinear differential equations often lack closed-form solutions. Whereas it is often possible to analyze the qualitative behavior of such systems, it is more difficult to get accurate quantitative predictions by analytical methods. As we will see in the first part of this section, one possibility is to linearize the system around a steady state and work with the linearized model. The resulting approximation, although valid only locally (in a neighborhood of a steady state), is often quite useful, both in theoretical studies and in empirical work. An alternative, which also allows us to deal with systems whose behavior is difficult to characterize with analytical methods, is to use a computer package to solve the system numerically. In the second part of this section we will solve the Solow model using Mathematica. In Chapter 13 we will see how to deal with more complicated systems.

## (a) Linearization and Derivation of a Convergence Equation

We have seen that in the Solow model the growth rate of the stock of capital per efficiency unit of labor is given by

$$
\begin{equation*}
\frac{\dot{Z}}{Z}=\frac{\dot{K}}{K}-\frac{\dot{L}}{L}-\frac{\dot{A}}{A}=s \frac{f(Z)}{Z}-(\delta+n+g) \tag{1}
\end{equation*}
$$

where $Z=K / A L$. If all countries have access to the same technology (i.e., if $A$ is the same for all of them) and all share the same rates of depreciation $(\delta)$ and technical progress $(g)$, and if the production function exhibits decreasing returns to capital, this equation implies that the rate of capital accumulation per worker (and therefore the rate of growth of income per capita, $Q$ ) will be a decreasing function of $Z$ (and hence of $Q$ ) and population growth $(n)$, and an increasing function of the investment rate $(s)$.

To test these hypotheses, we can try to estimate equation (1), after assuming some specific functional form for the production function. As it stands, however, this equation is not very suitable for empirical work. The main difficulty is that it is written in terms of a variable (the stock of capital per efficiency unit of labor) for which we do not have very good data. ${ }^{13}$ In this section we will construct an approximation to (1) that will be useful in empir-
ical work, following the procedure developed by Barro and Sala-i-Martin (1990) and Mankiw, Romer, and Weil (1992). The equation we will obtain can be seen as a reduced form of the Solow model, or simply as a convenient way of estimating the production function using flow data.

Suppose the production function is Cobb-Douglas. Then equation (1) becomes

$$
\begin{equation*}
\frac{\dot{Z}}{Z}=s Z^{\alpha-1}-(\delta+n+g) \tag{2}
\end{equation*}
$$

To construct a suitable approximation to this equation, we start by introducing a new variable,

$$
z=\ln Z
$$

and observing that

$$
\dot{z}=\frac{\dot{Z}}{Z} \quad \text { and } \quad Z=e^{z}
$$

Hence, we can rewrite (1) in the form

$$
\begin{equation*}
\dot{z}=s e^{z(\alpha-1)}-(\delta+g+n) \equiv \phi(z) \tag{3}
\end{equation*}
$$

Notice that the steady-state value of $z$ satisfies

$$
\begin{align*}
s e^{z(\alpha-1)} & =(\delta+g+n) \\
\Rightarrow \bar{z} & =\frac{1}{1-\alpha} \ln \frac{s}{\delta+g+n} \tag{4}
\end{align*}
$$

and the derivative of $\phi()$ at the steady state is given by

$$
\phi^{\prime}(\bar{z})=(\alpha-1) s e^{z(\alpha-1)}=-(1-\alpha)(\delta+g+n)<0
$$

Hence, the log-linearized system

$$
\begin{equation*}
\dot{z}=-\lambda(z-\bar{z}), \quad \text { where } \lambda=(1-\alpha)(\delta+g+n) \tag{5}
\end{equation*}
$$

is stable, like the original one, provided that $\alpha<1$ (see Problem 3.1).

Because equation (5) is a first-order linear differential equation, we can write its solution immediately. If we consider the period from $t$ to $t+h$, the final value of $z\left(z_{t+h}\right)$ is given by a weighted average of its initial $\left(z_{t}\right)$ and stationary ( $\bar{z}$ ) values, with weights determined by the coefficient $\lambda$ and the duration of the period $h$ :

$$
\begin{equation*}
z_{t+h}=\bar{z}+\left(z_{t}-\bar{z}\right) e^{-\lambda h}=z_{t} e^{-\lambda h}+\bar{z}\left(1-e^{-\lambda h}\right) \tag{6}
\end{equation*}
$$

Equation (6) implies a relationship between the rate of income growth over the period and its initial level, as well as other variables. To make this relation explicit, recall that output per worker is given by $Q=A Z^{\alpha}$. Taking logarithms of both sides of this expression,

$$
\begin{equation*}
q=a+\alpha z \Rightarrow \alpha z=q-a \tag{7}
\end{equation*}
$$

and substituting (6) into (7) evaluated at time $t+h$,

$$
q_{t+h}=a_{t+h}+\alpha z_{t+h}=a_{t+h}+\left(q_{t}-a_{t}\right) e^{-\lambda h}+\left(1-e^{-\lambda h}\right) \alpha \bar{z}
$$

Subtracting initial income $q_{t}$ from both sides, dividing through by $h$, and using the fact that $a_{t+h}=a_{t}+g h$, we obtain

$$
\begin{align*}
\frac{q_{t+h}-q_{t}}{h} & =g+\frac{1-e^{-\lambda h}}{h}\left[\alpha \bar{z}-\left(q_{t}-a_{t}\right)\right] \\
& =g+\frac{1-e^{-\lambda h}}{h}\left(\frac{\alpha}{1-\alpha} \ln \frac{s}{\delta+g+n}-\left(q_{t}-a_{t}\right)\right) \tag{8}
\end{align*}
$$

This convergence equation relates the growth of per-capita income over the period to the initial level of income per capita, the determinants of the steady state, the rate of technical progress, and the inital value of the technological index. In particular, equation (8) tells us that the rate of growth over a given period is equal to the rate of technical progress, $g$, plus a transitional factor that depends on the difference between current output per efficiency unit of labor $(q-a)$ and the steady-state value of this variable, $\alpha \bar{z}$. For a given value of the steady state, the transitional component of growth decreases with initial income and increases with $a$, because technical progress reduces the stock of capital per efficiency unit of labor.

The empirical implementation of equation (8) does not raise any special difficulties. Given time-series data on output per capita or per worker, investment, and population or labor-force growth, the equation can be estimated using cross-section or panel data at the national or regional level. This specification allows us to estimate the rate of convergence and to recover (given values for some parameters) the coefficient of capital in the production function. ${ }^{14}$

Problem 4.1. Measuring the speed of convergence. The "eigenvalue" $\lambda$ of the log-linearized system provides a measure of the speed of convergence of an economy toward its steady state. Show that the half-life of the system described by equation (5) (defined as the time $H$ at which half the original deviation of $z$ from its steady-state value has been eliminated $)^{15}$ is given by

$$
H=\frac{\ln 2}{\lambda}
$$

Notice that $H$ is inversely proportional to $\lambda$.

Problem 4.2. Determinants of long-run income dispersion. Assume that the evolution of income per capita in a given country can be described by the equation

$$
\begin{equation*}
y_{i, t+1}=x_{i}+(1-\beta) y_{i, t}+\varepsilon_{i t} \quad \text { or } \quad \Delta y_{i, t}=x_{i}-\beta y_{i, t}+\varepsilon_{i t} \tag{1}
\end{equation*}
$$

where $y_{i, t}=\ln \left(Q_{i t} / Q_{t}\right)$ denotes the logarithm of income per capita in country $i$ in period $t\left(Q_{i t}\right)$ normalized by the sample mean of the same variable $\left(Q_{t}\right)$, and $\Delta y_{i, t}=y_{i, t+1}-y_{i, t}$ is approximately equal to the growth rate of per-capita income in country $i$, measured in deviations from the average growth rate in the sample. In this expression, $\varepsilon_{i t}$ is a random disturbance, with zero mean and variance, $\sigma_{\varepsilon}^{2}$, independent and identically distributed over time and across countries and uncorrelated with $y_{i, t}$ and $x_{i}$. The term $x_{i}$, which summarizes the "fundamental" determinants of growth in territory $i$, is constant over time and is distributed across countries, with zero mean and variance $\sigma_{x}^{2}$. (This equation can be interpreted as a linear approximation to the convergence equation we have just derived, with $x_{i}$ summarizing the effect of the rates of investment and population growth in country $i$.)

Taking the expected values for both sides of (1), given initial income $y_{i, 0}$, we obtain a nonstochastic equation in expected income $y_{i, t}^{e}$ :

$$
\begin{equation*}
y_{i, t+1}^{e}=x_{i}+(1-\beta) y_{i, t}^{e}, \quad \text { with } y_{i, 0}^{e}=y_{i, 0} \tag{2}
\end{equation*}
$$

The solution of (2) is of the form

$$
\begin{equation*}
y_{i, t}^{e}=y_{i}^{*}+\left(y_{i, 0}-y_{i}^{*}\right)(1-\beta)^{t} \tag{3}
\end{equation*}
$$

where

$$
y_{i}^{*}=\frac{x_{i}}{\beta}
$$

is the steady-state value of $y_{i t}$. Equation (3) shows that the stability of the system depends on the value of the slope coefficient $\beta$. If $\beta \in(0,1)$, the term $(1-\beta)^{t}$ goes to zero as $t \rightarrow \infty$. The system is therefore stable, and the expected income for each nation converges monotonically to its steady state $y_{i}^{*}$ at a rate determined by $\beta$. Hence, we can interpret $y_{i}^{*}$ as the expected (relative) income level of country $i$ in a long-run equilibrium.

We want to use equation (1) to investigate the determinants of income inequality across countries in the long run. Let $\sigma_{t}^{2}$ denote the sample variance of $y_{i t}$, and $c_{t}=E x_{i} y_{i t}$ the covariance between current income and country fundamentals, and observe that if the number of countries is large, the sample variance and covariance will be approximately equal to their population values. Using (1), derive a system of difference equations in $\sigma_{t}^{2}$ and $c_{t}$, discuss its stability properties, and compute its steady state. What determines the degree of income inequality in the long run, measured by the steadystate value of $\sigma_{t}^{2}$ ?

Hint: Take the variance for both sides of (1), and notice that $c_{t+1}=E x_{i} y_{i, t+1}$.

## (b) Solving the Solow Model with Mathematica

It is easy to see that the law of motion for the capital/labor ratio in the Solow model with a Cobb-Douglas production function is given by

$$
\dot{Z}=s Z^{\alpha}-(\delta+n+g) Z
$$

(see Problem 3.1). This equation is a nonlinear differential equation that does not have a closed-form solution. In this section we will show how equations such as this one can be solved numerically using Mathematica, a computer program that has a built-in routine for such computations.

Because Mathematica does not have Greek letters, we will start by rewriting our equation in the form

$$
\begin{equation*}
\dot{Z}=F(z, s, a, d, g, n)=s z^{a}-(d+n+g) z \tag{9}
\end{equation*}
$$

The first step is to define the function $F($ ). For this, we type (the text in boldface letters is what we type in; the stuff in italics is the computer's output):

$$
\begin{aligned}
& \operatorname{In}[1]:= \\
& \quad F\left[z_{-}, s_{-}, a_{-}, d_{-}, g_{-}, n_{-}\right]:=s^{*}\left(z^{\wedge} a\right)-(d+g+n) * z
\end{aligned}
$$

followed by "enter" or "shift-return." (A normal "return" puts you on a new line, but it does not tell the computer to execute the command.) This tells the computer to define a function called $\mathbf{F}$ with the arguments specified inside the square brackets. Notice that each argument is followed by the symbol ".", arguments are separated by commas, and the definition of the function must be preceded by the symbol ":=".

Next, we assign values to the parameters and compute the steady-state value of $z$ using the formula

$$
\bar{Z}=\left(\frac{s}{\delta+n+g}\right)^{1 /(1-\alpha)}
$$

derived in Problem 3.1. In order to illustrate how the value of $\alpha(a)$ affects the speed of convergence to the steady state, we will repeat the exercise with two different values of $a(\mathbf{a}=0.69$ and $\mathbf{a 2}=0.33)$. Notice that we use "=" to assign values to parameters. The program returns the steady states corresponding to the two values of $a$. (To prevent the computer from repeating all the parameter values, we use a semicolon at the end of each line.)

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-541.jpg?height=296&width=676&top_left_y=1922&top_left_x=393)

Out [5]=

99.8432

Out $[6]=$

8.41507

The next statement asks the computer to solve equation (9) numerically, together with an initial condition which specifies that the initial value of $z$ is equal to one-half the corresponding steady state. Notice that a separate statement is needed to compute the solution for each set of parameter values. Prior to executing NDSolve, we must assign values to all the parameters ${ }^{16}$ so that the only unspecified argument of $F()$ is the variable whose time path we seek $(z)$. We must also specify that this variable is a function of time by writing it $\mathbf{z}[\mathbf{t}]$ (or $\mathbf{z}[\mathbf{s}] \ldots$....) on both sides of the equation, which are separated by two equal signs $(==)$. The list of equations to be solved goes inside curly brackets separated by commas (the initial condition is also considered an equation). After the list of equations, we specify that the "unknown" is $z$, and then (also in curly brackets) we indicate that the dependent variable (i.e., "time") is $t$ and that we want the solution evaluated for all $t$ between 0 and 100. Finally, the first side of each statement assigns a name (sol1 and sol2) to each "solution function."

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-542.jpg?height=444&width=1056&top_left_y=1134&top_left_x=208)

Out[7] and Out[8] inform us that the commands have been executed successfully (otherwise you will get an error message) and the solution path of $z$ has been placed into what Mathematica calls InterpolatingFunctions. The next step is to put the solution functions in a usable form. For this, we evaluate the generic solution function $\mathbf{z}[\mathbf{t}]$ using each of the solution rules (sol1 and sol2) to obtain two new functions, pz1[t] and pz2[t], that can be manipulated as ordinary functions.

$$
\begin{aligned}
& \operatorname{In}[9]:= \\
& \operatorname{pz1}\left[t \_\right]:=z[t] / \text { sol1 } \\
& \operatorname{pz2}\left[t_{-}\right]:=z[t] / . \text { sol2 }
\end{aligned}
$$

Finally, we can use the Plot command to display the time path of $z$. The following statement asks Mathematica to plot pz1[t] and (the
constant) zs1 as functions of $t$, with this variable taking values between 0 and 100 .

$$
\begin{aligned}
& \operatorname{In}[11]:= \\
& \quad \text { Plot }[\{p z 1[t], \mathbf{z s 1}\},\{t, 0,100\}]
\end{aligned}
$$

$$
\operatorname{Out}[11]=
$$

-Graphics-

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-543.jpg?height=551&width=921&top_left_y=517&top_left_x=269)

In[12] repeats the experiment with the lower value of $\alpha$. Notice that in this case convergence toward the steady state is much faster.

$$
\begin{aligned}
& \text { In }[12]:= \\
& \quad \operatorname{Plot}[\{\mathbf{p z 2}[t], \mathbf{z s 2}\},\{t, \mathbf{0}, 100\}]
\end{aligned}
$$

Out $[12]=$

-Graphics-

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-543.jpg?height=538&width=943&top_left_y=1464&top_left_x=262)

## 5. Problems

Problem 5.1. Homogeneous output is produced using two types of capital (private and public), $K$ and $P$, according to a technology of the form

$$
\begin{equation*}
Y_{t}=K_{t}^{\alpha} P_{t}^{\beta} \quad \text { where } \alpha+\beta<1 \tag{1}
\end{equation*}
$$

Both types of capital depreciate completely upon use. In each period, the government taxes income at a rate $\tau$ and invests the proceeds in public capital for the next period. Agents save a fixed fraction $s$ of their after-tax income and invest it in private capital. Hence,

$$
\begin{equation*}
K_{t+1}=s(1-\tau) Y_{t} \tag{2}
\end{equation*}
$$

and

$$
\begin{equation*}
P_{t+1}=\tau Y_{t} \tag{3}
\end{equation*}
$$

Using (1)-(3), derive a single difference equation in $Y$ that describes the evolution of income. Call this equation (4). Solve for the steady-state value of $Y$, and show that the system is stable. How does steady-state income vary with $s$ and $\tau$ ? What value of $\tau$ should the government choose if it wants to maximize steady-state output?

Problem 5.2. Consider an economy endowed with an aggregate production function of the form

$$
\begin{equation*}
Y=K^{\alpha}(L H)^{1-\alpha} \tag{1}
\end{equation*}
$$

where $K$ is the aggregate stock of physical capital, $L$ is employment in goods production, and $H$ is the average stock of human capital. "Pure knowledge," $A$, increases over time at a constant exogenous rate $g$, that is,

$$
\begin{equation*}
A_{t+1}=(1+g) A_{t} \tag{2}
\end{equation*}
$$

Pure knowledge and teacher's time and human capital are combined to "produce" the next generation's human capital according to

$$
\begin{equation*}
H_{t+1}=\left(\tau H_{t}\right)^{\gamma} A_{t}^{1-\gamma} \tag{3}
\end{equation*}
$$

where $\tau$ is the fraction of the population employed as teachers, a variable chosen by the government.

Suppose that population is constant, and normalize it to 1 (so that the labor force is $L=1-\tau$ ), and suppose that capital depreciates completely upon use and that agents save a constant fraction $s$ of their income. Then the law of motion for the capital stock is of the form

$$
\begin{equation*}
K_{t+1}=s K_{t}^{\alpha} H_{t}^{1-\alpha}(1-\tau)^{1-\alpha} \tag{4}
\end{equation*}
$$

(i) Define

$$
Z=K / A \text { and } E=H / A
$$

Using the previous expressions, derive a system of difference equations in $Z$ and $E$ that will describe the evolution of the economy.
(ii) Solve for the steady-state values of $Z$ and $E$, and compute the steady-state value of $Q=Y / A$.

(iii) Find the value of $\tau$ that will maximize steady-state $Q$.

(iv) Let $z=\ln Z$ and $e=\ln E$. The system derived in (i) should be linear in $e$ and $z$. Working with the system in logs, compute its eigenvalues, and discuss the stability of its steady state.

(v) Draw the phase diagram for the system.

Problem 5.3. A model of learning by doing. Starting from the Solow model with exogenous technical progress, we will develop a simple model of endogenous growth and examine some of its implications. Assume that the production function is of the form

$$
Y=K^{\alpha}(A L)^{1-\alpha}
$$

Then output per worker is given by

$$
\begin{equation*}
Q=A Z^{\alpha} \tag{1}
\end{equation*}
$$

where $A$ is an index of technical efficiency, and $Z=K / A L$ is the capital/labor ratio in efficiency units. Given a constant investment coefficient $s$, the growth rate of $Z$ is given by the following equation:

$$
\begin{equation*}
\frac{\dot{Z}}{Z}=s Z^{\alpha-1}-\left(\delta+n+g_{A}\right) \tag{2}
\end{equation*}
$$

where $n$ is the rate of population growth, and $g_{A}=\dot{A} / A$ is the rate of technical progress.

Instead of assuming that $g_{A}$ is a given constant, we will now assume that the rate of technical progress $g_{A}$ reflects the accumulation of knowledge with productive experience. In particular, we assume that the instantaneous increase of $A$ is proportional to output per worker, that is,

$$
\begin{equation*}
\dot{A}=\gamma Q=\gamma A Z^{\alpha} \tag{3}
\end{equation*}
$$

where the coefficient $\gamma$ measures the speed of learning.

(i) Show that under these assumptions the law of motion of the capital/labor ratio is of the form

$$
\begin{equation*}
\dot{Z}=(s-\gamma Z) Z^{\alpha}-(\delta+n) Z \tag{5}
\end{equation*}
$$

(ii) Construct the phase diagram for the system, and discuss the stability of its steady state. What is the growth rate of income per worker along the steadystate path?

(iii) Analyze the impact of an increase in the investment rate on the steady state and on the time path of the system. Things are now quite different from what they were in the Solow model with exogenous technical progress. In what sense?
(iv) Consider two countries that are identical except for their investment rates. Discuss the predictions of the current model and the Solow model with exogenous technical progress concerning the evolution of the relative income levels of the two countries.

Problem 5.4. An extended Solow model with human capital (Mankiw et al., 1992). Suppose the aggregate production function is of the form

$$
\begin{equation*}
Y=K^{\alpha} E^{\gamma}(A L)^{1-\alpha-\gamma}=A L Z^{\alpha} H^{\gamma} \tag{1}
\end{equation*}
$$

where $K$ and $E$ are the aggregate stocks of physical capital and human capital, $L$ is the size of the labor force, and $A$ is a productivity index that summarizes the current state of technical knowledge. The normalized variables $Z=K / A L$ and $H=E / A L$ denote the stocks of physical capital and human capital per efficiency unit of labor.

We postulate constant rates of population growth and exogenous technical progress ( $\dot{L} / L=n$ and $\dot{A} / A=g$ ) and assume that the fractions of gross domestic product (GDP) devoted to investment in physical capital and human capital ( $s_{k}$ and $s_{h}$ ) remain constant over time. Under these assumptions, the accumulation of productive factors is described by the system

$$
\begin{equation*}
\dot{K}=s_{k} Y-\delta K \quad \text { and } \quad \dot{E}=s_{h} Y-\delta E \tag{2}
\end{equation*}
$$

where the depreciation rate $\delta$ is assumed to be the same for both types of capital. Using the fact that $\dot{Z} / Z=\dot{K} / K-n-g$, and $\dot{H} / H=(\dot{E} / E)-n-g$, the laws of motion for the stocks of physical capital and human capital can be rewritten in terms of the normalized variables,

$$
\begin{align*}
& \frac{\dot{Z}}{Z}=s_{k} Z^{\alpha-1} H^{\gamma}-(\delta+g+n)  \tag{3}\\
& \frac{\dot{H}}{H}=s_{h} Z^{\alpha} H^{\gamma-1}-(\delta+g+n) \tag{4}
\end{align*}
$$

(i) Find the steady-state values of $Z, H$, and output per efficiency unit of labor, $P=Y / A L$.

(ii) We will now construct a log-linear approximation to the system and use it to derive a convergence equation similar to the one obtained in Section 4(a) Letting $z=\ln Z$ and $h=\ln H$ (from where $Z=e^{2}$ and $H=e^{h}$ ), rewrite the system (3)-(4) in terms of $z$ and $h$. Show that the linear approximation to the transformed system around the steady state is given by

$$
\begin{gather*}
\dot{z}=-(1-\alpha)(\delta+g+n) \tilde{z}+\gamma(\delta+g+n) \tilde{h}  \tag{11}\\
\dot{h}=\alpha(\delta+g+n) \tilde{z}-(1-\beta)(\delta+g+n) \tilde{h} \tag{12}
\end{gather*}
$$

where $\tilde{x}=x-\bar{x}$ denotes the current deviation of variable $x$ from its steady-state value. Discuss the stability of the system (11)-(12) (and hence that of the original system).
(iii) Using the system (11)-(12) and the fact that $p=\alpha z+\gamma h$, derive a linear differential equation in $p$ that describes the approximate behavior of this variable, and solve it. Rewriting the solution in terms of output per worker $q=p+a$, derive a convergence equation of the form

$$
\frac{q_{t+d}-q_{t}}{d}=g+\frac{1-e^{-\lambda d}}{d}\left[p_{t}-\left(q_{t}-a_{t}\right)\right]
$$

where $d$ is the duration of the period, and $\lambda=(1-\alpha-\gamma)(\delta+g+n)$.

Problem 5.5. Diamond's model with variable labor supply. In the basic Diamond model, leisure does not enter the utility function of households. As a result, each worker supplies inelastically his or her endowment of labor time, and the level of employment is constant (on a per-capita basis). We will now relax this assumption.

To simplify things, we assume that the rate of population growth is zero $(n=0)$ and that individuals work in youth and consume only in old age. Young workers, on the other hand, enjoy their leisure and must therefore seek an optimal trade-off between the disutility of working and the need for income. The utility function of a representative worker is given by

$$
U\left(x_{t+1}, L_{t}\right)=\frac{x_{t+1}^{1-\gamma}}{1-\gamma}-L_{t}
$$

where $\gamma \in(0,1), L$ is labor time supplied in youth, and $x$ is old-age consumption. The per-capita production function is

$$
y=\sqrt{k L}
$$

(i) Because consumption takes place only in old age, workers save their entire labor income $w L$ and consume their savings plus interest earnings $\left(w_{t} L_{t} R_{t+1}\right)$ in the second period of their lives. They solve, then,

$$
\max _{x, L}\left\{U=\frac{x^{1-\gamma}}{1-\gamma}-L \text { s.t. } x=w L R\right\}
$$

Solve this problem for the agent's labor supply $\left(L^{s}\right)$ and savings functions.

(ii) Firms maximize profits per worker, that is,

$$
\max _{k, L} \pi_{t}=y_{t}-R_{t} k_{t}-w_{t} L_{t}=\left(k_{t} L_{t}\right)^{1 / 2}-R_{t} k_{t}-w_{t} L_{t}
$$

Write the first-order conditions for this problem, solve for $w$ and $R$ as functions of $(k / L)$, and derive the firm's labor demand function.

(iii) In equilibrium, agents optimize, and labor and capital markets clear. Because population is constant, market clearing requires, in per-capita terms,

$$
\begin{equation*}
L_{t}^{s}=L_{t}^{d} \tag{5}
\end{equation*}
$$

$$
\begin{equation*}
s_{t}=k_{t+1} \tag{6}
\end{equation*}
$$

Show that the conditions for market clearing and individual optimization can be reduced to the following system of first-order difference equations in $k$ and $R$ :

$$
\begin{gather*}
k_{t+1}=R_{t} k_{t}  \tag{A}\\
R_{t+1}^{1-\gamma}=4 k_{t}^{\gamma} R_{t}^{1+\gamma} \tag{B}
\end{gather*}
$$

Hint: The idea is to eliminate $w$ and $L$ from the foregoing equations. Use the first-order conditions for the firm's problem to show that

$$
\begin{align*}
& w_{t}=1 / 4 R_{t}  \tag{7}\\
& w_{t} L_{t}=k_{t} R_{t} \tag{8}
\end{align*}
$$

and substitute the savings function into the market-clearing condition to get (A). Next, use the market-clearing and optimization conditions together with (7) to obtain (B).

(iv) We have been able, then, to reduce the model to a system of two first-order difference equations that describe the sequence of competitive equilibria in this economy. Note that if we take logs, the system becomes linear. Defining

$$
\kappa=\ln k \quad \text { and } \quad \rho=\ln R
$$

we can rewrite $(\mathrm{A})$ and $(\mathrm{B})$ as

$$
\begin{gather*}
\kappa_{t+1}=\rho_{t}+\kappa_{t} \\
(1-\gamma) \rho_{t+1}=\ln 4+\gamma \kappa_{t}+(1+\gamma) \rho_{t}
\end{gather*}
$$

Construct the phase diagram of the system, compute its solution, and analyze its dynamics. What would be a reasonable initial condition for this model?

Problem 5.6. Social security in Diamond's model. Consider a Diamond economy like the one analyzed in Example 3.6. Population grows at a constant rate $n$, preferences are of the form

$$
\begin{equation*}
U(c, x)=\beta \ln c+(1-\beta) \ln x \tag{U}
\end{equation*}
$$

with $\beta \in(0,1)$, and the production function is Cobb-Douglas,

$$
\begin{equation*}
Y=K^{\alpha} L^{1-\alpha} \tag{P}
\end{equation*}
$$

with $\alpha \in(0,1)$.

We assume that wages are taxed at a proportional rate $\tau$ and that proceeds are used to finance a balanced pay-as-you go social-security scheme. Hence, first-period after-tax income for an agent born at time $t$ is given by

$$
y_{1}=(1-\tau) w_{t}
$$

and his second-period retirement subsidy is equal to

$$
y_{2}=\tau(1+n) w_{t+1}
$$

(because there are $1+n$ young agents for each old agent).

(i) Maximize $U(c, x)$ subject to the appropriate budget constraint, and solve for the agent's savings function $s^{*}=s\left(y_{1}, y_{2}, R\right)$ and his indirect utility function $v\left(w_{t}, w_{t+1}, R_{t+1}, \tau\right)$. Taking factor prices as given, when is the agent's welfare an increasing function of the social-security tax rate?

(ii) Derive the law of motion for the capital/labor ratio, $Z=K / L$, and compute the steady-state values of $Z$ and factor prices as functions of $\tau$. Call these functions

$$
\bar{Z}=Z_{s}(\tau), \quad \bar{w}=w_{s}(\tau), \quad \text { and } \quad \bar{R}=R_{s}(\tau)
$$

Under what conditions is it true that $1+n>R_{s}(0)$ ?

(iii) What are the effects of an increase in $\tau$ on steady-state $Z$ and factor prices? Compute the following derivatives evaluated at $\tau=0$ :

$$
\frac{Z_{s}^{\prime}(\tau)}{Z_{s}(\tau)}, \frac{w_{s}^{\prime}(\tau)}{w_{s}(\tau)}, \text { and } \frac{R_{s}^{\prime}(\tau)}{w_{s}(\tau)}
$$

(iv) One of the advantages of working with a model in which indiviudal preferences are clearly specified is that this gives us a natural criterion for evaluating the desirability of possible policy alternatives. Using your previous results, and considering only its effects on steady-state welfare, when will it be a good idea to introduce a social-security scheme? To answer this question, compute the derivative of a representative individual's (maximized) welfare with respect to $\tau$, taking into account both the direct effects of the tax and its indirect effects through the induced change in steady-state factor prices, and evaluate it at $\tau=0$.

Hint: Leave everything in terms of $z_{s}^{\prime}(0)$.

## Bibliography

Azariadis, C. 1993. Intertemporal Macroeconomics. Oxford: Blackwell.

Barro, R., and Sala-i-Martin, X. 1990. Economic Growth and Convergence across the United States. NBER working paper no. 3419.

Barro, R., and Sala-i-Martin, X. 1992. Convergence. Journal of Political Economy 100(2):223-51.

Blanchard, O., and Fischer, S. 1989. Lectures on Macroeconomics. Massachusetts Institute of Technology Press.

Cagan, P. 1956. The Monetary Dynamics of Hyperinflation. In: Studies in the Quantity Theory of Money, ed. M. Friedman. University of Chicago Press.

Calvo, G. 1977. The Stability of Models of Money and Perfect Foresight: A Comment. Econometrica 45:1737-9.

Cass, D. 1965. Optimum Growth in an Aggregative Model of Capital Accumulation. Review of Economic Studies 32:223-40.
de la Fuente, A. 1992. Histoire d'A: Crecimiento y Progreso Técnico. Investigaciones Económicas 16(3):331-91.

Galor, O., and Ryder, H. 1989. On the existence of equilibrium in an overlapping generations model with productive capital. Journal of Economic Theory 49:360-75.

Diamond, P. 1965. National Debt in a Neoclassical Growth Model. American Economic Review 55:1126-50.

Dornbusch, R. 1976. Expectations and Exchange Rate Dynamics. Journal of Political Economy 84:1161-76.

Koopmans, T. 1965. On the Concept of Optimal Economic Growth. In: The Econometric Approach to Development Planning. Chicago: Rand McNally.

Mankiw, G., Romer, D., and Weil, D. 1992. A Contribution to the Empirics of Economic Growth. Quarterly Journal of Economics 107(2):407-37.

Obstfeld, M. 1980. Anticipated Disturbances in a Perfect Foresight Model. Mimeograph, Department of Economics, Columbia University.

Ramsey, F. 1928. A Mathematical Theory of Savings. Economic Journal 38:543-59.

Sargent, T., and Wallace, N. 1973. The Stability of Models of Money and Growth with Pefect Foresight. Econometrica 45:1043-8.

Solow, R. 1956. A Contribution to the Theory of Economic Growth. Quarterly Journal of Economics 70:65-94.

Solow, R. 1970. Growth Theory: An Exposition. Oxford University Press.

Swan, T. W. 1956. Economic Growth and Capital Accumulation. The Economic Record 32:334-61.

Wolfram, S. 1991. Mathematica. A System for Doing Mathematics by Computer, 2nd ed. Reading, MA: Addison-Wesley.

## Notes

1 Solving (6) for the level of output, we can reinterpret this relation as a "Lucas" aggregate supply function,

$$
y=\bar{y}+(1 / \theta)\left(\pi-\pi^{e}\right)
$$

saying that output supply will be above its natural rate whenever inflation exceeds expectations. One possible mechanism behind this relation works through the impact of unanticipated inflation on perceived real wages. When inflation is higher than workers realize, they may overestimate their real wage, and this may induce them to supply more labor than they would otherwise.

2 Note how we have arranged things so that the model becomes autonomous. Instead of working with price levels, we are working with inflation rates. In a steady state, therefore, it is not prices, but rather inflation, that remains constant. Second, the driving force behind inflation will be the growth of the nominal money supply. If we allowed the rate of monetary growth to change over time, we would have a nonautonomous system. To simplify things, we assume that $\mu$ is constant. Then we can analyze the effect of a change in monetary policy by looking at the impact of a once-and-for-all change in $\mu$.

3 Notice that we would get the same answer if we moved east, rather than north, from the steady state. Hence, we could have used $\partial \dot{\pi}^{e} / \partial \pi^{e}$ instead of $\partial \dot{\pi}^{e} / \partial m$.

4 See Section 2(d) of Chapter 10 for a discussion of the conditions for the stability of linear systems with constant coefficients.

5 This is more an assumption than a result. Our original equations already embody the natural-rate hypothesis.

6 A simple way to see this is the following. Suppose the production function is homogeneous of degree $h$, where $h$ is not necessarily equal to 1 . Then, by Euler's theorem,

$$
\begin{equation*}
K F_{K}(K, L)+L F_{L}(K, L)=h F(K, L) \tag{1}
\end{equation*}
$$

Suppose $h=1$ (i.e., we have constant returns to scale) and there is perfect competition. Then factor prices are given by the corresponding marginal products, and equation (1) says that when capital and labor are paid their equilibrium prices, total output is just exhausted. If $h>1$, however (i.e., when we have increasing returns), factors cannot be paid their marginal product, because the required amount is larger than total output.

7 It can be shown that if $F$ is homogeneous of degree 1, then its partial derivatives are homogeneous of degree 0 , that is, for any $\lambda>0, F_{K}(K, L)=F_{K}(\lambda K, \lambda L)$, and similarly for $F_{L}$. See Chapter 4.

8 A similar model with a Cobb-Douglas technology was proposed simultaneously by Swan (1956). Hence, we sometimes speak of the Solow-Swan model.

9 The first equality in this expression follows by L'Hôpital's rule whenever $f()$ is unbounded.

10 Notice that firms return undepreciated capital to the old workers after production takes place. Because the old "eat everything," the young have to start from scratch each period.

11 Technical progress can be handled in the same way as population growth. Let $g$ be the rate of labor-augmenting technical progress, i.e., $A_{t+1}=(1+g) A_{t}$, and define $Z=K / A L$. Then we have

$$
\frac{K_{t+1}}{A_{t+1} L_{t+1}}=\frac{L_{t} s_{t}}{(1+n)(1+g) A_{t} L_{t}} \Rightarrow(1+n)(1+g) Z_{t+1}=\frac{s\left[A_{t} w\left(Z_{t}\right), f^{\prime}\left(Z_{t+1}\right)+(1-\delta)\right]}{A_{t}}
$$

where $A w(Z)$ is the salary per worker. Notice, however, that this equation will not, in general, have a constant- $Z$ solution. If preferences are homothetic, however, the savings function is of the form $s(y, R)=s(R) y$, and the previous expression simplifies to

$$
(1+n)(1+g) Z_{t+1}=s\left[f^{\prime}\left(Z_{t+1}\right)+(1-\delta)\right] w\left(Z_{t}\right)
$$

which does have a steady state.

12 It is shown in the proof that $\phi^{\prime}(0)>1$ requires that $w^{\prime}(0)>1$. Galor and Ryder (1989) have shown that this condition is stronger than the Inada condition $f^{\prime}(0)=\infty$. Hence, the Inada condition is not sufficient to guarantee the existence of a nontrivial steady state.

13 Because $Z$ is a function of $A$, which is not observable, it may instead be better to work with the growth rate of the capital stock per worker. Although data on this variable are indeed available for some countries, their quality is in general rather poor, and the available figures may not be fully comparable across countries. Hence, it may be better to use a transformation of (1) that will allow us to work directly with (more reliable) data on investment flows, rather than with capital stocks.

14 See Barro and Sala-i-Martin (1990, 1992) and Mankiw, Romer, and Weil (1992) for empirical applications of this methodology.

15 Because $z$ is in logs, this is approximately the deviation from the steady state in percentage terms.

16 This can also be done inside the function. Thus we could replace the statement in In[7] by

sol1 $=$ NDSolve $\left[\left\{z^{\prime}[t]==F[z[t], 0.25,0.69,0.03,0.02\right.\right.$, $0.01], z[0]==z s 1 / 2\}, z,\{t, 0,100\}]$

## An Introduction to Dynamic Optimization

This chapter contains an introduction to dynamic optimization. In Section 1 we develop some basic elements of dynamic programming that are then used in Section 2 in an informal derivation of the maximum principle. Applications will be discussed in Chapter 13.

## 1. Dynamic Programming

Consider a system, economic or otherwise, whose evolution over time can be at least partially controlled by the actions of a decision-maker. At each point in time $s$, the state of the system can be described by a dated vector of real variables, $x_{s} \in \mathbb{R}^{\mathrm{n}}$, which we call the state vector. In each period the decision-maker chooses a vector of control or decision variables, $u_{s} \in \mathbb{R}^{\mathrm{m}}$. Together, the current state of the system and the choices of controls determine the value of the state vector for the following period according to the (possibly time-dependent) law of motion

$$
\begin{equation*}
x_{s+1}=m_{s}\left(x_{s}, u_{s}\right) \tag{1}
\end{equation*}
$$

Thus, different choices of the control variables will yield different time paths of the system. It will be assumed that the decision-maker has preferences defined over such time paths that can be summarized by a time-additive return or objective function

$$
\begin{equation*}
W_{t}=\sum_{s=t}^{T-1} f_{s}\left(x_{s}, u_{s}\right) \tag{2}
\end{equation*}
$$

For simplicity, we will take as given the planning horizon and the initial and terminal values of the state vector. Thus, we consider the problem faced by a planner who inherits at time $t$ a predetermined state vector $x_{t}$, cares only about what happens between times $t$ and $T(\leq \infty)$, and is obliged to leave the state vector with value $x_{T}$ at the end of the planning period. The agent
can also be constrained by further restrictions on the state and control vectors, which we will write $\left(x_{s}, u_{s}\right) \in C_{s}$ for each $s$.

Given the initial state of the system, $x_{t}$, and a sequence $\mathbf{u}_{t, \mathrm{~T}-1}=\left\{u_{s} ; s=t\right.$, $t+1, \ldots, T-1\}$ of control variables, the evolution of the state vector is determined by the law of motion (1). Thus, $x_{t}$ and $\mathbf{u}_{t, T-1}$ induce a sequence of states $\mathbf{x}_{\mathbf{t + 1 , T}}=\left\{x_{s} ; s=t+1, \ldots, T\right\}$. We will write $\mathbf{z}_{\mathbf{t}, \mathbf{T}}=\left\{\mathbf{u}_{\mathbf{t}, \mathbf{T}-\mathbf{1}} \cup \mathbf{x}_{\mathbf{t + 1 ,}}\right\}$ and say that a such sequence is admissible if both states and controls are feasible at all times and the terminal value of the state vector is equal to the required value, $x_{T}$. The set of all sequences $\mathbf{z}_{\mathbf{t}, \mathrm{r}}$ admissible from a given initial state vector $x_{t}$ will be denoted by $\Phi\left(x_{t}\right)$, or by $\Phi\left(x_{t}, x_{T}\right)$ when we also want to make explicit the terminal constraint on the state. When we want to indicate explicitly the initial and terminal conditions on this sequence, we will write $\mathbf{z}\left(\mathbf{u}_{\mathbf{t}, \mathbf{T}-\mathbf{b}}, x_{t}, x_{T}\right)$, and we will denote the portion of $\mathbf{z}_{\mathbf{t}, \mathbf{r}}$ between points $a$ and $b$ in time by $\left.\mathbf{z}\left(\mathbf{u}_{\mathbf{t}, \mathbf{T}-1}, x_{t}, x_{T}\right)\right|_{a} ^{b}$.

In this notation the decision-maker's objective function can be written

$$
W\left(\mathbf{z}_{\mathbf{t}, \mathbf{r}}, t, T-1\right)=\sum_{s=t}^{T-1} f_{s}\left(x_{s}, u_{s}\right)
$$

Notice that $W()$ is given by the sum of the instantaneous or period return functions $\left\{f_{s}\right\}$, where each $f_{s}$ is a function only of time and the current state and control vectors and does not depend on either past or future values of $x$ or $u$.

## (a) The Principle of Optimality and Bellman's Equation

The problem the agent faces is that of choosing the time path of the control variables so as to maximize the objective function $W_{t}$ subject to the law of motion (1) and appropriate feasibility constraints, taking as given the planning horizon $(t, T)$ and the initial and terminal values of the state vector. We will denote by $V()$ the value function for the planner's problem (i.e., the maximum attainable value of the objective function). Clearly, $V()$ will be a function of the parameters of the maximization problem (the initial and terminal times and state vectors) and is equal to the objective function evaluated at the optimal control path and the induced state sequence, assuming they exist. Formally, the problem can be written

$$
\begin{align*}
V\left(x_{t}, t ; x_{T}, T\right)= & \max _{\mathbf{u}, \mathbf{T}-1}\left\{W\left[\mathbf{z}\left(\mathbf{u}_{\mathbf{t}, \mathrm{T}-\mathbf{1}}, x_{t}, x_{T}\right), t, T-1\right]\right. \\
= & \sum_{s=1}^{T-1} f_{s}\left(x_{s}, u_{s}\right) \text { s.t. } x_{s+1}=m_{s}\left(x_{s}, u_{s}\right), t, T, x_{t}, \\
& \text { and } \left.x_{T} \text { given, }\left(x_{s}, u_{s}\right) \in C_{s} \subseteq \mathbb{R}^{\mathrm{n}+\mathrm{m}} \text { for each } s\right\} \tag{DP}
\end{align*}
$$

If $T$ is finite (which may not be the case), (DP) can be solved by the standard methods for dealing with constrained optimization problems (i.e., by
applying the Lagrange or Kuhn-Tucker theorems). The structure of the problem, moreover, permits some important simplifications and will also allow us to deal with infinite-horizon problems (to which the standard theorems do not apply). The features that make things easier are the additive separability of the objective function and the simple structure of the law of motion - the fact that for each $s, f_{s}$ (the period return function) and $m_{s}$ (the law of motion) depend only on $s$ and on the current values of the state and control variables, but not on their past or future values, and that the total return is simply the sum of the period return functions.

This property has the following implication. Let $\mathbf{z}_{\mathbf{t}, \mathrm{T}}=\mathbf{z}\left(\mathbf{u}_{t, T-1}, \boldsymbol{x}_{t}, x_{T}\right)$ be an admissible sequence of controls and induced states between end points $x_{t}$ and $x_{T}$, and let $a$ and $b$ be positive integers, with $t \leq a<b \leq T-1$. Then we can write the return function in the form

$$
W\left(\mathbf{z}_{\mathbf{t}, \mathbf{T}}, t, T-1\right)=W\left(\left.\mathbf{z}_{\mathbf{t}, \mathbf{T}}\right|_{t} ^{a-1}, t, a-1\right)+W\left(\left.\mathbf{z}_{\mathbf{t}, \mathbf{T}}\right|_{a} ^{b-1}, a, b-1\right)+W\left(\left.\mathbf{z}_{\mathbf{t}, \mathbf{T}}\right|_{b} ^{T-1}, b, T-1\right)
$$

That is, the total payoff associated with a state-control sequence over the whole planning horizon is simply the sum of the payoffs associated with different portions of the sequence over the corresponding subperiods. Using this additivity property, it is easy to establish the following result, which gives an important property of the optimal solution of (DP).

Theorem 1.1. The principle of optimality. Let $z_{i, T}^{*}=\mathbf{z}\left(\mathbf{u}_{t, \mathrm{~T}-1}^{*}, \mathbf{x}_{\mathrm{t}}, \mathbf{x}_{\mathrm{T}}\right)=\left\{\mathbf{u}_{\mathrm{s}}^{*}\right.$, $\left.\mathrm{x}_{\mathrm{s}+1}^{*}\right)$ be the optimal solution of $(D P)$ between given end points $\left(\mathrm{x}_{\mathrm{t}}, \mathrm{t}\right)$ and $\left(\mathrm{x}_{\mathrm{T}}\right.$, $\mathrm{T})$. Given arbitrary points $\mathrm{a}$ and $\mathrm{b}$, with $\mathrm{t} \leq \mathrm{a}<\mathrm{b} \leq \mathrm{T}-1$, let $\mathrm{x}_{\mathrm{a}}^{*}$ and $\mathrm{x}_{\mathrm{b}}^{*}$ be the corresponding terms of the optimal state sequence $\left\{\mathrm{x}_{\mathrm{s}}^{*}\right\}$. Then the optimal solution to

$$
\begin{align*}
\mathrm{V}\left(\mathrm{x}_{\mathrm{a}}^{*}, \mathrm{a} ; \mathrm{x}_{\mathrm{b}}^{*}, \mathrm{~b}\right)= & \max _{\mathrm{u}_{a, b-1}}\left\{\mathrm{~W}\left(z_{a, b-1}, \mathrm{a}, \mathrm{b}-1\right)=\sum_{\mathrm{s}=\mathrm{a}}^{\mathrm{b}-1} \mathrm{f}_{\mathrm{s}}\left(\mathrm{x}_{\mathrm{s}}, \mathrm{u}_{\mathrm{s}}\right)\right. \\
\text { s.t. } \mathrm{x}_{\mathrm{s}+1}= & \mathrm{m}_{\mathrm{s}}\left(\mathrm{x}_{\mathrm{s}}, \mathrm{u}_{\mathrm{s}}\right), \mathrm{a}, \mathrm{b}, \mathrm{x}_{\mathrm{a}}^{*}, \text { and } \mathrm{x}_{\mathrm{b}}^{*} \text { given, } \\
& \left.\left(\mathrm{x}_{\mathrm{s}}, \mathrm{u}_{\mathrm{s}}\right) \in \mathrm{C}_{\mathrm{s}} \subseteq \mathbb{R}^{\mathrm{a}+1 \mathrm{~s}} \text { for each } \mathrm{s}\right\} \tag{DP.ab}
\end{align*}
$$

is given by $\left.z_{h}^{*}\right|_{a} ^{b-I}$.

Roughly speaking, the theorem says that each portion of the optimal plan is optimal on its own right. More precisely, any portion of an optimal trajectory is an optimal trajectory for an appropriate subproblem of (DP) in which we constrain the end-point values of the state vector to be equal to the corresponding terms of the optimal state sequence for the whole problem.

Proof. We proceed by contradiction. Let $\Phi\left(x_{a}^{*}, x_{b}^{*}\right)$ be the set of feasible trajectories $\mathbf{z}_{\mathbf{a}, \mathbf{b}-\mathbf{1}}$ between end points $\left(x_{a}^{*}, a\right)$ and $\left(x_{b}^{*}, b\right)$. This set is not empty, as it contains at least the relevant portion of the optimal sequence for the whole problem, $\left.\mathbf{z}_{i, \mathrm{r}-1}^{*}\right|_{a} ^{b}$, which exists by assumption. Now suppose that $\left.\mathbf{z}_{i, \mathrm{x}-1}^{*}\right|_{a} ^{b-1}$ is not optimal for the subperiod from $a$ to $b$. Then there exists a feasible sequence between these end points, $\mathbf{z}_{\mathbf{a}, \mathbf{b}-\mathbf{l}}^{\prime}$, such that $W\left(\mathbf{z}_{\mathbf{a}, \mathbf{b - 1}}^{\prime}\right)>$ $W\left(\mathbf{z}^{*}, \mathrm{~T}-\left.1\right|_{a} ^{b-1}\right)$. By the time-additivity of the objective function,

$$
W\left(\left.\mathbf{z}_{\mathbf{t}, \mathbf{r}}^{*}\right|_{t} ^{a-1}\right)+W\left(\mathbf{z}_{\mathbf{a}, \mathbf{b}-1}^{\prime}\right)+W\left(\left.\mathbf{z}_{\mathbf{t}, \mathbf{r}}^{*}\right|_{b} ^{T-1}\right)>W\left(\left.\mathbf{z}_{\mathbf{t}, \mathbf{r}}^{*}\right|_{t} ^{T-1}\right)
$$

Hence, we have found a sequence $\left.\left.\mathbf{z}_{i, \mathrm{~T}-1}^{*}\right|_{t} ^{a-1} \cup \mathbf{z}_{\mathrm{a}, \mathrm{b}-1}^{\prime} \cup \mathbf{z}_{1, \mathrm{~T}-1}^{*}\right|_{b} ^{T-1}$ that yields a higher return than $\mathbf{z}_{\mathbf{i}, \mathrm{T}-\mathbf{1}}$. Moreover, because this sequence is feasible by construction, we have reached a contradiction: $\mathbf{z}_{\text {, }}^{*} \mathbf{- 1}$ cannot be an optimal solution for the "whole" problem.

Problem 1.2. A violation of the principle of optimality. Consider an agent who lives three periods and maximizes a utility function of the form

$$
V_{1}=U_{1}+\alpha U_{2}+\beta U_{3}
$$

where utility in period $i, U_{i}$, is a function of current and (expected) future consumption, that is,

$$
U_{1}\left(c_{1}, c_{2}, c_{3}\right)=\ln \left(c_{1} c_{2} c_{3}\right), \quad U_{2}\left(c_{2}, c_{3}\right)=\ln \left(c_{2} c_{3}\right), \quad \text { and } \quad U_{3}\left(c_{3}\right)=\ln c_{3}
$$

and the budget constraint is of the form

$$
A_{t+1}=A_{t}-c_{t} \quad\left(A_{1} \text { given, and } A_{4}=0\right)
$$

where $A$ is wealth.

Notice that the return function is additive, but not separable over periods, as the period-1 utility, for example, depends on (expected) consumption at times 2 and 3. Hence, the assumptions of Theorem 1.1 do not hold, and, as we will see, the principle of optimality fails.

(i) Compute the optimal consumption plan from the perspective of time 1 , $c^{1}=\left(c_{1}^{1}, c_{2}^{1}, c_{3}^{1}\right)$.

(ii) Next, consider what happens as the agent begins to implement this plan. At time 1 , he consumes $c_{1}^{1}$, receives utility $U_{1}$, and has leftover wealth $A_{2}=A_{1}-c_{1}^{1}$. He then faces the problem of maximizing utility over the remainder of his life,

$$
\max V_{2}=\alpha U_{2}+\beta U_{3}
$$

subject to $c_{2}+c_{3}=A_{2}$. Compute the new optimal plan, $c^{2}=\left(c_{2}^{2}, c_{2}^{3}\right)$, and compare it with the last portion of $c^{1}$. Has the consumer changed his mind? How and why? Does the Bellman equation (discussed later) hold?

The principle of optimality has an important implication, sometimes called time consistency: Suppose we compute the optimal path from the beginning of the planning period and start moving along it. After a while, we stop and recalculate the optimal solution from the current time and state. The principle of optimality tells us that the solution of this new problem will be the remainder of the original optimal plan. Hence, the decision-maker will not be tempted to "change his mind."

This property allows us to approach the problem sequentially, leaving for tomorrow decisions about future controls, thus breaking up the original dynamic problem into a sequence of static subproblems. To make this precise, consider one particular decomposition of the problem, that into (i) today's choice of controls and (ii) all the rest of the plan. By the additivity of the objective function, we can write

$$
\begin{aligned}
V\left(x_{t}, t ; x_{T}, T\right) & =\max _{\mathbf{u}_{t}, \mathrm{~T}-1} W\left[\mathbf{z}\left(\mathbf{u}_{\mathbf{t}, \mathbf{T}-\mathbf{1}}, x_{t}, x_{T}\right), t, T-1\right] \\
& =\max _{u_{t}, \mathbf{u}_{t+1, \mathrm{~T}-1}}\left\{f_{t}\left(u_{t}, x_{t}\right)+W\left[\mathbf{z}\left(\mathbf{u}_{\mathbf{t + 1}, \mathbf{T}-\mathbf{1}}, x_{t+1}, x_{T}\right), t+1, T-1\right]\right\}
\end{aligned}
$$

where the maximization is subject to the usual constraints and, in particular, $x_{t+1}=m_{t}\left(x_{t}, u_{t}\right)$. The structure of the problem allows us to approach the choice of the current $\left(u_{t}\right)$ and future $\left(\mathbf{u}_{t+1, \mathbf{T}-1}\right)$ controls sequentially. Notice that states and controls dated $t+1$ or higher do not affect the current return, given by $f_{t}\left(u_{t}, x_{t}\right)$, and that the current state and control vectors $\left(x_{t}, u_{t}\right)$ affect future returns only through their effects on tomorrow's state, $x_{t+1}$. Thus, we can solve the problem in two steps: Given any choice of the current control, tomorrow we will face the problem of choosing $\mathbf{u}_{t+1, \mathbf{T}-1}$ so as to maximize $W\left[\mathbf{z}\left(\mathbf{u}_{t+1, T-1}, x_{t+1}, x_{t}\right), t+1, T-1\right]$, taking as given the state $x_{t+1}$ resulting from today's decision - a problem identical with today's except for the initial state and time. Having solved this problem, today's decision reduces to choosing $u_{t}$, taking into account both its direct contribution to the current return and its indirect contribution to future payoffs through its effect on tomorrow's state. The principle of optimality assures us that this stepwise or sequential maximization process will yield the same result as simultaneous determination of the whole control path. Thus, we can write

$$
\begin{aligned}
& V\left(x_{t}, t ; x_{T}, T\right)=\max _{u_{t} \cdot \mathbf{u}_{t+1, T-1}}\left\{f_{t}\left(u_{t}, x_{t}\right)+W\left[\mathbf{z}\left(\mathbf{u}_{t+1, \mathbf{T}-1}, x_{t+1}, x_{T}\right), t+1, T-1\right]\right\} \\
& =\max _{u_{t}}\left\{f_{t}\left(u_{t}, x_{t}\right)+\max _{\mathbf{u}_{t+1}, \mathbf{T}-\mathbf{1}}\left\{W\left[\mathbf{z}\left(\mathbf{u}_{\mathbf{t}+\mathbf{1}, \mathbf{T}-\mathbf{1}}, x_{t+1}, x_{T}\right), t+1, T-1\right]\right\}\right. \\
& \text { s.t. } \left.x_{t+1}=m_{t}\left(x_{t}, u_{t}\right)\right\}
\end{aligned}
$$

Finally, observe that the payoff resulting from the inside maximization is given by the value function corresponding to "tomorrow's problem." Thus,

$$
\begin{aligned}
& \max _{u_{t}}\left\{f_{t}\left(u_{t}, x_{t}\right)+\max _{\mathbf{u}_{t+1, \mathbf{T}-1}}\left\{W\left[\mathbf{z}\left(\mathbf{u}_{t+1, \mathbf{T}-1}, x_{t+1}, x_{T}\right), t+1, T-1\right]\right\} \text { s.t. } x_{t+1}=m_{t}\left(x_{t}, u_{t}\right)\right\} \\
& \quad=\max _{u_{t}}\left\{f_{t}\left(u_{t}, x_{t}\right)+V\left(x_{t+1}, t+1 ; x_{T}, T\right) \text { s.t. } x_{t+1}=m_{t}\left(x_{t}, u_{t}\right)\right\}
\end{aligned}
$$

and we arrive at Bellman's equation,

$$
\begin{equation*}
V\left(x_{t}, t ; x_{T}, T\right)=\max _{u_{t}}\left\{f_{t}\left(u_{t}, x_{t}\right)+V\left(x_{t+1}, t+1 ; x_{T}, T\right) \text { s.t. } x_{t+1}=m_{t}\left(x_{t}, u_{t}\right)\right\} \tag{BE}
\end{equation*}
$$

This expression formally characterizes the optimal choice of the current control vector as the solution of a static optimization problem in which the future consequences of current actions are summarized by incorporating tomorrow's value function into today's objective function. The solution to the static maximization problem in (BE) yields a policy function that gives the optimal value of the current control, $u_{t}^{*}$, as a function $g_{t}\left(x_{t}\right)$ of time and the current state. Tomorrow's state is then given by $x_{t+1}=m_{t}\left[g_{t}\left(x_{t}\right), x_{t}\right]$, and a solution to a similar problem (with $x_{t+1}$ now given) then yields tomorrow's optimal control. (Notice that time enters both the value and policy functions as a separate argument, reflecting the fact that periods may differ in factors other than the state vector.)

The recursive relation given by (BE) is useful in that it allows us to conceptually transform a dynamic choice problem into a sequence of static problems we already know how to handle, at least in principle. But notice that the maximization in Bellman's equation is not really a standard problem in at least one sense: The value function $V()$ appears both inside and outside the maximization operator (although with different arguments) and therefore is not a known function. In fact, (BE) is a functional equation - an equation in the unknown function $V()$. Hence, the reformulation of the original problem does not really solve it, nor put it in a form we can solve directly. The Bellman equation, however, does provide the basis for an alternative approach to the problem that will indeed lead to an operational solution method. In the sections that follow we will consider two cases: finite-horizon problems, and infinite-horizon problems with some additional restrictions.

## (i) Solution of Finite-Horizon Problems through Backward Induction

Dynamic programming problems over a finite planning horizon do not present any conceptual difficulties. The value and policy functions can be obtained by starting from the end and working backward. The optimal control sequence can then be computed by applying the sequence of policy functions, $g_{1}, \ldots, g_{T-1}$, to the initial state vector.

One period before the end of the planning period the problem reduces to choosing the last control, taking as given the terminal value of the state. Omitting some of the arguments of the value function, we can write

$$
V\left(x_{T-1}, T-1\right)=\max _{u_{T-1}}\left\{f_{T-1}\left(u_{T-1}, x_{T-1}\right) \text { s.t. } m_{T-1}\left(x_{T-1}, u_{T-1}\right)=x_{T} \text { given }\right\}
$$

Notice that at this stage there is no unknown value function inside the max operator; hence, $V\left(x_{T-1}, T-1\right)$ is well defined by the foregoing expression, and for a fully specified problem its computation is, in principle, straightforward. On the other hand, the value of $x_{T-1}$ is not known at this point, but this does not matter, for we are interested in the whole function $V(\cdot, T-1)$, rather than its value for a specific state vector.

This procedure will also work for a class of problems more general than those we have considered thus far. In particular, we can abandon the assumption of a predetermined terminal state vector and let the agent choose $x_{T}$ taking into account its contribution to his payoff, given by a scrap or salvage value function $S\left(x_{T}\right) \cdot{ }^{1}$ In this case, the last-stage maximization becomes

$$
V\left(x_{T-1}, T-1\right)=\max _{u_{T-1}}\left\{f_{T-1}\left(u_{T-1}, x_{T-1}\right)+S\left(x_{T}\right) \text { s.t. } x_{T}=m_{T-1}\left(x_{T-1}, u_{T-1}\right)\right\}
$$

In any case, the solution of the last-period problem yields a policy function that gives the optimal value of the last control as a function of the state at the beginning of the period: $u_{T-1}^{*}=g_{T-1}\left(x_{T-1}\right)$. As for the value function, the value of the argument is not known at this stage, but what we want is the function itself.

Given $V\left(x_{T-1}, T-1\right)$, we can go back one step and compute the value function for the previous period,

$$
\begin{aligned}
V\left(x_{T-2}, T-2\right) & =\max _{u_{T-2}}\left\{f_{T-2}\left(u_{T-2}, x_{T-2}\right)+V\left(x_{T-1}, T-1\right)\right. \\
\text { s.t. } x_{T-1} & \left.=m_{T-2}\left(x_{T-2}, u_{T-2}\right)\right\}
\end{aligned}
$$

obtaining also the corresponding policy function, $u_{T-2}^{*}=g_{T-2}\left(x_{T-2}\right)$. Proceeding in this manner, we eventually reach the initial period and solve

$$
V\left(x_{t}, t\right)=\max _{u_{t}}\left\{f_{t}\left(u_{t}, x_{t}\right)+V\left(x_{t+1}, t+1 ; x_{T}, T\right) \text { s.t. } x_{t+1}=m_{t}\left(x_{t}, u_{t}\right)\right\}
$$

to obtain the value function for the original problem and the first policy function, $g_{t}(\cdot)$. At this point, the initial value of the state, $x_{t}$, is a given quantity, and the whole sequence of policy functions $\left\{g_{s} ; s=t, t+1, \ldots, T-1\right\}$ is also known. Hence, we can recover the optimal sequence of instruments, given by $u_{s}^{*}=g_{s}\left(x_{s}\right)$, and the induced sequence of states, $x_{s+1}=m_{s}\left(x_{s}, u_{s}^{*}\right)$.

## (ii) Discounting and Stationarity

It should be clear that the foregoing solution algorithm cannot be used when the planning horizon is infinite, for there is no terminal date from which to work backward. As we will see, however, certain kinds of infinite-horizon
problems can be dealt with and in many cases are easier to solve than finitehorizon problems. In this section we introduce some notation and impose some additional structure on the dynamic programming problem before briefly discussing a particular class of infinite-horizon problems that will be analyzed in greater detail later.

Discounting. In many situations, payoffs accruing at different points in time are valued differently by the decision-maker. Typically, those that are realized further into the future are valued less than those that accrue immediately. Although our earlier specification of a time-dependent period return function $f_{s}\left(x_{s}, u_{s}\right)$ implicitly allows for this possibility, it will be convenient to bring it out explicitly by introducing a sequence of periodspecific weights. In particular, we will assume that the period return function at time $s$ is of the form $f_{s}\left(x_{s}, u_{s}\right)=\alpha_{s} F_{s}\left(x_{s}, u_{s}\right)$, where the discount factor $\alpha_{s}$ is a nonnegative real number, and consider an agent who faces a problem of the form

$$
V\left(x_{0}, 0\right)=\max _{\mathbf{u}, \mathbf{T}-1} \sum_{s=0}^{T-1} \alpha_{s} F_{s}\left(x_{s}, u_{s}\right)
$$

subject to the usual constraints. We will interpret $F_{s}()$ as the payoff that accrues at time $s$, valued from the perspective of time $s$ itself, and $f_{s}($ ) $=\alpha_{s} F_{s}()$ as the same payoff "discounted back" to the beginning of the planning period at time zero. Thus, multiplication of the current payoff $F_{s}()$ by $\alpha_{s}$ brings it back to time-zero units, and division of the discounted payoff $f_{s}($ ) by the same factor brings it forward to time-s units. Because firstperiod returns need no discounting, we set $\alpha_{0}$ equal to 1 .

As time passes and the agent gets to period $t$, he faces the subproblem of maximizing the remainder of the objective function,

$$
V\left(x_{t}, t\right)=\max _{\mathbf{u}, \mathrm{T}-\mathbf{1}} \sum_{s=t}^{T-1} \alpha_{s} F_{s}\left(x_{s}, u_{s}\right)
$$

Notice that the value function in this expression gives the maximum attainable payoff evaluated from the perspective of time zero, because each period return is multiplied by the corresponding discount factor. When maximizing over the subperiod starting at $t$, however, it is often more convenient to make "current" valuations (as of time $t$ ). Thus, we define the current value function by

$$
V^{c}\left(x_{t}, t\right)=\frac{V\left(x_{t}, t\right)}{\alpha_{t}}=\max _{\mathbf{a}, \mathbf{T}-\mathbf{1}} \sum_{s=t}^{T-1} \frac{\alpha_{s}}{\alpha_{t}} F_{s}\left(x_{s}, u_{s}\right)
$$

As usual, successive subproblems are linked by the Bellman equation:

$$
V\left(x_{t}, t\right)=\max _{u_{t}}\left\{\alpha_{t} F_{t}\left(x_{t}, u_{t}\right)+V\left(x_{t+1}, t+1\right)\right\}
$$

To rewrite this equation in terms of current values, we divide both sides of this expression by $\alpha_{t}$, obtaining

$$
V^{c}\left(x_{t}, t\right)=\max _{u_{t}}\left\{F_{t}\left(x_{t}, u_{t}\right)+\beta_{t} V^{c}\left(x_{t+1}, t+1\right)\right\}
$$

where the one-period discount factor, $\beta_{t}=\alpha_{t+1} / \alpha_{t}$, discounts values from $t+$ 1 to $t$ (multiplying by $\alpha_{t+1}$ brings them back to zero, dividing by $\alpha_{t}$ takes them back up to $t$ ). The interpretation of this expression is almost exactly the same as that of the undiscounted version of the Bellman equation: Given tomorrow's state, $x_{t+1}, V^{c}\left(x_{t+1}, t+1\right)$ gives the maximum attainable payoff in "tomorrow's utility units." To bring it back to "today's units," we multiply $V^{c}()$ by $\beta_{t}$. The optimal policy is then to choose $u_{t}$ so as to maximize the sum of today's period return and the discounted value of tomorrow's current value function.

Infinite Horizon, Stationary Problem. In many problems of interest it can be assumed that the period return function, the law of motion, the oneperiod discount factor, and the feasible set $C$ to which states and controls must belong are all time-invariant, that is,

$$
F_{s}=F, \quad m_{s}=m, \quad C_{s}=C, \quad \beta_{s}=\beta
$$

This assumption allows some further simplifications of the problem. Notice that with a constant $\beta$, we have $\alpha_{s+1}=\beta \alpha_{s}$. This equation, together with the assumption that $\alpha_{0}=1$, implies that the discount factor must be of the form $\alpha_{s}=\beta^{s}$. Thus, the subproblem starting at time $t$ can be written

$$
V^{c}\left(x_{t}, t\right)=\max _{u_{t}, T-1} \sum_{s=t}^{T-1} \mathbf{b}^{s-t} F\left(x_{s}, u_{s}\right)
$$

In the finite-horizon case, $t$ is still a separate argument of the current value function, as subproblems that start at different dates differ from each other not only in the initial value of the state vector but also in the time remaining until the end of the planning period. If the planning horizon is infinite, however, this is no longer the case, and all subproblems are identical. Thus, for infinite-horizon stationary problems, the current value function is a function of the initial state alone, $V^{c}\left(x_{t}\right)$, and the Bellman equation becomes

$$
V^{c}\left(x_{t}\right)=\max _{u_{t}}\left\{F\left(x_{t}, u_{t}\right)+\beta V^{c}\left(x_{t+1}\right)\right\}
$$

It follows that the policy function, $u_{\mathrm{t}}^{*}=g\left(x_{t}\right)$, is also time-invariant. This is an important simplification, because we now have to find only one such function, rather than $T-t$ of them.

As noted earlier, the backward-induction algorithm cannot be used to solve infinite-horizon problems. The following observation, however, provides the basis for a way to deal with such problems, as we will see later. Given a function $v()$ from $\mathbb{R}^{\mathrm{n}}$ to $\mathbb{R}$, we can define an operator $T$ mapping the space of such functions into itself:

$$
T v(x)=\max _{u}\{F(x, u)+\beta v(y) \text { s.t. } y=m(x, u),(x, u) \in C\}
$$

The Bellman equation can then be written $V^{c}=T V^{c}$. Hence, a function $V$ solves Bellman's equation if and only if it is a fixed point of the operator $T$. Under certain assumptions, the contraction mapping theorem can be used to establish the existence and uniqueness of a solution to Bellman's equation and to determine some properties of interest of such a function.

## (iii) Uncertainty

Dynamic programming is particularly useful when dealing with problems that involve uncertainty in a dynamic setting. Provided we ignore some technical problems, the previous discussion can be easily extended to deal with stochastic problems.

Imagine that instead of a deterministic law of motion we have a stochastic law: $x_{t}$ and $u_{t}$ no longer determine the value of $x_{t+1}$, but only its probability distribution, described by a distribution function of the form $G\left(x_{t+1} ; x_{t}, u_{t}\right)$, where

$$
G\left(y ; x_{t}, u_{t}\right)=\operatorname{pr}\left(x_{t+1} \leq y \mid x_{t}, u_{t}\right)
$$

Agents now maximize expected utility. At time $t$, they choose $u_{t}$, not knowing for certain the value of next period's state. Whatever $x_{t+1}$ turns out to be, they will optimize from tomorrow on, obtaining a value of $V^{c}\left(x_{t+1}, t+1\right)$. From today's perspective, then, $u_{t}$ must be chosen so as to maximize the sum of the current return and the discounted value of the expectation of $V^{c}\left(x_{t+1}, t+1\right)$, computed using $G()$. Hence, the Bellman equation becomes

$$
V^{c}\left(x_{t}, t\right)=\max _{u_{t}}\left\{F_{t}\left(u_{t}, x_{t}\right)+\beta_{t} \int V^{c}\left(x_{t+1}, t+1\right) d G\left(x_{t+1} ; x_{t}, u_{t}\right)\right\}
$$

## (b) Some Results for Stationary Discounted Problems

In this section we will analyze in greater detail a class of infinite-horizon problems. Given a predetermined state vector $x_{t}$, a decision-maker faces the problem of maximizing the objective function

$$
W_{t}\left(\mathbf{z}_{t, \infty}\right)=\sum_{s=t}^{\infty} \beta^{s-t} F\left(x_{s}, u_{s}\right)
$$

with $\beta \in(0,1)$, over the set of feasible sequences $\mathbf{z}_{t, \infty}=\left\{u_{s}, x_{s+1}\right\} \in \Phi\left(x_{t}\right)$, where $x_{s+1}=m\left(x_{s}, u_{s}\right)$. We will assume that the series $W_{t}$ converges (although possibly to plus or minus infinity) for all feasible sequences $\mathbf{z}_{t, \infty}$ and that the feasibility constraints are of the form

$$
u_{s} \in \Gamma\left(x_{s}\right)
$$

where $\Gamma$ is a correspondence mapping points in $\mathbb{R}^{\mathrm{n}}$ into sets in $\mathbb{R}^{\mathrm{m}}$. The problem faced by the agent can then be written

$$
\begin{align*}
& V^{c}\left(x_{t}\right)=\max _{u_{t, \infty}}\left\{\sum_{s=t}^{\infty} \beta^{s-t} F\left(x_{s}, u_{s}\right)\right. \\
& \text { s.t. } \left.x_{s+1}=m\left(x_{s}, u_{s}\right), u_{s} \in \Gamma\left(x_{s}\right), x_{t} \text { given }\right\}
\end{align*}
$$

and the current value function $V^{c}\left(x_{t}\right)$ gives the maximum attainable value of the objective function whenever the problem has a solution. We know from our previous discussion that if the value function does exist, then it satisfies the Bellman equation:

$$
\begin{equation*}
V^{c}(x)=\max _{u \in \Gamma(x)}\left\{F(x, u)+\beta V^{c}(y) \text { s.t. } y=m(x, u)\right\} \tag{BE}
\end{equation*}
$$

The converse of this statement, however, is not necessarily true. The Bellman equation may have several solutions, and only one of them can be the value function for the programming problem. Hence, we need to establish conditions under which we can be sure that a given solution of (BE) is the value function we seek.

Theorem 1.3. Let the function $\mathrm{v}: \mathbb{R}^{n} \longrightarrow \mathbb{R}$ solve the Bellman equation $(B E)$ and satisfy the boundedness condition

$$
\begin{equation*}
\lim _{n \rightarrow \infty} \beta^{n} v\left(x_{n}\right)=0 \tag{0}
\end{equation*}
$$

for any sequence $\left\{\mathrm{x}_{\mathrm{n}}\right\}$ feasible from the initial state $\mathrm{x}_{\mathrm{t}}$. Suppose, moreover, that there exists a sequence $z_{t, \infty}^{*}=\mathrm{x}_{\mathrm{t}} \cup\left\{\mathrm{u}_{\mathrm{s}}^{*}, \mathrm{x}_{\mathrm{s}+1}^{*}\right\}$, where $\mathrm{u}_{\mathrm{s}}^{*}$ solves

$$
\begin{equation*}
\mathrm{v}\left(\mathrm{x}_{\mathrm{s}}\right)=\max _{\mathrm{u}_{\mathrm{s}} \in \Gamma\left(\mathrm{x}_{\mathrm{s}}\right)}\left\{\mathrm{F}\left(\mathrm{x}_{\mathrm{s}}, \mathrm{u}_{\mathrm{s}}\right)+\beta \mathrm{v}\left[\mathrm{m}\left(\mathrm{x}_{\mathrm{s}}, \mathrm{u}_{\mathrm{s}}\right)\right]\right\} \tag{BE.s}
\end{equation*}
$$

for each $\mathrm{s}$ and $\mathrm{x}_{\mathrm{s}+1}^{*}=\mathrm{m}\left(\mathrm{x}_{\mathrm{s}}^{*}, \mathrm{u}_{\mathrm{s}}^{*}\right)$. Then $\mathrm{v}$ is the current value function for the programming problem, and $\mathbf{z}_{i, \infty}^{*}$ solves (DP. $\infty$ ) .

Proof. To show that $v()$ is the value function for the programming problem, we need to show that for any given initial state $x_{t}$,

(i) $v\left(x_{t}\right) \geq W_{t}\left(\mathbf{z}_{t, \infty}\right)$ for any sequence $\mathbf{z}_{t, \infty} \in \Phi\left(x_{t}\right)$, and

(ii) there exists a sequence $\mathbf{z}_{\mathrm{t}, \infty}^{*} \in \Phi\left(x_{t}\right)$ such that $W_{t}\left(\mathbf{z}_{\lambda, \infty}^{*}\right)=v\left(x_{t}\right)$.

That is, $v\left(x_{t}\right)$ is an upper bound for the value of the problem over the set of feasible sequences, and there is a feasible sequence that attains this value.

Let $\mathbf{z}_{t, \infty}=x_{t} \cup\left\{u_{s}, x_{s+1} ; s \geq t\right\}$ be an arbitrary sequence feasible from $x_{t}$. Then, by (BE.s),

$$
\begin{align*}
v\left(x_{t}\right)= & \max _{u_{t} \in \Gamma\left(x_{t}\right)}\left\{F\left(x_{t}, u_{t}\right)+\beta v\left(x_{t+1}\right)\right\} \geq F\left(x_{t}, u_{t}\right)+\beta v\left(x_{t+1}\right) \\
& \geq F\left(x_{t}, u_{t}\right)+\beta\left[F\left(x_{t+1}, u_{t+1}\right)+\beta v\left(x_{t+2}\right)\right] \\
& \geq \ldots \geq \sum_{s=t}^{t+n} \beta^{s-t} F\left(x_{s}, u_{s}\right)+\beta^{n+1} v\left(x_{t+n+1}\right) \tag{3}
\end{align*}
$$

Taking the limit of this expression as $n \rightarrow \infty$, and using the boundedness condition $(0)$,

$$
v\left(x_{t}\right) \geq W_{t}\left(\mathbf{z}_{t, \infty}\right)+\lim _{n \rightarrow \infty} \beta^{n+1} v\left(x_{n+1}\right)=W_{t}\left(\mathbf{z}_{t, \infty}\right)
$$

for any feasible sequence $\mathbf{z}_{t, \infty}$. Hence, $v\left(x_{t}\right)$ is an upper bound for the value of the problem. Moreover, the sequence $\mathbf{z}_{t, \infty}^{*}=x_{t} \cup\left\{u_{s}^{*}, x_{s+1}^{*}\right\}$ of solutions to (BE.s) attains this value. Notice that by definition,

$$
v\left(x_{s}^{*}\right)=\max _{u_{s} \in \Gamma\left(x_{s}\right)}\left\{F\left(x_{s}^{*}, u_{s}\right)+\beta v\left[m\left(x_{s}^{*}, u_{s}\right)\right]\right\}=F\left(x_{s}^{*}, u_{s}^{*}\right)+\beta v\left(x_{s+1}^{*}\right)
$$

Hence, all the weak inequalities in (3) hold as equalities, and we conclude that

$$
v\left(x_{t}^{*}\right)=W_{t}\left(\mathbf{z}_{t, \infty}^{*}\right)
$$

which proves the theorem.

Theorem 1.3 says that if we can find a bounded solution to the Bellman equation, the original problem reduces to a sequence of static maximizations. There is, however, no assurance that such a solution will exist in all cases. Our next task is to identify conditions under which the Bellman equation has a unique bounded solution. The discussion relies heavily on the reader's familiarity with the concepts of a complete metric space and the contraction mapping theorem (for a review of this material, see Section 7 of Chapter 2).

We define the operator $T$ mapping real-valued functions into real-valued functions by

$$
T v(x)=\max _{u \in \Gamma(x)}\{F(x, u)+\beta v[m(x, u)]\}
$$

Then the Bellman equation can be written in the form

$$
V(x)=T V(x)
$$

Thus, we see that finding a solution to the Bellman equation is equivalent to finding a fixed point of the operator $T$. If we can show that under appropriate assumptions, $T$ is a contraction mapping a complete metric space into itself, we can invoke the contraction mapping theorem to establish the existence and uniqueness of an appropriate solution to (BE).

We recall from Chapter 2 (see Theorem 7.12) that the space $C(X)$ of bounded, continuous real-valued functions defined on a set $X$ in $\mathbb{R}^{\mathrm{n}}$ is a complete metric space under the sup norm, defined by

$$
\|f\|_{s}=\sup \{|f(x)| ; x \in X\}
$$

Next we will check that under certain continuity and boundedness restrictions on the objective function, the law of motion, and the constraint correspondence, the operator $T$ maps $C(X)$ into itself (i.e., $T$ maps continuous bounded functions into continuous bounded functions) and that $T$ is a contraction. By the contraction mapping theorem, it follows that $\left(\mathrm{BE}^{\prime}\right)$ has a unique bounded solution in $C(X)$ that, by Theorem 1.3 , is the value function we are seeking.

In what follows, we will make the following assumption.

Assumption 1.4. Continuity. The period return function $F$ is bounded and continuous, the law of motion $m$ is continuous, the constraint correspondence $\Gamma$ is continuous, ${ }^{2}$ and the set $\Gamma(x)$ is nonempty and compact for each $x$.

Under these conditions we can establish the following result.

Theorem 1.5. Suppose that Assumption 1.4 holds. Then $\mathrm{T}$ is an operator mapping continuous bounded functions into continuous bounded functions. Moreover $\mathrm{T}: \mathrm{C}(\mathrm{X}) \longrightarrow \mathrm{C}(\mathrm{X})$ is a contraction and therefore has a unique fixed point $\mathrm{V}$ in $\mathrm{C}(\mathrm{X})$. This $\mathrm{V}$ is the value function for the corresponding dynamic programming problem.

Moreover, under Assumption 1.4, the solution function for the maximization in $(B E)$ is the policy correspondence $\mathrm{g}()$ for the programming problem, giving the set of optimal values of the control $u$ as a function of the state, and $\mathrm{g}()$ is nonempty and uhc.

## Proof

- Let $v \in C(X)$. Under our assumptions, the maximization problem that defines the operator $T$,

$$
T v(x)=\max _{u \in \Gamma(x)}\{F(x, u)+\beta v[m(x, u)]\}
$$

is, for each $x$, that of maximizing a continuous function on a compact set. Hence, by the extreme-value theorem, a maximum exists, and $T v$ is well defined. Because
both $v$ and $F$ are bounded, $T v$ is also bounded; and because $F$ and $v$ are continuous and the constraint correspondence is continuous and compact-valued, the theorem of the maximum (Theorem 2.1 in Chapter 7) guarantees the continuity of $T v$. Hence, $T$ maps $C(X)$ into itself. Moreover, by the theorem of the maximum, the solution mapping for this maximization (i.e., the policy function $g(x)$ ), is a nonempty and uhc correspondence.

- To establish that $T$ is a contraction, we make use of Blackwell's sufficient conditions (see Theorem 7.19 in Chapter 2). We have to show that $T$ satisfies

(i) monotonicity: $\forall f, \mathrm{~g} \in C(X), f(x) \leq g(x) \forall X \Rightarrow T f(x) \leq T g(x)$, and

(ii) discounting: $\exists \beta \in(0,1)$ s.th. $\forall f \in C(X), x \in X, a \geq 0: T[f(x)+a] \leq T f(x)+\beta a$.

First, suppose that $w(y) \leq v(y)$ for all $y$ in $X$. Then for each $(x, u), w[m(x, u)] \leq$ $v[m(x, u)]$, and therefore

$$
T v(x)=\max _{u \in \Gamma(x)}\{F(x, u)+\beta v[m(x, u)]\} \geq \max _{u \in \Gamma(x)}\{F(x, u)+\beta w[m(x, u)]\}=T w(x)
$$

Thus, $T$ is monotone. Next, note that for any positive constant $a$, we have

$$
\begin{aligned}
T[v(x)+a] & =\max _{u \in \Gamma(x)}\{F(x, u)+\beta\{v[m(x, u)]+a\}\} \\
& =\max _{u \in \Gamma(x)}\{F(x, u)+\beta v[m(x, u)]\}+\beta a=T v(x)+\beta a
\end{aligned}
$$

Hence, $T$ discounts. Because it satisfies both of Blackwell's conditions, $T$ is a contraction.

- Because $T$ is a contraction on a complete metric space, it follows directly from the contraction mapping theorem (Theorem 7.15 in Chapter 2) that it has a unique fixed point $V$.
- By Theorem 1.3, the bounded continuous function $V$ is the value function for the corresponding dynamic programming problem. Moreover, the solution mapping for the maximum problem in the Bellman equation is the optimal policy correspondence.

It also follows from the contraction mapping theorem that if, starting with an arbitrary continuous and bounded function $V_{0}$, we define a sequence $\left\{V_{n}\right\}$ of functions by

$$
V_{n-1}=T V_{n}
$$

this sequence converges to the value function $V$. This fact can sometimes be used to find the value function.

Knowing when the Bellman equation has a unique bounded solution (i.e., when the value function is well defined) is an important first step, but one that is of little practical help. To go further we need to establish conditions under which $V$ will have certain desirable properties.

In the remainder of this section we will use the foregoing results relating the value function with the bounded solution of the Bellman equation to show that under reasonable restrictions on the period objective function $F$ and the constraints, the value function is strictly increasing and strictly
concave, and the policy correspondence is a continuous function. For this, we will rely on the following result: Recall that if $(X, d)$ is a complete metric space and $Y$ is a closed subset of $X$, then $(Y, d)$ is also a complete metric space (Theorem 7.9 in Chapter 2). Now suppose that $T: X \rightarrow X$ is a contraction in $X$ and, moreover, that $T$ maps $Y$ into itself. Then $T$ is also a contraction in $Y$, and it follows that the unique fixed point of $T$ on $X$ must be in $Y$. A slight twist on this result yields the following theorem.

Theorem 1.6. Let $(\mathrm{X}, \mathrm{d})$ be a complete metric space, and let $\mathrm{T}: \mathrm{X} \longrightarrow \mathrm{X}$ be a contraction with fixed point $\mathrm{v} \in \mathrm{X}$. Further, let $\mathrm{Y}$ be a closed subset of $\mathrm{X}$, and assume that $\mathrm{T}$ maps points in $\mathrm{Y}$ into some subset $\mathrm{Z}$ of $\mathrm{Y}$ (i.e., $\mathrm{T}: \mathrm{Y} \longrightarrow$ $\mathrm{Z})$. Then the unique fixed point $\mathrm{v}$ of $\mathrm{T}$ in $\mathrm{X}$ will be in $\mathrm{Z}$.

## Problem 1.7. Prove Theorem 1.6.

We will show that the set $N D(X)$ of nondecreasing bounded and continuous functions is a closed subset of $C(X)$ and that the operator $T$ in the Bellman equation maps nondecreasing functions into strictly increasing functions. It follows by Theorem 1.6 that the value function $V$ must be strictly increasing. A similar argument will allow us to establish strict concavity.

Lemma 1.8. Consider the normed vector space $\left[\mathrm{C}(\mathrm{X}),\|\cdot\|_{s}\right]$, where $\mathrm{C}(\mathrm{X})$ is the set of bounded continuous functions $\mathrm{f}: \mathbb{R}^{\mathrm{n}} \supseteq \mathrm{X} \longrightarrow \mathbb{R}$, with the sup norm $\|\mathrm{f}\|_{\mathrm{s}}=\sup (|\mathrm{f}(\mathrm{x})| ; x \in \mathrm{X}\}$. Let $\mathrm{ND}(\mathrm{X})$ be the set of nondecreasing bounded and continuous functions on $\mathrm{X}$. Then $\mathrm{ND}(\mathrm{X})$ is a closed subset of $\mathrm{C}(\mathrm{X})$.

Recall that a function $f: X \rightarrow \mathbb{R}$ is said to be nondecreasing if

$$
\forall x_{0}, x_{1} \in X, x_{1}>x_{0} \Rightarrow f\left(x_{1}\right) \geq f\left(x_{0}\right)
$$

and strictly increasing if

$$
\forall x_{0}, x_{1} \in X, x_{1}>x_{0} \Rightarrow f\left(x_{1}\right)>f\left(x_{0}\right)
$$

Proof. Let $\left\{f_{n}\right\}$ be a sequence of nondecreasing continuous functions convergent (in the sup norm and hence pointwise) to a function $f$ (which is bounded and continuous, by the completeness of $C(X)$ ). To establish that $N D(X)$ is a closed subset of $C(X)$, it suffices to show that $f$ is nondecreasing. Let $x_{0}$ and $x_{1}$ be arbitrary points in $X$ such that $x_{1}>x_{0}$, and consider the sequence of real numbers $\left\{f_{n}\left(x_{1}\right)-f_{n}\left(x_{0}\right)\right\}$. Because $\left\{f_{n}\right\} \rightarrow f,\left\{f_{n}\left(x_{1}\right)-f_{n}\left(x_{0}\right)\right\}$ converges to $f\left(x_{1}\right)-f\left(x_{0}\right)$, and because $f_{n}$ is nondecreasing, $f_{n}\left(x_{1}\right)-f_{n}\left(x_{0}\right) \geq 0$ for all $n$. Hence, we have a convergent sequence of nonnegative real numbers, and it follows that the limit of the sequence, $f\left(x_{1}\right)-f\left(x_{0}\right)$,
is nonnegative. This establishes that the limit function $f()$ is also nondecreasing.

Assumption 1.9. Monotonicity. Assume that $F()$ is strictly increasing in $x$, $m()$ is increasing in $x$, and the constraint correspondence $\Gamma()$ is increasing in the sense that

$$
x_{1} \geq x_{0} \Rightarrow \Gamma\left(x_{1}\right) \supseteq \Gamma\left(x_{0}\right)
$$

Lemma 1.10. Let $\mathrm{T}: \mathrm{C}(\mathrm{X}) \longrightarrow \mathrm{C}(\mathrm{X})$ be the operator defined by

$$
\operatorname{Tv}(\mathrm{x})=\max _{\mathrm{u} \in \Gamma(\mathrm{x})}\{\mathrm{F}(\mathrm{x}, \mathrm{u})+\beta \mathrm{v}[\mathrm{m}(\mathrm{x}, \mathrm{u})]\}
$$

and assume that Assumption 1.9 (monotonicity) holds. Then T maps nondecreasing functions into strictly increasing functions.

Problem 1.11. Prove Lemma 1.10.

Combining these two lemmas with Theorem 1.6, the following result is immediate.

Theorem 1.12. Suppose that Assumptions 1.4 and 1.9 (continuity and monotonicity) hold. Then the value function $\mathrm{V}$ is strictly increasing in the state $\mathrm{x}$.

To summarize, we know that under the continuity assumption the Bellman equation has a unique continuous and bounded solution $V$ that is the value function for the corresponding programming problem. This function can be characterized as a fixed point of an appropriately defined operator $T: C(X)$ $\longrightarrow C(X)$. We have shown that the set of nondecreasing bounded and continuous functions $N D(X)$ is a closed subset of $C(X)$ and that under Assumption 1.9, $T$ maps nondecreasing functions into strictly increasing functions. It follows that the value function must be strictly increasing. Intuitively, our assumptions ensure that an "increase" in the state is strictly desirable because it strictly increases the current return and does not reduce future opportunities.

We will now develop a very similar argument to show that under certain conditions, $V$ is strictly concave. Recall that a function $f$ is said to be (weakly) concave if

$$
\forall x_{0}, x_{1} \in X, \lambda \in[0,1],(1-\lambda) f\left(x_{0}\right)+\lambda f\left(x_{1}\right) \leq f\left[(1-\lambda) x_{0}+\lambda x_{1}\right]
$$

and strictly concave if

$$
\forall x_{0}, x_{1} \in X, \lambda \in(0,1),(1-\lambda) f\left(x_{0}\right)+\lambda f\left(x_{1}\right)<f\left[(1-\lambda) x_{0}+\lambda x_{1}\right]
$$

Lemma 1.13. Consider the normed vector space $\left[\mathrm{C}(\mathrm{X}),\|\cdot\|_{s}\right]$, where $\|\cdot\|_{s}$ is the sup norm, and assume $\mathrm{X}$ is a convex set. The set of (weakly) concave functions in $\mathrm{C}(\mathrm{X})$ is a closed subset of $\mathrm{C}(\mathrm{X})$.

Problem 1.14. Prove Lemma 1.13.

Assumption 1.15. Concavity. Assume that $F$ is strictly concave, $m$ is concave, for each $x$ the constraint set $\Gamma(x)$ is convex, and the constraint correspondence $\Gamma$ is convex in the sense that

$$
\begin{aligned}
& \forall x_{0}, x_{1} \in X, \lambda \in[0,1], u_{0} \in \Gamma\left(x_{0}\right), u_{1} \in \Gamma\left(x_{1}\right) \\
& \quad \Rightarrow(1-\lambda) u_{0}+\lambda u_{1} \in \Gamma\left[(1-\lambda) x_{0}+\lambda x_{1}\right]
\end{aligned}
$$

Lemma 1.16. Let $\mathrm{T}: \mathrm{C}(\mathrm{X}) \longrightarrow \mathrm{C}(\mathrm{X})$ be the operator defined by

$$
\operatorname{Tv}(\mathbf{x})=\max _{\mathrm{u} \in \Gamma(\mathbf{x})}\{\mathrm{F}(\mathrm{x}, \mathrm{u})+\beta \mathrm{v}[\mathrm{m}(\mathrm{x}, \mathrm{u})]\}
$$

and assume that the concavity and monotonicity assumptions hold. Then $\mathrm{T}$ maps weakly concave functions into strictly concave functions.

Problem 1.17. Prove Lemma 1.16.

Using Lemmas 1.13 and 1.16 and Theorem 1.6, it follows that under the continuity, monotonicity, and concavity assumptions, the value function $V$ is strictly concave.

Theorem 1.18. Suppose the continuity, monotonicity, and concavity assumptions hold. Then the value function $\mathrm{V}$ is strictly concave and strictly increasing, and the policy correspondence $\mathrm{g}($ ) is a continuous function.

Proof. The first part of the theorem is immediate. Moreover, we know by the maximum theorem and Theorem 1.5 that the optimal policy correspondence is uhc. Because any single-valued uhc correspondence is a continuous function (see Section 11 of Chapter 2), we need only establish that the solution $u^{*}$ to the maximization in the Bellman equation is unique, but this follows immediately by the strict concavity of $F$, the concavity of $m()$, and the concavity and monotonicity of $V$, all of which ensure that the objective function for the problem is strictly concave (in $(x, u)$ and therefore in $u$ alone).

Differentiability of the Value Function. The maximization in the Bellman equation is a static optimization problem that looks like an ordinary Lagrange or Kuhn-Tucker problem. Hence, one is tempted to write the Lagrangean function and differentiate it with respect to $u$ to obtain a set of first-order conditions and then proceed in the usual way (by applying the implicit-function theorem or differentiating implicitly the firstorder conditions) to establish the comparative-statics properties of the optimal policy function. This approach, however, presupposes that all the functions involved are twice differentiable, an assumption that generally is not valid.

The basic problem arises because the value function for the problem, $V($ ), appears also inside the maximization operator. Whereas we are free to make whatever assumptions we want about $m()$ and $F()$, the differentiability of $V()$ must be established rather than directly assumed. ${ }^{3}$ It can be shown that $V()$ will be (once or twice) differentiable for a certain class of problems, but not in general. ${ }^{4}$ As a result, the standard approach to studying the comparative-statics properties of maximization systems is not generally available for the case of dynamic programming problems.

## 2. Optimal Control

We now switch from discrete time to continuous time and develop the basic elements of optimal control theory. A central result of this section is a set of necessary conditions for an optimum in a certain class of dynamic optimization problems, the so-called maximum principle of Pontryagin. We will derive the maximum principle from a dynamic programming formulation. Roughly, we start with a discrete-time problem, apply the dynamic programming techniques discussed earlier, and consider what happens in the limit as the length of the period goes to zero.

The continuous-time analogue of the problem studied in the preceding section can be written

$$
\begin{align*}
V^{c}\left(x_{0}, 0\right)= & \max _{u(t), 0 \leq t \leq T}\left\{W_{0}\left(\left.u(t)\right|_{t=0} ^{T},\left.x(t)\right|_{t=0} ^{T}\right)=\int_{0}^{T} \alpha(t) F[u(t), x(t), t] d t\right. \\
& +\alpha(T) S[x(T)] \text { s.t. } x(0)=x_{0} \text { given, } \\
& \text { and } \dot{x}(t)=m[u(t), x(t), t]\} \tag{P.0}
\end{align*}
$$

where, as before, $x$ is the state vector, and $u$ the vector of control variables. The salvage or scrap function $S()$ is used to allow for the possibility that we may place some value on the state at the end of the planning horizon $T$ (which may or may not be finite). We will assume that the discount factor corresponding to period $t$ is of the form

$$
\alpha(t)=\exp \left(-\int_{0}^{t} \rho(s) d s\right)
$$

which reduces to the more familiar $e^{-\rho t}$ whenever the discount rate $\rho$ is constant over time. ${ }^{5}$ The notation $x(t)$ indicates that the state is a function of time. For convenience, we will often replace this functional notation by the subscript notation $x_{t}$ to indicate dependence on time, or omit the $t$ 's when they are not particularly needed. We will often treat $x$ and $u$ as if they were single variables, but the reader should keep in mind that they are vectors.

The problem is similar to the one analyzed in Section 1 except that the planner now must choose a control trajectory (i.e., a function of time, $u(t)$, defined for $t \in[0, T]$, that describes the values of the instruments at each point in time), rather than a control sequence $\left\{u_{t}\right\}_{t=0}^{T-1}$. Given a control path $\left.u^{0}(t)\right|_{t=0} ^{T}$, the corresponding trajectory of the state vector, $\left.x^{0}(t)\right|_{t=0} ^{T}$, is determined by the law of motion, $\dot{x}_{t}=m(u, x, t)$, and the initial condition $x(0)=x_{0}$. Evaluating $W_{0}$, we obtain the value of the given trajectories,

$W_{0}\left(\left.u^{0}(t)\right|_{t=0} ^{T},\left.x^{0}(t)\right|_{t=0} ^{T}\right)$. Our goal is to characterize the time paths of $u$ and $x$ that will yield the largest possible value for the objective function. This will be achieved by transforming the dynamic maximization problem (P.0) into a combination of two more familiar problems: a static maximization at each point in time, and a system of ordinary differential equations.

## (a) The Maximum Principle

We begin with an intuitive discussion of the logic of the maximum principle. At each point in time $t$ the planner finds herself with some predetermined value of the state $x_{t}$ and must choose a control vector $u_{t}$ that will determine both the immediate payoff $F_{t}()$ and the rate of change of the state variables $\dot{x}_{t} \cdot{ }^{6}$ Current decisions, therefore, have two effects on total value: an immediate one through $F_{t}()$, and an indirect one through the induced change in $x$. Clearly, a control chosen to maximize just the current return is unlikely to be optimal. We need some way to take into account the effects of current decisions on future opportunities. Intuitively, the maximum principle achieves this by attaching a price to the stocks of state variables.

The idea is to introduce a modified objective function that will add to the immediate return the value of the change in the state vector due to current decisions. To this end, we introduce a new set of variables $q_{i}$, one for each component of the state vector. These variables, known as multipliers or costate variables, can be interpreted as the prices associated with the state variables. The modified objective function, known as the current-value Hamiltonian, is then defined as

$$
H_{t}^{c}=H^{c}\left(u_{t}, x_{t}, q_{t}, t\right) \equiv F_{t}\left(u_{t}, x_{t}\right)+q_{t} m_{t}\left(u_{t}, x_{t}\right)=F_{t}()+q_{t} \dot{x}_{t}
$$

The first component of the Hamiltonian is $F_{t}\left(u_{t}, x_{t}\right)$, the current flow return (utility, profit) to the decision-maker. The second term, $q_{t} \dot{x}_{t}$, measures the increase in value due to the change in the state variables. Thus, we can think of $H^{c}$ as the sum of the immediate payoff from $(x, u)$ plus the value of the future gains to accrue from the "investment in the future" represented by the change in the state variable.

In view of the foregoing discussion, it seems plausible that, given the correct shadow prices, maximization of the Hamiltonian will yield the optimal choice of instruments at each point in time. If $H^{c}$ is a differentiable function of $u$, a necessary condition for an optimum is

$$
\frac{\partial H_{t}^{c}}{\partial u_{t}}=0 \Rightarrow \frac{\partial F_{t}\left(u_{t}, x_{t}\right)}{\partial u_{t}}+q_{t} \frac{\partial m_{t}\left(u_{t}, x_{t}\right)}{\partial u_{t}}=0
$$

That is, the decision-maker must balance immediate gains from a higher $u$ against the value loss stemming from the reduction of future opportunities that the correspondingly lower future $x$ entails.

The procedure is in some ways analogous to the method of Lagrange multipliers used to solve static optimization problems with side constraints. In both cases, the idea is to reduce a more complicated problem to an unconstrained maximization by introducing a set of prices to give the decisionmaker the right incentives. As in the Lagrange case, this leaves us with the problem of making sure the shadow prices are set correctly (i.e., that they truly reflect the marginal contribution of the state variables to the agent's total payoff). One way to ensure this is simply to define the multipliers as the partial derivatives of the value function with respect to the corresponding state variables,

$$
q_{t} \equiv \frac{\partial V^{c}(x, t)}{\partial x_{t}}
$$

As we will see, this implies that the evolution of the costate variables over time is described by the system

$$
\begin{equation*}
-\frac{\partial H_{t}^{c}}{\partial x_{t}}=\dot{q}_{t}-\rho_{t} q_{t} \tag{1}
\end{equation*}
$$

The law of motion for the shadow prices can be interpreted as a noarbitrage or asset-valuation equation. Observe that the derivative of the Hamiltonian with respect to the state variables,

$$
\frac{\partial H_{t}^{c}}{\partial x_{t}}=\frac{\partial F_{t}\left(u_{t}, x_{t}\right)}{\partial x_{t}}+q_{t} \frac{\partial m_{t}\left(u_{t}, x_{t}\right)}{\partial x_{t}}
$$

measures the marginal yield of the "asset" $x$, given by the sum of its current marginal return $\partial F_{t} / \partial x_{t}$ and its contribution to the increase in the stock of $x$ valued at its shadow price $q$. Rearranging (1), we obtain

$$
\begin{equation*}
\frac{\partial H_{t}^{c} / \partial x_{t}+\dot{q}_{t}}{q_{t}}=\rho_{t} \tag{2}
\end{equation*}
$$

The left-hand side of this expression is the instantaneous rate of return on the asset $x$, given by the ratio of its total return (the sum of its "dividend" $\partial H_{t}^{c} / \partial x_{t}$ and capital gains $\left.\dot{q}_{t}\right)$ to its current price $q_{t}$. The right-hand side is the instantaneous discount rate (the "utility interest rate"). Equation (2) requires that the marginal yield on "asset $x$ " be equal to the required rate of return, $\rho_{t}$, signaling the impossibility of further gains from a change in asset holdings. This ensures that the asset is correctly valued.

We can now give a more formal statement of the result. We seek to characterize the solution to the problem

$$
\begin{align*}
V^{c}\left(x_{0}, 0\right)= & \max _{u(t), 0 \leq t \leq T}\left\{W_{0}\left(\left.u(t)\right|_{t=0} ^{T},\left.x(t)\right|_{t=0} ^{T}\right)=\int_{0}^{T} \alpha(t) F[u(t), x(t), t] d t\right. \\
& \left.+\alpha(T) S[x(T)] \text { s.t. } x(0)=x_{0} \text { given, } \dot{x}(t)=m[u(t), x(t), t]\right\} \tag{P.0}
\end{align*}
$$

We will assume that the functions $F(u, x, t)$ and $m(u, x, t)$ are continuously differentiable with respect to the state vector $x$. Control trajectories $u(t)$ will be required to be piecewise-continuous functions of time, with at most a finite number of discontinuities in any bounded interval, and to have both right- and left-hand-side limits at any points of discontinuity. Under these assumptions, necessary conditions for an optimum are given by the following theorem.

Theorem 2.1. Pontryagin's maximum principle. Let $\mathrm{u}^{*}(\mathrm{t})$, with $\mathrm{t} \in[0, \mathrm{~T}]$, be the time path of the control vector that solves the problem (P.0). Then there exist continuous functions of time $\mathrm{q}(\mathrm{t})$ such that for each $\mathrm{t} \in[0, \mathrm{~T}]$,

(i) the control maximizes the current-value Hamiltonian,

$$
\mathrm{u}_{\mathrm{t}}^{*}=\arg \max _{\mathrm{u}} \mathrm{H}^{\mathrm{c}}(\mathrm{u}, \mathrm{x}, \mathrm{q}, \mathrm{t})=\arg \max _{\mathrm{u}}\{\mathrm{F}(\mathrm{x}, \mathrm{u}, \mathrm{t})+\mathrm{qm}(\mathrm{x}, \mathrm{u}, \mathrm{t})\}
$$

(ii) the law of motion of the state vector holds,

$$
\begin{equation*}
\dot{\mathrm{x}}(\mathrm{t})=\mathrm{m}\left[\mathrm{u}^{*}(\mathrm{t}), \mathrm{x}(\mathrm{t}), \mathrm{t}\right] \tag{3}
\end{equation*}
$$

(iii) and the functions $\mathrm{q}(\mathrm{t})$ satisfy the differential equations

$$
\begin{equation*}
-\frac{\partial H_{t}^{c}}{\partial x_{t}}=\dot{q}_{t}-\rho_{t} q_{t} \tag{4}
\end{equation*}
$$

Given an admissible control path, $m[u(t), x(t), t]$ is a piecewisecontinuous function of time. Thus the state trajectory, given by

$$
x(t)=x(0)+\int_{0}^{t} m[u(s), x(s), s] d s
$$

is continuous and piecewise-differentiable. The same is true of the time paths of the costate variables $q(t)$. The time derivatives of both $q(t)$ and $x(t)$ may be discontinuous at points of discontinuity of the controls. At such points, however, (3) and (4) will still hold for both left and right time derivatives.

We will now give a heuristic derivation of this result based on a dynamic programming approach. To simplify things a bit, we consider the case in which the discount rate is constant over time,

$$
\begin{align*}
& V^{c}\left(x_{0}, 0\right)=\max _{u(t) ; 0 \leq t \leq T}\left\{\int_{0}^{T} e^{-\rho t} F[u(t), x(t), t] d t+e^{-\rho T} S[x(T)]\right. \\
& \text { s.t. } \left.x(0)=x_{0} \text { given, } \dot{x}(t)=m[u(t), x(t), t]\right\} \tag{P.1}
\end{align*}
$$

and assume that the value function and the time paths of the controls are differentiable functions (as they will be in most applications we are likely to encounter). We begin by constructing a convenient discrete-time analogue of (P.1). Time is now measured in discrete periods of length $h$, and the oneperiod discount rate is of the form $\beta(h)=e^{-\rho h}$. At the beginning of the period starting at $t$, the planner chooses the value of the control $u_{t}$, which remains constant over the interval $[t, t+h)$. The function $F_{t}\left(u_{t}, x_{t}\right)$ now measures the instantaneous flow of value, and the total return from $\left(u_{t}, x_{t}\right)$ over a period of length $h$ is given by $h F_{t}\left(u_{t}, x_{t}\right)$ in current-value terms. The state and control vectors determine next period's state in accordance with the law of motion, $x_{t+h}=x_{t}+h m_{t}\left(x_{t}, u_{t}\right)$. The planner, then, solves

$$
\begin{aligned}
V^{c}\left(x_{0}, 0\right)= & \max _{u_{0}, x-1}\left\{\sum_{t=0}^{T-1} \beta(h)^{t} h F_{t}\left(x_{t}, u_{t}\right)+\beta(h)^{T} S\left(x_{T}\right)\right. \\
& \text { s.t. } \left.x_{t+h}=x_{t}+h m_{t}\left(x_{t}, u_{t}\right), x_{0} \text { given }\right\}
\end{aligned}
$$

The Bellman equation for this problem can be written

$$
\begin{equation*}
V^{c}\left(x_{t}, t\right)=\max _{u_{t}}\left\{h F_{t}\left(x_{t}, u_{t}\right)+\beta(h) V^{c}\left[x_{t}+h m_{t}\left(x_{t}, u_{t}\right), t+h\right]\right\} \tag{5}
\end{equation*}
$$

If the value function is differentiable, the first-order condition for the maximization in (5) is given by

$$
h \frac{\partial F_{t}\left(u_{t}, x_{t}\right)}{\partial u_{t}}+\beta(h) \frac{\partial V^{c}\left(x_{t+h}, t+h\right)}{\partial x_{t+h}} \frac{\partial x_{t+h}}{\partial u_{t}}=0
$$

which describes the optimal trade-off between current and future values. Recalling that the multiplier is defined as the partial derivative of the value function with respect to the state, $q_{t} \equiv \partial V^{c}(x, t) / \partial x_{t}$, and using the law of motion to calculate $\partial x_{t+h} / \partial u_{t}$, we obtain

$$
h \frac{\partial F_{t}\left(u_{t}, x_{t}\right)}{\partial u_{t}}+\beta(h) q_{t+h} h \frac{\partial m_{t}\left(u_{t}, x_{t}\right)}{\partial u_{t}}=0
$$

Dividing by $h$ and taking limits as $h$ goes to zero, we arrive at the necessary condition for the control to maximize the Hamiltonian,

$$
\frac{\partial H_{t}^{c}}{\partial u_{t}}=\frac{\partial F_{t}\left(u_{t}, x_{t}\right)}{\partial u_{t}}+q_{t} \frac{\partial m_{t}\left(u_{t}, x_{t}\right)}{\partial u_{t}}=0
$$

Next, we compute the partial derivative that defines the costate variable. Using the envelope theorem in (5), and operating as before,

$$
\begin{aligned}
q_{t} & =\frac{\partial V^{c}\left(x_{t}, t\right)}{\partial x_{t}}=h \frac{\partial F_{t}\left(u_{t}, x_{t}\right)}{\partial x_{t}}+\beta(h) \frac{\partial V^{c}\left(x_{t+h}, t+h\right)}{\partial x_{t+h}} \frac{\partial x_{t+h}}{\partial x_{t}} \\
& =h \frac{\partial F_{t}\left(u_{t}, x_{t}\right)}{\partial x_{t}}+\beta(h) q_{t+h}\left(1+h \frac{\partial m_{t}\left(x_{t}, u_{t}\right)}{\partial x_{t}}\right)
\end{aligned}
$$

Subtracting $\beta q_{t}$ from both sides of this expression,

$$
[1-\beta(h)] q_{t}=h \frac{\partial F_{t}\left(u_{t}, x_{t}\right)}{\partial x_{t}}+\beta(h)\left(q_{t+h}-q_{t}\right)+\beta(h) q_{t+h} h \frac{\partial m_{t}\left(x_{t}, u_{t}\right)}{\partial x_{t}}
$$

dividing by $h$,

$$
\frac{1-\beta(h)}{h} q_{t}=\frac{\partial F_{t}\left(u_{t}, x_{t}\right)}{\partial x_{t}}+\beta(h) q_{t+h} \frac{\partial m_{t}\left(x_{t}, u_{t}\right)}{\partial x_{t}}+\beta(h) \frac{q_{t+h}-q_{t}}{h}
$$

and taking the limit as $h$ goes to zero, we obtain the equation of motion for the costate variables:

$$
\rho q_{t}=\frac{\partial F_{t}\left(u_{t}, x_{t}\right)}{\partial x_{t}}+q_{t} \frac{\partial m_{t}\left(u_{t}, x_{t}\right)}{\partial x_{t}}+\dot{q}_{t} \Leftrightarrow-\frac{\partial H_{t}^{c}}{\partial x_{t}}=\dot{q}_{t}-\rho q_{t}
$$

The maximum principle allows us to transform the original dynamic optimization problem into a combination of two more familiar problems. The maximization of the current-value Hamiltonian at each point in time yields a policy function,

$$
\begin{equation*}
u_{t}^{*}=g\left(x_{t}, q_{t}, t\right)=\arg \max _{u}\left\{H^{c}(u, x, q, t)=F(x, u, t)+q m(x, u, t)\right\} \tag{6}
\end{equation*}
$$

giving the optimal control as a function of the contemporaneous values of the state and costate vectors and time. ${ }^{7}$ Substituting this function into the other necessary conditions, we eliminate $u_{t}$ and obtain a system of differential equations in the state and costate variables:

$$
\begin{gather*}
\dot{x}(t)=m\left[g\left(x_{t}, q_{t}, t\right), x_{t}, t\right]  \tag{7}\\
\dot{q}_{t}-\rho_{t} q_{t}=-\frac{\partial H_{t}^{c}\left[g\left(x_{t}, q_{t}, t\right), q_{t}, x_{t}, t\right]}{\partial x_{t}} \tag{8}
\end{gather*}
$$

The solution of the dynamic optimization problem will then be one of the solutions of this system that satisfy the initial condition $x(0)=x_{0}$ given. Notice, however, that if the state vector is of dimension $n$, then (7)-(8) is a system of $2 n$ equations in as many variables, and we have only $n$ initial conditions (corresponding to the initial values of the state variables). To determine which of the solutions of the dynamical system solves the original problem, we need some additional conditions, as discussed in the following section.

## (b) Transversality and Sufficient Conditions

The additional restrictions needed to identify the optimal path often take the form of terminal conditions on the multipliers, sometimes called transversality conditions. The simplest case is that of the finite-horizon problem with a scrap function, that is, maximization of

$$
\int_{0}^{T} \alpha(t) F[u(t), x(t), t] d t+\alpha(T) S[x(T)]
$$

subject to the usual conditions. Notice that the current value function at the end of the planning horizon is now simply

$$
V^{c}\left(x_{T}, T\right)=S\left(x_{T}\right)
$$

Because the costate vector is defined as the derivative of the value function with respect to the state, the appropriate terminal condition is

$$
q_{T}=D S\left(x_{T}\right)
$$

In many cases of interest there is no scrap function, but it may be natural to impose some restrictions on the terminal value of the state vector. A finitely-lived consumer, for example, (see footnote 5) may not derive any utility from leaving a bequest to his children, but it seems reasonable to require his terminal wealth to be nonnegative or, equivalently, to impose the constraint that the discounted value of his consumption stream should not
exceed the present value of his lifetime income. In this case, the objective function reduces to

$$
\int_{0}^{T} \alpha(t) F[u(t), x(t), t] d t
$$

but we have as an additional constraint the nonnegativity condition $x_{T} \geq 0$. To derive the appropriate transversality condition, let us go back to the artificial discrete-time problem we used to derive the maximum principle,

$V^{c}\left(x_{0}, 0\right)=\max _{u_{0, T-1}}\left\{\sum_{t=0}^{T-1} \beta(h)^{t} h F_{t}\left(x_{t}, u_{t}\right)\right.$ s.t. $x_{t+h}=x_{t}+h m_{t}\left(x_{t}, u_{t}\right), x_{0}$ given, $\left.x_{T} \geq 0\right\}$

and consider the subproblem corresponding to the choice of the last control, $u_{T-h}$

$$
V^{c}\left(x_{T-h}, T-h\right)=\max _{u_{T-h}}\left\{h F_{T-h}\left(x_{T-h}, u_{T-h}\right) \text { s.t. } x_{T}=x_{T-h}+h m_{T-h}\left(x_{T-h}, u_{T-h}\right) \geq 0\right\}
$$

This is an ordinary Kuhn-Tucker problem. Forming the Lagrangian,

$$
£=h F_{T-h}\left(x_{T-h}, u_{T-h}\right)+\lambda\left[x_{T-h}+h m_{T-h}\left(x_{T-h}, u_{T-h}\right)\right]
$$

the necessary conditions for the optimal choice of $u_{T-h}$ can be written

$$
\begin{gathered}
\frac{\partial £}{\partial u_{T-h}}=0 \Rightarrow \frac{\partial F_{T-h}\left(x_{T-h}, u_{T-h}\right)}{\partial u_{T-h}}+\lambda \frac{\partial m_{T-h}\left(x_{T-h}, u_{T-h}\right)}{\partial u_{T-h}}=0 \\
x_{T} \geq 0, \quad \text { with equality if } \lambda>0 \\
\lambda \geq 0, \quad \text { with equality if } x_{T}>0
\end{gathered}
$$

Moreover, the envelope theorem yields

$$
\begin{aligned}
q_{T-h} & =\frac{\partial V^{c}\left(x_{T-h}, T-h\right)}{\partial x_{T-h}}=\frac{\partial £}{\partial x_{T-h}} \\
& =h \frac{\partial F_{T-h}\left(x_{T-h}, u_{T-h}\right)}{\partial x_{T-h}}+\lambda\left(1+h \frac{\partial m_{T-h}\left(x_{T-h}, u_{T-h}\right)}{\partial x_{T-h}}\right)
\end{aligned}
$$

Taking the limit of this expression as $h \rightarrow 0$, we obtain $q_{T}=\lambda$. Hence, the last two necessary conditions can be written

$$
\begin{equation*}
x_{T} \geq 0, \quad q_{T} \geq 0, \quad \text { and } \quad q_{T} x_{T}=0 \tag{T.1}
\end{equation*}
$$

Thus the transversality condition is essentially the complementary slackness condition for a Kuhn-Tucker problem. It says that if we are going to "leave something at the end," that something must be worthless, and if it is not worthless, then we will leave nothing. In any case, the value of the terminal state, $q_{T} x_{T}$, must be zero.

As an illustration, consider once more the problem of a nonaltruistic consumer who maximizes the discounted value of lifetime utility subject to a flow budget constraint and the restriction that terminal wealth be nonnegative:

$$
\max \int_{0}^{T} e^{-\rho t} U\left(c_{t}\right) d t \text { s.t. } \dot{a}_{t}=r_{t} a_{t}+y_{t}-c_{t} \text { and } a_{T} \geq 0
$$

It is easily shown that in this problem the current-value multiplier is the marginal utility of consumption, $q_{t}=U^{\prime}\left(c_{t}\right)$. The transversality condition now requires that terminal wealth be positive only if the agent is satiated, that is, if $q_{T}=U^{\prime}\left(c_{T}\right)=0$, and that $a_{T}$ be zero whenever the marginal utility of terminal consumption is strictly positive.

The following proposition gives the necessary conditions for an optimal solution of the finite-horizon problem with nonnegativity terminal constraints on the states. The maximum principle still holds.

Theorem 2.2. Maximum principle and transversality conditions, finite horizon. Let $\mathrm{u}^{*}(\mathrm{t}), \mathrm{t} \in[0, \mathrm{~T}]$, be the time path of the control vector that solves the problem

$$
\begin{array}{r}
\mathrm{V}^{\mathrm{c}}\left(\mathrm{x}_{0}, 0\right)=\max _{\mathrm{u}(\mathrm{t}) ; 0 \leq \mathrm{t} \leq \mathrm{x}}\left\{\int_{0}^{\mathrm{T}} \alpha(\mathrm{t}) \mathrm{F}[\mathrm{u}(\mathrm{t}), \mathrm{x}(\mathrm{t}), \mathrm{t}] \mathrm{dt} \text { s.t. } \mathrm{x}_{\mathrm{T}} \geq 0,\right. \\
\left.\mathrm{x}(0)=\mathrm{x}_{0} \text { given, } \dot{\mathrm{x}}(\mathrm{t})=\mathrm{m}[\mathrm{u}(\mathrm{t}), \mathrm{x}(\mathrm{t}), \mathrm{t}]\right\} \tag{P.0}
\end{array}
$$

where $\alpha(\mathrm{t})=\exp \left(-\int_{0}^{\mathrm{t}} \mathrm{\rho}(\mathrm{s}) \mathrm{ds}\right)$. Then there exist costate variables $\mathrm{q}(\mathrm{t})$, continuous functions of time, such that for each $t$,

(i) the control maximizes the current-value Hamiltonian,

$$
\mathrm{u}_{\mathrm{t}}^{*}=\arg \max _{\mathrm{u}} \mathrm{H}^{\mathrm{c}}(\mathrm{u}, \mathrm{x}, \mathrm{q}, \mathrm{t})=\arg \max _{\mathrm{u}}\{\mathrm{F}(\mathrm{x}, \mathrm{u}, \mathrm{t})+\mathrm{qm}(\mathrm{x}, \mathrm{u}, \mathrm{t})\}
$$

(ii) the law of motion of the state vector holds,

$$
\dot{\mathrm{x}}(\mathrm{t})=\mathrm{m}\left[\mathrm{u}^{*}(\mathrm{t}), \mathrm{x}(\mathrm{t}), \mathrm{t}\right]
$$

(iii) the functions $\mathrm{q}(\mathrm{t})$ satisfy the differential equations

$$
-\frac{\partial \mathrm{H}_{\mathrm{t}}^{\mathrm{c}}}{\partial \mathrm{x}_{\mathrm{t}}}=\dot{\mathrm{q}}_{\mathrm{t}}-\rho_{\mathrm{t}} \mathrm{q}_{\mathrm{t}}
$$

(iv) and the transversality conditions

$$
\begin{equation*}
\mathrm{q}_{\mathrm{T}} \geq 0 \quad \text { and } \quad \mathrm{q}_{\mathrm{T}} \mathbf{x}_{\mathrm{T}}=0 \tag{T.1}
\end{equation*}
$$

The conditions we have derived thus far are necessary conditions for an optimum. To be certain that they characterize a maximum, we need sufficient
or "second-order" conditions, which, as in the case of static optimization problems, often take the form of concavity assumptions.

Theorem 2.3. Sufficient conditions for an optimal path. Assume that the maximized Hamiltonian,

$$
\tilde{\mathrm{H}}(\mathrm{x}, \mathrm{q}, \mathrm{t})=\max _{\mathrm{u}}\left\{\mathrm{H}^{\mathrm{c}}(\mathrm{x}, \mathrm{u}, \mathrm{q})=\mathrm{F}_{\mathrm{t}}(\mathrm{x}, \mathrm{u}, \mathrm{t})+\mathrm{q}_{\mathrm{t}} \mathrm{m}_{\mathrm{t}}(\mathrm{x}, \mathrm{u})\right\}
$$

is a concave function of $\mathrm{x}$ for given $\mathrm{q}$ and $\mathrm{t}$. Then any policy satisfying the necessary conditions specified in Theorem 2.2 (i.e., the Pontryagin and transversality conditions) is optimal for the finite-horizon problem with terminal constraint $\mathbf{x}_{\mathrm{T}} \geq 0$.

Observe that $\tilde{H}$ will be concave in $x$ provided that $F()$ and $m()$ are concave in $(x, u)$, but weaker conditions will suffice.

Proof. Let $u_{t}^{*}$ be a policy satisfying the necessary conditions for a solution to the control problem, and $\left(x_{i}^{*}, q_{i}^{*}\right)$ the corresponding paths of the state and costate vectors. Let $u_{t}$ be any other feasible policy, and $x_{t}$ the corresponding path of the state. We will show that the time path $\left(u_{t}^{*}, x_{t}^{*}\right)$ yields a greater value than any other feasible trajectory.

For any given $(q, x)$, we have (omitting the time subscripts)

$$
\begin{equation*}
\tilde{H}(x, q)=\max _{u} H^{c}(x, u, q)=H^{c}\left(u^{0}, x, q\right) \geq H^{c}(u, x, q) \text { for any } u \tag{1}
\end{equation*}
$$

where $u^{0}$ is the optimal choice of instruments given $(q, x)$. By the assumption that $\tilde{H}(x, q)$ is concave in $x$ for given $q$ (and $t$ ), we can write

$$
\begin{equation*}
\tilde{H}\left(x, q^{*}\right) \leq \tilde{H}\left(x^{*}, q^{*}\right)+D_{x} \tilde{H}\left(x^{*}, q^{*}\right)\left(x-x^{*}\right) \tag{2}
\end{equation*}
$$

for any $x$. From (1), moreover,

$\tilde{H}\left(x, q^{*}\right) \geq H^{c}\left(u, x, q^{*}\right)$ for any $u$, and $\tilde{H}\left(x^{*}, q^{*}\right)=H^{c}\left(x^{*}, u^{*}, q^{*}\right)$

Using (3), (2) implies

$$
\begin{equation*}
H^{c}\left(u, x, q^{*}\right) \leq H^{c}\left(x^{*}, u^{*}, q^{*}\right)+D_{x} \tilde{H}\left(x^{*}, q^{*}\right)\left(x-x^{*}\right) \tag{3}
\end{equation*}
$$

from where

$$
\begin{equation*}
F\left(u^{*}, x^{*}\right)-F(u, x) \geq q^{*}\left(\dot{x}-\dot{x}^{*}\right)-D_{x} \tilde{H}\left(x^{*}, q^{*}\right)\left(x-x^{*}\right) \tag{4}
\end{equation*}
$$

Next, using the envelope theorem in (1) and the necessary conditions for an optimal path,

$$
-D_{x} \tilde{H}\left(x^{*}, q^{*}\right)=-D_{x} H^{c}\left(x^{*}, q^{*}, u^{*}\right)=\dot{q}-\rho q
$$

Substituting this expression into (4) and multiplying both sides by the discount factor $\alpha(t)$,

$$
\begin{equation*}
\alpha(t)\left[F\left(u^{*}, x^{*}\right)-F(u, x)\right] \geq \alpha(t) q^{*}\left(\dot{x}-\dot{x}^{*}\right)+\alpha(t)(\dot{q}-\rho q)\left(x-x^{*}\right) \tag{5}
\end{equation*}
$$

We observe that the expression on the right-hand side of (5) is the derivative of $\alpha(t) q_{t}\left(x_{t}-x_{t}^{*}\right)$ with respect to time. ${ }^{8}$ Integrating both sides of the inequality from $t=0$ to $T$,

$$
\begin{align*}
& \int_{0}^{T} \alpha(t)\left[F_{t}\left(u^{*}, x^{*}\right)-F(u, x)\right] d t \geq \int_{0}^{T} \frac{d}{d t}\left(\alpha(t) q_{t}^{*}\left(x_{t}-x_{t}^{*}\right)\right) d t \\
& \quad=\alpha(T) q_{T}^{*}\left(x_{T}-x_{T}^{*}\right)-\alpha(0) q_{0}^{*}\left(x_{0}-x_{0}^{*}\right) \tag{6}
\end{align*}
$$

The last term in this expression vanishes, as the given initial value of the state must be the same for any feasible trajectory. Using the transversality conditions

$$
\begin{equation*}
q_{T}^{*} \geq 0 \quad \text { and } \quad q_{T}^{*} x_{T}^{*}=0 \tag{T.1}
\end{equation*}
$$

and the terminal constraint $x_{T} \geq 0$, (6) implies the desired result:

$$
\int_{0}^{T} \alpha(t)\left[F_{t}\left(u^{*}, x^{*}\right)-F(u, x)\right] d t \geq \alpha(T) q_{T}^{*} x_{T} \geq 0
$$

That is, the path $\left[x^{*}(t), u^{*}(t)\right]$ that satisfies the Pontryagin and transversality conditions provides a greater return than any other feasible trajectory and is therefore optimal.

## Infinite Horizon

It is often convenient (and not a bad approximation) to assume that the planning horizon is infinite. Infinite-horizon problems, however, pose some new problems. First, the objective functional, now given by the improper integral

$$
\int_{0}^{\infty} \alpha(t) F[u(t), x(t), t] d t=\lim _{T \rightarrow \infty} \int_{0}^{T} \alpha(t) F[u(t), x(t), t] d t
$$

may not converge. Even if it does, moreover, there is no guarantee that an optimal control path will exist. If it does exist, however, the necessary conditions derived earlier are still valid. The one exception to this has to do with the transversality conditions, which can no longer be derived from a terminal condition on $x$. On the other hand, the proof of the sufficiency theorem (Theorem 2.3) will still go through provided that we replace (T.1) with

$$
\begin{equation*}
\lim _{t \rightarrow \infty} \alpha(t) q_{t} \geq 0 \text { and } \quad \lim _{t \rightarrow \infty} \alpha(t) q_{t} x_{t}=0 \tag{T.2}
\end{equation*}
$$

Thus, the transversality conditions may no longer be necessary for an optimum, but they still have a role as sufficient conditions. That is, they may not hold, but if they do hold for a given path $u^{*}(t)$, and if the maximized Hamiltonian is concave in $x$, then that path is optimal.

The transversality conditions at infinity (T.2) can be seen as natural extensions of those for the finite-horizon problem. Recall that (T.1) can be interpreted as the complementary slackness condition associated with a nonnegativity restriction on the terminal state. It tells us that the current value of the terminal state, evaluated using its shadow price, must be zero (i.e., that nothing valuable should be left at the end of the planning period). Because we no longer have a terminal date, we can make no such argument. However, the condition that the value of the state be asymptotically nonnegative still makes sense in many cases. For example, in the consumer optimization problem that we have been using as an illustration, such a constraint is equivalent to the requirement that the discounted value of the agent's consumption not exceed the present value of her income. Intuitively speaking, (T.2) can be used to impose this type of constraint. The main change from the finite-horizon case is that now we must consider the discounted value of the state, $\alpha(t) q_{t} x_{t}$, whereas in the finite-horizon case it made no difference whether we worked in current or in discounted value terms. We summarize in the following.

Theorem 2.4. Maximum principle and sufficient conditions, infinite horizon. Let $\mathrm{u}^{*}(\mathrm{t}), \mathrm{t} \in[0, \mathrm{~T}]$, be the time path of the control vectors that solves the problem

$$
\begin{gather*}
\mathrm{V}^{\mathrm{c}}\left(\mathrm{x}_{0}, 0\right)=\max _{\mathrm{u}(\mathrm{t}) ; 0 \leq \mathrm{i} \leq \infty}\left\{\int_{0}^{\infty} \alpha(\mathrm{t}) \mathrm{F}[\mathrm{u}(\mathrm{t}), \mathrm{x}(\mathrm{t}), \mathrm{t}] \mathrm{dt}\right. \text { s.t. } \\
\left.\mathrm{x}(0)=\mathrm{x}_{0} \text { given, } \dot{\mathrm{x}}(\mathrm{t})=\mathrm{m}[\mathrm{u}(\mathrm{t}), \mathrm{x}(\mathrm{t}), \mathrm{t}]\right\} \tag{P.0}
\end{gather*}
$$

where $\alpha(t)=\exp \left(-\int_{0}^{t} \rho(s) d s\right)$. Then there exist continuous functions of time, $\mathrm{q}(\mathrm{t})$, such that for each $\mathrm{t}$,

(i) the controlmaximizes the current-value Hamiltonian, $\mathrm{u}_{\mathrm{i}}^{*}=\arg \max _{\mathrm{u}} \mathrm{H}^{\mathrm{c}}(\mathrm{u}, \mathrm{x}, \mathrm{q}, \mathrm{t})$,

(ii) the law of motion of the state vector holds, $\left.\dot{\mathrm{x}}(\mathrm{t})=\mathrm{m} / \mathrm{u}^{*}(\mathrm{t}), \mathrm{x}(\mathrm{t}), \mathrm{t}\right]$, and

(iii) the functions $\mathrm{q}(\mathrm{t})$ satisfy the differential equations $-\partial \mathrm{H}_{\mathrm{t}}^{\mathrm{c}} / \partial \mathrm{x}_{\mathrm{t}}=\dot{\mathrm{q}}_{\mathrm{t}}-\mathrm{\rho}_{\mathrm{t}} \mathrm{q}_{\mathrm{t}}$.

Moreover, if the maximized Hamiltonian,

$$
\tilde{H}(x, q, t)=\max _{u}\left\{H^{c}(x, u, q)=F_{t}(x, u, t)+q_{t} m_{t}(x, u)\right\}
$$

is a concave function of $x$ for given $q$ and $t$, then any policy satisfying the Pontryagin conditions and the transversality conditions at infinity,

$$
\begin{equation*}
\lim _{t \rightarrow \infty} \alpha(t) q_{t} \geq 0 \quad \text { and } \quad \lim _{t \rightarrow \infty} \alpha(t) q_{t} x_{t}=0 \tag{T.2}
\end{equation*}
$$

is optimal.

In some cases of interest, the sufficient conditions allow us to identify the optimal path with the stable manifold leading to a saddle-point steady state. For example, in the case of a stationary problem with a constant discount rate $\rho$ and time-invariant instantaneous return function $F(x, u)$ and law of motion $m(x, u)$, the maximum principle yields an autonomous system of differential equations

$$
\begin{gathered}
\dot{x}_{t}=m\left[g\left(x_{t}, q_{t}\right), x_{t}\right] \\
\dot{q}_{t}-\rho q_{t}=-\frac{\partial H_{t}^{c}\left[g\left(x_{t}, q_{t}\right), q_{t}, x_{t}\right]}{\partial x_{t}}
\end{gathered}
$$

in which time does not enter as a separate argument in any of the transition equations. This system often has a steady state and solution trajectories leading to it. The following proposition shows that if we can find a path ( $x_{t}$, $\left.q_{t}\right)$ that satisfies the necessary conditions and converges to a steady state, then, under certain conditions, that path is optimal.

Theorem 2.5. Sufficient conditions for an optimum. Let $\mathrm{x}^{*}(\mathrm{t}), \mathrm{u}^{*}(\mathrm{t})$, and $\mathrm{q}^{*}(\mathrm{t})$ be a path satisfying the necessary conditions for a stationary, infinite-horizon control problem, as given in Theorem 2.3, with $\alpha(\mathrm{t})=\mathrm{e}^{-\mathrm{pt}}, \rho>0$. Suppose further that the concavity assumption of the sufficiency part of the theorem holds. Then, if $\mathrm{x}^{*}(\mathrm{t})$ and $\mathrm{q}^{*}(\mathrm{t})$ converge to a steady state $\left(\mathrm{x}^{\mathrm{s}}, \mathrm{q}^{\mathrm{s}}\right)$, with $\mathrm{x}^{\mathrm{s}}, \mathrm{q}^{\mathrm{s}} \geq$ 0 , they constitute an optimal path.

Proof. Because $x^{*}(t)$ and $q^{*}(t)$ converge to finite limits, and $e^{-\rho t} \rightarrow 0$ as $t \rightarrow$ $\infty$, the transversality conditions

$$
\begin{equation*}
\lim _{t \rightarrow \infty} e^{-\rho t} q_{t} \geq 0 \text { and } \lim _{t \rightarrow \infty} e^{-\rho t} q_{t} x_{t}=0 \tag{T.2}
\end{equation*}
$$

are satisfied. Optimality follows by the first sufficiency theorem.

This result is particularly useful when the Pontryagin conditions give rise to an autonomous system that has a unique saddle-point equilibrium, because then the unique convergent path leading to the steady state will be the optimal one.

## (c) Constraints Involving State and Control Variables

In many cases, control problems involve additional complications in the form of constraints that limit the choice of the decision or control variables
$u$ to a set that generally depends on the contemporaneous values of the state variables $x$. The procedure for dealing with this problem involves the introduction of a Lagrange function, similar to the one used in static programming problems. The necessary conditions for an optimum can then be rewritten in terms of the partial derivatives of the Lagrangian (sometimes called the augmented Hamiltonian), rather than the Hamiltonian.

To illustrate the procedure for solving such problems, we return to the finite-horizon problem of Section 2(a), to which we add some additional side constraints. The problem is now

$$
\begin{align*}
V^{c}\left(x_{0}, 0\right)= & \max _{u(t) ; 0 \leq t \leq T}\left\{\int_{0}^{T} \alpha(t) F[u(t), x(t), t] d t \text { s.t. } x_{T} \geq 0, x(0)=x_{0}\right. \text { given, } \\
& \mathrm{C}[x(t), u(t), t] \geq 0, \dot{x}(t)=m[u(t), x(t), t]\} \tag{P.C}
\end{align*}
$$

where $\alpha(t)=\exp \left(-\int_{0}^{t} \rho(s) d s\right)$.

The same logic as before can be used to show that at any given time $t$ the optimal policy $u^{*}$ will maximize the corresponding Hamiltonian. Of course, the maximization is now subject to the additional side constraints. Thus $u^{*}(t)$ now solves

$$
\begin{equation*}
\max _{u}\left\{H^{c}(u, x, q, t) \text { s.t. } C[x(t), u(t), t] \geq 0\right\} \tag{1}
\end{equation*}
$$

Subject to the standard constraint qualification, we can apply the KuhnTucker theorem to characterize the solution to this problem. In particular, if $u^{*}$ solves (1), there will exist Lagrange multipliers $\lambda^{*}$ such that

$$
\begin{equation*}
\lambda^{*} \geq 0 \text { and } \lambda^{* T} C\left(x, u^{*}, t\right)=0 \tag{2}
\end{equation*}
$$

Moreover, if we define the Lagrangian function by

$$
\begin{equation*}
\mathfrak{f}_{t}^{c}=H^{c}(u, x, q, t)+\lambda C[x(t), u(t), t]=F(u, x, t)+g m(x, u, t)+\lambda C(x, u, t) \tag{3}
\end{equation*}
$$

the necessary conditions for the maximization problem in (1) will include

$$
\begin{equation*}
\frac{\partial f_{t}^{c}}{\partial x_{t}}=0 \tag{4}
\end{equation*}
$$

Similarly, the equation of motion for the costate variables can be written in terms of the partial derivatives of the Lagrangian. In particular, we have now

$$
\begin{equation*}
-\frac{\partial £_{t}^{c}}{\partial x_{t}}=\dot{q}_{t}-\rho_{t} q_{t} \tag{5}
\end{equation*}
$$

For other versions of the control problem, the necessary conditions can be similarly amended to involve partial derivatives of the Lagrangian func-
tion. (In particular, the necessary conditions are the same for the infinitehorizon case.) Moreover, our previous results concerning the transversality conditions and sufficient conditions for an optimum still hold as stated. Note, however, that certain conditions may have to be imposed on the constraint functions $C()$ to ensure the concavity of the maximized Hamiltonian required in the sufficiency theorem.

## Bibliography

Araujo, A. 1991. The Once but not Twice Differentiability of the Policy Function. Econometrica 59(5):1383-93.

Araujo. A., and Scheinkman, J. 1983. Maximum Principle and Transversality Conditions for Concave Infinite-Horizon Economic Models. Journal of Economic Theory 27:1-16.

Arrow, K. 1968. Applications of Control Theory to Economic Growth. In: Mathematics of Decision Sciences, Part 2, pp. 85-119. Providence, RI: American Mathematical Society.

Arrow, K., and Kurz, M. 1970. Methods of Optimization over Time. In: Public Investment, the Rate of Return, and Optimal Fiscal Policy. Baltimore: Johns Hopkins University Press.

Beavis, B., and Dobbs, I. 1990. Optimization and Stability Theory for Economic Analysis. Cambridge University Press.

Benveniste, L., and Scheinkman, J. 1982. Duality Theory for Dynamic Optimizing Models in Economics: the Continuous Time Case. Journal of Economic Theory 30:1-19.

Dixit, A. 1990. Optimization in Economic Theory, 2nd ed. Oxford University Press.

Dorfman, R. 1969. An Economic Interpretation of Optimal Control Theory. American Economic Review 59:817-31.

Intriligator, M. 1981. Mathematical Optimization and Economic Theory. Englewood Cliffs, NJ: Prentice-Hall.

Kamien, M., and Schwartz, N. 1981. Dynamic Optimization: The Calculus of Variations and Optimal Control in Economics and Management. Amsterdam: North Holland.

Léonard, D., and Van Long, N. 1992. Optimal Control Theory and Static Optimization in Economics. Cambridge University Press.

Santos, M. 1995. Smoothness of the Policy Function in Discrete Time Economic Models. Econometrica 59(5):1365-82.

Sargent, T. 1987. Dynamic Macroeconomic Theoory. Harvard University Press.

Stokey, N., and Lucas. R. 1989. Recursive Methods in Economic Dynamics. Harvard University Press.

Takayama, A. 1987. Mathematical Economics. Cambridge University Press.

## Notes

1 For example, if $x_{T}$ is leftover wealth at the time of death, $S\left(x_{T}\right)$ captures the utility the agent obtains by leaving a bequest to his or her children. More generally, $S()$ assigns a valuation to the final state vector.

2 Continuity for correspondences was defined in Section 11 of Chapter 2. Intuitively, the idea is the same as for the continuity of functions: $\Gamma$ is continuous if the set $\Gamma(x)$ does not change very much with small changes of $x$.

3 Theorem 2.15 in Chapter 6 can sometimes be used to establish the differentiability of the value function. See Section 2 of Chapter 13 for an example.

4 See, for example, Araujo (1991) and Santos (1995).

5 In certain cases of interest the instantaneous discount rate $\rho$ cannot be assumed to be constant over time. For example, if the control problem is that faced by a firm that attempts to maximize the present value of a stream of cash flows, future receipts will be discounted at the market rate of interest, which is likely to vary from period to period. This gives rise to a discount factor of the form given in the text.

6 It may be useful to have a concrete example in mind. Consider the problem of an individual who wants to maximize the discounted value of lifetime utility from consumption plus the utility of the bequest he leaves to his children at death:

$$
\int_{0}^{T} e^{-\rho t} U\left(c_{t}\right) d t+e^{-\rho t} S\left(a_{r}\right)
$$

The state variable $a$ now represents the consumer's current asset holdings. The agent takes as given his initial wealth $\left(a_{0}\right)$ and the time paths of income $\left(y_{t}\right)$ and interest rates $\left(r_{t}\right)$. The law for motion for the state variable is the flow budget constraint:

$$
\dot{a}_{t}=r_{t} a_{t}+y_{t}-c_{t}
$$

7 In some cases it turns out to be more convenient to use the first-order conditions for the maximization of the Hamiltonian to solve for the costate variable as a function of the control and then use this expression to get rid of $q$ in the system of differential equations. We will see some examples in Chapter 13.

8 Observe that $\alpha(t)=-\alpha(t) \rho_{i}$; then

$$
\frac{d}{d t}\left(\alpha(t) q_{t}\left(x_{t}-x_{t}^{*}\right)\right)=\alpha(t) q_{t}\left(\dot{x}-\dot{x}^{*}\right)+\left[\alpha(t) \dot{q}-\alpha(t) \rho_{t} q_{t}\right]\left(x_{t}-x_{t}^{*}\right)
$$

## Some Applications of Dynamic Optimization

In this chapter we will review some applications of dynamic optimization to economics. In Section 1 we develop two models of search to illustrate the use of dynamic programming in a stochastic setting. Section 2 analyzes the decision problem faced by a social planner who maximizes the utility of an infinitely-lived representative agent in a one-good neoclassical economy. In Section 3 we study the optimal investment policy of a competitive firm when the installation of capital is costly. Finally, in Section 4 we develop the Cass-Koopmans model of a dynamic competitive economy and use it to analyze the welfare cost of factor taxes. Section 5 concludes with a series of problems.

## 1. Search Models

Search theory provides a simple and yet interesting application of dynamic programming to economics. In the basic search model, wage offers drawn from a given distribution arrive at fixed or random intervals, and an agent simply decides whether to accept one of them and become employed or reject them and continue searching for a better opportunity. We have, then, a very simple problem in stochastic dynamic programming: The control is simply a take-it-or-leave-it decision, and the distribution of the state variables (the offers) is time-invariant and does not depend on either the state or the control.

The first part of this section introduces the basic "microeconomic" model of job search. In addition to its interest as an application of dynamic programming, this model provides a useful counterpoint to the neoclassical model of a competitive labor market. In the latter model, transactions are assumed to take place instantaneously and at no cost, and wages are set so that the market clears continuously. Hence, there is no room for unemployment. In the search model, on the other hand, it may be optimal for an agent to remain temporarily unemployed in order to wait for a better opportunity
than those available today. Hence, the search model provides a useful framework for analyzing how rational agents will respond to changes in the level or duration of unemployment benefits, the abundance and riskiness of employment offers, and many other questions that can hardly be addressed within the neoclassical model.

The search model, however, does not necessarily require a departure from the spirit of the neoclassical model. Notice, in particular, that the unemployment that naturally arises in any search model is frictional in nature and essentially voluntary. Hence, the explicit modeling of the process of job search may well yield nothing more than a model with a natural rate of unemployment. On the other hand, it is relatively easy to incorporate additional features into a search model that add a strong Keynesian flavor to it. If we are willing to assume that an increase in the level of aggregate activity makes it easier for potential trading partners to locate each other, we have a participation externality that generates inefficiency and the possibility of multiple equilibria, thus opening the door for public intervention to improve things. A "macro" model with these features will be developed in the second part of the section.

## (a) The Basic Model of Job Search

Consider an infinitely-lived, risk-neutral worker who maximizes (the expectation of) the discounted value of lifetime income,

$$
E\left\{\sum_{t=0}^{\infty} \beta^{t} y_{t}\right\}
$$

where income at time $t, y_{t}$, is equal to the wage rate $(x)$ for employed workers and to a government-provided benefit $(b)$ for the unemployed. Unemployed workers also receive one employment offer each period. All jobs are permanent and pay the same wage each period. Wages, however, may differ across jobs. Hence, $x$ is a (nonnegative) random variable that we assume to be drawn from a time-invariant distribution described by a cumulative distribution function (cdf) $F()$, where $F(w)=\operatorname{pr}(x \leq w)$.

A worker who has just received an offer has two options: One is to accept the job and work forever at the specified wage $x ;{ }^{1}$ the other is to reject the offer and wait for a better one to arrive. We will denote the value of the first option (accepting and being employed at wage $x$ ) by $W_{a}(x)$, and that of the second (rejecting the offer and remaining unemployed) by $W_{r}$. Clearly, $W_{a}(x)$, the present value of lifetime earnings on a job paying salary $x$, is an increasing function of $x$ given by

$$
\begin{equation*}
W_{a}(x)=\sum_{i=0}^{\infty} \beta^{t} x=\frac{x}{1-\beta} \tag{1}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-587.jpg?height=648&width=937&top_left_y=185&top_left_x=270)

Figure 13.1. Value function and reservation wage for the search problem.

On the other hand, $W_{r}$ is not a function of $x$ : The expected present value of lifetime earnings for an unemployed worker is independent of the wage offer he has just rejected.

A rational worker will choose the action that will yield the larger value. Thus, the expected value of lifetime income for an agent who has just received an offer $x$ is given by the value function

$$
\begin{equation*}
v(x)=\max \left[W_{a}(x,), W_{r}\right] \tag{2}
\end{equation*}
$$

and he accepts the offer if and only if $W_{a}(x) \geq W_{r}$ (i.e., if the value of being employed at the offered wage exceeds the value of being unemployed). As illustrated in Figure 13.1, the optimal decision strategy takes the form of a reservation-wage rule. Because $W_{a}(x)$ is increasing in the salary, and $W_{r}$ is independent of it, a job will be accepted if and only if it pays a wage that is higher than some critical value $x^{*}$. This critical or reservation wage is defined as the value of $x$ that makes the agent indifferent between taking the job and remaining unemployed, that is, $x^{*}$ solves $W_{a}\left(x^{*}\right)=W_{r}$.

It remains, of course, to determine the reservation wage $x^{*}$ or, equivalently, the value of being unemployed, $W_{r}$. As a first step, consider the situation of a worker who is currently unemployed (i.e., who has just rejected an offer): His income today is the unemployment benefit $b$; tomorrow he will receive a new offer, $x$, and will accept it or reject it depending on whether or not its value exceeds $W_{r}$. Hence, his current value one period hence (from tomorrow's perspective) will be given by $v(x)=\max \left[W_{a}(x), W_{r}\right]$. As of today, however, the realization of $x$ is not known, so we can only work with the expected value of $v(x)$. Moreover, because this value will accrue tomorrow,
we have to discount it by one period. Formally, then, the value of being unemployed is defined recursively by

$$
\begin{equation*}
W_{r}=b+\beta E\left\{\max \left[W_{a}(x), W_{r}\right]\right\} \tag{3}
\end{equation*}
$$

We can now characterize the reservation salary. By definition, $x^{*}$ is the value of $x$ that makes the agent indifferent between accepting and rejecting the offer. Hence, $x^{*}$ satisfies

$$
W_{a}\left(x^{*}\right) \equiv \frac{x^{*}}{1-\beta}=W_{r}
$$

and therefore

$$
\begin{equation*}
x^{*}=(1-\beta) W_{r} \tag{4}
\end{equation*}
$$

Substituting (3) into (4),

$$
x^{*}=W_{r}-\beta W_{r}=b+\beta E\left\{\max \left[W_{a}(x), W_{r}\right]\right\}-\beta W_{r}
$$

Bringing the (constant) last term into the expectation and the max operator, we obtain

$$
\begin{equation*}
x^{*}=b+\beta E\left\{\max \left[W_{a}(x)-W_{r}, 0\right]\right\} \tag{5}
\end{equation*}
$$

an equation that can be solved for $x^{*}$. This expression can be simplified as follows. We begin by writing out the expectation,

$$
\begin{equation*}
x^{*}=b+\beta \int_{0}^{\infty} \max \left[W_{a}(x)-W_{r}, 0\right] d F(x) \tag{6}
\end{equation*}
$$

and observing that the resulting integral can be broken up into two parts:

$$
\int_{0}^{\infty} \max \left[W_{a}-W_{r}, 0\right] d F=\int_{0}^{x^{*}} \max \left[W_{a}-W_{r}, 0\right] d F+\int_{x^{*}}^{\infty} \max \left[W_{a}-W_{r}, 0\right] d F
$$

Notice that over the first interval of integration we have $x \leq x^{*}$, implying that $W_{a}(x) \leq W_{r}$; thus, $\max \left[W_{a}(x)-W_{r}, 0\right]=0$ for $x \in\left(0, x^{*}\right]$, and the first integral vanishes. For $x \in\left(x^{*}, \infty\right)$, on the other hand, we have $W_{a}(x) \geq W_{r}$, implying $\max \left[W_{a}(x)-W_{r}, 0\right]=W_{a}(x)-W_{r}$. Hence, (6) reduces to

$$
x^{*}=b+\beta \int_{x^{*}}^{\infty}\left[W_{a}(x)-W_{r}\right] d F(x)
$$

Finally, recalling that $W_{r}=x^{*} /(1-\beta)$ and $W_{a}(x)=x /(1-\beta)$, we arrive at the fundamental reservation-wage equation,

$$
\begin{equation*}
x^{*}=b+\frac{\beta}{1-\beta} \int_{x^{*}}^{\infty}\left(x-x^{*}\right) d F(x) \tag{R}
\end{equation*}
$$

which implicitly defines the reservation wage $x^{*}$ as a function of the parameters of the model and the distribution of wage offers. This equation can be used to study the comparative statics of the reservation wage, as we will show later using an extension of this model.

## Continuous-Time and Stochastic-Offer Arrivals

One of the crucial determinants of how selective a worker can afford to be in regard to wage offers is the availability of job opportunities. The model in the preceding section, which assumes that the worker receives an offer every period, ignores this aspect of the problem. We will now relax this restrictive assumption and extend the model to incorporate a measure of the "scarcity" of work opportunities through a parameter that reflects the rate of arrival of job offers. We will also illustrate how to go from discrete time to continuous time - a formulation that, although less intuitive when it comes to the derivation of the valuation equations, turns out to be more convenient in many cases.

We will make two changes with respect to the earlier model. The first will be to parameterize the length of the period. We will assume that all periods have the same duration $h$ and reinterpret the wage and the unemployment benefit as rates per unit of time. Thus, an unemployed worker's income during a period is now $b h$, and an employed worker earns $x h$. We will also assume that the one-period discount factor is a function $\beta(h)$ of the length of the period. To go from discrete time to continuous time, we will take limits as the length of the period goes to zero.

Second, we will now model the arrival of wage offers as a stochastic process. We will assume that an unemployed worker has probability $\lambda h$ of receiving an offer during the current period. In the limit, as $h$ goes to zero, offer arrivals follow a Poisson process with parameter $\lambda$, which can be interpreted as the instantaneous probability of receiving an offer.

The solution procedure is similar to that used earlier. The value of accepting a job that pays salary $x$ per unit of time is given by

$$
\begin{equation*}
W_{a}(x)=\sum_{t=0}^{\infty} \beta(h)^{t} x h=\frac{x h}{1-\beta(h)} \tag{1}
\end{equation*}
$$

and the value of rejecting it, $W_{r}$, is still independent of $x$. The reservation wage $x^{*}$ is the salary that makes the agent indifferent between accepting and rejecting employment and therefore satisfies

$$
\begin{align*}
W_{a}\left(x^{*}\right) & =W_{r} \\
\Rightarrow x^{*} & =\frac{1-\beta(h)}{h} W_{r} \tag{2}
\end{align*}
$$

To characterize $W_{r}$, consider the prospects of an unemployed worker, which are now slightly more complicated by the fact that he no longer knows when the next offer will arrive. During the current period, his only income is the unemployment benefit $b h$. Next period, he will receive an offer with probability $\lambda h$, and no offer otherwise (with probability $1-\lambda h$ ).

In the second case, his value next period will again be $W_{r}$. In the first case, his payoff next period will be given by $v(x)=\max \left[W_{a}(x), W_{r}\right]$, but because the realization of $x$ is not known today, we have to compute the expected return. Finally, all values accruing tomorrow must be discounted by one period. Hence, the expected value of being currently unemployed is given by

$$
\begin{equation*}
W_{r}=b h+\beta(h)\left\{\lambda h E \max \left[W_{a}(x), W_{r}\right]+(1-\lambda h) W_{r}\right\} \tag{3}
\end{equation*}
$$

The next step is to manipulate this expression so that we can substitute it into the right-hand side of (2). Subtracting $\beta(h) W_{r}$ from both sides of (3),

$$
\begin{aligned}
{[1-\beta(h)] W_{r} } & =b h+\beta(h) E\left\{\lambda h \max \left[W_{a}(x), W_{r}\right]-\lambda h W_{r}\right\} \\
& =b h+\beta(h) \lambda h E\left\{E \max \left[W_{a}(x)-W_{r}, 0\right]\right\}
\end{aligned}
$$

and dividing by $h$,

$$
\begin{equation*}
\frac{1-\beta(h)}{h} W_{r}=b+\beta(h) \lambda E\left\{\max \left[W_{a}(x)-W_{r}, 0\right]\right\} \tag{4}
\end{equation*}
$$

Substituting (4) into (3) and simplifying, we could obtain a reservationwage equation very similar to the one in the preceding section. Instead, let us go to continuous time. For this, let the discount factor be of the form $\beta(h)=e^{-\rho h}$. Then we have (using L'Hôpital's rule in the second expression)

$$
\begin{equation*}
\lim _{h \rightarrow \infty} \beta(h)=1 \text { and } \lim _{h \rightarrow 0} \frac{1-\beta(h)}{h}=\rho \tag{5}
\end{equation*}
$$

Taking limits as $h \rightarrow 0$, (1) yields $W_{a}(x)=x / \rho,(2)$ becomes

$$
x^{*}=\rho W_{r}
$$

and (4) implies ${ }^{2}$

$$
\rho W_{r}=b+\lambda E\left\{\max \left[W_{a}(x)-W_{r}, 0\right]\right\}
$$

Substituting $\left(4^{\prime}\right)$ into $\left(2^{\prime}\right)$ and proceeding as in the preceding section, we obtain the reservation-wage equation:

$$
x^{*}=\rho W_{r}=b+\lambda \int_{0}^{\infty} \max \left[W_{a}(x)-W_{r}, 0\right] d F(x)
$$

Now, if $x<x^{*}$, the agent rejects the offer, that is, $W_{a}(x)<W_{r}$, and therefore $\max \left[W_{a}(x)-W_{r}, 0\right]=0$. On the other hand, if $x>x^{*}$, then $W_{a}(x)>W_{r}$, and therefore $\max \left[W_{a}(x)-W_{r}, 0\right]=W_{a}(x)-W_{r}$. Hence, we can break up the domain of integration into two parts, $\left(0, x^{*}\right)$ and $\left(x^{*}, \infty\right)$, and observing that the integral over the first interval vanishes, we have

$$
x^{*}=b+\lambda \int_{x^{*}}^{\infty}\left[W_{a}(x)-W_{r}\right] d F(x)
$$

Finally, substituting $W_{r}=x^{*} /(\rho)$ and $W_{a}(x)=x /(\rho)$ in this expression, we obtain the fundamental reservation-wage equation:

$$
\begin{equation*}
x^{*}=b+\frac{\lambda}{\rho} \int_{x^{*}}^{\infty}\left(x-x^{*}\right) d F(x) \tag{R}
\end{equation*}
$$

This equation has an intuitive interpretation. Rearrange it to get

$$
x^{*}-b=\frac{\lambda}{\rho} \int_{x^{*}}^{\infty}\left(x-x^{*}\right) d F(x)
$$

Then the left-hand side measures the immediate opportunity cost of rejecting an offer, and the right-hand side gives the present value of the expected gain from continued search. The reservation wage, by definition, equates the two quantities.

It is straightforward to do comparative statics using this expression. Write

$$
H\left(x^{*} ; b, \lambda, \rho\right)=x^{*}-b-\frac{\lambda}{\rho} \int_{x^{*}}^{\infty}\left(x-x^{*}\right) d F(x)=0
$$

and compute the partial derivatives of $H():^{3}$

$$
\begin{aligned}
H_{x^{*}} & =1-\frac{\lambda}{\rho}\left(\int_{x^{*}}^{\infty}(-1) d F(x)-\left(x^{*}-x^{*}\right) F^{\prime}\left(x^{*}\right)\right) \\
& =1+\frac{\lambda}{\rho} \int_{x^{*}}^{\infty} d F(x)=1+\frac{\lambda}{\rho}\left[1-F\left(x^{*}\right)\right]>0 \\
H_{b} & =-1<0 \\
H_{\lambda} & =-\frac{1}{\rho} \int_{x^{*}}^{\infty}\left(x-x^{*}\right) d F(x)<0 \\
H_{\rho} & =\frac{\lambda}{\rho^{2}} \int_{x^{*}}^{\infty}\left(x-x^{*}\right) d F(x)>0
\end{aligned}
$$

By the implicit-function theorem,

$$
\frac{\partial x^{*}}{\partial b}=-\frac{H_{b}}{H_{x^{*}}}>0, \quad \frac{\partial x^{*}}{\partial \lambda}=-\frac{H_{\lambda}}{H_{x^{*}}}>0, \quad \text { and } \frac{\partial x^{*}}{\partial \rho}=-\frac{H_{\rho}}{H_{x^{*}}}<0
$$

That is, an increase in the unemployment benefit leads to an increase in the reservation salary, as workers can now afford to wait longer for a better offer (an increase in $b$ reduces the opportunity cost of rejecting any offer). An increase in $\lambda$ means that jobs become less scarce, and it has a similar effect (the expected cost of rejecting an offer is now lower because the expected delay until a new one arrives is shorter). Finally, an increase in $\rho$ means that future benefits are discounted at a higher rate (agents are less patient); because the expected benefits of continued search will accrue in the future, waiting becomes less attractive, and the reservation wage decreases.

## (b) A Search-Based Macro Model

Standard neoclassical models implicitly rely on the Walrasian auctioneer to perform two crucial tasks. One is setting prices so that markets will clear continuously. The second can be called trade coordination: The auctioneer is assumed to provide clearing services that will make it unnecessary for the parties to a transaction to physically locate each other, thus simplifying the task of matching desired quantities. In short, these models assume that the allocation of resources is a costless and frictionless process. One implication of this assumption, if we take it literally, is that there is no room for involuntary unemployment. Extensions of the neoclassical model can generate fluctuations in employment levels as agents adjust their labor supply in response to price or productivity shocks, but the labor market must clear continuously, like any other market.

Search models do away with the trade-coordination function of the auctioneer and explicitly model the fact that many transactions must take place between individuals who must first find each other. Trade thus becomes a costly and time-consuming process. Applied to labor markets, this kind of model leads to the emergence of frictional unemployment, for agents will be inactive during some of the time that they wait for an acceptable job.

Moreover, this view of the process of resource allocation naturally suggests an important externality associated with the exchange technology: It seems likely that the greater the number of people who want to trade at any given time, the easier it will be for each of them to locate a suitable partner. Loosely speaking, because an increase in the level of economic activity makes it easier for the parties to an exchange to find each other, individual decisions have external effects over the opportunities available to other agents. One result of this phenomenon is that the equilibrium will not be Pareto-optimal, as agents will fail to take into account the external effects of their actions. Another implication is the possibility of multiple equilibria, as either pessimistic or optimistic expectations tend to become self-fulfilling. Thus, there is a role for government policy, both in correcting for externalities and in helping the economy select a good equilibrium. Policy may be useful as a device for improving coordination between agents in a way the market cannot achieve because of the presence of external effects.

The search model has served as a framework for some contributions to a literature which shows that macro models with "Keynesian" properties can be built from solid micro foundations. The remainder of this section develops one such model, due to Diamond (1982) and Diamond and Fudenberg (1989), in which an agent must first search for production opportunities and then locate a trading partner before consumption can take place. The model illustrates how, in the presence of a plausible participation externality, a sub-
optimally low level of economic activity may arise as a result of the difficulty of coordinating exchange in an economy with many agents.

## Diamond's Search Model

Imagine a tropical island inhabited by infinitely-lived natives who walk around the beaches looking for coconut trees (production opportunities). Having found a tree, an agent must decide whether or not to climb it. If he does, he comes down with a coconut, but he is not finished yet: An ancient taboo forbids the consumption of one's own coconuts. Hence, the agent must find another native with whom to trade coconuts (one for one) before eating. ${ }^{4}$ Having done this, he continues to search for additional production opportunities.

All trees have exactly one piece of fruit, but they may differ in height (production cost). Consumption of a coconut yields utility $y$. Production costs (the disutility of climbing) are proportional to the height of the tree, which is a nonnegative random variable, $c$, bounded below by $\underline{c}$ and drawn from a known distribution with cdf $G()$. That is, $G(x)=\operatorname{pr}(c \leq x)$, and $G(\underline{c})=0$. Agents maximize the expected value of discounted lifetime utility,

$$
V=E \sum_{t=0}^{\infty} e^{-p t_{i}} U_{t_{i}} \text {, where } \quad U_{t_{i}}=y_{t_{i}}-c_{t_{i}}
$$

Notice that although time is continuous, production and consumption take place at discrete intervals. At a given time $t_{i}$, the agent may be engaged in production (climbing a tree), in which case his instantaneous utility is $-c$, in eating (with utility $y$ ), or in doing neither, in which case his instantaneous utility is zero.

An agent who is not engaged in production or consumption may be in either of two states. We will say that he is unemployed if he is looking for a production opportunity and that he is employed if he is carrying a coconut and is looking for someone with whom to trade. The arrivals of production opportunities and trading partners follow Poisson processes, with parameters that are taken as given by each individual agent. We will denote by $a$ the instantaneous probability of finding a tree, and by $b(e)$ the instantaneous probability of finding a trading partner.

A crucial assumption of the model is that $b$ is an increasing function of the aggregate employment rate $e$. That is, the larger the number of people who are walking around with coconuts in their hands, the easier it will be for them to bump into each other. We will assume that

$$
b(0)=0, \quad b^{\prime}(e)>0, \quad \text { and } \quad b^{\prime \prime}(e)<0
$$

Thus, an individual's decision to produce has a positive spillover effect on other agents' trading opportunities. When making production decisions, agents will not take this factor into account. As a result, the equilibrium level
of activity will be suboptimally low. As we will see, the externality is also at the root of the possibility of multiple equilibria, for it makes both optimism and pessimism potentially self-fulfilling. For example, if most agents believe that trading will be easy, they will have an incentive to climb even relatively high trees. If they all do, then finding a trading partner will indeed be easy, thus validating ex post their initial optimism.

Production Decisions. The only decision that an agent has to take in the model is whether or not to climb a tree he has just run into. As in the jobsearch model, the decision rule takes the form of a reservation level: Agents will accept all of those production opportunities whose cost is smaller than some critical level $c^{*}$ (i.e., natives will climb all sufficiently low trees).

To characterize the reservation cost, we will proceed as before, beginning with a discrete-time version of the model and then taking limits as the duration of the period, $h$, goes to zero. In what follows, then, the relevant transition probabilities will be $a h$ and $b h$ for one period, and the one-period discount factor will be given by $\beta(h)=e^{-\rho h}$.

Denote by $W_{e}(e)$ the expected lifetime utility of an employed worker when the employment rate is equal to $e$, and by $W_{u}(e)$ the value of being unemployed given $e,{ }^{5}$ and consider the situation of an employed worker at time $t$. With probability $b\left(e_{t}\right) h$ he will find a trading partner during the current period, consume his coconut (earning utility $y$ ), and then become unemployed. With probability $1-b\left(e_{t}\right) h$ he will be unable to consume and will remain employed. Thus, his expected payoff is given by

$$
W_{e}\left(e_{t}\right)=b h\left[y+\beta(h) W_{u}\left(e_{t+h}\right)\right]+(1-b h) \beta(h) W_{e}\left(e_{t+h}\right)
$$

where we have taken into account the fact that from this period to the next (which starts at $t+h$ ) the employment rate may change, altering the expected values of both employed and unemployed agents. Subtracting $\beta(h) W_{e}\left(e_{t}\right)$ from both sides of the foregoing expression and dividing both sides by $h$, we obtain

$$
\begin{aligned}
& {[1-\beta(h)] W_{e}\left(e_{t}\right) }=b h y+\beta(h)\left[b h W_{u}\left(e_{t+h}\right)+(1-b h) W_{e}\left(e_{t+h}\right)-W_{e}\left(e_{t}\right)\right] \\
&=b h y+\beta(h)\left[b h\left[W_{u}\left(e_{t+h}\right)\right]-W_{e}\left(e_{t+h}\right)\right]+\left[W_{u}\left(e_{t+h}\right)-W_{e}\left(e_{t}\right)\right] \\
& \Rightarrow \frac{1-\beta(h)}{h} W_{e}\left(e_{t}\right)=b y+\beta(h)\left(b\left[W_{u}\left(e_{t+h}\right)-W_{e}\left(e_{t+h}\right)\right]+\frac{W_{e}\left(e_{t+h}\right)-W_{e}\left(e_{t}\right)}{h}\right)
\end{aligned}
$$

Taking the limit on both sides of this expression as $h$ goes to zero,

$$
\rho W_{e}\left(e_{t}\right)=b y+b\left[W_{u}\left(e_{t}\right)-W_{e}\left(e_{t}\right)\right]+\frac{d W_{e}\left(e_{t}\right)}{d t}
$$

or, assuming that $W_{e}(\cdot)$ is a differentiable function,

$$
\begin{equation*}
\rho W_{e}\left(e_{t}\right)=b y+b\left[W_{u}\left(e_{t}\right)-W_{e}\left(e_{t}\right)\right]+W_{e}^{\prime}\left(e_{t}\right) \dot{e}_{t} \tag{1}
\end{equation*}
$$

where $\dot{e}$ denotes the derivative of the employment rate with respect to time.

This expression is similar to the asset-valuation equations of earlier sections, but contains an additional term, $W_{e}^{\prime}\left(e_{t}\right) \dot{e}_{t}$, that captures a new source of "capital gains" (or losses) not present in the previous model: the possibility that changes in the state variable $e$ will affect the asset's value.

In a similar way, it is easy to show that the expected utility of an unemployed worker satisfies

$$
\begin{equation*}
\rho W_{u}\left(e_{t}\right)=a \int_{\underline{c}}^{c^{*}}\left[W_{e}\left(e_{t}\right)-W_{u}\left(e_{t}\right)-c\right] d G(c)+W_{u}^{\prime}\left(e_{t}\right) \dot{e}_{t} \tag{2}
\end{equation*}
$$

where $c^{*}$ is the reservation cost of production (the maximum acceptable tree height). An unemployed worker finds a production opportunity with instantaneous probability $a$. If the opportunity is good enough (i.e., if $c \leq c^{*}$ ), he takes it, pays the cost $c$, and changes status from unemployed to employed. Thus, the net gain in value is given by $\left(W_{e}-W_{u}-c\right)$ if $c$ is low enough, and by zero otherwise (as for $c>c^{*}$, the agent ignores the tree and remains unemployed). Ex ante, the realization of $c$ is not known, so we have to calculate the expected value of this quantity. Using the argument illustrated in the preceding section, it is easy to see that this expectation can be written as the average gain over the interval of acceptable opportunities $\left(\underline{c}, c^{*}\right)$.

The reservation cost is the value of $c$ that makes the agent indifferent between accepting and rejecting a production opportunity. Hence, the net gain from climbing a tree of height $c^{*}$ is zero or, equivalently,

$$
\begin{equation*}
W_{e}\left(e_{t}\right)-W_{u}\left(e_{t}\right)=c^{*} \Rightarrow \rho c^{*}=\rho\left[W_{e}(e)-W_{u}(e)\right] \tag{3}
\end{equation*}
$$

Substituting (1) and (2) into (3),

$$
\begin{align*}
\rho c^{*} & =\rho W_{e}(e)-\rho W_{u}(e) \\
& =b y+b\left[W_{u}(e)-W_{e}(e)\right]+W_{e}^{\prime}(e) \dot{e}-a \int_{\underline{c}}^{c^{*}}\left[W_{e}(e)-W_{u}(e)-c\right] d G(c)-W_{u}^{\prime}(e) \dot{e} \\
\Rightarrow & \rho c^{*}=b y-b c^{*}+W_{e}^{\prime}(e) \dot{e}-a \int_{\underline{c}}^{c^{*}}\left[W_{e}(e)-W_{u}(e)-c\right] d G(c)-W_{u}^{\prime}(e) \dot{e} \tag{4}
\end{align*}
$$

To simplify this expression, notice that (i) differentiating (3) with respect to time, $\dot{c}^{*}=W_{e}^{\prime}(e) \dot{e}-W_{u}^{\prime}(e) \dot{e}$, and (ii)

$$
\begin{aligned}
& \int_{\underline{c}}^{c^{*}}\left[W_{e}(e)-W_{u}(e)-c\right] d G(c)=\left[W_{e}(e)-W_{u}(e)\right] g\left(c^{*}\right) \\
& \quad-\int_{\underline{c}}^{c^{*}} c d G(c)=c^{*} G\left(c^{*}\right)-\int_{\underline{c}}^{c^{*}} c d G(c)
\end{aligned}
$$

because $W_{e}(e)$ and $W_{u}(e)$ are not functions of $c$.

Substituting these expressions into (4), we obtain a necessary condition for the optimal willingness to produce along a path:

$$
\rho c^{*}=b(e)\left(y-c^{*}\right)-a c^{*} G\left(c^{*}\right)+a \int_{\underline{c}}^{c^{*}} c d G(c)+\dot{c}^{*}
$$

Solving this equation for $\dot{c}^{*}$ as a function of $c^{*}$ and $e$, we obtain the law of motion for $c^{*}$ along an individually rational trajectory:

$$
\begin{equation*}
\dot{c}^{*}=\left[\rho+b(e)+a G\left(c^{*}\right)\right] c^{*}-b(e) y-a \int_{\underline{c}}^{c^{*}} c d G(c) \equiv B\left(e, c^{*}\right) \tag{5}
\end{equation*}
$$

From the point of view of each agent, the time path of $e$ is exogenous, but in equilibrium $e$ is also determined by individual choices. Given the matching technology described by $b()$ and the rate of arrival of production opportunities, $a$, the instantaneous rate of change of employment is the difference between the flows into and out of employment. At each point in time, a fraction $e$ of the population is employed. The probability that each employed agent will run into a trading partner and become unemployed after eating is $b(e)$. Thus the fraction of the population that becomes unemployed during the "period" is $e b(e)$. The remaining fraction $1-e$ of the agents are unemployed. Each of them finds a tree with probability $a$ and climbs it, thus becoming employed, provided that $c \leq c^{*}$, that is with probability $G\left(c^{*}\right)=$ $\operatorname{pr}\left(c \leq c^{*}\right)$. Thus, the instantaneous flow into employment is $(1-e) a G\left(c^{*}\right)$, and the rate of change in employment is given by

$$
\begin{equation*}
\dot{e}=a G\left(c^{*}\right)(1-e)-b(e) e \equiv A\left(e, c^{*}\right) \tag{6}
\end{equation*}
$$

Dynamics. We now have a system of differential equations in $e$ and $c^{*}$ that describe the evolution of the economy over time. To analyze its behavior, we begin by constructing the phase diagram. Setting $\dot{e}=0$, we obtain

$$
\begin{equation*}
\dot{e}=A\left(e, c^{*}\right) \equiv a G\left(c^{*}\right)(1-e)-b(e) e=0 \tag{7}
\end{equation*}
$$

Equation (7) implicitly defines a function of the form $e=e\left(c^{*}\right)$ that gives the stationary level of employment as a function of the reservation cost $c^{*}$. Because a higher $c^{*}$ means that agents are willing to accept more production opportunities and therefore tend to become employed faster, the stationary level of employment increases with $c^{*}$, yielding an upward-sloping phase line. Formally, we compute the partial derivatives of $A$,

$$
A_{e}=-a G\left(c^{*}\right)-\left[b^{\prime}(e) e+b(e)\right]<0 \text { and } A_{C}=a G^{\prime}\left(c^{*}\right)(1-e)>0
$$

and apply the implicit-function theorem to calculate the derivative of $e\left(c^{*}\right)$ :

$$
e^{\prime}\left(c^{*}\right)=-\frac{A_{c}}{A_{e}}>0
$$

To plot the function $e\left(c^{*}\right)$, notice further that if $c^{*} \leq \underline{c}$, then $G\left(c^{*}\right)=0$, and therefore $e=0$; that is, if nobody is climbing coconut trees (the reservation height is below that of the shortest tree), the only sustainable employment

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-597.jpg?height=628&width=889&top_left_y=186&top_left_x=289)

Figure 13.2. The $\dot{e}=0$ phase line.

rate is zero. Second, as $c^{*}$ increases without bound, we have $G\left(c^{*}\right) \rightarrow 1$ (natives come closer to climbing all trees), and the stationary level of employment approaches a maximum value, $e_{M}$, which solves $a(1-e)-b(e) e$ $=0$. Hence, the $\dot{e}=0$ phase line looks as shown in Figure 13.2. Its first portion coincides with the vertical axis ( $e=0$ for all $\left.c \leq c^{*}\right)$, and the function has a vertical asymptote at $e_{M}$.

It remains to determine the direction of the arrows of motion along the $e$ axis. Notice that

$$
\dot{e} \geq 0 \text { if and only if } G\left(c^{*}\right) \geq \frac{b(e) e}{a(1-e)}
$$

and because $G$ is an increasing function, this is true for "high" values of $c^{*}$. Thus, for points in the state space that lie above the phase line, the arrows of motion along the $e$ axis point to the right, as shown in Figure 13.2. Alternatively, notice that

$$
\frac{\partial \dot{e}}{\partial c^{*}}=A_{C}=a G^{\prime}\left(c^{*}\right)(1-e)>0
$$

So, starting from the $\dot{\boldsymbol{e}}=0$ locus, a small increase in $c^{*}$ (which takes us above the phase line) puts us in the region where the level of employment is rising over time.

To plot the second phase line we proceed in a similar way. Setting $\dot{c}^{*}=0$ in (5), we obtain

$$
\begin{equation*}
\dot{c}^{*}=B\left(c^{*}, e\right)=\left[\rho+b(e)+a G\left(c^{*}\right)\right] c^{*}-b(e) y-a \int_{\underline{c}}^{c^{*}} c d G(c)=0 \tag{8}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-598.jpg?height=623&width=1036&top_left_y=188&top_left_x=198)

e

Figure 13.3. The $\dot{c}^{*}=0$ phase line.

an equation that implicitly defines a function of the form $c^{*}=c(e)$ giving the reservation cost $c^{*}$ as a function of $e$ when the latter is constant (or when agents expect it to be constant). Taking the partial derivatives of $B()$,

$$
\begin{aligned}
& B_{e}=b^{\prime}(e)\left(c^{*}-y\right)<0 \\
& B_{c}=\left[\rho+b(e)+a G\left(c^{*}\right)\right]+a c^{*} G^{\prime}\left(c^{*}\right)-a c^{*} G^{\prime}\left(c^{*}\right)=\rho+b(e)+a G\left(c^{*}\right)>0
\end{aligned}
$$

we find that

$$
c^{\prime}(e)=-\frac{B_{e}}{B_{c}}=\frac{b^{\prime}(e)\left(y-c^{*}\right)}{\rho+b(e)+a G\left(c^{*}\right)}>0
$$

That is, in a stationary environment, the reservation cost increases with the employment rate, provided that $b^{\prime}()>0$. When $e$ is high, agents do not have to wait long for partners with whom to trade. Thus, they find it worthwhile to climb even relatively high trees, rather than waiting for a better opportunity, for doing so does not imply a large delay, on average.

Observe that $c^{*}<y$, for no agent will accept a production opportunity whose net return is negative (the cost of climbing exceeds the value of the coconut). Also, the phase line goes through the origin, $c(0)=0$, for it is never worthwhile to expend effort to get a coconut when there is nobody around with whom to exchange it. ${ }^{6}$ Finally, the arrows of motion along the $c^{*}$ axis point upward in the region above the $\dot{c}^{*}=0$ line, as $\partial \dot{c}^{*} / \partial e=B_{e}<0$ (Figure 13.3).

Combining the preceding two figures, we obtain the phase diagram shown

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-599.jpg?height=741&width=1193&top_left_y=183&top_left_x=158)

Figure 13.4. Phase diagram.

in Figure 13.4. Notice that there is always a steady state at the origin: If no production is undertaken, nobody will be employed, and if nobody is employed, it would never pay one to become employed and produce, because one would never find a trading partner.

In some cases, this may be the only long-run equilibrium. But if the phase lines cross outside the origin, they must do so at least twice, for the $\dot{c}^{*}=0$ locus is bounded above by $y$, and the $\dot{e}=0$ curve has a vertical asymptote at $e_{M}$. Notice that the existence of trading externalities is crucial for the existence of multiple steady states. The $\dot{e}=0$ phase line is always upward-sloping (as natives become willing to climb higher trees, they become employed faster, raising the stationary employment level). The $\dot{c}^{*}=0$ locus, on the other hand, becomes a horizontal line if the rate of arrival of trading opportunities is independent of the employment rate, that is, if $b^{\prime}(e)=0$. In this case, the system has a unique interior steady state.

The stability properties of each steady state can be determined from the eigenvalues of the corresponding Jacobian matrix (the coefficient matrix for the linearization of the system around each steady state). Given the Jacobian

$$
J=\left[\begin{array}{ll}
A_{e} & A_{c^{*}} \\
B_{e} & B_{c^{*}}
\end{array}\right]
$$

the corresponding eigenvalues satisfy

$$
\lambda_{1} \lambda_{2}=\operatorname{det} J=A_{e} B_{c^{*}}-A_{c^{*}} B_{e}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-600.jpg?height=689&width=1155&top_left_y=191&top_left_x=161)

Figure 13.5. Convergent trajectories.

If $\operatorname{det} J<0$, the eigenvalues are real numbers of opposite signs, and the steady state is a saddle point. We can relate the sign of $\operatorname{det} J$ to the relative slopes of the phase lines. Observe that

$$
\operatorname{det} J<0 \Leftrightarrow-\frac{B_{e}}{B_{c^{*}}}<-\frac{A_{e}}{A_{c^{*}}} \Leftrightarrow c^{\prime}(e)<\frac{1}{e^{\prime}\left(c^{*}\right)}
$$

Hence, a steady state is a saddle point if and only if it corresponds to a point where the $\dot{e}=0$ phase line is steeper and cuts the $\dot{c}^{*}=0$ locus from below.

In the phase diagram shown in Figure 13.4 there are therefore two saddle points: the equilibrium at the origin, and the steady state with the highest level of activity. Figure 13.5 shows the saddle-path trajectories leading to these equilibria, which are also the possible equilibrium paths of the system. ${ }^{7}$ The figure shows that, at least for certain initial values of the predetermined state variable $e$, there are two equilibrium trajectories, one leading to the high-activity steady state, and the other leading to the "shutdown" equilibrium at the origin.

There are, then, two "natural rates" or long-run equilibria, one clearly superior to the other, and, in many cases, two equilibrium paths, each leading to one of these steady states. We therefore face a coordination problem which of the paths will be taken will depend on the ability of agents to coordinate their actions on the good equilibrium. As noted earlier, we can think of the problem in terms of the tendency for optimistic or pessimistic expectations to become self-fulfilling. In some sense, the problem is one of coordinating beliefs. This raises the possibility that the assumption of rational
expectations may not be sufficient to fully close the model: Even if agents know the structure of the model and can compute the equilibrium paths, there is uncertainty concerning the actual path of the economy, for agents cannot know for sure which equilibrium will be selected.

## 2. Optimal Growth in Discrete Time

Consider an economy populated by a constant number of identical infinitelylived agents. There is a single good that can be consumed directly or used as capital in production. The preferences of a representative individual are described by a utility function of the form

$$
\begin{equation*}
\sum_{t=0}^{\infty} \beta^{t} U\left(c_{t}\right) \tag{1}
\end{equation*}
$$

where $\beta \in(0,1)$ is the rate of time discount, a measure of the agent's "impatience," $c_{t}$ is consumption at time $t$, and the period utility function $U()$ is a strictly increasing and strictly concave $C^{2}$ function. All agents are endowed with one unit of labor time each period.

Production of the single good requires both labor $(L)$ and capital $(K)$. The production technology is described by a strictly concave production function,

$$
Y=F(K, L)
$$

where we interpret $Y$ as gross output (i.e., new production plus undepreciated capital). ${ }^{8}$ We assume that $F()$ is $C^{2}$ and is strictly increasing and exhibits constant returns to scale (i.e., is homogeneous of degree 1). Thus, if both inputs are changed by the same factor $\lambda$, output changes also by a factor of $\lambda$, and we have

$$
\begin{equation*}
F(\lambda K, \lambda L)=\lambda F(K, L) \tag{2}
\end{equation*}
$$

This property of the production function allows a convenient normalization. In (2), let $\lambda=1 / L$, and note that

$$
F(K / L, L / L)=(1 / L) F(K, L) \Rightarrow F(K, L)=L F(K / L, 1)
$$

If we write $k$ for the per-capita capital stock $(K / L)$ and define the per-capita production function by

$$
\begin{equation*}
f(k) \equiv F(k, 1) \tag{3}
\end{equation*}
$$

we can write total output as

$$
Y=L f(k)
$$

and per-capita output $y=Y / L$ as a function of the average capital stock per worker,

$$
\begin{equation*}
y=f(k) \tag{4}
\end{equation*}
$$

Imagine that this economy is regulated by a benevolent, all-powerful social planner who makes production, consumption, and investment decisions so as to maximize the lifetime utility of the representative individual. The planner chooses a sequence $\left\{c_{t}, k_{t+1}\right\}_{t=0}^{\infty}$ of consumption levels and capital stocks so as to maximize the utility function (1), taking as given the production technology, and subject to a resource-availability constraint. Working in per-capita terms, the initial capital stock $k_{0}$ is given, and at each point in time, consumption and investment must satisfy the constraint

$$
\begin{equation*}
f\left(k_{t}\right)=c_{t}+k_{t+1} \tag{5}
\end{equation*}
$$

That is, current output per capita, including undepreciated capital, $f\left(k_{t}\right)$, can be either consumed today or used for tomorrow's production.

At any given point in time $t$, the initial capital stock $k_{t}$ describes completely the state of the system and determines the economy's consumption possibilities for the current period and all future time. Given $k_{t}$, the planner's immediate concern is to choose current consumption. Alternatively, because $k_{t+1}+c_{t}$ must add up to current output, we can think of the planner as choosing an investment level $k_{t+1}$. Hence, the planner's problem can be written

$$
\begin{equation*}
V\left(k_{0}\right)=\max _{\left\{k_{t+1}\right\}_{t=0}^{\infty}}\left\{\sum_{t=0}^{\infty} \beta^{t} U\left[f\left(k_{t}\right)-k_{t+1}\right] \text { s.t. } 0 \leq k_{t+1} \leq f\left(k_{t}\right), k_{0} \text { given }\right\} \tag{P}
\end{equation*}
$$

The constraint says that next period's capital stock cannot be negative and cannot exceed current gross output. To rule out corner solutions, we will assume that both the production function and the period utility function satisfy the following conditions:

$$
\begin{equation*}
f(0)=0, \quad f^{\prime}(0)=\infty, \quad f^{\prime}(\infty)=0, \quad U^{\prime}(0)=\infty, \quad \text { and } \quad U^{\prime}(\infty)=0 \tag{6}
\end{equation*}
$$

Following our discussion in Chapter 12, the (current) value function for the planner's problem satisfies the Bellman equation,

$$
\begin{equation*}
V\left(k_{t}\right)=\max _{k_{t+1}}\left\{U\left[f\left(k_{t}\right)-k_{t+1}\right]+\beta V\left(k_{t+1}\right) \text { s.t } 0 \leq k_{t+1} \leq f\left(k_{t}\right)\right\} \tag{BE.P}
\end{equation*}
$$

Under our assumptions regarding preferences and technology, all but one of the conditions that would guarantee the existence and uniqueness of a bounded, continuous, strictly increasing and strictly concave solution to (BE.P) are satisfied. In particular, recall that Theorem 1.5 in Chapter 12 required the period return function to be bounded. In the current context, however, the period utility function $U()$ and the production function may very well be unbounded. There is, however, a simple way to sidestep the problem by restricting ourselves to a bounded subset of the domain of $f($ ).

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-603.jpg?height=608&width=851&top_left_y=189&top_left_x=324)

Figure 13.6.

Imagine, for a moment, that consumption is zero in all periods. Then the evolution of the capital stock is described by the difference equation

$$
\begin{equation*}
k_{t+1}=f\left(k_{t}\right) \tag{7}
\end{equation*}
$$

It is easy to show (see the discussion of the Solow model in Chapter 11) that under our assumptions, the phase diagram for this equation is as shown in Figure 13.6, with a unique and globally stable steady state, $k_{M}$. Hence, even if all output is invested each period, there is a maximum sustainable percapita capital stock. We can therefore restrict ourselves to values of $k$ in the interval $\left[0, k_{M}\right]$. Because $U[f(k)]$ is certainly bounded in this set, we can apply Theorems 1.5 and 1.18 in Chapter 12 to obtain the following result.

Proposition 2.1. The Bellman equation (BE.P) has a unique continuous and bounded solution $\mathrm{V}$. This function is the value function for the planner's problem $(P)$ and is strictly increasing and strictly concave. Moreover, the policy correspondence $\mathrm{g}$ () giving next period's optimal capital stock as a function of today's state $\mathrm{k}_{\mathrm{t}}$ is a well-defined and continuous function.

Given this result, we can establish some important properties of the policy function by studying the maximization inside the Bellman equation. We begin by using Theorem 2.15 in Chapter 6 to show that $V()$ is differentiable. This will allow us to use the first-order condition for the maximization in (BE.P) to characterize the optimal investment decision.

Proposition 2.2. The value function for the planner's problem, $\mathrm{V}($ ), is differentiable, with

$$
\mathrm{V}^{\prime}\left(\mathrm{k}_{\mathrm{t}}\right)=\mathrm{U}^{\prime}\left[\mathrm{f}\left(\mathrm{k}_{\mathrm{t}}\right)-\mathrm{k}_{\mathrm{t}+\mathrm{l}}\right] \mathrm{f}^{\prime}\left(\mathrm{k}_{\mathrm{t}}\right)
$$

Proof. Fix some $k_{t}^{0}$ in $\left(0, k_{M}\right)$, and let $k_{t+1}^{0}$ be a solution of the problem

$$
\begin{equation*}
V\left(k_{t}^{0}\right)=\max _{k_{t+1}}\left\{U\left[f\left(k_{t}^{0}\right)-k_{t+1}\right]+\beta V\left(k_{t+1}\right) \text { s.t. } 0 \leq k_{t+1} \leq f\left(k_{t}^{0}\right)\right\} \tag{BE.P}
\end{equation*}
$$

Next, define the function

$$
W\left(k_{t}\right)=U\left[f\left(k_{t}\right)-k_{t+1}^{0}\right]+\beta V\left(k_{t+1}^{0}\right)
$$

for $k_{t}$ within some $\varepsilon$-ball with center at $k_{t}^{0}, B_{\varepsilon}\left(k_{t}^{0}\right)$. Under assumption (6), $k_{t+1}^{0}$ will be an interior solution of this problem, that is, $0<k_{t+1}^{0}<f\left(k_{t}^{0}\right)$. By the continuity of $f, \varepsilon$ can be chosen small enough that $f\left(k_{t}\right)>k_{t+1}^{0}$ for all $k_{t} \in B_{\varepsilon}\left(k_{t}^{0}\right)$, that is, so that $k_{t+1}^{0}$ is still feasible for all $k_{t} \in B_{\varepsilon}\left(k_{t}^{0}\right)$. On the other hand, $k_{t+1}^{0}$ is not necessarily optimal for an arbitrary $k_{t}$ in $B_{\varepsilon}\left(k_{t}^{0}\right)$. Hence,

$$
W\left(k_{t}\right)=U\left[f\left(k_{t}\right)-k_{t+1}^{0}\right]+\beta V\left(k_{t+1}^{0}\right) \leq \max _{k_{t+1}}\left\{U\left[f\left(k_{t}\right)-k_{t+1}\right]+\beta V\left(k_{t+1}\right)\right\}=V\left(k_{t}\right)
$$

for all $k_{t} \in B_{\varepsilon}\left(k_{t}^{0}\right)$, and

$$
W\left(k_{t}^{0}\right)=V\left(k_{t}^{0}\right)
$$

because $k_{t+1}^{0}$ is optimal for $k_{t}^{0}$. Moreover, $W()$ is a differentiable function of $k_{t}$, because $U()$ and $f()$ are differentiable, and $V\left(k_{t+1}^{0}\right)$ is just a constant. Hence, by Theorem 2.15 in Chapter 6, $V()$ is differentiable at $k_{t}^{0}$, and

$$
V^{\prime}\left(k_{t}^{0}\right)=W^{\prime}\left(k_{t}^{0}\right)=U^{\prime}\left[f\left(k_{t}^{0}\right)-k_{t+1}^{0}\right] f^{\prime}\left(k_{t}^{0}\right)
$$

Because $V()$ is differentiable, an interior solution of the maximization inside the Bellman equation is characterized by the first-order condition

$$
\begin{equation*}
U^{\prime}\left[f\left(k_{t}\right)-k_{t+1}\right]=\beta V^{\prime}\left(k_{t+1}\right) \tag{8}
\end{equation*}
$$

which implicitly defines the policy function

$$
k_{t+1}^{*}=g\left(k_{t}\right)
$$

Without additional restrictions there will be no guarantee that $V$ will be twice differentiable. Hence, we cannot differentiate (8) again to establish the comparative-statics properties of the function $g()$. As we will see, however, equation (8) and the concavity of the value function provide sufficient information to establish some important properties of the policy function and the optimal sequence of capital stocks.

In some cases it will be useful to rewrite (8) in an alternative way. By Proposition 2.2, applied at time $t+1$, we have that

$$
\begin{equation*}
V^{\prime}\left(k_{t+1}\right)=U^{\prime}\left[f\left(k_{t+1}\right)-k_{t+2}\right] f^{\prime}\left(k_{t+1}\right)=U^{\prime}\left(c_{t+1}\right) f^{\prime}\left(k_{t+1}\right) \tag{9}
\end{equation*}
$$

Substituting (9) into (8), we obtain the so-called Euler equation,

$$
\begin{equation*}
U^{\prime}\left[f\left(k_{t}\right)-k_{t+1}\right]=\beta U^{\prime}\left[f\left(k_{t+1}\right)-k_{t+2}\right] f^{\prime}\left(k_{t+1}\right) \tag{10}
\end{equation*}
$$

or, reintroducing consumption explicitly,

$$
U^{\prime}\left(c_{t}\right)=\beta U^{\prime}\left(c_{t+1}\right) f^{\prime}\left(k_{t+1}\right)
$$

To interpret this equation, consider reducing period- $t$ consumption by one unit in order to invest it and increase consumption at $t+1$. On the one hand, there is a utility loss of $U^{\prime}\left(c_{t}\right)$ in period $t$. On the other, an additional unit of investment will allow consumption to be higher by $f^{\prime}\left(k_{t+1}\right)$ units next period, yielding a utility gain of $U^{\prime}\left(c_{t+1}\right) f^{\prime}\left(k_{t+1}\right)$. Because this utility gain comes one period later, however, we must discount it by $\beta$. The Euler equation says that along an optimal path, today's loss and tomorrow's gain must be equal, for otherwise a feasible rearrangement of the consumption/investment plan would increase its total value, implying that the original plan could not have been optimal. Hence, along an optimal trajectory, the planner must be indifferent, at the margin, between using an additional unit of output for current consumption or for investment.

There are now two different ways to proceed. One is to work directly with the first-order condition (8); the other is to analyze the two-equation system formed by the Euler equation $\left(10^{\prime}\right)$ and the constraint (5), reinterpreted as the law of motion for the capital stock,

$$
k_{t+1}=f\left(k_{t}\right)-c_{t}
$$

We will work through the first approach and let the reader explore the second approach through a series of problems.

## (a) Properties of the Policy Function and the Optimal Capital Sequence

Given the policy function $g()$, the optimal time path for the capital stock is the solution of the difference equation $k_{t+1}=g\left(k_{t}\right)$. We know that the optimal sequence, $\left\{k_{t}^{*}\right\}$, must satisfy the first-order condition (8) and the Euler equation (10) and that the value function $V()$ is strictly concave and increasing. In this section, we will use this information to establish some properties of $g()$ and $\left\{k_{t}^{*}\right\}$.

We begin by characterizing the steady state of the system. Setting $k_{t}=k_{t+1}$ $=k_{t+2} \equiv k$ in the Euler equation (10), we obtain

$$
\begin{align*}
& U^{\prime}[f(k)-k]=\beta U^{\prime}[f(k)-k] f^{\prime}(k) \\
& \quad \Rightarrow f^{\prime}(k)=1 / \beta \tag{11}
\end{align*}
$$

an equation that implicitly defines the steady-state capital stock $\bar{k}$ as a function of the discount rate $\beta .{ }^{9}$ Because $f()$ is strictly concave, the marginal product of capital, $f^{\prime}(k)$, is a strictly decreasing function of the capital stock, implying that equation (11) has at most one solution. The assumptions that $f^{\prime}(0)=\infty$ and $f^{\prime}(\infty)=0$, moreover, ensure the existence of a positive solution,
$\bar{k}$. Moreover, we have $\bar{k} \leq k_{M}$, as $\bar{k}$ cannot be larger than the maximum sustainable capital stock described earlier.

Next, we show that the policy function $g()$ is an increasing function of $\boldsymbol{k}_{t}$. This result is then used to establish that the optimal sequence of capital stocks $\left\{k_{t}^{*}\right\}_{t=0}^{\infty}$ is monotonic and converges asymptotically to the steady state for any given initial stock $k_{0}>0$.

Proposition 2.3. The policy function $\mathrm{k}_{t+1}^{*}=\mathrm{g}\left(\mathrm{k}_{\mathrm{t}}\right)$ is increasing in $\mathrm{k}_{\mathrm{t}}$.

Proof. By contradiction. Suppose $g()$ is not increasing everywhere. Then there exist capital stocks $k^{\prime}$ and $k^{\prime \prime}$ such that $k^{\prime \prime}>k^{\prime}$ and

$$
\begin{equation*}
g\left(k^{\prime \prime}\right)<g\left(k^{\prime}\right) \tag{1}
\end{equation*}
$$

Because $V()$ is concave, moreover, $V^{\prime}()$ is decreasing, and (1) implies

$$
\begin{equation*}
V^{\prime}\left[g\left(k^{\prime \prime}\right)\right]>V^{\prime}\left[g\left(k^{\prime}\right)\right] \tag{2}
\end{equation*}
$$

By the first-order condition

$$
\begin{equation*}
U^{\prime}\left[f\left(k_{t}\right)-k_{t+1}\right]=\beta V^{\prime}\left(k_{t+1}\right) \tag{8}
\end{equation*}
$$

inequality (2) implies

$$
U^{\prime}\left[f\left(k^{\prime \prime}\right)-g\left(k^{\prime \prime}\right)\right]>U^{\prime}\left[f\left(k^{\prime}\right)-g\left(k^{\prime}\right)\right]
$$

Now, Because $U()$ is strictly concave by assumption, the foregoing expression implies that

$$
f\left(k^{\prime \prime}\right)-g\left(k^{\prime \prime}\right)<f\left(k^{\prime}\right)-g\left(k^{\prime}\right) \Rightarrow g\left(k^{\prime \prime}\right)-g\left(k^{\prime}\right)>f\left(k^{\prime \prime}\right)-f\left(k^{\prime}\right)>0
$$

where the last inequality holds because $f()$ is increasing. But then $g\left(k^{\prime \prime}\right)>$ $g\left(k^{\prime}\right)$, which contradicts (1).

Proposition 2.4. The optimal capital sequence $\left\{\mathrm{k}_{t}^{*}\right\}$, defined recursively by $\mathrm{k}_{t+1}^{*}$ $=\mathrm{g}\left(\mathrm{k}_{\mathrm{t}}^{*}\right)$, with $\mathrm{k}_{0}$ given, is monotonic.

Proof. Suppose $k_{1}^{*}>k_{0}$. Because $g()$ is increasing, we have

$$
k_{2}^{*}=g\left(k_{1}^{*}\right) \geq g\left(k_{0}\right)=k_{1}^{*}
$$

which implies, in turn,

$$
k_{3}^{*}=g\left(k_{2}^{*}\right) \geq g\left(k_{1}^{*}\right)=k_{2}^{*}
$$

and so forth. Similarly, if $k_{1}^{*}<k_{0}$, then

$$
k_{2}^{*}=g\left(k_{1}^{*}\right) \leq g\left(k_{0}\right)=k_{1}^{*}
$$

and so on.

Proposition 2.5. If the initial capital stock $\mathrm{k}_{0}$ is above the steady state $\overline{\mathrm{k}}$, then $\left\{\mathrm{k}_{\mathrm{t}}^{*}\right\}$ decreases monotonically; if $\mathrm{k}_{0}<\overline{\mathrm{k}}$ then $\left\{\mathrm{k}_{t+1}^{*}\right\}$ increases monotonically.

Proof. Because $V()$ is strictly concave, $V^{\prime}()$ is strictly decreasing. Hence

$$
\begin{equation*}
k^{\prime \prime}>k^{\prime} \Rightarrow V^{\prime}\left(k^{\prime \prime}\right)<V^{\prime}\left(k^{\prime}\right) \tag{1}
\end{equation*}
$$

Consider two successive capital stocks, $k_{t}^{*}$ and $k_{t+1}^{*}$, where $k_{t+1}^{*}=g\left(k_{t}^{*}\right)$. By (1), $k_{t}^{*}-k_{t+1}^{*}$ and $V^{\prime}\left(k_{t}^{*}\right)-V^{\prime}\left(k_{t+1}^{*}\right)$ will have opposite signs, that is,

$$
\begin{equation*}
\left(k_{t}^{*}-k_{t+1}^{*}\right)\left[V^{\prime}\left(k_{t}^{*}\right)-V^{\prime}\left(k_{t+1}^{*}\right)\right] \leq 0 \quad(=0 \text { at the steady state }) \tag{2}
\end{equation*}
$$

By equations (8) and (9), we have

$$
\begin{aligned}
& (8) \Rightarrow V^{\prime}\left(k_{t+1}^{*}\right)=(1 / \beta) U^{\prime}\left[f\left(k_{t}^{*}\right)-k_{t+1}^{*}\right] \\
& (9) \Rightarrow V^{\prime}\left(k_{t}^{*}\right)=U^{\prime}\left[f\left(k_{t}^{*}\right)-k_{t+1}^{*}\right] f^{\prime}\left(k_{t}^{*}\right)
\end{aligned}
$$

Substituting these expressions in (2),

$$
\left(k_{t}^{*}-k_{t+1}^{*}\right)\left\{U^{\prime}\left[f\left(k_{t}^{*}\right)-k_{t+1}^{*}\right] f\left(k_{t}^{*}\right)-(1 / \beta) U^{\prime}\left[f\left(k_{t}^{*}\right)-k_{t+1}^{*}\right]\right\} \leq 0
$$

and, dividing by $U^{\prime}()>0$,

$$
\begin{equation*}
\left(k_{t}^{*}-k_{t+1}^{*}\right)\left[f^{\prime}\left(k_{t}^{*}\right)-(1 / \beta)\right] \leq 0 \tag{3}
\end{equation*}
$$

Recall that at the steady state, $f^{\prime}(\bar{k})=1 / \beta$, and $f^{\prime}()$ is decreasing, by the concavity of $f($ ). Hence,

- if $k_{t}^{*}<\bar{k}$, we have $f^{\prime}\left(k_{t}^{*}\right)>(1 / \beta)$, and (3) implies that $k_{t}^{*} \leq k_{t+1}^{*}$, that is, $\left\{k_{t}^{*}\right\}$ is increasing, and
- if $k_{l}^{*}>\vec{k}$, we have $f^{\prime}\left(k_{t}^{*}\right)<(1 / \beta)$, and (3) implies that $k_{t}^{*} \geq k_{t+1}^{*}$, that is, $\left\{k_{t}^{*}\right\}$ is decreasing.

Proposition 2.6. The optimal capital sequence $\left\{\mathrm{k}_{1}^{*}\right\}$ converges (monotonically) to the steady-state capital stock $\overline{\mathrm{k}}$ for any initial $\mathrm{k}_{0}>0$.

Proof. Note that $\left\{k_{t}^{*}\right\}$ is monotonic and bounded (above by $k_{M}$, below by zero or, alternatively, by $k_{0}$ and $\bar{k}$ ). Because every monotonic bounded sequence converges, $\left\{k_{i}^{*}\right\}$ has a limit that we will call $k^{*}$. By the continuity of the policy function $g(), k^{*}$ must be a fixed point of $g()$, for

$$
k^{*}=\lim _{t \rightarrow \infty} k_{t+1}^{*}=\lim _{t \rightarrow \infty} g\left(k_{t}\right)=g\left(\lim _{t \rightarrow \infty} k_{t}\right)=g\left(k^{*}\right)
$$

Hence, $k^{*}$ is a steady state. Because there is a unique steady state $\bar{k}$, we conclude that $\left\{k_{i}^{*}\right\} \rightarrow \bar{k}$.

## (b) The Euler Equation and Dynamics

In the preceding section we found it convenient to solve the resource constraint for $c$ and work only with the capital stock. Using the concavity of the
value function and the first-order condition for the maximization in the Bellman equation, we have established that the optimal capital sequence $\left\{k_{t}^{*}\right\}$ converges monotonically to the steady state of the system. We can then use the constraint again to infer the optimal path of consumption over time. We now illustrate a second and probably more instructive approach to analyzing the dynamics of the optimal-growth model. The basic idea is to treat the system formed by the Euler equation and the transition law for the capital stock,

$$
\begin{gather*}
U^{\prime}\left(c_{t}\right)=\beta U^{\prime}\left(c_{t+1}\right) f^{\prime}\left(k_{t+1}\right)  \tag{11}\\
k_{t+1}=f\left(k_{t}\right)-c_{t} \tag{12}
\end{gather*}
$$

as an ordinary system of difference equations and study its dynamics in the standard way. Thus, we first solve for the steady state; then we construct a phase diagram and compute the eigenvalues of the Jacobian matrix at the steady state to check for stability.

Setting $c_{t}=c_{t+1} \equiv c$ and $k_{t}=k_{t+1} \equiv k$ in (11) and (12), we get

$$
\begin{gather*}
(11) \Rightarrow U^{\prime}(c)=\beta U^{\prime}(c) f^{\prime}(k) \Rightarrow \beta f^{\prime}(k)=1  \tag{13}\\
(12) \Rightarrow c=f(k)-k \tag{14}
\end{gather*}
$$

As we have seen, equation (13) has a unique solution $\bar{k}$. Given $\bar{k}$, equation (14) can be solved for steady-state consumption $\bar{c}$.

The system (11)-(12) is not quite in the "standard form." In particular, we would like to have each variable ( $k_{t+1}$ and $c_{t+1}$ ) as a function of the lagged values $k_{t}$ and $c_{t}$. To this end, we solve (12) for $k_{t+1}$, substitute the result into (11), and apply the implicit-function theorem to the resulting equation to obtain a function $\phi()$ giving $c_{t+1}$ as a function of $k_{t}$ and $c_{t}$. This yields the system

$$
\begin{gather*}
k_{t+1}=f\left(k_{t}\right)-c_{t} \equiv \varphi\left(k_{t}, c_{t}\right)  \tag{15}\\
U^{\prime}\left(c_{t}\right)=\beta U^{\prime}\left(c_{t+1}\right) f^{\prime}\left[f\left(k_{t}\right)-c_{t}\right] \Leftrightarrow c_{t+1}=\phi\left(k_{t}, c_{t}\right) \tag{16}
\end{gather*}
$$

Problem 2.7. Apply the implicit-function theorem to compute the partial derivatives of the function $\phi\left(k_{t}, c_{t}\right)$ defined implicitly by equation (16), and determine their sign.

Problem 2.8. Setting $c_{t}=c_{t+1}=c$ and $k_{t}=k_{t+1}=k$ in (15) and (16), draw the phase lines $\Delta k_{t}=0$ and $\Delta c_{t}=0$. To complete the phase diagram, determine the directions of motion along the $c$ and $k$ axes in each of the four regions into which the state plane $(c, x)$ is divided by the phase lines.

Problem 2.9. The phase diagram you have just drawn should suggest that the steady state is a saddle point. Check that this is true by showing that the
eigenvalues of the Jacobian matrix for the system are positive real numbers lying on opposite sides of 1 .

The phase diagram we have constructed shows the orbits of the system (15)-(16), but only one of these trajectories corresponds to the solution of the original planning problem. These two equations can be thought of as the first-order conditions for an optimum, but they are not sufficient to fully characterize the optimal path.

Out of all the solutions of (15)-(16), we want to identify the one that corresponds to the solution of the programming problem. To select one particular solution, we need two boundary conditions to pin down one point in the phase plane through which the system will have to go. The initial value of the capital stock should be taken as given; this yields one initial condition, $k(t=0)=k_{0}$, a given constant, specifying that the system starts out from some point on a vertical line through $k_{0}$ in the phase plane. On the other hand, there is no natural initial condition for the free variable $c$, so we need another way to identify the optimal path.

It turns out that the optimal consumption/investment plan is the one described by the saddle-path trajectory. An intuitive way to see this is by examining the phase diagram for the system after adding to it a feasibility bound requiring that consumption not exceed current output, that is, $c \leq$ $f(k)$. Inspection of this figure suggests that all trajectories other than the saddle path eventually run into either the $k$ axis or the feasibility bound, where present consumption exhausts output, leaving nothing for next period. In either case, consumption becomes zero and remains so thereafter. It is clear that such paths cannot be optimal, leaving us with only the saddle path.

A more formal way to identify the optimal path is through a so-called transversality condition. In some sense, the problem is the same as in a static maximization problem: The first-order conditions (the Euler equations here) identify possible candidates for a maximum, but they are also satisfied by points that are not maxima. To find an optimum, we need an additional criterion, some sort of second-order condition relating to the concavity of the objective function at the candidate point. The transversality condition plays a similar role in the present context, and as we will see, the sufficiency proof relies heavily on the concavity of the objective function.

An alternative way to think of the transversality condition is as a terminal condition for the system of difference equations. Consider first a finitehorizon version of the planning problem we are studying. In that case $k_{T+1}$ is the capital stock to be left "at the end of time"; it is clear that the optimal thing to do is to leave nothing, so $k_{T+1}=0$, providing us with a second boundary condition to identify the particular solution of (15)-(16) that solves the planner's problem. As we saw in Chapter 12, in the infinite-horizon case the
transversality condition can be interpreted in a somewhat similar way, as the requirement that as $t \rightarrow \infty$ the suitably discounted value of the capital stock should go to zero. Intuitively, we want to prevent the planner from accumulating too much capital at the expense of deferring consumption forever.

Proposition 2.10. Transversality condition. Let $\mathrm{s}^{*}=\mathrm{k}_{0} \cup\left\{\mathrm{c}_{\mathrm{t}}^{*}, \mathrm{k}_{t+1}^{*}\right\}_{\mathrm{t}=0}^{\infty}$ be a solution sequence of the system (15)-(16). If this sequence satisfies the transversality condition

$$
\begin{equation*}
\lim _{\mathrm{T} \rightarrow \infty} \beta^{\mathrm{T}} \mathrm{U}^{\prime}\left(\mathrm{c}_{\mathrm{T}}\right) \mathrm{f}^{\prime}\left(\mathrm{k}_{\mathrm{T}}\right) \mathrm{k}_{\mathrm{T}}=0 \tag{T}
\end{equation*}
$$

then it solves the planner's problem.

Proof. Let $s^{*}=k_{0} \cup\left\{c_{t}^{*}, k_{t+1}^{*}\right\}$ be a sequence satisfying the conditions of the proposition, and $s=k_{0} \cup\left\{c_{t}, k_{t+1}\right\}$ an arbitrary feasible sequence. To establish that $s^{*}$ is optimal, we show that

$$
d=W_{0}\left(s^{*}\right)-W_{0}(s)=\sum_{t=0}^{\infty} \beta^{t}\left[U\left(c_{t}^{*}\right)-U\left(c_{t}\right)\right] \geq 0
$$

That is, the total "utility value" of the candidate sequence $s^{*}$ is at least as large as that of any feasible sequence.

To show this, it will be convenient to solve the resource constraint for $c$,

$$
k_{t+1}=f\left(k_{t}\right)-c_{t} \Rightarrow c_{t}=f\left(k_{t}\right)-k_{t+1}
$$

and write the period utility function as

$$
U\left(k_{t}, k_{t+1}\right)=U\left[f\left(k_{t}\right)-k_{t+1}\right]
$$

It is easy to show that the function $U\left(k_{t}, k_{t+1}\right)$ is concave. Moreover, we have

$$
\begin{gather*}
U_{1}\left(k_{t}, k_{t+1}\right)=U^{\prime}\left[f\left(k_{t}\right)-k_{t+1}\right] f^{\prime}\left(k_{t}\right)>0  \tag{1}\\
U_{2}\left(k_{t}, k_{t+1}\right)=-U^{\prime}\left[f\left(k_{t}\right)-k_{t+1}\right]<0 \tag{2}
\end{gather*}
$$

In this notation the Euler equation can be written

$$
\begin{align*}
& U^{\prime}\left[f\left(k_{t}\right)-k_{t+1}\right]=\beta U^{\prime}\left[f\left(k_{t+1}\right)-k_{t+2}\right] f^{\prime}\left(k_{t+1}\right) \\
& \Rightarrow U_{2}\left(k_{t}, k_{t+1}\right)+\beta U_{1}\left(k_{t+1}, k_{t+2}\right)=0 \tag{3}
\end{align*}
$$

Next, write $d$ in the form

$$
d=W_{0}\left(s^{*}\right)-W_{0}(s)=\lim _{T \rightarrow \infty} \sum_{t=0}^{T} \beta^{t}\left\{U\left(k_{t}^{*}, k_{t+1}^{*}\right)-U\left(k_{t}, k_{t+1}\right)\right\}
$$

and observe that, by the concavity of $U\left(k_{t}, k_{t+1}\right)$,

$$
U\left(k_{t}, k_{t+1}\right) \leq U\left(k_{t}^{*}, k_{t+1}^{*}\right)+U_{1}\left(k_{t}^{*}, k_{t+1}^{*}\right)\left(k_{t}-k_{t}^{*}\right)+U_{2}\left(k_{t}^{*}, k_{t+1}^{*}\right)\left(k_{t+1}-k_{t+1}^{*}\right)
$$

or, rearranging,

$$
\begin{equation*}
U\left(k_{t}^{*}, k_{t+1}^{*}\right)-U\left(k_{t}, k_{t+1}\right) \geq U_{1}\left(k_{t}^{*}, k_{t+1}^{*}\right)\left(k_{t}^{*}-k_{t}\right)+U_{2}\left(k_{t}^{*}, k_{t+1}^{*}\right)\left(k_{t+1}^{*}-k_{t+1}\right) \tag{4}
\end{equation*}
$$

Hence, we have

$$
\begin{aligned}
d= & \lim _{T \rightarrow \infty} \sum_{t=0}^{T} \beta^{t}\left\{U\left(k_{t}^{*}, k_{t+1}^{*}\right)-U\left(k_{t}, k_{t+1}\right)\right\} \\
& \geq \lim _{T \rightarrow \infty} \sum_{t=0}^{T} \beta^{t}\left\{U_{1}\left(k_{t}^{*}, k_{t+1}^{*}\right)\left(k_{t}^{*}-k_{t}\right)+U_{2}\left(k_{t}^{*}, k_{t+1}^{*}\right)\left(k_{t+1}^{*}-k_{t+1}\right)\right\} \\
= & \beta^{0}\left\{U_{1}\left(k_{0}^{*}, k_{1}^{*}\right)\left(k_{0}^{*}-k_{0}\right)+U_{2}\left(k_{0}^{*}, k_{1}^{*}\right)\left(k_{1}^{*}-k_{1}\right)\right\} \\
& +\beta\left\{U_{1}\left(k_{1}^{*}, k_{2}^{*}\right)\left(k_{1}^{*}-k_{1}\right)+U_{2}\left(k_{1}^{*}, k_{2}^{*}\right)\left(k_{2}^{*}-k_{2}\right)\right\}+\ldots+ \\
& \beta^{t}\left\{U_{1}\left(k_{t}^{*}, k_{t+1}^{*}\right)\left(k_{t}^{*}-k_{t}\right)+U_{2}\left(k_{t}^{*}, k_{t+1}^{*}\right)\left(k_{t+1}^{*}-k_{t+1}\right)\right\} \\
& +\beta^{t+1}\left\{U_{1}\left(k_{t+1}^{*}, k_{t+2}^{*}\right)\left(k_{t+1}^{*}-k_{t+1}\right)+U_{2}\left(k_{t+1}^{*}, k_{t+2}^{*}\right)\left(k_{t+2}^{*}-k_{t+2}\right)\right\}+\ldots
\end{aligned}
$$

Observe that the initial capital stock is given and thus is the same in both $s$ and $s^{*}$; hence $k_{0}^{*}-k_{0}=0$, and the first term in the sum vanishes. The remaining terms can be rearranged to give

$$
\begin{align*}
d= & \lim _{T \rightarrow \infty}\left\{\sum_{t=1}^{T} \beta^{t-1}\left\{\left[U_{2}\left(k_{t+1}^{*}, k_{t}^{*}\right)+\beta U_{1}\left(k_{t}^{*}, k_{t+1}^{*}\right)\right]\left(k_{t}^{*}-k_{t}\right)\right\}\right. \\
& \left.+\beta^{T} U_{2}\left(k_{T}^{*}, k_{T+1}^{*}\right)\left(k_{T+1}^{*}-k_{T+1}\right)\right\} \tag{5}
\end{align*}
$$

Next, recall that $s^{*}$ is assumed to satisfy the Euler equation

$$
\begin{equation*}
U_{2}\left(k_{t}^{*}, k_{t+1}^{*}\right)+\beta U_{1}\left(k_{t+1}^{*}, k_{t+2}^{*}\right)=0 \tag{3}
\end{equation*}
$$

Hence the terms in the summation vanish, and we have

$$
d=W_{0}\left(s^{*}\right)-W_{0}(s) \geq \lim _{T \rightarrow \infty} \beta^{T} U_{2}\left(k_{T}^{*}, k_{T+1}^{*}\right)\left(k_{T+1}^{*}-k_{T+1}\right)
$$

Moreover, we have $k_{T+1} \geq 0$, by the feasibility constraint, and $U_{2}()<0$, by (2). Hence, the product $U_{2}\left(k_{T}^{*}, k_{T+1}^{*}\right)\left(-k_{T+1}\right)$ is positive, and we have, using the Euler equation,

$$
\begin{aligned}
d & =W_{0}\left(s^{*}\right)-W_{0}(s) \geq \lim _{T \rightarrow \infty} \beta^{T} U_{2}\left(k_{T}^{*}, k_{T+1}^{*}\right) k_{t+1}^{*} \\
& =\lim _{T \rightarrow \infty} \beta^{T+1} U_{1}\left(k_{T+1}^{*}, k_{T+2}^{*}\right) k_{T+1}^{*}=-\lim _{T \rightarrow \infty} \beta^{T+1} U^{\prime}\left(c_{T+1}^{*}\right) f^{\prime}\left(k_{T+1}^{*}\right) k_{T+1}^{*}=0
\end{aligned}
$$

where the next-to-last equality follows from (1), and the last limit is zero, by the transversality condition ( $\mathrm{T}$ ).

In conclusion, we have shown that

$$
d=W_{0}\left(s^{*}\right)-W_{0}(s) \geq 0
$$

Because the sequence $s^{*}$ that satisfies both the Euler equation and the transversality condition must yield a greater value than any other feasible sequence, it must be optimal.

Problem 2.11. Show that the function $U\left(k_{t}, k_{t+1}\right)$ defined in the proof of Proposition 2.10 is concave.

To conclude, it is easy to verify that the saddle-path solution satisfies the transversality condition (T) and is therefore optimal. For this solution, both $c_{t}$ and $k_{t}$ converge to finite values $c$ and $k$. Hence, $k, U^{\prime}(c)$, and $f^{\prime}(k)$ are just finite constants, and

$$
\lim _{T \rightarrow \infty} \beta^{T} U^{\prime}(c) f^{\prime}(k) k=0
$$

because $\beta \in(0,1)$. Along explosive paths, however, either $k$ or $c$ will become zero. In that case, $f^{\prime}(k) \rightarrow \infty$ or $U^{\prime}(c) \rightarrow \infty$, so (T) may not hold.

## 3. Investment with Installation Costs

In the standard static model the firm is assumed to maximize current profits, defined as the difference between output and contemporaneous factor payments. Letting $K$ and $L$ denote labor and capital inputs, and $w$ and $R$ the wage and the rental rate of capital in units of output, the firm's problem can be written

$$
\begin{equation*}
\max _{K . L} F(K, L)-w L-R K \tag{1}
\end{equation*}
$$

The solution functions for this problem are factor demands giving optimal input levels as functions of factor prices:

$$
K^{*}=K(w, r) \quad \text { and } \quad L^{*}=L(w, r)
$$

This formulation assumes that the firm can rent inputs in "spot markets" and put them to work immediately and at no cost. This clearly unrealistic assumption may lead, at best, to a theory of the determination of the optimal capital stock, but it has no implications (or very naive ones) for the optimal investment policy.

In practice, capital is typically purchased, rather than rented, and its installation may involve considerable delays and adjustment costs. Thus, a firm's stock of "installed capital" becomes a sluggish state variable, and investment decisions must be made taking into account their effect on the entire time path of profits, rather than on a period-by-period basis.

The first part of this section analyzes the optimal investment policy for a competitive firm when the installation of capital is costly. In the second part, we go from partial to general equilibrium and study the time paths of investment and share prices in a small open economy and their responses to changes in tax policy.

## (a) A Model of Investment with Installation Costs

Consider a competitive firm with access to a constant-returns technology $F(K, L)$. The firm hires labor in spot markets at a constant wage rate $w$ and may devote part of its output to productive investment $I$. The installation of new capital involves a cost. In particular, an investment expenditure of $I$ units of output yields $\Psi(I, K)<I$ units of new productive capital when the already-installed stock is $K$. If capital depreciates at a constant rate $\delta$, the instantaneous rate of change of the firm's stock of installed capital is given by

$$
\begin{equation*}
\dot{K}_{t}=\Psi\left(I_{t}, K_{t}\right)-\delta K_{t} \tag{1}
\end{equation*}
$$

Profits, defined as output minus wage payments, are taxed at a constant rate $\tau$, and investment is subsidized at a rate $c$. Thus, the firm's instantaneous net cash flow is given by

$$
\Pi_{t}=(1-\tau)\left[F\left(K_{t}, L_{t}\right)-w L_{t}\right]-(1-c) I_{t}
$$

We will assume that net cash flows are distributed as dividends among the firm's owners each period and that the stock market values the firm correctly (i.e., that the value of its stock is the discounted value of the dividend stream),

$$
\begin{equation*}
\int_{0}^{\infty} e^{-r t} \Pi_{t} d t \tag{2}
\end{equation*}
$$

where $r$ is the market rate of interest (assumed constant). In these circumstances, all shareholders will agree that the firm should maximize (2). The firm's problem can therefore be written ${ }^{10}$

$$
\begin{align*}
V\left(K_{0}\right)= & \max _{\substack{I(t), L(t), 0 \leq t \leq \infty}}\left\{\int_{0}^{\infty} e^{-r t}\left((1-\tau)\left[F\left(K_{t}, L_{t}\right)-w L_{t}\right]-(1-c) I_{t}\right) d t\right. \\
& \text { s.t. } \left.\dot{K}_{t}=\Psi\left(I_{t}, K_{t}\right)-\delta K_{t}, K_{0} \text { given }\right\} \tag{P}
\end{align*}
$$

We will assume that $F()$ and $\Psi()$ exhibit constant returns to scale and are increasing and concave functions that are twice continuously differentiable, with

$$
\begin{aligned}
& F_{K K}, F_{L L}<0, \quad F_{K L}>0, \quad F_{L}(K, 0)=\infty \\
& \Psi_{K K}, \Psi_{I I}, \Psi_{K I}<0, \quad \Psi(I, K) \leq I, \quad \text { and } \Psi(0, K)=0 \forall K
\end{aligned}
$$

Thus, the installation function is concave in $I$ for given $K$ and goes through the origin. More investment leads to faster capital accumulation, but at a decreasing rate, and the marginal productivity of capital in installation $\left(\Psi_{K}\right)$ is positive, but decreases with both $K$ and $I$. In principle, we allow investment to be negative; that is, capital can be disinstalled and
"eaten," but only at a loss ( $\Psi<I$ implies that we lose some capital when we disinstall it).

The state variable is the stock of installed capital $K$, and the decision variables are the investment rate and the level of employment at each point in time. Necessary conditions for an optimal solution of $(\mathrm{P})$ can be obtained by applying the maximum principle. Following the procedure developed in Section 2 of Chapter 12, we begin by introducing a (current-value) costate variable or multiplier, $q_{t}$, and forming the current-value Hamiltonian,

$$
H_{t}^{c}=(1-\tau)\left[F\left(K_{t}, L_{t}\right)-w L_{t}\right]-(1-c) I_{t}+q_{t}\left[\Psi\left(I_{t}, K_{t}\right)-\delta K_{t}\right]
$$

The shadow price of installed capital, $q$, is the derivative of the value of the firm, $V$, with respect to $K$, that is, the increase in the firm's (stock-market) value that would result from an additional unit of installed capital. The last term in $H^{c}, q \dot{K}$, is the current value of the contemporaneous increase in $K$. The Hamiltonian, defined as the sum of $q \dot{K}$ and the firm's current dividend, measures the total flow of (current and discounted future) benefits arising from today's decisions. Thus, the control variables $L$ and $I$ should be chosen to maximize $H_{t}^{c}$, yielding the following conditions:

$$
\begin{align*}
& \frac{\partial H_{t}^{C}}{\partial L_{t}}=0 \Rightarrow(1-\tau)\left[F_{L}(K, L)-w\right]=0 \\
& \quad \Rightarrow F_{L}(K, L)=w  \tag{3}\\
& \frac{\partial H_{t}^{C}}{\partial I_{t}}=0 \Rightarrow-(1-c)+q \Psi_{I}(I, K)=0 \\
& \quad \Rightarrow 1-c=q \Psi_{I}(I, K) \tag{4}
\end{align*}
$$

The equation of motion for the costate variable $q$ is given by

$$
\begin{align*}
\dot{q}_{t}-r q_{t} & =-\frac{\partial H_{t}^{C}}{\partial K_{t}} \\
\Rightarrow \dot{q} & =q\left[r+\delta-\Psi_{K}(I, K)\right]-(1-\tau) F_{K}(K, L) \tag{5}
\end{align*}
$$

Maximization of $H^{c}$ with respect to $L$ yields a familiar condition: Because employment decisions can be made on a period-by-period basis, the marginal product of labor should be set equal to the wage, exactly as in the static model. Equation (4) requires that the net cost (after subsidies) of one unit of newly purchased capital equal its marginal contribution to the firm's value, obtained by multiplying the resulting increase in installed capital $\left(\Psi_{I}\right)$ by its shadow price $q$. Both conditions are in agreement with the general proposition that additional units of an input should be purchased as long as each yields a marginal benefit that exceeds its cost.

Equations (3) and (4) define policy functions giving the optimal choices
of instruments $\left(I^{*}\right.$ and $\left.L^{*}\right)$ as functions of the state and costate variables and the wage rate. To write these functions in a convenient form, we will exploit the homogeneity of degree 0 and the monotonicity of the first partial derivatives of the production and installation functions. ${ }^{11}$ Equation (3) can be written

$$
F_{L}(K, L)=F_{L}(K / L, 1)=w
$$

Inverting $F_{L}(\cdot, 1)$, we can solve for the optimal capital/labor ratio as a function of the wage and write

$$
\begin{equation*}
L^{*}=\frac{K}{\Phi(w)}, \quad \text { where } \quad \Phi=F_{L}^{-1}(\cdot, 1) \tag{6}
\end{equation*}
$$

showing that the optimal employment level increases with the stock of capital and decreases with the wage. Similarly, equation (4) can be written

$$
\frac{1-c}{q}=\Psi_{I}(I / K, 1)
$$

and, letting $\beta()=\Psi_{I}^{-1}(\cdot, 1)$, we see that the optimal level of investment is an increasing function of $K$ and $q:^{12}$

$$
\begin{equation*}
I^{*}=\beta\left(\frac{1-c}{q}\right) K, \text { with } \frac{\partial \beta[(1-c) / q]}{\partial q}=\beta^{\prime}() \frac{-(1-c)}{q^{2}}=\frac{1}{\Psi_{I I}} \frac{-(1-c)}{q^{2}}>0 \tag{7}
\end{equation*}
$$

Finally, we turn to the law of motion for the multiplier. Rearranging equation (5), we obtain

$$
\begin{equation*}
r=\frac{\dot{q}+(1-\tau) F_{K}()}{q}+\Psi_{K}()-\delta \tag{8}
\end{equation*}
$$

To interpret this expression, think of an investor who has a choice between two assets: a bond that pays the market rate of interest, $r$, and "stock certificates," each of which entitles the holder to ownership of one unit of the firm's capital and the corresponding dividends. The right-hand side of this expression gives the rate of return on installed capital if we price it at its shadow value. ${ }^{13}$ Equation (8), which requires that the returns on the two assets be the same, can therefore be interpreted as an equilibrium condition, for nobody will hold capital if there is another riskless asset that will yield a higher return.

In fact, the no-arbitrage interpretation of the law of motion for the multipliers can be taken quite literally in the present model, for it turns out that $q$ will indeed correspond to the market valuation of a unit of installed capital. Recall that $q$ is the marginal contribution of an additional unit of capital to the firm's market value; in principle, this need not coincide with
the market price, which should reflect the average value. With constant returns to scale in both production and installation, however, "average" $q$ and "marginal" $q$ coincide, as we will presently show, implying that we can indeed interpret $q$ as the market price of a unit of installed capital, ${ }^{14}$ equation (8) as a no-arbitrage condition, and the current-value Hamiltonian as the objective function for a manager who seeks to maximize the current market valuation of his firm.

Proposition 3.1. Assume that the installation and production functions ( $\Psi$ and F) exhibit constant returns to scale (homogeneity of degree 1) and that the transversality condition

$$
\lim _{\mathrm{t} \rightarrow \infty} e^{-\mathrm{rt}} \mathrm{q}_{\mathrm{t}} \mathbf{x}_{\mathrm{t}}=0
$$

holds. Then average $\mathrm{q}$ and marginal $\mathrm{q}$ coincide (i.e., $\mathrm{V}^{\mathrm{c}}(\mathrm{K})=\mathrm{qK}$ ).

Proof. The value of the firm at time $s$ is given by

$$
\begin{equation*}
V^{c}\left(K_{s}\right)=\int_{s}^{\infty} e^{-r(t-s)}\left((1-\tau)\left[F\left(K_{t}^{*}, L_{t}^{*}\right)-w L_{t}^{*}\right]-(1-c) I_{t}^{*}\right) d t \tag{9}
\end{equation*}
$$

where the asterisks indicate the optimal values of the instruments, as characterized earlier, and $K_{l}^{*}$ is the optimal path of the capital stock, the solution to

$$
\dot{K}_{t}=\Psi\left(I_{t}^{*}, K_{t}\right)-\delta K_{t} \quad\left(K_{0} \text { given }\right)
$$

Exploiting the homogeneity of the installation and production functions, we can rewrite (9) in a convenient way. Notice the following:

- Euler's theorem and the equality of the wage and the marginal product of labor imply that current profits will be equal to the product of the stock of capital and its marginal product:

$$
\begin{align*}
& F(K, L)=K F_{K}+L F_{L}=K F_{K}+L w \\
& \quad \Rightarrow F(K, L)-w L=K F_{K} \tag{10}
\end{align*}
$$

- Similarly, by the linear homogeneity of the installation function, we have

$$
\Psi(I, K)=I \Psi_{I}+K \Psi_{K} \Rightarrow I \Psi_{I}=\Psi(I, K)-K \Psi_{K}
$$

Substituting this expression in the condition for the optimal investment level, equation (4), $(1-c)=q \Psi_{I}(I, K)$, we have

$$
\begin{equation*}
(1-c) I=q\left[\Psi(I, K)-K \Psi_{K}\right] \tag{11}
\end{equation*}
$$

Substituting (10) and (11) into (9), the value of the firm is given by

$$
\begin{aligned}
V^{c}\left(K_{s}\right) & =\int_{s}^{\infty} e^{-r(t-s)}\left\{(1-\tau) K F_{K}-q\left[\Psi(I, K)-K \Psi_{K}\right]\right\} d t \\
& =\int_{s}^{\infty} e^{-r(t-s)}\left\{(1-\tau) K F_{K}-q\left(\dot{K}+\delta K-K \Psi_{K}\right)\right\} d t \\
& =\int_{s}^{\infty} e^{-r(t-s)}\left\{K\left[(1-\tau) F_{K}-q\left(\delta-\Psi_{K}\right)\right]-q \dot{K}\right\} d t \\
& =\int_{s}^{\infty} e^{-r(t-s)}\{K(r q-\dot{q})-q \dot{K}\} d t
\end{aligned}
$$

where the second equality follows by the law of motion for the capital stock ( $\Psi(I$, $K)=\dot{K}+\delta K$ ), and the last follows by the transition equation for the costate variables. ${ }^{15}$ Observing that

$$
\dot{q} K+q \dot{K}=\frac{d(q K)}{d t}
$$

we have

$$
V^{c}\left(K_{s}\right)=r e^{r s} \int_{s}^{\infty} e^{-r t} q_{t} K_{t} d t-e^{r s} \int_{s}^{\infty} e^{-r t} \frac{d(q K)}{d t} d t
$$

Integrating the second integral by parts, we arrive at

$$
\begin{aligned}
V^{C}\left(k_{s}\right) & =r e^{r s} \int_{s}^{\infty} e^{-r t} q_{t} K_{t} d t-e^{r s}\left(\left[e^{-r t} q_{t} K_{t}\right]_{s}^{\infty}+r \int_{s}^{\infty} e^{-r t} q_{t} K_{t} d t\right) \\
& =-e^{r s}\left[e^{-r t} q_{t} K_{t}\right]_{s}^{\infty}=-e^{r s}\left(\lim _{t \rightarrow \infty} e^{-r t} q_{t} K_{t}-e^{-r s} q_{s} K_{s}\right)=q_{s} K_{s}
\end{aligned}
$$

where the limit vanishes, by the transversality condition.

Phase Diagram and Dynamics. Substituting the policy functions (6) and (7) into the transition equations for the state and costate variables,

$$
\begin{aligned}
\dot{K}_{t} & =\Psi\left(I_{t}^{*}, K_{t}\right)-\delta K_{t} \\
\dot{q}_{t} & =q_{t}\left[r+\delta-\Psi_{K}\left(I_{t}^{*}, K_{t}\right)\right]-(1-\tau) F_{K}\left(K_{t}, L_{t}^{*}\right)
\end{aligned}
$$

we obtain a system of differential equations in $(q, K)$ :

$$
\begin{gather*}
\dot{K}_{t}=\Psi\left(\beta\left(\frac{1-c}{q t}\right), 1\right) K_{t}-\delta K_{t}  \tag{12}\\
\dot{q}_{t}=q_{t}\left(r+\delta-\Psi_{K}\left(\beta\left(\frac{1-c}{q_{t}}\right), 1\right)\right)-(1-\tau) F_{K}(\Phi(w), 1) \tag{13}
\end{gather*}
$$

where we have once more made use of the homogeneity of $\Psi(), F_{K}()$, and $\Psi_{K}($ ).

Setting $\dot{K}=0$, the equation of the first phase line is implicitly defined by the condition that gross investment per unit of capital be equal to the rate of depreciation,

$$
\begin{equation*}
\Psi\left(\beta\left(\frac{1-c}{q}\right), 1\right)=\delta \tag{14}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-618.jpg?height=567&width=886&top_left_y=189&top_left_x=266)

Figure 13.7. The $\dot{K}=0$ phase line.

Because the left-hand side of this equation is a monotonic function of $q$, there is at most one value of $q$ that satisfies this equation. We will assume that $\Psi()$ is such that equation (14) has a solution, and we call it $\bar{q} .{ }^{16}$ This solution value of $q$ corresponds to the lowest "share price" at which it becomes profitable to invest enough to offset depreciation. From (12),

$$
\frac{\partial \dot{K}}{\partial q}=\Psi_{I}() \frac{\partial \beta}{\partial q} K>0
$$

so $K$ increases over time whener $q>\bar{q}$, as indicated by the arrows of motion shown in Figure 13.7.

The second phase line $(\dot{q}=0)$ is defined by the condition that the rate of return on installed capital in the absence of capital gains be equal to the interest rate, that is,

$$
\begin{equation*}
r=\frac{(1-\tau) F_{K}(\Phi(w), 1)}{q}+\Psi_{K}\left(\beta\left(\frac{1-c}{q}\right), 1\right)-\delta \tag{15}
\end{equation*}
$$

As $K$ does not enter into this equation, and the right-hand side is a decreasing function of $q,(15)$ also yields a horizontal phase line at a constant value of $q$, say $q^{*}$. Differentiating (13) with respect to $q$,

$$
\begin{align*}
\left.\frac{\partial \dot{q}}{\partial q}\right|_{\dot{q}=0} ^{0} & =\left[r+\delta-\Psi_{K}(\beta(), 1)\right]-q \Psi_{K I}(\beta(), 1) \frac{\partial \beta}{\partial q} \\
& =\frac{(1-\tau) F_{K}(\Phi(w), 1)}{q}-q \Psi_{K I}(\beta(), 1) \frac{\partial \beta}{\partial q}>0 \tag{16}
\end{align*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-619.jpg?height=569&width=891&top_left_y=188&top_left_x=268)

Figure 13.8. The $\dot{q}=0$ phase line.

(provided that $\Psi_{K I}<0$ ), we see that the arrows of motion along the $q$ axis point away from the phase line, as shown in Figure 13.8. Intuitively, if $q$ is "too high" relative to the underlying stream of dividends, people will hold capital only if they expect it to appreciate over time.

Assuming that $q^{*}>\bar{q}$ (i.e., that the sustainable stationary price of capital induces investment in excess of depreciation), and combining the two phase lines, we obtain the phase diagram shown in Figure 13.9. The system has no steady states, and all paths are explosive in some sense. The closest thing to a saddle path is the horizontal trajectory along the $\dot{q}=0$ phase line, with constant $q$ and unbounded capital accumulation at a constant rate given by

$$
\begin{equation*}
\frac{\dot{K}}{K}=\Psi\left(\beta\left(\frac{1-c}{q^{*}}\right), 1\right)-\delta \equiv g \tag{17}
\end{equation*}
$$

If $g<r$, the transversality condition

$$
\lim _{t \rightarrow \infty} e^{-r t} q^{*} K_{t}=0
$$

holds, and this is indeed the optimal path, by Theorem 2.3 in Chapter 12. Using (15) and (17) and the homogeneity of the installation function,

$$
\begin{aligned}
g-r & =\Psi\left(\beta\left(\frac{1-c}{q^{*}}\right), 1\right)-\delta-\frac{(1-\tau) F_{K}(\Phi(w), 1)}{q^{*}}-\Psi_{K}\left(\beta\left(\frac{1-c}{q^{*}}\right), 1\right)+\delta \\
& =\Psi\left(\beta^{*}, 1\right)-\Psi_{K}\left(\beta^{*}, 1\right)-\frac{(1-\tau) F_{K}(\Phi(w), 1)}{q^{*}} \\
& =\Psi_{I}\left(\beta^{*}, 1\right) \beta^{*}-\frac{(1-\tau) F_{K}(\Phi(w), 1)}{q^{*}}=\frac{(1-c) \beta^{*}-(1-\tau) F_{K}(\Phi(w), 1)}{q^{*}}
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-620.jpg?height=603&width=885&top_left_y=189&top_left_x=269)

Figure 13.9. Phase diagram.

where the last equality follows from the necessary condition for optimal investment, equation (4). Because $\beta^{*}=I^{*} / K$, we have $g<r$ whenever $(1-$ c) $I^{*}<(1-\tau) F_{K}() K$, that is, whenever the firm pays positive dividends.

In conclusion, given constant returns to scale in both production and installation and constant factor prices, a competitive firm will grow over time at a steady rate while maintaining a constant shadow price of installed capital equal to the present value of the (constant) stream of dividends per unit of capital. It is clear, however, that this situation cannot persist in equilibrium, where the factor demands of firms are unlikely to be made compatible with the factor supply decisions of households at constant input prices. In particular, capital accumulation is unlikely to continue at a constant rate forever. With a constant population, for example, the increase in the stock of capital per worker will drive down the marginal product of capital and increase the equilibrium wage rate. Both changes will reduce the profitability of investment and eventually bring it to a stop.

## (b) Capital Accumulation and Share Prices in a Small Open Economy

We will now construct the simplest possible general-equilibrium extension of the investment model developed in the first part of this section. We consider a small open economy with constant population. Wages will now be determined endogenously and will indeed rise with capital accumulation, putting a limit to it. The interest rate, however, will be determined in world capital markets and can therefore be taken as a given constant. Thus, capital
will flow in from abroad if domestic investment is sufficiently productive, and we can solve the model for the equilibrium paths of $q$ and $K$ without taking explicitly into account the behavior of households.

Because firms behave exactly as in the preceding section, the Pontryagin conditions obtained earlier still apply:

$$
\begin{gather*}
\dot{K}_{t}=\Psi\left(I_{t}^{*}, K_{t}\right)-\delta K_{t}  \tag{1}\\
\dot{q}_{t}=q_{t}\left[r+\delta-\Psi_{K}\left(I_{t}^{*}, K_{t}\right)\right]-(1-\tau) F_{K}\left(K_{t}, L_{t}^{*}\right)  \tag{5}\\
I^{*}=\beta\left(\frac{1-c}{q}\right) K  \tag{7}\\
F_{L}\left(K_{t}, L_{t}^{*}\right)=w_{t}
\end{gather*}
$$

The only thing that changes is that the wage is no longer exogenous. Normalizing the size of the population to 1 , we can write the labor-marketclearing condition

$$
\begin{equation*}
L_{t}^{*}=1 \tag{18}
\end{equation*}
$$

and interpret equation ( $\left.3^{\prime}\right)$ as giving the equilibrium wage as a function of $(K, L)$, rather than as the demand for labor as a function of the wage. Aside from this, the model remains the same. Substituting (7) and (18) into (1) and (5), we obtain a system of two differential equations in $(K, q)$ :

$$
\begin{gather*}
\dot{K}_{t}=\Psi\left(\beta\left(\frac{1-c}{q_{t}}\right), 1\right) K_{t}-\delta k_{t} \equiv \varphi\left(q_{t}, K_{t}\right)  \tag{19}\\
\dot{q}_{t}=q_{t}\left(r+\delta-\Psi_{K}\left(\beta\left(\frac{1-c}{q_{t}}\right), 1\right)\right)-(1-\tau) F_{K}(K, 1) \equiv \phi\left(q_{t}, K_{t}\right) \tag{20}
\end{gather*}
$$

Equation (19) still yields a horizontal $\dot{K}=0$ line at the value of $q$ that makes optimal investment equal to depreciation, $\bar{q}$. On the other hand, the $\dot{q}=0$ phase line is no longer horizontal; it is now defined implicitly by

$$
q\left(r+\delta-\Psi_{K}\left(\beta\left(\frac{1-c}{q}\right), 1\right)\right)=(1-\tau) F_{K}(K, 1)
$$

It is easy to check that the left-hand side of this expression is an increasing function of $q$ and that the right-hand side decreases with $K$. Thus, an increase in $K$ lowers the stationary value of $q$ to reflect the declining marginal productivity of capital. The $\dot{q}=0$ locus is therefore downward-sloping, and under plausible assumptions the system has a steady state. It is still true, however, that $\partial \dot{q} /\left.\partial q\right|_{\dot{q}=0}>0$, so the vertical lines of motion point away from the phase line. The phase diagram and arrows of motion are shown in Figure 13.10.

The Jacobian of the system (19)-(20), evaluated at the steady state, is given by ${ }^{17}$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-622.jpg?height=639&width=939&top_left_y=194&top_left_x=269)

Figure 13.10. Phase diagram.

$$
J=\left[\begin{array}{cc}
\varphi_{K} & \varphi_{q} \\
\phi_{k} & \phi_{q}
\end{array}\right]=\left[\begin{array}{cc}
0 & \Psi_{I} \frac{\partial \beta()}{\partial q} K \\
\left(-(1-\tau) F_{K K}(K, 1)\right) & r
\end{array}\right]
$$

Recalling that the product of the system's eigenvalues is equal to the determinant of $J$,

$$
\lambda_{1} \lambda_{2}=\operatorname{det} J=\Psi_{I} \frac{\partial \beta()}{\partial q} K(1-\tau) F_{K K}(K, 1)<0
$$

we see that the steady state is a saddle point, as suggested by the pattern of the arrows of motion in the phase diagram (Figure 13.10). It is easy to see that the transversality condition for the firm's problem is satisfied along the convergent trajectory (Figure 13.11). Because the Hamiltonian is concave in $K$, the convergent path is compatible with firm optimization and is therefore the equilibrium trajectory of the system. Given an initial $K$ below the steady state, $\bar{K}$, the market price of installed capital decreases as capital accumulation reduces the marginal return on investment.

Changes in Tax Policy. We will now use the model to analyze the responses of investment and asset prices to a change in tax policy. Imagine that there is an unanticipated and permanent increase in the corporate tax rate $\tau$. The first step is to see how this policy change affects the steady state of the system. Because $\tau$ does not enter into the law of motion for the capital stock, given by equation (19), a change in $\tau$ leaves the $\dot{K}=0$ phase line unchanged.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-623.jpg?height=646&width=889&top_left_y=186&top_left_x=298)

Figure 13.11. Convergent trajectory.

That is, the value of $q$ that induces replacement investment is independent of the tax rate. Taxes, however, do enter into the other transition equation,

$$
\begin{equation*}
\dot{q}_{t}=q_{t}\left(r+\delta-\Psi_{K}\left(\beta\left(\frac{1-c}{q_{t}}\right), 1\right)\right)-(1-\tau) F_{K}(K, 1) \equiv \phi\left(q_{t}, K_{t}\right) \tag{20}
\end{equation*}
$$

and do, therefore, affect the position of the $\dot{q}=0$ locus. Setting $\dot{q}=0$, (20) yields

$$
q\left(r+\delta-\Psi_{K}\left(\beta\left(\frac{1-c}{q}\right), 1\right)\right)=(1-\tau) F_{K}(K, 1)
$$

Because the left-hand side of this expression is an increasing function of $q$, an increase in $\tau$, which reduces the value of the right-hand side, yields a lower value of $q$ for any given $K$. Thus, an increase in the corporate tax rate shifts the $\dot{q}=0$ locus down, as, given $K$, the sustainable price of capital must fall in response to a reduction in after-tax dividends.

In summary, the tax increase reduces the steady-state capital stock, but has no effect on the steady-state value of $q$. To study the transition, refer to Figure 13.12 and suppose that just prior to the policy change the economy was at the steady state corresponding to the old tax rate, $E(0)$. After the change, the new steady state is $E(1)$, and the equilibrium path of the new system is the stable manifold leading to the new stationary equilibrium $S S^{\prime}$. At the time of the change, therefore, the economy must jump from the initial position to the new equilibrium path, and because the initial capital stock is predetermined, the whole burden of the adjustment falls on share prices, which experience a sudden drop. Initially, the higher tax rate reduces

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-624.jpg?height=678&width=995&top_left_y=188&top_left_x=245)

Figure 13.12. Effect of an unanticipated tax increase.

the stream of dividends accruing to the owners of the firm. As the capital stock declines, however, the marginal product of capital rises, and eventually $q$ goes back to the original level, which supports only replacement investment.

Finally, we analyze the response of the system to an anticipated tax increase. At time zero (i.e., today), the government announces that at some time $T$ in the future the corporate tax rate will be permanently increased. Eventually, the economy must reach the same steady state we have just described, but what is the adjustment trajectory? We know that the transition path

(i) asymptotically reaches the new steady state,

(ii) must obey at each instant the laws of motion for the system corresponding to the tax policy currently in effect (i.e., until the policy change actually takes place, the motion of the system must be consistent with the phase diagram for the original tax rate), and

(iii) must be continuous everywhere, except possibly at time zero. ${ }^{18}$

Using these three properties, we can reconstruct the adjustment trajectory by working backward (Figure 13.13). At time $T$, we must be on the saddle path leading to the new steady state. From 0 to $T$, we must be on what looks like an explosive trajectory of the old system. This trajectory must take us to the saddle path of the new system at precisely the time of the policy change. Following it backward, we can determine the value of $q$ at time zero and calculate the immediate drop in prices.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-625.jpg?height=669&width=1064&top_left_y=192&top_left_x=213)

Figure 13.13. Effect of an anticipated tax increase.

## 4. The Cass-Koopmans Model and Some Applications

Perhaps the most commonly used model in the growth literature, and in much of macroeconomics as well, is that developed by Cass (1965) and Koopmans (1965), building on earlier work by Ramsey (1928). In this section we will develop a version of this model and use it to discuss some techniques that will be useful in policy analysis when we don't have closed-form solutions.

## (a) Optimal Consumption for an Infinitely-Lived Household

Imagine a neoclassical economy populated by a number of identical agents (or altruistic families) who live forever. The preferences of each (identical) individual are summarized by a time-separable utility function of the form ${ }^{19}$

$$
\begin{equation*}
\int_{0}^{\infty} \frac{C_{t}^{1-\sigma}}{1-\sigma} e^{-\rho t} d t \tag{1}
\end{equation*}
$$

where $\sigma>0$ is the inverse of the intertemporal elasticity of substitution, $C$ is consumption, and $\rho$ is the rate of time discount. At each point in time, the agent faces the flow budget constraint

$$
\begin{equation*}
\dot{a}_{t}=a_{t} r_{t}+y_{t}-C_{t} \tag{2}
\end{equation*}
$$

That is, the instantaneous change in the stock of real assets held by the household $\left(\dot{a}_{t}\right)$ is equal to the difference between the current flow of earnings (interest on existing assets, ar, plus other income, $y$ ) and current con-
sumption. The agent chooses time paths of consumption and asset holdings so as to maximize (1) subject to (2), taking as given initial wealth, $a_{0}$, and the time paths of interest rates and noninterest income.

To obtain the necessary conditions for a solution to this problem, we will use the maximum principle. The current-value Hamiltonian for the problem is

$$
H_{t}^{c}=\frac{C_{t}^{1-\sigma}}{1-\sigma}+\lambda_{t}\left(a_{t} r_{t}+y_{t}-C_{t}\right)
$$

The costate variable, $\lambda_{t}$, can be interpreted as the shadow price of wealth (in utility units), and $H_{t}^{c}$ gives the current flow of utility plus the increase in the "utility value" of the stock of assets that results from the current consumption/saving decision. The Pontryagin conditions are given by

$$
\begin{gather*}
\frac{\partial H^{C}}{\partial C}=C^{-\sigma}-\lambda=0  \tag{3}\\
-\frac{\partial H^{C}}{\partial a}=-\lambda r=\dot{\lambda}-\rho \lambda  \tag{4}\\
\Rightarrow \frac{\dot{\lambda}}{\lambda}=\rho-r_{t}
\end{gather*}
$$

Equation (3) says that the agent balances the benefits of current consumption against its opportunity cost in terms of forgone future consumption. Equation (4) can be interpreted as saying that the total return on savings ( $r$ plus the rate of "capital gains," $\dot{\lambda} / \lambda)$ is equal to the "interest rate" $\rho$ at which the agent discounts future utility flows; hence, there will be no gain or loss (in utility terms) from holding one more unit of capital rather than consuming it.

Equations (3) and (4) can be consolidated into a single differential equation describing the time path of consumption. Taking logs of both sides of (3) and differentiating with respect to time, we have

$$
\ln C=(-1 / \sigma) \ln \lambda \Rightarrow \frac{\dot{C}}{C}=-\frac{1}{\sigma} \frac{\dot{\lambda}}{\lambda}
$$

and substituting $\left(4^{\prime}\right)$ into this last expression,

$$
\begin{equation*}
\frac{\dot{C}}{C}=\frac{1}{\sigma}(r-\rho) \tag{5}
\end{equation*}
$$

Along an optimal path, the growth rate of per-capita consumption is equal to the product of the intertemporal elasticity of substitution and the difference between the interest rate and the rate of intertemporal discount. We can think of $\rho$ as measuring the agent's impatience, and of $r$ as the reward for postponing consumption. Hence, less impatient agents will be more willing to defer consumption and will tend to save more, and consequently
their consumption will increase at a faster rate. This tendency will be stronger if the elasticity of substitution $(1 / \sigma)$ is high (i.e., if future consumption is a good substitute for current consumption).

Equations (2) and (5), together with the initial asset holdings of the household and the transversality condition,

$$
\begin{equation*}
\lim _{t \rightarrow \infty} a_{t} e^{-\rho t} \geq 0 \text { and } \quad \lim _{t \rightarrow \infty} a_{t} \lambda_{t} e^{-\rho t}=0 \tag{6}
\end{equation*}
$$

characterize the optimal paths of consumption and asset holdings for the household for given paths of income and the interest rate.

Integrating the law of motion for consumption (5) and the flow budget constraint (2), we obtain ${ }^{20}$

$$
\begin{gather*}
C_{t}=C_{0} e^{\beta(t)}, \text { with } \beta(t)=\frac{1}{\sigma} \int_{0}^{t}\left(r_{s}-\rho\right) d s  \tag{7}\\
a_{t} e^{-R(t)}=a_{0}+\int_{0}^{t} e^{-R(s)}\left(y_{s}-C_{s}\right) d s, \text { with } R(t)=\int_{0}^{t} r_{s} d s \tag{8}
\end{gather*}
$$

Equation (8) says that the present value (discounted to time zero) of household assets at time $t$ is equal to initial assets plus the discounted value of accumulated savings.

The transversality condition (6) imposes a nonnegativity restriction on the asymptotic value of household assets. In the absence of this constraint, the optimal behavior of the household would involve unbounded borrowing and consumption. To understand the role of this condition, rearrange (8) and take limits as $t \rightarrow \infty$ to obtain

$$
\begin{equation*}
\lim _{t \rightarrow \infty} a_{t} e^{-\rho t}=\lim _{t \rightarrow \infty}\left(a_{0}+\int_{0}^{t} e^{-R(s)}\left(y_{s}-C_{s}\right) d s\right) e^{R(t)-\rho t} \tag{9}
\end{equation*}
$$

The first part of the transversality condition requires that the limit in this expression be nonnegative. For this inequality to hold, the limit of the term inside the parentheses must be greater than zero, that is,

$$
\left(a_{0}+\int_{0}^{\infty} e^{-R(s)} y_{s} d s\right)-\int_{0}^{\infty} e^{-R(s)} C_{s} d s \equiv\left(a_{0}+Y_{0}\right)-\mathrm{PV} C_{0} \geq 0
$$

where $Y_{0}$ and $\mathrm{PVC}_{0}$ denote the present value, as of time zero, of the income and consumption streams, respectively. Hence, the first part of (6) requires that the discounted value of consumption not exceed total wealth,

$$
\mathrm{PVC}_{0} \equiv \int_{0}^{\infty} e^{-R(s)} C_{s} d s \leq a_{0}+Y_{0}
$$

In fact, this expression will hold as an equality, for the utility function we have chosen implies that the agent will never be satiated. Given that $\lambda_{t}=$ $C_{t}^{-\sigma}$, we can use (9) and (7) to write the second half of the transversality condition in the form

$$
\begin{equation*}
\lim _{t \rightarrow \infty} a_{t} \lambda_{t} e^{-\rho t}=\lim _{t \rightarrow \infty}\left(a_{0}+\int_{0}^{t} e^{-R(s)}\left(y_{s}-C_{s}\right) d s\right) e^{R(t)-\rho t} C_{0}^{-\sigma} e^{-\sigma \beta(t)}=0 \tag{10}
\end{equation*}
$$

Now, notice that

$$
-\sigma \beta(t)=-\int_{0}^{t}\left(r_{s}-\rho\right) d s=p t-R(t)
$$

so the exponential terms in (10) cancel out, and we end up with

$$
\begin{equation*}
\left(a_{0}+\int_{0}^{\infty} e^{-R(s)} y_{s} d s\right)-\int_{0}^{\infty} e^{-R(s)} C_{s} d s \equiv\left(a_{0}+Y_{0}\right)-\mathrm{PV} C_{0}=0 \tag{11}
\end{equation*}
$$

which can be interpreted as the present-value form of the budget constraint.

Finally, we can solve for the initial consumption level. Substituting (7) into (11),

$$
\int_{0}^{\infty} e^{-R(s)} C_{s} d s=\int_{0}^{\infty} e^{\beta(s)-R(s)} C_{0} d s=a_{0}+Y_{0}
$$

from where

$$
\begin{equation*}
C_{0}=\frac{a_{0}+Y_{0}}{\int_{0}^{\infty} e^{\beta(s)-R(s)} d s} \tag{12}
\end{equation*}
$$

Notice that this is a fairly complicated function. Current consumption is a linear function of total wealth, but it depends on the whole time path of income and interest rates. A change in interest rates will affect the propensity to consume out of current wealth (the direction of the effect depends on whether or not $\sigma<1$ ), but also the discounted value of the income stream $\left(Y_{0}\right)$.

## (b) Equilibrium and Dynamics in a Model with Taxes on Factor Income

So far, we have focused on the behavior of individual agents, taking as given the time path of wages and the interest rate. In equilibrium, the equations derived in the preceding section continue to hold, but they must be evaluated at equilibrium factor prices. We will now derive these and introduce a couple of policy parameters.

We will assume that the technology is described by a constant-returns-toscale neoclassical production function with labor-augmenting exogenous technical change, that is,

$$
\begin{equation*}
Y=F(K, A L)=A L f(Z), \quad \text { where } \quad Z=K / A L \text { and } f(Z) \equiv F(Z, 1) \tag{11}
\end{equation*}
$$

$$
\begin{equation*}
\frac{\dot{A}}{A}=g \tag{12}
\end{equation*}
$$

Firms rent capital and labor services in competitive markets at equilibrium prices given by the net marginal products of capital and labor,

$$
\begin{equation*}
r=f^{\prime}(Z)-\delta \tag{13}
\end{equation*}
$$

$$
\begin{equation*}
w=w(Z)=f(Z)=f^{\prime}(Z) Z \tag{14}
\end{equation*}
$$

where $w$ is the salary per efficiency unit of labor. In equilibrium, factor markets must clear. We will assume that population is constant, and normalize it to 1 , and that each agent is endowed with one unit of labor "per instant." Because they have no taste for leisure, agents supply their entire endowment of time inelastically, and labor-market clearing requires $L_{t}=1$ for all $t$.

The government taxes labor and net capital incomes at proportional rates $\tau_{w}$ and $\tau_{r}$, makes a lump-sum transfer $P$ to each individual, and destines $X$ units of output (per capita) to public consumption. We will assume that the government must run a balanced budget at each point in time and that tax rates, transfers, and public-consumption expenditures per efficiency unit of labor $(x=X / A$ and $p=P / A$ ) are constant over time. Hence, the government's budget constraint can be written

$$
\begin{equation*}
\tau_{r}\left[f^{\prime}(Z)-\delta\right] Z+\tau_{w} w(Z)=x+p \tag{15}
\end{equation*}
$$

where the left-hand side is total tax revenue per efficiency unit of labor, and the right-hand side gives total expenditure. Given constant values of $x+p$ and $\tau_{r}$, equation (15) can be solved for the value of $\tau_{w}$ that will preserve budget balance for each value of $Z$.

Substituting (13) into (5) (where $r$ should be interpreted as the net-of-tax interest rate), the law of motion for consumption becomes

$$
\begin{equation*}
\frac{\dot{C}}{C}=\frac{1}{\sigma}\left\{\left(1-\tau_{r}\right)\left[f^{\prime}(Z)-\delta\right]-\rho\right\} \tag{16}
\end{equation*}
$$

In equilibrium, the representative agent's non-interest income after tax is given by

$$
\begin{equation*}
y=\left(1-\tau_{w}\right) A w(Z)+A p \tag{17}
\end{equation*}
$$

and his real asset holdings must be equal to the stock of capital per worker (there are no other assets). Hence $a=K=A Z$, and the flow budget constraint given by equation (2) becomes

$$
\begin{aligned}
\dot{K} & =\left(1-\tau_{r}\right)\left[f^{\prime}(Z)-\delta\right] A Z+\left(1-\tau_{w}\right) A w(Z)+p A-C \\
& =A\left[f^{\prime}(Z) Z+w(Z)\right]-\delta K-C-A\left\{\tau_{r}\left[f^{\prime}(Z)-\delta\right] Z+\tau_{w} w(Z)-p\right\}
\end{aligned}
$$

Using equations (14) and (15), the growth rate of the capital stock is given by

$$
\begin{equation*}
\frac{\dot{K}}{K}=\frac{f(Z)}{Z}-\delta-\frac{C / A}{Z}-\frac{x}{Z} \tag{18}
\end{equation*}
$$

In the presence of exogenous technical change, productivity increases without bound, and so does consumption per capita. Hence, the system as it stands will not have a steady state. It is convenient to define a new variable,

$$
\begin{equation*}
c=\frac{C}{A} \tag{19}
\end{equation*}
$$

to rewrite the system in a way that will admit a constant solution. Taking logs of (19) and differentiating with respect to time,

$$
\frac{\dot{c}}{c}=\frac{\dot{C}}{C}-g
$$

Substituting (16) into this expression,

$$
\begin{equation*}
\frac{\dot{c}}{c}=\frac{1}{\sigma}\left\{\left(1-\tau_{r}\right)\left[f^{\prime}(Z)-\delta\right]-\rho\right\}-g \tag{20}
\end{equation*}
$$

Similarly, $\dot{Z} / Z=\dot{K} / K-g$, so (18) yields

$$
\frac{\dot{Z}}{Z}=\frac{f(Z)}{Z}-\delta-\frac{c}{Z}-\frac{x}{Z}-g
$$

from where

$$
\begin{equation*}
\dot{Z}=f(Z)-(g+\delta) Z-c-x \tag{21}
\end{equation*}
$$

We have reduced the model to a system of two autonomous equations in $Z$ and $c$ :

$$
\begin{gather*}
\dot{c}=\left(\frac{1}{\sigma}\left\{\left(1-\tau_{r}\right)\left[f^{\prime}(Z)-\delta\right]-\rho\right\}-g\right) c_{t} \equiv \phi\left(c, Z ; \tau_{r}\right)  \tag{20}\\
\dot{Z}=f(Z)-(g+\delta) Z-c-x \equiv \varphi(c, Z) \tag{21}
\end{gather*}
$$

Equation (21) is a resource constraint; it says that the instantaneous change in the capital/labor ratio is equal to net output per efficiency unit of labor (after depreciation, taxes, and current consumption) minus the amount required to equip new efficiency units of labor with the prevailing average stock of capital $(g Z)$. Equation (20) is the condition for the optimal allocation of consumption over time evaluated at equilibrium factor prices.

From (20) and (21) we see that

$$
\begin{gather*}
\dot{Z} \geq 0 \Leftrightarrow c \leq f(Z)-(g+\delta) Z-x \equiv c_{s}(Z)  \tag{22}\\
\dot{c} \geq 0 \Leftrightarrow f^{\prime}(Z) \geq \frac{g \sigma+\phi p}{1-\tau_{r}}+\delta \tag{23}
\end{gather*}
$$

The phase diagram is shown in Figure 13.14, under the assumptions that $x$ is small enough that the two phase lines cross in the positive quadrant and $f(0)=0, f^{\prime}(0)=\infty$, and $f^{\prime}(\infty)=0$. These conditions are sufficient to guarantee the existence of a unique nontrivial steady state $\left(Z^{*}, c^{*}\right)$.

The direction of the arrows of motion suggests that the steady state is a saddle point. To verify this, we compute the determinant of the Jacobian matrix of the system evaluated at the steady state:

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-631.jpg?height=621&width=858&top_left_y=187&top_left_x=316)

Figure 13.14. Phase diagram and convergent trajectory.

$$
J=\left[\begin{array}{ll}
\phi_{C} & \phi_{Z}  \tag{24}\\
\varphi_{C} & \varphi_{Z}
\end{array}\right]=\left[\begin{array}{cl}
0 & \frac{c^{*}}{\sigma}\left(1-\tau_{r}\right) f^{\prime \prime}\left(Z^{*}\right) \\
-1 & f^{\prime}\left(Z^{*}\right)-g-\delta
\end{array}\right]
$$

Because

$$
\operatorname{det} J=\lambda_{1} \lambda_{2}=\frac{c^{*}}{\sigma}\left(1-\tau_{r}\right) f^{\prime \prime}\left(Z^{*}\right)<0
$$

the eigenvalues of the system are real numbers of opposite signs, and the steady state is indeed a saddle. Using the transversality condition for the household problem, it can be shown that the equilibrium path for this economy is the unique solution to the system (20)-(21) that satisfies the initial condition $Z(0)=Z_{0}$ (a given constant) and converges to the steady state.

Let $\lambda<0$ denote the stable root of the system. For future reference, we will compute the eigenvector $\underline{e}=\left(e_{1}, e_{2}\right)$ associated with this root. As the reader will recall, $\underline{e}$ is "tangent" to the saddle path at the steady state. Normalizing the second component of $\underline{e}$ to 1 , the stable eigenvector satisfies $J \underline{e}=\lambda \underline{e}$, and therefore

$$
-e_{1}+\varphi_{z}=\lambda
$$

Hence, the slope of the stable manifold at the steady state is given by

$$
\begin{equation*}
e_{1}=\varphi_{z}-\lambda \tag{25}
\end{equation*}
$$

where, using (23) and (24),

$$
\begin{equation*}
\varphi_{z}=f^{\prime}\left(Z^{*}\right)-g-\delta=\frac{g \sigma+\rho}{1-\tau_{r}}-g \tag{26}
\end{equation*}
$$

Note. The equilibrium trajectory of the system approaches a steady state in which $c$ is constant and $C_{t}=c A_{t}=c A_{0} e^{g t}$ grows at a constant rate equal to the rate of technical progress. In such an equilibrium, the utility of a representative individual, given by

$$
\begin{equation*}
\int_{0}^{\infty} \frac{C_{t}^{1-\sigma}}{1-\sigma} e^{-\rho t} d t=\frac{\left(A_{0} c\right)^{1-\sigma}}{1-\sigma} \int_{0}^{\infty} e^{[(1-\sigma) g-\rho \mid t} d t \tag{27}
\end{equation*}
$$

will be unbounded whenever $(1-\sigma) g-\rho>0$. In fact, in this case the problem cannot be solved by the methods we developed in Chapter 12. To avoid such problems, we will assume that $g$ is low enough that (27) converges, that is,

$$
\begin{equation*}
(1-\sigma) g-\rho<0 \tag{28}
\end{equation*}
$$

We will refer to this assumption as the boundedness condition.

Problem 4.1. A social planner maximizes the utility of the representative individual,

$$
\int_{0}^{\infty} \frac{C_{t}^{1-\sigma}}{1-\sigma} e^{-\rho t} d t
$$

subject to the resource constraint

$$
\dot{K}_{t}=F\left(K_{t}, A_{t}\right)-\delta K_{t}-C_{t} \text {, with } \frac{\dot{A}}{A}=g
$$

List the necessary conditions for this problem, and show that they reduce to equations (20) and (21) whenever there are no taxes or subsidies. Hence, under these conditions, the competitive equilibrium will be a social optimum.

## (c) The Welfare Cost of Factor Taxes

We will now study the effects of a tax change. The specific experimeni we will analyze is the following: Suppose the economy is initially at the steady state corresponding to the given values of the different tax parameters. Without previous announcement, the government changes the tax rate on interest income from the initial value $\tau_{r 0}$ to a new one $\tau_{r 1}$, keeping total expenditure per efficiency unit of labor $(x+p)$ constant, and adjusting the tax rate on wage income as needed to preserve budget balance at each point in time.

The first step is to determine the effects of the policy change on the steadystate values of income and consumption, given by the solution of the system

$$
\dot{Z}=0 \Leftrightarrow c=f(Z)-(g+\delta) Z-x \equiv c_{s}(Z)
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-633.jpg?height=630&width=893&top_left_y=187&top_left_x=301)

Figure 13.15. Long-run effect of an increase in capital income taxes.

$$
\dot{c}=0 \Leftrightarrow f^{\prime}(Z)=\frac{g \sigma+\rho}{1-\tau_{r}}+\delta
$$

With $x$ fixed, the position of the $\dot{Z}=0$ phase line does not depend on the value of $\tau_{r}$. From (23'), however, it is clear that an increase in $\tau_{r}$ reduces the stationary value of the capital/labor ratio and shifts the $\dot{c}=0$ phase line to the left, as shown in Figure 13.15. The effect on consumption depends on the slope of the $\dot{Z}=0$ phase line at the steady state, given by

$$
c_{s}^{\prime}\left(Z^{*}\right)=\varphi_{z}=f^{\prime}\left(Z^{*}\right)-(g+\delta)=\frac{g \sigma+\rho}{1-\tau_{r}}-g
$$

Hence, $c_{s}^{\prime}\left(Z^{*}\right)>0$, provided that $g(1-\sigma)-\rho<g \tau_{r}$. The boundedness condition (28) ensures that the left-hand side of this expression is negative. Hence, for any nonnegative tax rate on interest income, an increase in this parameter will reduce steady-state consumption. The reason should be clear from the law of motion for consumption, equation (20): An increase in $\tau_{r}$ discourages accumulation by reducing the net return on savings. In the long run, therefore, the capital stock is a decreasing function of $\tau_{r}$.

Problem 4.2. Assuming a Cobb-Douglas production function (i.e., $f(Z)=$ $\left.Z^{\alpha}\right)$, solve for the steady-state savings rate as a function of $\tau_{r}$ and the other parameters of the model.

Welfare comparisons across steady states are straightforward. Because steady-state utility, given by

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-634.jpg?height=606&width=891&top_left_y=192&top_left_x=286)

Figure 13.16. Transition path following an increase in capital income taxes.

$$
\begin{align*}
v_{s}\left(c^{*}\right) & =\int_{0}^{\infty} \frac{\left(c^{*} A_{t}\right)^{1-\sigma}}{1-\sigma} e^{-\rho t} d t=\frac{\left(A_{0} c^{*}\right)^{1-\sigma}}{1-\sigma} \int_{0}^{\infty} e^{[(1-\sigma) g-\rho] t} d t \\
& =\frac{\left(A_{0} c^{*}\right)^{1-\sigma}}{1-\sigma} \frac{1}{\rho-(1-\sigma) g} \tag{29}
\end{align*}
$$

is an increasing function of steady-state consumption, increases in $\tau_{r}$ will reduce welfare.

Once we take into account the transition from one steady state to another, the effect of capital income taxes on welfare is no longer so obvious. To see why, consider the transition path shown in Figure 13.16. The impact effect of the tax change is a jump in consumption that takes us to the new saddle path. The saddle lies above the $\dot{Z}=0$ line and therefore above the initial steady state. The reduction in the incentive to save causes agents to increase their consumption. This behavior, of course, leads to a reduction in the capital stock and, in the long run, to lower consumption as well. During part of the transition, however, consumption exceeds its old steady-state level, and therefore so does the current flow of utility.

To calculate the net welfare change, we have to evaluate the utility function along the whole adjustment path. The idea is simple. We define a function that gives the utility of the representative individual as a function of the policy parameter:

$$
V\left(\tau_{r}\right)=\int_{0}^{\infty} \frac{C_{t}\left(\tau_{r}\right)^{1-\sigma}}{1-\sigma} e^{-\rho t} d t
$$

where $C_{t}\left(\tau_{r}\right)=A_{t} c_{t}\left(\tau_{r}\right)$ is consumption along the equilibrium solution of the system

$$
\begin{gather*}
\dot{c}=\left(\frac{1}{\sigma}\left\{\left(1-\tau_{r}\right)\left[f^{\prime}(Z)-\delta\right]-\rho\right\}-g\right) c_{t} \equiv \phi\left(c, Z ; \tau_{r}\right)  \tag{20}\\
\dot{Z}=f(Z)-(g+\delta) Z-c-x \equiv \varphi(c, Z) \tag{21}
\end{gather*}
$$

corresponding to the given value of the policy parameter. Our objective is to evaluate the derivative $V^{\prime}\left(\tau_{r}\right)$ starting from a steady state.

The most difficult part of the problem is to characterize the solution function of the system in a way that will be precise enough to allow us to compute derivatives. We begin by observing that we can think of the saddle path of the system as the graph of a policy function,

$$
c=p\left(Z, \tau_{r}\right)
$$

that gives the equilibrium value of consumption as a function of the current value of the state variable $Z$ and the tax parameter. Notice that we have some information on the properties of this function at the steady state. In particular, we know that the slope of the saddle at the steady state is negative and is given by the slope of the stable eigenvector and that a tax increase will shift the saddle path upward. Using subscripts to denote partial derivatives, we have, then,

$$
\begin{equation*}
p_{z}=e_{1}=\varphi_{z}-\lambda=f^{\prime}\left(Z^{*}\right)-g-\delta-\lambda=\frac{g \sigma+\rho}{1-\tau_{r}}-g-\lambda<0 \quad \text { and } \quad p_{\tau}>0 \tag{30}
\end{equation*}
$$

Next, substituting the policy function into the law of motion for $Z$ given in equation (21), the equilibrium dynamics of the system can be characterized by a single differential equation that describes the evolution of the state variable along the stable manifold:

$$
\begin{equation*}
\dot{Z}=\varphi(c, Z)=\varphi\left[p\left(Z, \tau_{r}\right), Z\right] \equiv \Psi\left(Z, \tau_{r}\right) \tag{31}
\end{equation*}
$$

Notice that this equation has a unique steady state that coincides with the steady-state value of $Z$ for the original system. This steady state is stable; in fact, the "eigenvalue" of this equation is the stable eigenvalue of the full system, because, using (24) and (30),

$$
\Psi_{Z}\left(Z^{*}, \tau_{r}\right)=\varphi_{c} p_{z}+\varphi_{z}=-p_{z}+\varphi_{z}=-\varphi_{z}+\lambda+\varphi_{z}=\lambda<0
$$

The solution of (31) yields the equilibrium value of $Z$ as a function of time and the tax parameter $Z_{t}\left(\tau_{r}\right)$. Finally, substituting this function into the policy function, we obtain the time path of $c$ :

$$
\begin{equation*}
c_{t}\left(\tau_{r}\right)=p\left[Z_{t}\left(\tau_{r}\right), \tau_{r}\right] \tag{32}
\end{equation*}
$$

To calculate the change in welfare, we need to compute the effect of the policy change on the whole time path of consumption. Using (32), the marginal change in consumption at time $t$ is given by

$$
\begin{equation*}
\frac{d c_{t}\left(\tau_{r}\right)}{d \tau_{r}}=p_{z}() \frac{d Z_{t}\left(\tau_{r}\right)}{d \tau_{r}}+p_{\tau}() \tag{33}
\end{equation*}
$$

Evaluating this expression will be easier than it might seem, at least when we start from a steady state. In that case, $p_{z}\left(Z^{*}, \tau_{r}\right)$ and $p_{\tau}\left(Z^{*}, \tau_{r}\right)$ are constants of known sign, and $d Z_{t}\left(\tau_{r}\right) / d \tau_{r}=Z_{\tau}\left(t, \tau_{r}\right)$ is, as we shall presently see, easily computed using the method discussed in Section 3(c) of Chapter 9.

To compute $Z_{\tau}\left(t, \tau_{r}\right)$, notice that the solution function of (31), $Z_{t}\left(\tau_{r}\right)=Z(t$, $\tau_{r}$ ), must satisfy identically the original equation,

$$
\dot{Z}\left(t, \tau_{r}\right) \equiv \varphi\left[p\left(Z\left(t, \tau_{r}\right), \tau_{r}\right), Z\left(t, \tau_{r}\right)\right]
$$

Differentiating both sides of this identity with respect to $\tau_{r}$ (and assuming that all the functions involved are sufficiently smooth), we can write

$$
\begin{aligned}
\dot{Z}_{\tau} & =\frac{d Z_{\tau}}{d t}=\varphi_{c}()\left[p_{z}() Z_{\tau}()+p_{\tau}()\right]+\varphi_{z}() Z_{\tau}() \\
& =\left[\varphi_{c}() p_{z}()+\varphi_{z}()\right] Z_{\tau}()+\varphi_{c}() p_{\tau}()
\end{aligned}
$$

Hence, $Z_{\tau}$ satisfies a linear differential equation. When we start from a steady state, moreover, the coefficients of this equation are constant, and we can write, using (24) and (30),

$$
\begin{equation*}
\dot{Z}_{\tau}=\left[-1\left(\varphi_{z}-\lambda\right)+\varphi_{z}\right] Z_{\tau}-p_{\tau}=\lambda Z_{\tau}-p_{\tau} \tag{34}
\end{equation*}
$$

The general solution of this autonomous linear equation is given by

$$
Z_{\tau}(t)=e^{\lambda_{t}} Z_{\tau}(0)+\left(1-e^{\lambda_{t}}\right) Z_{\tau}(\infty)
$$

where, because the capital stock is a predetermined variable, $Z_{\tau}(0)$, the impact effect of the tax change on the stock of capital is equal to zero. Because $\lambda<0$, the steady state of this equation is stable, and $Z_{\tau}$ converges asymptotically to its stationary value, given by

$$
\begin{equation*}
Z_{\tau}(\infty)=\frac{p_{\tau}\left(Z^{*}, \tau_{r}\right)}{\lambda}<0 \tag{35}
\end{equation*}
$$

which is also the derivative of the steady-state value of $Z$ with respect to the tax parameter ${ }^{21}$ Hence, the equilibrium time path of $Z_{\tau}$ is given by

$$
\begin{equation*}
Z_{\tau}(t)=\left(1-e^{\lambda t}\right) Z_{\tau}(\infty)=\left(1-e^{\lambda t}\right) \frac{p_{\tau}\left(Z^{*}, \tau_{r}\right)}{\lambda} \quad\left(=\frac{d Z_{t}\left(\tau_{r}\right)}{d \tau_{r}}\right) \tag{36}
\end{equation*}
$$

That is, following a small tax change, $Z$ falls gradually toward its new steadystate value at an exponential rate given by the stable root of the original system.

Substituting (36) into (33), we can now compute the derivative of the time path of consumption with respect to the tax parameter:

$$
\begin{equation*}
\frac{d c_{t}\left(\tau_{r}\right)}{d \tau_{r}}=p_{z} \frac{d Z_{t}\left(\tau_{r}\right)}{d \tau_{r}}+p_{\tau}=p_{z}\left(1-e^{\lambda t}\right) \frac{p_{\tau}\left(Z^{*}, \tau_{r}\right)}{\lambda}+p_{\tau}=p_{\tau}\left(\left(1-e^{\lambda t}\right) \frac{p_{z}}{\lambda}+1\right) \tag{37}
\end{equation*}
$$

Notice that

$$
\begin{gathered}
\frac{d c_{0}\left(\tau_{r}\right)}{d \tau_{r}}=p_{\tau}>0 \\
\frac{d c_{\infty}\left(\tau_{r}\right)}{d \tau_{r}}=p_{\tau}\left(\frac{p_{z}}{\lambda}+1\right)=p_{\tau} \frac{p_{z}+\lambda}{\lambda}=\frac{p_{\tau} \varphi_{z}}{\lambda}<0
\end{gathered}
$$

Hence, the derivative of $c_{t}\left(\tau_{r}\right)$ at time zero - the impact effect of the policy change - is equal to the upward shift in the saddle path, and its long-run effect is the decrease in steady-state consumption. As we already knew, consumption increases at first and then decreases.

Now that we have calculated the change in consumption at each point in time, it remains only to evaluate the derivative of the utility function with respect to the policy parameter. We have

$$
\begin{aligned}
V\left(\tau_{r}\right) & =\int_{0}^{\infty} \frac{C_{t}\left(\tau_{r}\right)^{1-\sigma}}{1-\sigma} e^{-\rho t} d t=\int_{0}^{\infty} \frac{\left(A_{t} c_{t}\right)^{1-\sigma}}{1-\sigma} e^{-\rho t} d t \\
& =\int_{0}^{\infty} \frac{\left(A_{0} e^{g t}\right)^{1-\sigma}}{1-\sigma}\left[c_{t}\left(\tau_{r}\right)\right]^{1-\sigma} e^{-\rho t} d t=\frac{A_{0}^{1-\sigma}}{1-\sigma} \int_{0}^{\infty} e^{[(1-\sigma) g-\rho] t} c_{t}\left(\tau_{r}\right)^{1-\sigma} d t
\end{aligned}
$$

Differentiating with respect to $\tau_{r}$, evaluating the result at a steady state, and using (37) and (30), $\left(p_{z}+\lambda=\varphi_{z}\right)$, we have

$$
\begin{aligned}
V^{\prime}\left(\tau_{r}\right) & =A_{0}^{1-\sigma} \int_{0}^{\infty} e^{[(1-\sigma) g-\rho] t} c_{t}^{-\sigma} \frac{d c_{t}\left(\tau_{r}\right)}{d \tau_{r}} d t \\
& =A_{0}^{1-\sigma}\left(c^{*}\right)^{-\sigma} \int_{0}^{\infty} e^{[(1-\sigma) g-\rho] t} p_{\tau}\left(\left(1-e^{\lambda t}\right) \frac{p_{z}}{\lambda}+1\right) d t \\
& =A_{0}^{1-\sigma}\left(c^{*}\right)^{-\sigma} p_{\tau} \int_{0}^{\infty} e^{[(1-\sigma) g-\rho] t}\left(\frac{p_{z}+\lambda}{\lambda}-e^{\lambda t} \frac{p_{z}}{\lambda}\right) d t \\
& =A_{0}^{1-\sigma}\left(c^{*}\right)^{-\sigma} p_{\tau}\left(\int_{0}^{\infty} e^{[(1-\sigma) g-\rho] t} \frac{p_{z}+\lambda}{\lambda} d t-\int_{0}^{\infty} e^{[(1-\sigma) g-\rho] t} e^{\lambda t} \frac{p_{z}}{\lambda} d t\right) \\
& =A_{0}^{1-\sigma}\left(c^{*}\right)^{-\sigma} p_{\tau}\left(\frac{p_{z}+\lambda}{\lambda[\rho-(1-\sigma) g]}-\frac{p_{z}}{\lambda[\rho-(1-\sigma) g-\lambda]}\right) \\
& =A_{0}^{1-\sigma}\left(c^{*}\right)^{-\sigma} \frac{p_{\tau}}{\lambda}\left(\frac{p_{z}+\lambda}{\rho-(1-\sigma) g}-\frac{p_{z}}{\rho-(1-\sigma) g-\lambda}\right)
\end{aligned}
$$

To simplify this expression, notice that, using (30), $p_{z}=(g \sigma+\rho) /\left(1-\tau_{r}\right)-g-\lambda$,

$$
\begin{gathered}
\frac{p_{z}+\lambda}{\rho-(1-\sigma) g}-\frac{p_{z}}{\rho-(1-\sigma) g-\lambda}=\frac{\left(p_{z}+\lambda\right)[\rho-(1-\sigma) g-\lambda]-p_{z}[\rho-(1-\sigma) g]}{[\rho-(1-\sigma) g][\rho-(1-\sigma) g-\lambda]} \\
=\frac{\lambda\left[\rho-(1-\sigma) g-\lambda-p_{z}\right]}{[\rho-(1-\sigma) g][\rho-(1-\sigma) g-\lambda]}=\lambda \frac{\rho+g \sigma-(g \sigma+\rho) /\left(1-\tau_{r}\right)}{[\rho-(1-\sigma) g][\rho-(1-\sigma) g-\lambda]} \\
=\frac{-\lambda \tau_{r}(g \sigma+\rho)}{[\rho-(1-\sigma) g][\rho-(1-\sigma) g-\lambda]\left(1-\tau_{r}\right)}
\end{gathered}
$$

Hence,

$$
V^{\prime}\left(\tau_{r}\right)=A_{0}^{1-\sigma}\left(c^{*}\right)^{-\sigma} p_{\tau} \frac{-\tau_{r}(g \sigma+\rho)}{[\rho-(1-\sigma) g][\rho-(1-\sigma) g-\lambda]\left(1-\tau_{r}\right)}
$$

Recall that $p_{\tau}>0, \lambda<0$, and that $\rho-(1-\sigma) g>0$ by the boundedness condition (28). Hence,

$$
V^{\prime}\left(\tau_{r}\right)<0 \text { iff } \tau_{r}>0
$$

and it follows that setting $\tau_{r}$ equal to zero is the optimal policy: Increasing tax rates on capital will decrease welfare if the tax rate is positive and increase welfare if the tax rate is negative.

Problem 4.3. One limitation of the approach we have followed is that it assumes that the economy is initially at a steady state. Otherwise the coefficients of the variational equation (the law of motion for $Z_{\tau}$ ) would change over time, and that would make it difficult to evaluate $V^{\prime}\left(\tau_{r}\right)$. It is still possible (and in fact much easier) to show that a zero tax on capital income is optimal by showing that when $\tau_{r}=0$, the equilibrium path for the economy solves a closely related planning problem.

Consider, in particular, the problem faced by a social planner, similar to the one described in Problem 2.1, who maximizes the utility of the representative agent subject to the standard resource constraint and the additional restriction that he must "throw away" an amount of output equal to $x A$ at each point in time. Write the planning problem, derive the necessary conditions for an optimum, and verify that they reduce to equations (20) and (21) when $\tau_{r}=0$ in this system.

## Numerical Solution: The Time-Elimination Method

The analysis of the preceding section can be used to provide (for specific parameter values and functional forms) a quantitative estimate of the welfare gain associated with a marginal policy change. To evaluate the impact of "large" policy changes, however, we need to resort to numerical methods.

In principle, this poses no problem. We saw in Chapter 11 that there are computer packages that can be used to solve systems of differential
equations numerically. The model we have developed in this section, however, presents one additional difficulty that we did not have to face in the case of the Solow model. The problem is that in the present model the boundary conditions that allow us to pick the particular solution of interest are not in a very convenient form. Whereas in the Solow model we had a single predetermined variable, in the Cass-Koopmans model consumption is a "free variable" without a predetermined initial value. As we have seen, the equilibrium trajectory of the model is the only time path that, from the given initial value of $Z$, approaches the steady state as $t \rightarrow \infty$. Computer programs, however, do not let us specify asymptotic boundary conditions directly, so we need to find an indirect way to impose them.

One possibility is to use a trial-and-error "shooting" method. Given $Z_{0}$, we can guess an initial value of $c$, have the computer solve the problem, and follow the solution path. If this path "explodes," we adjust the original guess accordingly and repeat the experiment until we find a solution that seems to approach the steady state. This method is quite time-consuming and not very accurate.

Fortunately, there is a better alternative, sometimes called the timeelimination method. ${ }^{22}$ The idea is to eliminate time from the original laws of motion to obtain a differential equation with $Z$ (rather than $t$ ) as the independent variable. The solutions of this single equation will correspond to the solution trajectories of the original system in the $(c, Z)$ phase plane (rather than to the time paths of $c$ and $Z$ ). Using an easy-to-impose boundary condition (instead of an asymptotic one), we can find the policy function that gives the equilibrium value of $c$ as a function of $Z$ (i.e., find the saddle path). Then we proceed as before: Substituting the policy function into the law of motion for $Z$, we eliminate $c$ and obtain a single differential equation in $Z$ (with time as the independent variable) that can be solved for the equilibrium time path of $Z$. Finally, evaluating the policy function along this trajectory, we obtain the equilibrium time path of $c$. We can then evaluate the utility function along the solution path to determine the change in welfare.

The procedure, in somewhat greater detail, is as follows. We seek the "saddle-path" solution of a system of the form

$$
\begin{align*}
& \frac{d c}{d t}=\phi(c, Z)  \tag{38}\\
& \frac{d Z}{d t}=\varphi(c, Z) \tag{39}
\end{align*}
$$

"Dividing" (38) by (39), we "eliminate time" from the system and obtain a single differential equation,

$$
\begin{equation*}
\frac{d c}{d Z}=\frac{d c / d t}{d Z / d t}=\frac{\phi(c, Z)}{\varphi(c, Z)} \equiv \psi(c, Z) \tag{40}
\end{equation*}
$$

whose solution gives us the value of $c$ as a function of $Z, c(Z)$. Intuitively, $\psi(c, Z)$ gives us, for each point in the phase plane $(c, Z)$, the slope of the solution trajectory of (38)-(39) that goes through this point. Solving (40) means using this information to reconstruct the family of curves in the phase plane that correspond to the solution trajectories of the original system. We are interested in one specific member of this family of curves, the one that goes through the steady state $\left(c^{*}, Z^{*}\right)$. To select it, we only have to impose the boundary condition $c\left(Z^{*}\right)=c^{*}$.

Before we can ask the computer to solve (40), we have to deal with one minor complication. Notice that the function $\psi(c, Z)$ is not well defined at the steady state, for $\psi\left(c^{*}, Z^{*}\right)=0 / 0$. We know, however, that the slope of the saddle path at the steady state is equal to the slope of the eigenvector associated with the stable (negative) eigenvalue of the linearized system, $e_{i 1} / e_{i 2}$. Hence, we need to extend (40) and define

$$
\begin{align*}
\psi(c, Z) & =e_{i 1} / e_{i 2}, \quad \text { when } \quad(c, Z)=\left(c^{*}, Z^{*}\right) \\
& =\frac{\phi(c, Z)}{\varphi(c, Z)} \quad \text { otherwise } \tag{41}
\end{align*}
$$

Now we can ask the computer to solve the problem

$$
\frac{d c}{d Z}=\psi(c, Z), \text { together with the boundary condition } c\left(Z^{*}\right)=c^{*}
$$

for the policy function $c=c(Z)$. Substituting this function into the law of motion for $Z$, we obtain an ordinary differential equation in $Z$,

$$
\begin{equation*}
\dot{Z}=\varphi[c(Z), Z] \tag{42}
\end{equation*}
$$

which describes the motion of the predetermined state variable along the saddle path. Solving equation (42) together with the natural initial condition on $Z\left(Z(0)=Z_{0}\right.$ given), we obtain the solution path of $Z, Z(t)$, which can then be substituted into the policy function to recover the time path of $c$,

$$
c(t)=c[Z(t)]
$$

To apply the method, of course, we need to choose explicit functional forms and assign specific values to the parameters. Under the assumption that the production function is Cobb-Douglas $\left(Y=K^{\alpha}(A L)^{1-\alpha}\right)$, equations (20) and (21) become

$$
\begin{equation*}
\dot{c}=\frac{c}{\sigma}\left\{\left(1-\tau_{r}\right)\left[\alpha Z^{\alpha-1}-\delta\right]-\rho\right\}-g c \equiv \phi(c, Z) \tag{43}
\end{equation*}
$$

$$
\begin{equation*}
\dot{Z}=Z^{\alpha}-(\delta+g) Z-x-c \equiv \varphi(c, Z) \tag{44}
\end{equation*}
$$

and the steady-state values of $c$ and $Z$ are given by

$$
\begin{aligned}
& \dot{c}=0 \Leftrightarrow Z^{*}=\left(\frac{g \sigma+\rho}{\alpha\left(1-\tau_{r}\right)}+\frac{\delta}{\alpha}\right)^{1 /(\alpha-1)} \\
& \dot{Z}=0 \Leftrightarrow c^{*}=Z^{* \alpha}-(\delta+g) Z^{*}-x
\end{aligned}
$$

The next subsection contains a Mathematica program that carries out the computations we have just outlined. After solving the system numerically for two different values of the parameters, $\tau_{r_{0}}$ and $\tau_{r_{1}}$, we evaluate the utility function of the representative individual in each case and compute the welfare gain in consumption-equivalent terms. For this, we will use a procedure that is useful to evaluate the welfare effects of discrete policy changes. We introduce an auxiliary parameter, $\eta$, in the utility function, defined now by

$$
V\left(\tau_{r}, \eta\right)=\int_{0}^{\infty} \frac{\left[(1+\eta) C_{t}\left(\tau_{r}\right)\right]^{1-\sigma}}{1-\sigma} e^{-\rho t} d t
$$

Notice that an increase in $\eta$ has the same effect on welfare as a proportional increase in consumption in all periods. Hence, the solution $\eta\left(\tau_{r_{0}}, \tau_{r_{1}}\right)$ of the equation

$$
V\left(\tau_{r_{0}}, \eta\right)=V\left(\tau_{r_{1}}, 0\right)
$$

can be interpreted as the proportional variation in consumption equivalent, in terms of welfare, to a change in policy from $\tau_{r_{0}}$ to $\tau_{r_{1}}$.

## Numerical Solution and Welfare Analysis with Mathematica

We will now write a Mathematica program to compute numerically the solution trajectory of the growth model developed earlier and analyze the welfare impact of change in a tax parameter.

We begin by assigning values to the parameters and computing the steadystate values of $Z$ (zss0 and zss1) and $c$ for two different values of the tax rate on interest income (tr0 and tr1). (Note: A semicolon after a command suppresses "feedback output"; without it, the computer prints out the value of the calculation or the value assigned to the parameter. Hence, Out[11]= 5.33363 gives the value of $\mathbf{z s s 0}$, for example. When you are writing a program, it may be a good idea not to use semicolons, so that you can check the results of intermediate calculations).

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-641.jpg?height=149&width=833&top_left_y=2066&top_left_x=320)

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-642.jpg?height=578&width=898&top_left_y=173&top_left_x=285)

We set $x$ (public consumption per efficiency unit of labor) to $10 \%$ of steady-state output per efficiency unit of labor to make sure that the assigned value is not "unreasonable."

The next step is to define the laws of motion for consumption (given by the function $\mathbf{f c}[\mathrm{l})$ and the capital/labor ratio (fz[ ]). Differentiating these functions with respect to $z$ and $c$, and evaluating the resulting function at the steady state, we construct the Jacobian of the linearized system (Jac) and compute its eigenvalues and eigenvectors.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-642.jpg?height=199&width=991&top_left_y=1193&top_left_x=239)

To calculate the Jacobian, we first define an "empty matrix," Jac, and give names to its entries. To compute each one of them, we proceed in two steps. First, we compute the symbolic derivative of the law of motion with respect to each of the state variables (using the command D[function[ ], with respect tol) and then evaluate this expression at the steady state.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-642.jpg?height=542&width=687&top_left_y=1675&top_left_x=384)

$$
\begin{aligned}
& j z z 0=D[f z[c, z, t r 1], z] ; \\
& j z z=j z z 0 / .\{c->\operatorname{css} 1, z->z s s 1\} ;
\end{aligned}
$$

Finally, we ask the computer to print out the Jacobian in matrix form and to compute its eigenvalues and eigenvectors. (Notice that the first entry of the Jacobian should be zero, it is almost zero, but not quite). The function N[ ] asks the computer to use the numerical values of the entries of the Jacobian matrix to perform the actual calculations.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-643.jpg?height=546&width=1125&top_left_y=590&top_left_x=174)

As expected, one of the eigenvalues of the system is positive, and the other negative. The eigenvector corresponding to the stable root is the second one. Because of the way we have arranged the elements of the Jacobian (with $\dot{c}$ on top of $\dot{Z}$, and the derivatives with respect to $c$ before the ones with respect to $Z$ ), the $c$ coordinate of the eigenvalue is listed first, and the slope of the saddle path at the steady state (in a Cartesian plane with $c$ in the vertical axis) is given by the ratio of the first to the second coordinate of the second eigenvector. To select each coordinate of this vector, we use subindices inside double brackets, as shown next.

The following statement defines the function we have called $\psi(c, Z)$ in the text (gc[ ] in the program). Next, we solve the differential equation

$$
\frac{d c}{d z}=\psi(c, Z)
$$

together with the boundary condition $c\left(Z^{*}\right)=c^{*}$, to obtain the "policy function" or saddle path, denoted by $\mathbf{p f c}[\mathbf{z}]$, and we ask the computer to plot it, together with the two steady-state values of $c$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-643.jpg?height=148&width=980&top_left_y=2064&top_left_x=246)

In [35] :=

AccuracyGoal->Infinity;

MaxSteps $->700$;

$\operatorname{mxz}=\operatorname{Max}\left[\mathrm{zss}^{2,} \operatorname{zss1}\right] * 1.1$;

$\operatorname{mnz}=\operatorname{Min}[\mathrm{zss} 0, \mathrm{zss} 1] * 0.9$;

In [40]:=

sol $=$ NDSolve $\left[\left\{c^{\prime}[z]==\operatorname{gc}[\mathrm{c}[z], \mathrm{z}], \mathrm{c}[\mathrm{zSS1}]==\right.\right.$

css 1$\}, c,\{z, m n z, m x z\}]$

Out $[40]=$

$\{\{C \rightarrow$ InterpolatingFunction [\{4.80027,

$6.31276\},<>\}\}\}$

$\operatorname{In}[41]:=$

pfc [z_]:=c[z]/.sol

Plot $[\{p f c[z], \operatorname{css} 0, \operatorname{css} 1\},\{z, \operatorname{zss} 0, \operatorname{zss} 1\}]$

out $[42]=$

-Graphics-

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-644.jpg?height=545&width=878&top_left_y=988&top_left_x=299)

To find the time path of $z$, we substitute the policy function into the law of motion for $z$ and solve the resulting "ordinary" differential equation in $z$, together with an initial condition that specifies that we start from the value of $z$ corresponding to the "old steady state." We call the solution function cpath[t]. Next, we recover the time path of $z$, denoted by zpath[t], and plot both time paths (for time $=0-100$ ) to visualize the adjustment path from one steady state to the next.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-644.jpg?height=249&width=1199&top_left_y=1964&top_left_x=141)

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-645.jpg?height=246&width=872&top_left_y=168&top_left_x=195)

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-645.jpg?height=527&width=903&top_left_y=560&top_left_x=305)

Out $[48]=$

-Graphics-

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-645.jpg?height=520&width=894&top_left_y=1295&top_left_x=314)

The last step is to calculate the welfare change due to the policy experiment. We begin by defining a function, Vs[ ], that gives us steady-state utility. (It does not matter that we get a negative number; we should with $\sigma>1$. What matters is that marginal utility is positive.) Then, Vs[css0] gives the equilibrium utility that would have obtained if the economy had stayed in the path corresponding to the old policy, and Vs[css1] the utility we obtain if we have moved immediately to the new steady state.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-646.jpg?height=434&width=895&top_left_y=166&top_left_x=318)

As expected, steady-state utility is higher with the lower tax rate on interest income. We still have to take into account the transition, however. To approximate total utility, we integrate numerically the utility function (evaluated along the new equilibrium path) between $t=0$ and $t=100$ and add to it the discounted value of the average of Vs[css1] and Vs[ ] evaluated at the consumption level obtained at the end of the 100 years. (We cannot integrate the utility function numerically over an infinite time path, but after 100 years we will be very close to the new steady state, and with a reasonable discount rate it does not matter much what happens that far in the future anyway.) As expected, utility is higher under the new policy, even when we take into account the transition.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-646.jpg?height=286&width=1139&top_left_y=1220&top_left_x=177)

Finally, we compute the consumption equivalent of the welfare gain from the change in tax policy, denoted by eta, which turns out to be around $0.9 \%$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-646.jpg?height=242&width=1015&top_left_y=1726&top_left_x=231)

## 5. Problems

In this section we will ask the reader to work through a number of problems that make use of the material developed in this chapter.

## (a) An Efficiency-Wage Model

Efficiency-wage theories are attempts to explain the emergence of wage rigidities that can generate unemployment in an equilibrium context. The key feature of these models is that labor productivity depends partly on the wage rate. Knowing this, firms set wages and employment levels so as to maximize profits. Because increasing wages increases output, firms may find it optimal to pay a wage that is above the market-clearing level. Hence, unemployment may arise in equilibrium.

The difficult part, of course, is explaining why the wage can have an impact on productivity. Several mechanisms have been explored in the literature. Some of them rely on informational asymmetries, others on turnover costs, and the rest on sociological factors. The following problem develops a "shirking" model of efficiency wages due to Shapiro and Stiglitz (1984). In this model, labor productivity depends on the level of (costly) effort exerted by workers, a variable that can be monitored only imperfectly by firms. In particular, workers who do not exert effort will be caught, with some probability $q<1$. Hence, all workers who are not caught shirking will have to be paid the same wage. If detected shirkers go unpunished, pay will be independent of effort, and workers will find it optimal to shirk.

One possible way to avoid this outcome is by firing detected shirkers. Notice, however, that this will work only as long as job losses are costly. To achieve this, a firm can resort to raising its wage offer above the marketclearing level, so that its workers will value their jobs and will not shirk. If all firms are alike, all of them will act in the same way, and the equilibrium wage will be above the market-clearing level. Hence, the equilibrium involves unemployment, which serves as a discipline device: Workers who are fired will not be rehired immediately and therefore will incur a cost. To prevent this, they refrain from shirking. This unemployment, moreover, is involuntary: Workers would prefer to work even at a wage below the current one, but firms will not reduce wages and hire them because at the lower wage, workers' promises not to shirk would not be credible.

Consider an economy populated by $N$ identical and risk-neutral workers, with a separable instantaneous utility function $U(w, E)=w-E$, where $w$ is the instantaneous wage rate (assumed to be constant over time), and $E$ the level of effort. Workers maximize

$$
\begin{equation*}
\int_{0}^{\infty}(w-E) e^{-\rho t} d t \tag{1}
\end{equation*}
$$

by choice of their effort level. For simplicity we will assume that effort can take only one of two values: zero and some positive level $x$. If a worker shirks (exerts zero effort), there is an instantaneous probability $q \in \varepsilon(0,1)$ that he
will be caught and fired. Whether or not he shirks, there is a probability $b$ of separation due to other factors. Unemployed workers are paid unemployment benefits at a rate $w_{u}$ and are assumed to find new jobs with instantaneous probability $a$, which we will take as given for now. The parameters $b$ and $q$ are taken as exogenous in the model and are constant over time.

## Problem 5.1.

(i) Let $V_{e}(s)$ be the expected lifetime utility of an employed worker who shirks, $V_{e}(n)$ the expected lifetime utility of an employed non-shirker, and $V_{u}$ the expected lifetime utility of an unemployed worker. Write the valuation equations defining $V_{e}(s)$ and $V_{e}(n)$, and explain their meaning.

Hint: If it helps, consider the analogous discrete-time problem with periods of length $h$ and take the limit as $h \rightarrow 0$.

(ii) An employed worker will choose not to shirk if $V_{e}(n) \geq V_{e}(s)$. Show that this "no-shirking" condition implies that $V_{e}(s) \geq V_{u}$, so that workers prefer to be employed, and use it to solve for the minimum wage $w_{m}$ at which workers will find it optimal not to shirk. What factors determine $w_{m}$ ?

Let $L$ be the effective labor force employed by the representative firm, defined as the number of non-shirkers it employs (for simplicity, we assume that workers who shirk contribute nothing to output). The firm maximizes profit $f(L)-w L$ subject to the constraint that (because it can detect shirking only imperfectly and ex post) it must pay the same wage to all workers. To produce at all, then, the firm needs to set a wage that will induce its workers not to shirk. It follows that in equilibrium, $w \geq w_{m}$, so workers do not shirk, and the expected lifetime utility of an employed worker, $V_{e}$, is given by $V_{e}(n)$.

To maximize profit, the representative firm will pay the minimum nonshirking wage $w_{m}$ and then set the level of employment so that the marginal product of labor will be equal to the wage. Hence, the firm's labor demand function is implicitly given by

$$
\begin{equation*}
f^{\prime}(L)=w_{m} \tag{8}
\end{equation*}
$$

Problem 5.2. We will now characterize a stationary equilibrium of the model.

(i) Let $w_{u}$ be the unemployment benefit. Derive the expected lifetime utility of an unemployed worker, $V_{u}$, as a function of $w_{u}$ and the value of an employed worker, $V_{e}$.

(ii) Using the expressions for $V_{e}\left(=V_{e}(n)\right)$ and $V_{u}$ derived earlier, solve for $V_{e}$ and $V_{u}$ as functions of $a$ and the parameters of the model. Rewrite the no-shirking condition, replacing $V_{u}$ by its equilibrium value. How do unemployment
benefits and the probability of finding employment affect the minimum nonshirking wage?

(iii) Let $N$ be the given labor supply. In a steady-state equilibrium, the flow into unemployment and the flow out of it must be equal. Using this condition, solve for the probability of finding employment, $a$, as a function of $b, L$, and $N$, and substitute the result into the no-shirking condition. Interpret the resulting condition. The equilibrium wage and unemployment levels are determined by the intersection of the non-shirking condition and the labor demand schedule $f^{\prime}(L)$ $=w_{m}$. Draw both functions in the $(w, L)$ plane, and verify that the equilibrium involves an excess supply of labor.

## (b) Unemployment in a Matching Model

This section is based on Pissarides (1990). Consider an economy in which workers and firms look for each other. The population is a continuum of measure 1 of homogeneous, risk-neutral workers. Let $u$ be the unemployment rate (the fraction of the population that is unemployed), and $v$ the vacancy rate (the number of open but vacant jobs available as a fraction of the population). The instantaneous rate of matching between unemployed workers and vacant jobs is given by a matching function of the form

$$
\begin{equation*}
x=u^{\alpha} v^{1-\alpha}=v \theta^{-\alpha}, \quad \text { where } \theta=v / u \tag{1}
\end{equation*}
$$

Hence, the instantaneous probability that an open vacancy will be filled is given by

$$
\begin{equation*}
\frac{x}{v}=\theta^{-\alpha} \tag{2}
\end{equation*}
$$

and the instantaneous probability that an unemployed worker will find a job is

$$
\begin{equation*}
\frac{x}{u}=\theta^{1-\alpha} \tag{3}
\end{equation*}
$$

Each firm consists of a single job that can be either filled or vacant. When a worker and a firm meet, they form a match. An occupied job produces a flow of output at a constant rate $y$ and has an instantaneous probability $s$ of disappearing because of "structural shocks." An open vacancy has a cost $c$ per instant of time. An unemployed worker earns unemployment benefits at an instantaneous rate $b$. The wage, $w$, is set through a bargaining process described later.

## Problem 5.3.

(i) Derive an expression that describes the evolution of the unemployment rate over time as a function of the instantaneous rate of separation $(s)$ and the prob-
ability of finding employment, $\theta^{1-\alpha}$. Set $\dot{u}=0$ and solve for the steady-state unemployment rate as a function of the rates of flow into and out of unemployment (assuming $\theta$ is constant).

(ii) Let $V$ be the value of a vacancy, $J$ the value of a filled job, and $r$ the discount rate. Taking into account the relevant transition probabilities and the flows of costs and benefits for an occupied job and a vacant job, write the valuation equations for these two assets, $J$ and $V$. Explain their meaning. Using the two asset-valuation equations (subtract one from the other), derive an expression for $J-V$ as a function of $y, c, w, r$, and the relevant transition probabilities.

(iii) Let $E$ and $U$ be the "values" of an employed worker and an unemployed worker, respectively. Write and explain the corresponding asset-valuation equations, and derive an expression for $E-U$.

Wages are set through a centralized bargaining process between a union and firms. The equilibrium wage is the one given by the Nash bargaining solution, that is, the value of $w$ that solves

$$
\max _{w}(E-U)^{\beta}(J-V)^{1-\beta}
$$

where $\beta$ is an index of workers' bargaining power.

Problem 5.4. Using the results of Problem 5.3, solve for the equilibrium wage.

Problem 5.5. In equilibrium, new firms enter until the value of a vacant job drops to zero, that is, until $V=0$.

(i) Using the valuation equations for $V$ and $J$, show that

$$
\begin{equation*}
\frac{y-w}{r+s}=c \theta^{\alpha} \tag{13}
\end{equation*}
$$

(ii) Using equation (13), along with the expression for the equilibrium wage obtained in Problem 5.4 and the formula for the steady-state unemployment rate obtained in Problem 5.3, solve for the equilibrium values of $u, w$, and $\theta$. Draw a diagram in the $(u, \theta)$ plane illustrating the determination of equilibrium.

(iii) What are the effects on the equilibrium unemployment rate of an increase in workers' bargaining power $(\beta)$, an increase in the unemployment benefit $(b)$, and an increase in the probability of structural shocks $(s)$ ?

## (c) The Behavior of the Savings Rate in the Cass-Koopmans Model

Consider an infinitely-lived dynasty whose size increases over time at a constant rate $n$. The objective function is now of the form

$$
\begin{equation*}
\int_{0}^{\infty} \frac{C^{1-\sigma}}{1-\sigma} L_{t} e^{-\rho t} d t \tag{1}
\end{equation*}
$$

where $L_{t}=L_{0} e^{n t}$ is the size of the dynasty, and $C$ is per-capita consumption. The household maximizes (1) subject to the budget constraint

$$
\begin{equation*}
\dot{K}=K^{\alpha}(A L)^{1-\alpha}-L C-\delta K \tag{2}
\end{equation*}
$$

where $\delta$ is the rate of depreciation, and $A$ grows at a constant rate $g$. We will assume that the condition

$$
\begin{equation*}
g \sigma+\rho>n+g \tag{3}
\end{equation*}
$$

holds, in order to guarantee the boundedness of (1). Following the same procedure as before, it is easy to show that the necessary conditions for household optimization yield the following system of equations:

$$
\begin{align*}
& \frac{\dot{c}}{c}=\frac{1}{\sigma}\left\{\alpha Z^{\alpha-1}-(\rho+\delta)\right\}-g  \tag{4}\\
& \frac{\dot{Z}}{Z}=Z^{\alpha-1}-\frac{c}{Z}-(n+g+\delta) \tag{5}
\end{align*}
$$

where $c=C / A$ and $Z=K / A L$.

Following Barro and Sala-i-Martin (1995), we will analyze the behavior of the savings rate in this model. The first step will be to rewrite it in terms of the consumption ratio and the interest factor.

Problem 5.6. Define the variables

$$
\begin{equation*}
X=\frac{c}{Z^{\alpha}} \quad \text { and } \quad R=Z^{\alpha-1} \tag{6}
\end{equation*}
$$

(i) Rewrite the system (4)-(5) in terms of $X$ and $R$. Solve for the steady-state values of $X$ and $Z$.

(ii) Construct the log-linearization of the system obtained in (i). Compute the eigenvalues of its coefficient matrix, and show that the steady state is a saddle point. Compute the eigenvector associated with the negative eigenvalue, and relate the slope of the saddle path to the size of the negative eigenvalue. Does anything look familiar?

Problem 5.7. Next, we will consider a special case. Assume that the following restriction on the parameters holds:

$$
\begin{equation*}
\rho+\delta+g \sigma=\alpha \sigma(\delta+n+g) \tag{12}
\end{equation*}
$$

Construct the phase diagram for the system, and compute its negative eigenvalue and the associated eigenvector.

Problem 5.8. Let us now return to the general case of the model. Define the parameter $\mu$ by

$$
\begin{equation*}
1+\mu \equiv \frac{\rho+\delta+g \sigma}{\alpha \sigma(\delta+n+g)} \tag{18}
\end{equation*}
$$

and notice that if $\mu=0$, then we are in Problem 5.7. Write the negative eigenvalue of the system and the corresponding eigenvector as functions of $\mu$, and relate the slope of the saddle path to the sign of $\mu$. Draw the phase diagram of the system for $\mu>0$ and $\mu<0$.

## (d) Productive Government Spending in a Model of Endogenous Growth

As in Barro (1990), a representative agent with the usual preferences

$$
\begin{equation*}
\int_{0}^{\infty} \frac{c^{1-\sigma}}{1-\sigma} e^{-\rho t} d t \tag{1}
\end{equation*}
$$

is endowed with an initial amount of capital $k_{0}$ and with a production technology of the form

$$
\begin{equation*}
y=k^{1-\alpha} p^{\alpha} \quad(0<\alpha<1) \tag{2}
\end{equation*}
$$

where $p$ are government-provided public services. Income is taxed at a constant proportional rate $\tau$. Assuming there is no depreciation, the agent's flow budget constraint can be written

$$
\begin{equation*}
\dot{k}=(1-\tau) k^{1-\alpha} p^{\alpha}-c \tag{3}
\end{equation*}
$$

Problem 5.9.

(i) Taking as given the time path of $p$, write the necessary conditions for a solution to the consumer's problem. Derive an equation describing the evolution of consumption over time.

(ii) Assume that $p=\tau y$, that is, that all tax revenue is used to finance public services. Substituting the production function in this last expression, solve for $p$ as a function of $\tau$ and $k$. Substitute the result into the flow budget constraint and the transition equation for consumption. Call $\gamma$ the growth rate of consumption, $\dot{c} / c$, obtained from this step, and let $\beta$ be the coefficient of $k$ in the law of motion for $k$ (both $\gamma$ and $\beta$ are functions of $\tau$ and other parameters). Notice that $\beta$ can be written as a simple function of $\gamma$.

(iii) Observe that consumption grows at a constant exponential rate. Hence, once we determine its initial level, we have characterized its entire path. Integrating the flow budget constraint and imposing the transversality condition, we obtain

$$
\begin{equation*}
k_{0}=\int_{0}^{\infty} c_{t} e^{-\beta t} d t \tag{9}
\end{equation*}
$$

Use this expression to solve for $c_{0}$.

## Problem 5.10.

(i) Substitute the equilibrium path of consumption into the agent's objective function to obtain utility as a function of $\gamma($ or $\tau), U(\gamma)$. What condition must we
impose in order to guarantee that utility is bounded? Assume this condition holds.

(ii) Find the optimal value of $\tau$.

Hint: Differentiate $U(\gamma)$. Can you sign the derivative? Proceed accordingly. Does the result "look right"? Why or why not?

## (e) A Model of Endogenous $R \& D$

Let us return to the product-variety model developed in Section 5(a) of Chapter 8. As the reader will recall, we had a two-sector economy in which labor was used to produce differentiated components that were then assembled into a homogeneous consumption good. In equilibrium, final output was proportional to ("variable") employment in goods production and was an increasing function of the existing number of component varieties. More specifically, output per worker was given by the (reduced-form) per-capita production function

$$
\begin{equation*}
Q=n^{(1-\alpha) / \alpha} \frac{L_{x}}{L} \tag{1}
\end{equation*}
$$

where $L_{x}$ was total employment in goods production, $L$ was the (constant) size of the labor force, and the parameter $\alpha<1$ measured the substitutability of components in the production of final goods.

The previous version of the model was static. The equilibrium number of component varieties was determined by a zero-profit condition and a fixed entry cost: Firms entered the market until their operating profits were just enough to pay for the cost of a given amount of labor required to set up production. Let us now consider a dynamic version of the same economy in which the entry charge must be paid only once and will be interpreted as the cost of designing a new intermediate product. ${ }^{23}$ More specifically, we will assume that blueprints for new components are developed in an R\&D sector that takes labor as an input. We will also assume that the amount of labor required to produce a blueprint for a new product is inversely proportional to the stock of accumulated technical knowledge, summarized by the number of preexisting varieties of intermediate products. ${ }^{24}$ Hence, the rate of introduction of new products is given by

$$
\begin{equation*}
\frac{\dot{n}}{n}=a L_{n}=a\left(L-L_{x}\right) \tag{2}
\end{equation*}
$$

where $n a$ is the number of blueprints that can be produced with a unit of labor, and $L_{n}=\left(L-L_{x}\right)$ is total employment in R\&D. Equation (2) then implies that (if the fraction of the labor force employed in R\&D remains constant over time, as will indeed be the case in equilibrium) output growth is driven exclusively by the increase in efficiency that results from the intro-
duction of new product varieties. The rate of technical progress will be determined by the level of employment in research activities. Our main task in this section will be to show how this variable is determined.

Problem 5.11. It will be convenient in what follows to work with the growth rate of per-capita consumption, denoted by $g$. Assuming that the level of employment in goods production, $L_{x}$, remains constant over time, solve for $L_{x}$ as a function of $g$. Keep an eye out for scale effects, that is, reasons why a larger economy (as measured by the size of the labor force, $L$ ) may be able to grow faster.

Our task is to determine how available resources are allocated between goods production and research. Loosely speaking, the equilibrium level of $R \& D$ employment (i.e., the value of $g$ ) will be determined by the requirement that the savings decisions of consumers must be compatible with the investment decisions of producers. Because researchers must be paid out of somebody's savings, factor prices must adjust so that in equilibrium consumers will be willing to finance the volume of investment that producers want to undertake.

We will characterize the equilibrium value of $g$ in terms of two relations between the interest rate and the growth rate, one implied by consumer intertemporal maximization, and the other summarizing equilibrium in the production sector of the economy. Let us start with the consumption side of the model. For a change, households will be assumed to maximize the function

$$
\begin{equation*}
U=\int_{0}^{\infty} \frac{C_{t}^{1-\sigma}}{1-\sigma} e^{-\rho t} d t \tag{4}
\end{equation*}
$$

where $C_{t}$ is consumption of the composite final good at time $t$, subject to a standard budget constraint. The solution of this problem yields the familiar condition for the optimal allocation of consumption over time,

$$
\begin{align*}
g & =\frac{\dot{C}}{C}=\frac{r-\rho}{\sigma} \\
& \Rightarrow r=\rho+\sigma g \tag{SS}
\end{align*}
$$

where $r$ is the market interest rate. Hence, consumer optimization implies a positive relationship between the growth rate of consumption and the interest rate (both at the individual level and at the aggregate level): High growth implies deferral of consumption to liberate resources for investment, and a high interest rate is required in order to provide consumers the incentive to postpone consumption. To put it in a slightly different way, if we want consumers to accept a steeper consumption profile (i.e., to trade more current consumption for future consumption), we have to give them an incentive, by making future consumption relatively cheaper.

To derive the second relation between $g$ and $r$, we need to think about the incentive to do research. It will be convenient to imagine that innovation takes place in a separate R\&D sector. Agents, in their role as suppliers of labor, have a choice between taking a "regular job" in industry at wage $w$ or entering the research sector. In the latter case, we will think of them as starting a new company for each blueprint they produce and selling its shares at the going price $(v)$ in the stock market. In equilibrium, employment levels and earnings in the research and production sectors must be such that, at the margin, no agent has an incentive to switch sectors. If research and manufacturing are to coexist in equilibrium, net earnings per unit of labor must be the same in the two sectors. That is, the equilibrium wage (w) must be equal to the market value of the blueprints that can be produced with one unit of labor (an):

$$
\begin{equation*}
w=a n v \tag{5}
\end{equation*}
$$

Finally, the stock-market value of a firm in the intermediate sector will be equal to the discounted value of its flow of future profits, that is,

$$
\begin{equation*}
v_{t}=\int_{t}^{\infty} \pi_{t+s} e^{-r s} d s \tag{6}
\end{equation*}
$$

Problem 5.12. Using equations (5) and (6), together with the expressions for equilibrium factor prices derived in Section 5(a) of Chapter 8, derive the following relationship between the interest rate and the growth rate of consumption:

$$
\begin{equation*}
r=\frac{a(1-\alpha)}{\alpha} L-\frac{\alpha}{1-\alpha} g \tag{II}
\end{equation*}
$$

Interpret this condition.

Putting the II and SS schedules together, we can solve for the equilibrium values of the interest rate and the rate of growth. When the interest rate is low, $R \& D$ investment is attractive, but saving is not, whereas at high interest rates we have the opposite situation. Savings and investment decisions will be compatible only at the interest rate given by the intersection of the SS and II schedules, as shown in Figure 13.17.

Problem 5.13. Solve for the equilibrium values of $g$ and the fraction of the labor force employed in research $\left(L_{n} / L\right)$. Discuss the determinants of the equilibrium growth rate and the impact on both variables of an increase in the size of the labor force, $L$. Consider also the effects of "merging" two isolated economies into a larger, integrated one. Does anything change? To

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-656.jpg?height=565&width=810&top_left_y=190&top_left_x=324)

Figure 13.17. Determination of the equilibrium growth rate.

what extent is the answer to this question sensitive to the details of the specification we have used?

## Bibliography

Abel, A. 1981. Dynamic Effects of Permanent and Temporary Tax Policies in a $q$ Model of Investment. Journal of Monetary Economics 9:353-73.

Abel, A., and Blanchard, O. 1983. An Intertemporal Equilibrium Model of Saving and Investment. Econometrica 51(3):675-92.

Arrow, K. 1968. Applications of Control Theory to Economic Growth. In: Mathematics of Decision Sciences, Part 2, pp. 85-119. Providence, RI:

American Mathematical Society.

Barro, R. 1990. Government Spending in a Simple Model of Endogenous Growth. Journal of Political Economy 98(5, pt.2):S103-25.

Barro, R., and Sala-i-Martin, X. 1995. Economic Growth. New York: McGraw-Hill.

Blanchard, O., and Fischer, S. 1989. Lectures on Macroeconomics. Massachusetts Institute of Technology Press.

Cass, D. 1965. Optimum Growth in an Aggregative Model of Capital Accumulation. Review of Economic Studies 32:223-40.

Diamond, P. 1982. Aggregate Demand Management in Search Equilibrium. Journal of Political Economy 90:881-94.

Diamond, P. 1984. A Search-Equilibrium Approach to the Micro Foundations of Macroeconomics. Massachusetts Institute of Technology Press.

Diamond, P., and Fudenberg, D. 1989. Rational Expectations Business Cycles in Search Equilibrium. Journal of Political Economy 97(3):606-20.

Grossman, G., and Helpman, E. 1991. Innovation and Growth in the Global Economy. Massachusetts Institute of Technology Press.

Hayashi, F. 1982. Tobin's Marginal $q$ and Average $q$ : A Neoclassical Interpretation. Econometrica 50(1):213-24.

Koopmans, T. 1965. On the Concept of Optimal Economic Growth. In: The Econometric Approach to Development Planning. Chicago: Rand McNally.

Lucas, R. 1990. Supply-Side Economics: An Analytical Review. Oxford Economic Papers 42:293-316.

Mortensen, D. 1986. Job Search and Labor Market Analysis. In: Handbook of Labor Economics, vol. 2, ed. O. Ashenfelter and R. Layard, pp. 849-919. Amsterdam: Elsevier.

Mulligan, C., and Sala-i-Martin, X. 1991. A Note on the Time-Elimination Method for Solving Recursive Dynamic Economic Models. NBER technical working paper no. 116.

Pissarides, C. 1990. Equilibrium Unemployment Theory. London: Blackwell.

Ramsey, F. 1928. A Mathematical Theory of Savings. Economic Journal 38:543-59.

Romer, P. 1990. Endogenous Technological Change. Journal of Political Economy (October):S71-S102.

Sargent, T. 1987. Dynamic Macroeconomic Theory. Harvard University Press.

Shapiro, C., and Stiglitz, J. 1989. Equilibrium Unemployment as a Worker Discipline Device. American Economic Review 74:433-44.

Simmons, G. 1972. Differential Equations with Applications and Historical Notes. New York: McGraw-Hill.

Stokey, N., and Lucas, R. 1989. Recursive Methods in Economic Dynamics. Harvard University Press.

Tobin, J. 1969. A General Equilibrium Approach to Monetary Theory. Journal of Money, Credit and Banking 1:15-29.

Wolfram, S. 1991. Mathematica. A System for Doing Mathematics by Computer. Reading, MA: Addison-Wesley.

## Notes

1 It can be shown that, given our assumptions, it will never be optimal for the worker to quit a job he has already accepted in order to look for a better job. To avoid complications, we will simply assume that he is not allowed to quit.

2 As usual, this expression can be interpreted directly as an asset-valuation equation. "Being unemployed" can be thought of as an asset that will pay a direct instantaneous dividend, $b$, and with instantaneous probability $\lambda$ will yield the opportunity for a capital gain $W_{a}(x)-W_{r}$, because of a change in status from unemployed to employed. Because this change will take place only when the offer is accepted, we take the maximum of this quantity and zero, and because $x$ is not known, we compute the expectation. Finally, the expected return of the asset, measured as a fraction of its value, must be equal to the discount rate $\rho$.

3 In computing $H_{x}^{*}$, we make use of the following result, known as Leibniz's rule. Consider the function $(x)=\int_{a(x)}^{b(x)} F(x, s) d s$. Then

$$
\phi^{\prime}(x)=\int_{a(x)}^{b(x)} \frac{\partial F(x, s)}{\partial x} d s+b^{\prime}(x) F[x, b(x)]-a^{\prime}(x) F[x, a(x)]
$$

4 This assumption captures the fact that in a modern economy, people seldom consume much of what they produce. Hence, consumption requires trade, as well as production.

5 The aggregate employment rate determines the probability of an "employed" worker finding a trading partner during the period, given by $b(e)$ : The larger $e$ is, the faster the agent can expect to be able to eat. Thus, the value of being employed increases with $e$. The value of being unemployed depends partly on the value of being employed and therefore is also a function of $e$.

6 From (8)

$$
c^{*}=\frac{b(e) y+a \int_{\underline{\underline{c}}}^{c^{*}} c d G(c)}{\rho+b(e)+a G\left(c^{*}\right)} \leq \frac{b(e) y+a c^{*} G\left(c^{*}\right)}{\rho+b(e)+a G\left(c^{*}\right)}
$$

and, rearranging terms,

$$
c^{*} \leq \frac{b(e) y}{\rho+b(e)} \leq y
$$

When $e=0, c^{*}$ is the solution to,

$$
\begin{equation*}
c^{*} \leq \frac{a \int_{\underline{C}}^{c *} c d G(c)}{\rho+a G\left(c^{*}\right)} \tag{1}
\end{equation*}
$$

Now, $c^{*}=0$ is clearly one solution of this equation. To show that there are no others, notice that

$$
\frac{a \int_{\underline{c}}^{c^{*}} c d G(c)}{\rho+a G\left(c^{*}\right)} \leq \phi\left(c^{*}\right) \equiv \frac{a c^{*} G\left(c^{*}\right)}{\rho+a G\left(c^{*}\right)}
$$

and observe that $\phi\left(c^{*}\right)=0$ for $c^{*} \leq \underline{c}$ and

$$
\phi\left(c^{*}\right)=\frac{c^{*}}{1+\left(\rho / a G\left(c^{*}\right)\right)}<c^{*} \text { for } c^{*}>\underline{c}
$$

Thus, the functions on the two sides of (1) cross only at the origin.

7 Other paths will eventually violate either some feasibility condition or the transversality condition for the agent's optimization problem, which requires $c^{*}$ to be bounded and strictly positive for $b(e)>0$.

8 That is, if net output is given by $G(K, L)$, and $\delta$ is the rate of depreciation of the capital stock, we have $F(K, L)=G(K, L)+(1-\delta) K$.

9 Observe that the steady-state capital stock depends only on the production function and the rate of time preference, not at all on the form of the period utility function.

10 We are assuming that the firm does not use debt financing. In the absence of taxes, however, the capital structure of the firm makes no difference. To see this, assume the firm borrows $b$ dollars at time zero, uses them to increase the current dividend, and then pays interest forever on the debt. The net gain to shareholders from the operation is $b-b r / r=0$. When we consider taxes, things get messier.

Notice also that there is no guarantee that dividends will be positive every period. Negative dividends would amount to stockholders buying additional shares of the firm in order to provide funds to carry out current investment plans.

11 Recall that the first partial derivatives of a linearly homogeneous function $g(x, y)$ are homogeneous of degree 0 . This implies that the partial derivative is a function only of the ratio of the two arguments, e.g., $g_{x}(x, y)=g_{x}(x / y, 1)$. For a discussion of homogeneous functions, see Section 5 of Chapter 4.

12 In a well-known paper, Tobin (1969) anticipated this result. He conjectured that the firm should continue to invest as long as what he called "marginal $q$ " (the marginal contribution of a unit of installed capital to the market value of the firm, divided by the price of investment goods) exceeded 1.

13 This rate of return is the sum of two terms: The first is the ratio of capital gains and the current dividend, net of taxes, to the asset's price, and the second captures depreciation and the fact that installed capital reduces installation costs.

14 Another useful aspect of this result is that it makes the theory potentially testable, as the firm's market value is an observable quantity, and $K$ can, in principle, be computed from accounting information.

15 That is, $\dot{q}=q\left[r+\delta-\Psi_{K}(I, K)\right]-(1-u) F_{K}(K, L) \Rightarrow(1-u) F_{K}(K, L)-q\left(\delta-\Psi_{K}\right)=r q-\dot{q}$.

16 This requires only that $\Psi(\beta(\cdot), 1)>\delta$ as $q \rightarrow \infty$, which seems reasonable enough.

17 First, note that

$$
\varphi_{K}()=\Psi\left(\beta\left(\frac{1-c}{q}\right), 1\right)-\delta=0
$$

at a steady state, and

$$
\left.\left.\phi_{q}=\frac{\partial \dot{q}}{\partial q}=\left[r+\delta-\Psi_{K}(\beta(), 1)\right]-q \Psi_{K I}(\beta(), 1)\right) \frac{\partial \beta}{\partial q}=\left[r+\delta-\Psi_{K I}(\beta(), 1)\right]+\Psi_{K I}(\beta(), 1)\right) \frac{1-c}{q \Psi_{I I}}
$$

where the second equality makes use of the fact that $\left.\partial \beta[(1-c) / q] / \partial q=-(1-c) / \Psi_{\mathrm{II}} q^{2}\right)$.

Next, because the installation function is homogeneous of degree 1, its partials are homogeneous of degree 0 , implying

$$
\Psi_{I I} I+\Psi_{I K} K=0 \Rightarrow\left(\Psi_{I K} / \Psi_{I I}\right)=-(I / K)
$$

Thus, we can write

$$
\frac{\partial \dot{q}}{\partial q}=\left[r+\delta-\Psi_{K}(\beta(), 1)\right]-\frac{(1-c) I}{q K}=\left[r+\delta-\Psi_{K}(\beta(), 1)\right]-\Psi_{I}(I / K, 1) \frac{I}{K}
$$

making use of the condition for optimal investment, $(1-c) / q=\Psi_{I}(I / K, 1)$. By the linear homogeneity of the installation function, $\Psi_{I}(I / K, 1)(I / K)+\Psi_{K}(I / K, 1)=\Psi(I / K, 1)$, implying

$$
\left.\frac{\partial \dot{q}}{\partial q}\right|_{s s}=r+\delta-\Psi(\beta(), 1)=r
$$

because at a steady state, $\Psi(\beta(), 1)=\delta$.

18 With perfect foresight, future discontinuities in the time path of asset prices are incompatible with equilibrium. If such discontinuities existed, agents would anticipate very large capital gains or losses at some point in the future and would act now to take advantage of them or avoid them. These actions, however, would bring the price change to the present. At the time of the announcement, for example, agents will know that stock prices will fall at time $T$, if not sooner. To avoid such losses, agents will dump their stock holdings now, causing an immediate drop in the "stock price" $q$. Thus the trajectory must be continuous, except possibly at the time of the announcement, when surprised stockholders will be unable to avoid unexpected capital losses. See Section 2 in Chapter 11.

19 The reader should check that this is the only functional form for which the model has a balanced growth path when there is technical progress.

20 See Section 5 of Chapter 9 for a discussion of the solution of nonautonomous linear differential equations.

21 Observe that this steady-state derivative can also be computed using $\left(22^{\prime}\right)$ and $\left(23^{\prime}\right)$. The resulting expression can be used, together with (35), to solve for $p_{r}\left(Z^{*}, \tau_{r}\right)$.

22 See Mulligan and Sala-i-Martin (1991), Simmons (1972), or some other textbook on differential equations.

23 This section draws on the work of Grossman and Helpman (1991) and Romer (1990).

24 Without this assumption, innovation would eventually stop with a fixed population, because of a market-saturation effect; as we know, profit is a decreasing function of the number of existing competitors.

## Chapter 1

Problem 2.2. Prove the following equivalence ( $X$ is the universal set):

$$
\begin{aligned}
& P \subseteq Q \Leftrightarrow(\sim P) \cup Q=X \\
& X=(\sim P) \cup Q \Leftrightarrow X \cap(\sim Q)=[(\sim P) \cup Q] \cap(\sim Q) \\
& \Leftrightarrow X \sim Q=[(\sim P) \cap(\sim Q)] \cup[Q \cap(\sim Q)] \\
& \Leftrightarrow X \sim Q=\sim(P \cup Q) \cup \varnothing \\
& \Leftrightarrow \sim Q=\sim(P \cup Q) \\
& \Leftrightarrow Q=P \cup Q \Leftrightarrow P \subseteq Q
\end{aligned}
$$

See Figure A.1.1.

Problem 2.3. Prove the second of De Morgan's laws: Let $\mathbb{A}=\left\{A_{i} ; i \in I\right\}$ be a family of sets in $X$. Then $\sim\left(\cap_{i} A_{i}\right)=\cup_{i}\left(\sim A_{i}\right)$.

$$
\begin{aligned}
x \in \sim\left(\cap_{i} A_{i}\right) & \Leftrightarrow x \notin \cap_{i} A_{i} \Leftrightarrow \neg\left(\forall i \in I, x \in A_{i}\right) \\
& \Leftrightarrow \exists i \in I \text { s.th. } x \notin A_{i} \Leftrightarrow \exists i \in I \text { s.th. } x \in \sim A_{i} \\
& \Leftrightarrow x \in \cup_{i}\left(\sim A_{i}\right)
\end{aligned}
$$

Problem 2.8. The following modification of the induction principle is sometimes useful: Let $P$ be a property that natural numbers (or positive integers) may or may not have. If

(i) $P(0)$ holds and

(ii) if $P$ holds for all integers $k=0,1, \ldots, n-1$, then it also holds for $n$.

Then $P$ holds for all natural numbers. Prove this result.

Let $S$ be the set of nonnegative integers for which $P(n)$ is false. Assume that $S$ is not empty. Then, by the well-ordering principle, this set has a smallest element we will call $n_{0}$. By (i), $n_{0} \neq 0$, and because $n_{0}$ is the least element of $S, P(k)$ holds for all $0 \leq \mathrm{k}<n_{0}$. By (ii), $P\left(n_{0}\right)$ is true, implying that $n_{0} \notin S$, a contradiction.

Problem 2.9. Use the modified induction principle to prove that any integer larger than 1 is either a prime number (it has no integer divisors other than 1) or the product of prime numbers.

The result holds trivially for 2 . Assume that it holds for every integer $k$ where 1 $<k<n$. We have to show that this implies that the result holds also for every $k$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-660.jpg?height=479&width=689&top_left_y=1647&top_left_x=394)

Figure A1.1.
with $1<k<n+1$. There are two possibilities: (i) $n$ is prime, in which case there is no problem, or (ii) $n$ is not a prime number. But if $n$ is not prime, it has a divisor $d<n$, and we have $n=d c$, where $c$ is also between 1 and $n$. Hence, $1<c, d<n$, so both numbers are, by hypothesis, either prime or products of primes, and therefore so is $n=d c$.

Problem 4.4. Explain why inclusion works only in one direction in the second part of Theorem 4.3, but in both directions in the first part.

(i) Give an example in which $\cap_{i \in I} f\left(A_{i}\right)$ is strictly larger than $f\left(\cap_{i \in I} A_{i}\right)$.

(ii) Prove that if $f$ is one-to-one, then $\cap_{i \in I} f\left(A_{i}\right)=f\left(\cap_{i \in I} A_{i}\right)$.

The proof that $f\left(\cap_{i \in I} A_{i}\right) \subseteq \cap_{i \in I} f\left(A_{i}\right)$ goes as follows:

$$
\begin{aligned}
y \in f\left(\cap_{i \in I} A_{i}\right) & \Leftrightarrow \exists x \in \cap_{i \in I} A_{i} \text { s.th. } f(x)=y \\
& \left.\Rightarrow \forall i \in I, \exists x_{i} \in A_{i} \text { s.th. } f\left(x_{i}\right)=y \quad \text { (e.g., } x_{i}=x \forall i\right) \\
& \Leftrightarrow \forall i \in I, y \in f\left(A_{i}\right) \Leftrightarrow y \in \cap_{t \in I} f\left(A_{i}\right)
\end{aligned}
$$

The second implication is the only one that goes only in one direction. If there exists some $x$ that belongs to all the $A_{i}$ 's simultaneously and has a certain property, it must be true that each $A_{i}$ contains at least one element (the given $x$ ) with the desired property. But the converse is not necessarily true: Even if each $A_{i}$ contains an appropriate $x_{i}$, it does not follow that any of these points will lie in the intersection of the $A_{i}$ 's, as each of the $x_{i}$ 's may be different, and it is possible that for each $i$ we might have $x_{i} \in A_{i} \cap\left(\sim A_{k}\right)$ for some $k \neq i$.

However, if the function is one-to-one, then $y$ has a unique inverse image, implying that all the $x_{i}^{\prime}$ s are the same. In this case, the converse implication also holds.

The proof of $f^{-1}\left(\cap_{i \in I} B_{i}\right)=\cap_{i \in I} f^{-1}\left(B_{i}\right)$, on the other hand, is of the form

$$
\begin{aligned}
x \in f^{-1}\left(\cap_{i \in I} B_{i}\right) & \Leftrightarrow f(x) \in \cap_{i \in I} B_{i} \\
& \Leftrightarrow \forall i \in I, f(x) \in B_{i} \\
& \Leftrightarrow \forall i \in I, x \in f^{-1}\left(B_{i}\right) \\
& \Leftrightarrow x \in \cap_{i \in I} f^{-1}\left(B_{i}\right)
\end{aligned}
$$

In this case, all the implications go in both directions. In particular, because $f(x)$ is a single element (which is not generally the case for inverse images), if $f(x) \in B_{i}$ for all $i$, then $f(x) \in \cap_{i \in I} B_{i}$, and vice versa.

Consider the function $f(x)=x^{2}$, defined on the interval $[-1,1]$. (See Fig. A.1.1.2 on p.661). Then we have

$$
f([-1,0] \cap[0,1])=f(0)=0 \quad \text { and } \quad f([-1,0]) \cap f([0,1])=[0,1]
$$

Problem 4.5. Given a function $f: X \longrightarrow Y$, two subsets of $X, A_{1}$ and $A_{2}$, and two subsets of $Y, B_{1}$ and $B_{2}$, show that

(i) $f^{-1}\left(\sim B_{1}\right)=\sim f^{-1}\left(B_{1}\right)$,

(ii) $f^{-1}\left(B_{1} \sim B_{2}\right)=f^{-1}\left(B_{1}\right) \sim f^{-1}\left(B_{2}\right)$, and

(iii) if $f$ is bijective, then

$$
f\left(\sim A_{1}\right)=\sim f\left(A_{1}\right) \quad \text { and } \quad f\left(A_{1} \sim A_{2}\right)=f\left(A_{1}\right) \sim f\left(A_{2}\right)
$$

What can we say if $f$ is not bijective?

(i) $x \in f^{-1}\left(\sim B_{1}\right) \Leftrightarrow f(x) \notin B_{1} \Leftrightarrow x \notin f^{-1}\left(B_{1}\right) \Leftrightarrow x \in \sim f^{-1}\left(B_{1}\right)$

(ii) $f^{-1}\left(B_{1} \sim B_{2}\right)=f^{-1}\left[B_{1} \cap\left(\sim B_{2}\right)\right]=f^{-1}\left(B_{1}\right) \cap f^{-1}\left(\sim B_{2}\right)=f^{-1}\left(B_{1}\right) \cap\left[\sim f^{-1}\left(B_{2}\right)\right]=$ $f^{-1}\left(B_{1}\right) \sim f^{-1}\left(B_{2}\right)$

(iii) $y \in f\left(\sim A_{1}\right) \Leftrightarrow \exists x_{0} \in\left(\sim A_{1}\right)$ s.th. $y=f\left(x_{0}\right)$ (if $f$ is one-to-one) $\Rightarrow y \in \sim f\left(A_{1}\right)$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-662.jpg?height=522&width=709&top_left_y=185&top_left_x=388)

Figure A1.2.

If $f$ is one-to-one, $x_{0}$ is the only inverse image of $y$ (i.e., there is no other $x$ with $y$ as an image). Hence, for every $x \in A_{1}, f(x) \neq y$, and it follows that $y \in \sim f\left(A_{1}\right)$.

Notice, however, that the argument requires that $f$ be one-to-one. If that were not so, $y$ could have several preimages, and then it could be an element of both $f\left(\sim A_{1}\right)$ and $f\left(A_{1}\right)$.

$$
\begin{aligned}
& y \in \sim f\left(A_{1}\right) \Leftrightarrow \nexists x \in A_{1} \text { s.th. } y=f(x) \text { (if } f \text { is "onto") } \\
& \Rightarrow \exists x \in \sim A_{1} \text { s.th. } y=f(x) \Leftrightarrow y \in f\left(\sim A_{1}\right)
\end{aligned}
$$

If $f$ is onto, each $y$ will have some preimage; if it does not belong to $A_{1}$, it will lie in $\sim A_{1}$, implying that $y \in f\left(\sim A_{1}\right)$. If $y$ is not onto, however, $y$ may have no preimage.

If $f$ is bijective, we have, using Problem 4.4 and condition (iii),

$$
\begin{aligned}
f\left(A_{1} \sim A_{2}\right) & =f\left[A_{1} \cap\left(\sim A_{2}\right)\right]=f\left(A_{1}\right) \cap f\left(\sim A_{2}\right) \\
& =f\left(A_{1}\right) \cap\left(\sim f\left(A_{2}\right)\right)=f\left(A_{1}\right) \sim f\left(A_{2}\right)
\end{aligned}
$$

If $f$ is not bijective, we have $f\left(A_{1}\right) \cap f\left(\sim A_{2}\right) \supseteq f\left[A_{1} \cap\left(\sim A_{2}\right)\right]=f\left(A_{1} \sim A_{2}\right)$.

Problem 4.6. Let $f$ be a function from $X$ to $Y$, with $A$ a subset of $X$, and $B$ a subset of $Y$. Then

$$
f\left[f^{-1}(B)\right] \subseteq B \quad \text { and } \quad A \subseteq f^{-1}[f(A)]
$$

When are the two sets not equal to each other?

Some elements of $B$ may not have preimages. Hence, when we "go" to $f^{-1}(B)$ and "come back," we may lose some elements. Similarly, there are elements of $f(A)$ that may have preimages outside $A$; hence, when we go to $f(A)$ and come back, we may pick up some additional elements.

Problem 5.3. Let "*" be a law of internal composition on $X$ that satisfies the associative property and is endowed with an identity element. Prove that if $x$ and $y$ have symmetric elements $x^{s}$ and $y^{s}$, then the symmetric element of $x * y$ is $y^{s} * x^{s}$.

$$
(x * y) *\left(y^{s} * x^{s}\right)=x *\left(y * y^{s}\right) * x^{s}=x * e * x^{s}=x * x^{s}=e
$$

Problem 5.4. Let $X$ be an arbitrary set, and $\{G, *\}$ a group. Show that the set of functions of $X$ into $G$, endowed with the operation defined by the composition of images, that is,

$$
\forall x \in X,(f * g)(x)=f(x) * g(x)
$$

is a group.

Given that $f(x)$ and $g(x)$ are elements of $G$, so is their composition, implying that the set of functions from $X$ to $G$ is closed under "*." For the same reason, this set inherits the associative property from $\{G, *\}$. The identity element is the function given by $e(x)=e$ for all $x$ in $G$, and the symmetric element of a function $f$ is the function $f^{s}$, defined by $f^{s}(x)=[f(x)]^{s}$ for each $x$ in $G$.

Problem 5.5. Show that the intersection of subgroups of $G$ is a subgroup of $G$.

Let $\left\{G_{i} ; G_{i} \subseteq G, i \in I\right\}$ be a family of subsets of $G$ such that $\left\{G_{i}, *\right\}$ is a group for each $i$. Because "*" is associative in $G$, it will remain so for any subset of $G$, including $\cap_{i} G_{i}$. By assumption, each $\left\{G_{i}, *\right\}$ is a subgroup, implying that the identity element $e$ belongs to each and all the $G_{i}$ 's and therefore to $\cap_{t} G_{i}$. Next, because each $G_{i}$ is closed under "*," if we take two points, $x$ and $y$, in $\cap_{i} G_{i}$ we will have $x * y \in G_{i}$ for all $i$, implying that $x * y \in \cap_{i} G_{i}$. Finally, every $x$ in $G_{i}$ has a symmetric element $x^{s}$ in $G_{i}$; thus, if $x \in G_{i}$ for all $i$, so does $x^{s}$, and it is therefore true that every $x$ in $\cap_{i} G_{i}$ has a symmetric element also in $\cap_{i} G_{i}$.

Problem 5.9. Prove Theorem 5.8: Let $V$ be a vector space over a field $F$, and let $S$ be a nonempty subset of $V$. Then $S$ is a vector subspace of $V$ if and only if

$$
\begin{equation*}
\forall \alpha, \beta \in F \text { and } \forall x, y \in S \text {, we have } \alpha x+\beta y \in S \tag{1}
\end{equation*}
$$

Clearly, $S$ inherits those manipulative properties of vector addition and multiplication by a scalar that hold in all $V$. With $\alpha=\beta=1$, equation (1) implies that $S$ is closed under vector addition, and also (with $\beta=0$ ) that the product of any element of $S$ and a scalar is an element of $S$. With $\alpha=\beta=0$, we have $0 x+0 y=\underline{0}+\underline{0}=\underline{0} \in S$, and $\alpha=-1$ and $\beta=0$ imply $(-1) x+0 y=-x+\underline{0}=-x \in S$, from which we conclude that the symmetric element of $x$ is also in $S$.

Problem 6.1. Show that there is no rational number $a=p / q$ (where $p$ and $q$ are integers with no common divisors) such that $a^{2}=2$.

Assume this is not true, that is, $p^{2} / q^{2}=2$. Then $p^{2}=2 q^{2}$, and $p^{2}$ is an even number. Because the square of an odd integer is odd [if $z=(2 n+1)$, then $z^{2}=$ $4 n^{2}+2 n+1=2\left(2 n^{2}+n\right)+1$, also odd], it must be that $p$ itself is even, and therefore we have $p=2 k$ for some integer $k$. But then

$$
p^{2}=2 q^{2} \Rightarrow 4 k^{2}=2 q^{2} \Rightarrow q^{2}=2 k^{2}
$$

and $q$ is also even. Hence, 2 is a common divisor of $p$ and $q$, which contradicts our assumptions.

Problem 6.5. Let $x, y$, and $z$ be arbitrary real numbers. Using the order axioms, show that the following statements are true:

(i) $\left(x \leq y\right.$ and $\left.x^{\prime} \leq y^{\prime}\right) \Rightarrow x+x^{\prime} \leq y+y^{\prime}$

(ii) $x \leq y \Rightarrow-y \leq-x$

(i) $x \leq y \Rightarrow x+x^{\prime} \leq y+x^{\prime}$, and $x^{\prime} \leq y^{\prime} \Rightarrow x^{\prime}+y \leq y^{\prime}+y$, from where $x+x^{\prime} \leq y+x^{\prime} \leq$ $y^{\prime}+y$.

(ii) Add $-x-y$ to both sides.

Problem 6.11. Prove Theorem 6.10: The set $\mathbb{N}$ of the natural numbers is not bounded above (i.e., for any $x \in \mathbb{R}$, there exists a natural number $n$ such that $n>x$ ).

If the result is false, there exists a real number $x$ that is an upper bound of $\mathbb{N}$. Then, by the supremum property, $\mathbb{N}$ has a supremum, $u$. Because $u$ is the least upper bound of $\mathbb{N}, u-1$ is not an upper bound, and there exists a positive integer $k$ such that $k>u-1$. Therefore, $u<k+1$, but because $k+1$ is a positive integer, this contradicts the fact that $u$ is an upper bound of $\mathbb{N}$.

Problem 6.13. Let $A$ and $B$ be nonempty sets of real numbers, both of them bounded above, and let $C$ be the set

$$
C=\{c=a+b ; a \in A, b \in B\}
$$

Show that $C$ has a supremum that is given by

$$
\sup C=\sup A+\sup B
$$

Let $\mathrm{a}^{*}=\sup A$ and $b^{*}=\sup B$. For each $c \in C$, we have $c=a+b$, where $a \in A$ and $b \in B$. Because $a \leq a^{*}$ and $b \leq b^{*}$, we have

$$
\begin{equation*}
\forall c \in C, c=a+b \leq a^{*}+b^{*} \tag{1}
\end{equation*}
$$

implying that $a^{*}+b^{*}$ is an upper bound of $C$. Hence $C$ is bounded above, and by the supremum property it has a supremum we will call $c^{*}$, with the property that $c^{*} \leq a^{*}+b^{*}$. It remains to prove the reverse inequality to show that $c^{*}=b^{*}+a^{*}$.

Fix an arbitrary $\varepsilon>0$. Because no number smaller than the supremum is an upper bound, there exist numbers $a \in A$ and $b \in B$ such that

$$
a>a^{*}-\varepsilon \text { and } b>b^{*}-\varepsilon
$$

Adding these inequalities,

$$
a^{*}+b^{*}-2 \varepsilon<a+b=c \leq c^{*}
$$

and given that this must hold for any $\varepsilon>0$, we conclude that $a^{*}+b^{*} \leq c^{*}$ by Theorem 2.4.

Problem 6.14. Show that a nonempty set $S$ of real numbers is an interval if and only if whenever $x$ and $y$ are in $S$, any real number $z$ such that $x<z<y$ lies also in $S$.

The first part is obvious by the definition of interval. Conversely, let $S$ be a set with the desired property, and define

$a=\inf S$ (or $a=-\infty$ if $S$ is not bounded below),

$b=\sup S$ (or $b=\infty^{*}$ if $S$ is not bounded above).

We will show that $(a, b) \subseteq S \subseteq[a, b]$, where we interpret $(a, b)$ as the empty set if $a=b$. Clearly, if this chain of inclusions can be established, $S$ can only be an interval.

First, notice that $S \subseteq[a, b]$ follows by the definition of $a$ and $b$. It remains to show that $(a, b) \subseteq S$. For this, let $z$ be an arbitrary point in $(a, b)$. Then $z>a$, and by the definition of $a$ there exists a point $x$ in $S$ with $x<z$ (otherwise $z$ would be a lower bound for $S$, and $a$ could not be the infimum). Similarly, $z<b$, and this implies that there exists a point $y$ in $S$ with $y>z$. Hence we have $x<z<y$, where both $x$ and $y$ are in $S$, and it follows that $z \in S$. Because $z$ was an arbitrary point of $(a, b)$, we have shown that $(a, b) \subseteq S$.

Problem 6.15. Show that if $a \geq 0$, then $|x| \leq a$ if and only if $-a \leq x \leq a$.

Because $|x|=x$ or $|x|=-x$, we have $-|x| \leq x \leq|x|$. If we assume $|x| \leq a$, we have $-a \leq-|x| \leq x \leq|x| \leq a$. Conversely, if $-a \leq x \leq a$, then

if $x \geq 0$, then $|x|=x \leq a$, and

if $x<0$, then $|x|=-x \leq a$ (because $x \leq y \Rightarrow-y \leq-x$ ),

so, in any event, $|x| \leq a$.

Problem 6.17. Given real numbers $x_{t}, i=1,2, \ldots, n$, show the following:

(i) $\left|\sum_{i=1}^{n} x_{i}\right| \leq \sum_{i=1}^{n}\left|x_{i}\right|$

(ii) $|a-c| \leq|a-b|+|b-c|$

(i) We know that the result holds for $n=2$, because it then reduces to the triangle inequality. Assume that the result holds for $n$; then it will also hold for $n+1$, because

$$
\left|\sum_{i=1}^{n+1} x_{i}\right|=\left|\left(\sum_{i=1}^{n} x_{i}\right)+x_{n+1}\right| \leq\left|\sum_{i=1}^{n} x_{i}\right|+\left|x_{n+1}\right| \leq \sum_{i=1}^{n}\left|x_{i}\right|+\left|x_{n+1}\right|=\sum_{i=1}^{n+1}\left|x_{i}\right|
$$

where the first inequality holds by the triangle inequality, and the second by the assumption that the property holds for $n$.

(ii) Let $x=a-b$ and $y=b-c$ in the triangle inequality, $|x+y| \leq|x|+|y|$.

## Chapter 2

Problem 1.7. The Cauchy-Schwarz-Bunyakovsky inequality. Let $f$ and $g$ be continuous functions $[a, b] \longrightarrow \mathbb{R}$. Adapt the proof of the Cauchy-Schwarz inequality to establish the following analogue for integrals:

$$
\left(\int_{a}^{b} f(x) g(x) d x\right)^{2} \leq\left(\int_{a}^{b}[f(x)]^{2} d x\right)\left(\int_{a}^{b}[g(x)]^{2} d x\right)
$$

Identical with the one in the text, with $\lambda=\int_{a}^{b} f(x) g(x) d x / \int_{a}^{b}[g(x)]^{2} d x$.

Problem 1.8. An alternative to the Euclidean norm in $\mathbb{R}^{\mathrm{n}}$ is given by the sup norm, defined for any $x \in \mathbb{R}^{\mathrm{n}}$ by the absolute value of its largest component:

$$
\|x\|_{s}=\max _{i}\left\{\left|x^{i}\right| ; i=1,2, \ldots, n\right\}
$$

Show that $\|\cdot\|_{s}: \mathbb{R}^{\mathrm{n}} \rightarrow \mathbb{R}$ is a norm.

The only thing that is not obvious is that $\|\cdot\|_{s}$ satisfies the triangle inequality. To show that it does, we use the triangle inequality for real numbers. Given three points $x, y$, and $z$ in $\mathbb{R}^{\mathrm{n}}$, we have, for each $i=1, \ldots, n$,

$$
\left|x^{i}-z^{i}\right|=\left|\left(x^{i}-y^{i}\right)+\left(y^{i}-z^{i}\right)\right| \leq\left|x^{i}-y^{i}\right|+\left|y^{i}-z^{i}\right| \leq\|x-y\|_{s}+\|y-z\|_{s}
$$

Therefore,

$$
\|x-z\|_{s} \leq\|x-y\|_{s}+\|y-z\|_{s}
$$

Problem 1.9. Show that $\|\cdot\|_{\text {, }}$ and the Euclidean norm $\|\cdot\|_{E}$ are Lipschitzequivalent norms by proving that for any $n$-vector $x$, $\|x\|_{s} \leq\|x\|_{E} \leq \sqrt{n}\|x\|_{s}$.

$$
\|x\|_{S}=\max _{i}\left|x^{i}\right|=\max _{\imath} \sqrt{\left(x^{i}\right)^{2}} \leq \sqrt{\sum_{k=1}^{n}\left(x^{k}\right)^{2}}=\|x\|_{E}
$$

$$
\|x\|_{E}=\sqrt{\sum_{k=1}^{n}\left(x^{k}\right)^{2}} \leq \sqrt{n\left(\max _{i}\left|x^{i}\right|\right)^{2}}=\sqrt{n} \max _{i}\left|x^{i}\right|=\sqrt{n}\|x\|_{E}
$$

Problem 1.11. Show that $d_{\pi}$ is a metric.

Let $z=(x, y), z^{\prime}=\left(x^{\prime}, y^{\prime}\right)$, and $z^{\prime \prime}=\left(x^{\prime \prime}, y^{\prime \prime}\right)$ be arbitrary points in $X \times Y$, and let $d_{\pi}$ be defined by

$$
\left[d_{\pi}\left(z, z^{\prime}\right)\right]^{2}=\left[d_{1}\left(x, x^{\prime}\right)\right]^{2}+\left[d_{2}\left(y, y^{\prime}\right)\right]^{2}
$$

We want to check that the triangle inequality holds for $d_{\pi}$, i.e., that

$$
\begin{equation*}
d_{\pi}\left(z, z^{\prime \prime}\right) \leq d_{\pi}\left(z, z^{\prime}\right)+d_{\pi}\left(z^{\prime}, z^{\prime \prime}\right) \tag{2}
\end{equation*}
$$

or, equivalently, that

$$
\left[d_{\pi}\left(z, z^{\prime \prime}\right)\right]^{2} \leq\left[d_{\pi}\left(z, z^{\prime}\right)+d_{\pi}\left(z^{\prime}, z^{\prime \prime}\right)\right]^{2}=\left[d_{\pi}\left(z, z^{\prime}\right)\right]^{2}+\left[d_{\pi}\left(z^{\prime}, z^{\prime \prime}\right)\right]^{2}+2 d_{\pi}\left(z, z^{\prime}\right) d_{\pi}\left(z^{\prime}, z^{\prime \prime}\right)
$$

Because the triangle inequality holds for both $d_{1}$ and $d_{2}$, we have

$$
\begin{align*}
{\left[d_{\pi}\left(z, z^{\prime \prime}\right)\right]^{2}=} & {\left[d_{1}\left(x, x^{\prime \prime}\right)\right]^{2}+\left[d_{2}\left(y, y^{\prime \prime}\right)\right]^{2} } \\
& \leq\left[d_{1}\left(x, x^{\prime}\right)+d_{1}\left(x^{\prime}, x^{\prime \prime}\right)\right]^{2}+\left[d_{2}\left(y, y^{\prime}\right)+d_{2}\left(y^{\prime}, y^{\prime \prime}\right)\right]^{2} \\
= & {\left[d_{1}\left(x, x^{\prime}\right)^{2}+d_{2}\left(y, y^{\prime}\right)^{2}\right]+\left[d_{1}\left(x^{\prime}, x^{\prime \prime}\right)^{2}+d_{2}\left(y^{\prime}, y^{\prime \prime}\right)^{2}\right] } \\
& +2\left[d_{1}\left(x, x^{\prime}\right) d_{1}\left(x^{\prime}, x^{\prime \prime}\right)+d_{2}\left(y, y^{\prime}\right) d_{2}\left(y^{\prime}, y^{\prime \prime}\right)\right] \\
= & d_{\pi}\left(z, z^{\prime}\right)^{2}+d_{\pi}\left(z^{\prime}, z^{\prime \prime}\right)^{2}+2\left[d_{1}\left(x, x^{\prime}\right) d_{1}\left(x^{\prime}, x^{\prime \prime}\right)+d_{2}\left(y, y^{\prime}\right) d_{2}\left(y^{\prime}, y^{\prime \prime}\right)\right] \tag{3}
\end{align*}
$$

Applying the Cauchy-Schwarz inequality to the expression within brackets in the last term of (3), we have

$$
\begin{align*}
& d_{1}\left(x, x^{\prime}\right) d_{1}\left(x^{\prime}, x^{\prime \prime}\right)+d_{2}\left(y, y^{\prime}\right) d_{2}\left(y^{\prime}, y^{\prime \prime}\right) \\
& \quad \leq \sqrt{d_{1}\left(x, x^{\prime}\right)^{2}+d_{2}\left(y, y^{\prime}\right)^{2}} \sqrt{d_{1}\left(x^{\prime}, x^{\prime \prime}\right)^{2}+d_{2}\left(y^{\prime}, y^{\prime \prime}\right)^{2}} \\
& \quad=d_{\pi}\left(z, z^{\prime}\right) d_{\pi}\left(z^{\prime}, z^{\prime \prime}\right) \tag{4}
\end{align*}
$$

Using (4) in (3), we obtain the desired result:

$$
\left[d_{\pi}\left(z, z^{\prime \prime}\right)\right]^{2} \leq d_{\pi}\left(z, z^{\prime}\right)^{2}+d_{\pi}\left(z^{\prime}, z^{\prime \prime}\right)^{2}+2 d_{\pi}\left(z, z^{\prime}\right) d_{\pi}\left(z^{\prime}, z^{\prime \prime}\right)=\left[d_{\pi}\left(z, z^{\prime}\right)+d_{\pi}\left(z^{\prime}, z^{\prime \prime}\right)\right]^{2}
$$

Problem 1.13. Prove that the union of any finite collection of bounded sets is bounded. (Prove it for two sets; the result then follows by induction.)

Let $S_{1}$ and $S_{2}$ be bounded sets in a metric space $(X, d)$, and let $x_{1}$ and $x_{2}$ in $X$ and $m_{1}$ and $m_{2}$ in $\mathbb{R}$ be such that $d\left(x_{i}, s_{i}\right) \leq m_{l}$ for all $s_{i} \in S_{i}$. (These numbers exist by the boundedness of $S_{1}$ and $S_{2}$.) Let $x=x_{1}$, and $m=\max \left\{m_{1}, m_{2}+d\left(x_{1}, x_{2}\right)\right\}$. Then for every $s \in S_{1} \cup S_{2}$, either

(i) $s \in S_{1}$ and $d(s, x)=d\left(s, x_{1}\right) \leq m_{1} \leq m$, or

(ii) $s \in S_{2}$ and $d(s, x)=d\left(s, x_{1}\right) \leq d\left(s, x_{2}\right)+d\left(x_{2}, x_{1}\right) \leq m_{2}+d\left(x_{1}, x_{2}\right) \leq m$.

Hence, $S_{1} \cup S_{2}$ is contained in $B_{m}(x)$.

Problem 1.14. Using the triangle inequality, show that for any $x, y$, and $z$ in a normed vector space, the following are true:
(i) $\|x-y\| \geq\|x\|-\|y\|$ and
(ii) $\|x-z\| \leq\|x-y\|+\|y-z\|$
(i) $\|x\|=\|(x-y)+y\| \leq\|x-y\|+\|y\| \Rightarrow\|x-y\| \geq\|x\|-\|y\|$

(ii) $\|x-z\|=\|(x-y)+(y-z)\| \leq\|x-y\|+\|y-z\|$

Problem 1.15. Show that the set of bounded real sequences is a metric space, with the norm defined by $d(x, y)=\sup _{n}\left|x_{n}-y_{n}\right|$.

Once more, we only need to check the triangle inequality:

$$
\begin{aligned}
d(x, z)= & \sup _{n}\left|x_{n}-z_{n}\right|=\sup _{n}\left|\left(x_{n}-y_{n}\right)+\left(y_{n}-z_{n}\right)\right| \leq \sup _{n}\left\{\left|x_{n}-y_{n}\right|+\left|y_{n}-z_{n}\right|\right\} \\
& \leq \sup _{n}\left|x_{n}-y_{n}\right|+\sup _{n}\left|y_{n}-z_{n}\right|=d(x, y)+d(y, z)
\end{aligned}
$$

The first inequality holds by the triangle inequality for real numbers, and the second holds because taking separate suprema for $\left|x_{n}-y_{n}\right|$ and $\left|y_{n}-z_{n}\right|$ may allow us to do better, but never worse, than taking a single supremum for the sum.

Problem 1.16. Let $\left(X_{2}, d_{2}\right)$ be a metric space, $X_{1}$ a set, and $f: X_{1} \longrightarrow X_{2}$ a one-toone function. Define a function $d_{1}()$ by

$$
d_{1}(x, y)=d_{2}[f(x), f(y)] \forall x, y \in X_{1}
$$

Show that $\left(X_{1}, d_{1}\right)$ is a metric space.

First, $d_{1}(x, y)=d_{2}[f(x), f(y)] \geq 0$, with equality if and only if $f(x)=f(y)$. Because $f$ is one-to-one, $f(x)=f(y)$ if and only if $x=y$.

$$
\begin{gathered}
d_{1}(x, y)=d_{2}[f(x), f(y)]=d_{2}[f(y), f(x)]=d_{1}(y, x) \\
d_{1}(x, z)=d_{2}[f(x), f(z)] \leq d_{2}[f(x), f(y)]+d_{2}[f(y), f(z)]=d_{1}(x, y)+d_{1}(y, z)
\end{gathered}
$$

Problem 1.17. Give an example of two sets $A$ and $B$ in a metric space such that $A \cap B=\varnothing$, but $d(A, B)=0$.

The intervals $(a, b)$ and $(b, c)$, with $a<b<c$, in the real line with the usual metric.

Problem 1.18. Prove that the set $C[a, b]$ of continuous real functions defined on the interval $[a, b]$ is a metric space when the distance between two functions $f$ and $g$ is defined by

$$
d(f, g)=\sup _{x \in[a, b]}|f(x)-g(x)|
$$

We verify that the triangle inequality holds:

$$
\begin{aligned}
d(f, h)= & \sup _{x \in[a, b]}|f(x)-h(x)|=\sup _{x \in[a, b]}|[f(x)-g(x)]+[g(x)-h(x)]| \\
& \leq \sup _{x \in[a, b]}\{|f(x)-g(x)|+|g(x)-h(x)|\} \leq \sup _{x \in[a, b]}|f(x)-g(x)|+\sup _{x \in[a, b]}|g(x)-h(x)| \\
= & d(f, g)+d(g, h)
\end{aligned}
$$

Problem 1.19. Show that the following inequality holds for any $x \in \mathbb{R}^{n}$ : $\|x\|_{E} \leq \sum_{i=1}^{n}\left|x_{i}\right|$.

Assume that $n=2$. Then we have

$$
\left(\left|x_{1}\right|+\left|x_{2}\right|\right)^{2}=\left|x_{1}\right|^{2}+\left|x_{2}\right|^{2}+2\left|x_{1}\right|\left|x_{2}\right| \geq\left|x_{1}\right|^{2}+\left|x_{2}\right|^{2}=x_{1}^{2}+x_{2}^{2}
$$

and taking the square root of this expression,

$$
\left|x_{1}\right|+\left|x_{2}\right| \geq \sqrt{x_{1}^{2}+x_{2}^{2}}=\|x\|_{E}
$$

as desired.

For $n>2$, we proceed by induction. Let $x \in \mathbb{R}^{n+1}$, partition $x=(y, z)$ with $y \in \mathbb{R}^{\mathrm{n}}$ and $z=x_{n+1} \in \mathbb{R}$, and assume that

$$
\begin{equation*}
\|y\|_{E}=\sqrt{\sum_{i=1}^{n} y_{i}^{2}} \leq \sum_{t=1}^{n}\left|y_{i}\right| \tag{1}
\end{equation*}
$$

Then we have

$$
\|x\|_{E}^{2}=\sum_{i=1}^{n+1} x_{i}^{2}=\sum_{i=1}^{n} y_{i}^{2}+z^{2}=\|y\|_{E}^{2}+|z|^{2} \leq\|y\|_{E}^{2}+|z|^{2}+2 \mid z\|\| y \|_{E}=\left(|z|+\|y\|_{E}\right)^{2}
$$

Taking the square root of this expression, using (1), and recalling that $z=x_{n+1}$, we have

$$
\|x\|_{E} \leq\|y\|_{E}+|z| \leq \sum_{i=1}^{n}\left|y_{i}\right|+|z|=\sum_{i=1}^{n}\left|x_{i}\right|+\left|x_{n+1}\right|=\sum_{i=1}^{n+1}\left|x_{i}\right|
$$

which is the desired result.

Problem 2.2. Using the formal definition of limit, show that
(i) $\lim _{n \rightarrow \infty} \frac{1}{n}=0$,
(ii) $\lim _{n \rightarrow \infty} \frac{1}{\sqrt{n}}=0$,
(iii) $\lim _{n \rightarrow \infty} \frac{n^{2}+2}{3 n^{2}+4}=\frac{1}{3}$

Imagine you are given some arbitrarily small $\varepsilon$. You must produce a positive integer $N$ such that. . .

(i) Fix some arbitrary $\varepsilon>0$. We want to find some $N(\varepsilon)$ such that for all $n>N(\varepsilon)$,

$$
\left|\frac{1}{n}-0\right|=\frac{1}{n}<\varepsilon
$$

Clearly, this inequality holds for $n>1 / \varepsilon$, so it is sufficient to choose $N(\varepsilon)=1 / \varepsilon$.

(ii) In the same manner,

$$
\left|\frac{1}{\sqrt{n}}-0\right|=\frac{1}{\sqrt{n}}<\varepsilon \Leftrightarrow n>\frac{1}{\varepsilon^{2}}, \text { so } N(\varepsilon)=\frac{1}{\varepsilon^{2}}
$$

(iii)

$$
\begin{aligned}
\left|\frac{n^{2}+2}{3 n^{2}+4}-\frac{1}{3}\right|= & \frac{n^{2}+2}{3 n^{2}+4}-\frac{1}{3}=\frac{3\left(n^{2}+2\right)-\left(3 n^{2}+4\right)}{3\left(3 n^{2}+4\right)}=\frac{2}{3\left(3 n^{2}+4\right)}<\varepsilon \\
& \Leftrightarrow 3 n^{2}+4>\frac{2}{3 \varepsilon} \Leftrightarrow n^{2}>\frac{2}{9 \varepsilon}-\frac{4}{3} \Leftrightarrow n>\sqrt{\frac{2}{9 \varepsilon}-\frac{4}{3}}
\end{aligned}
$$

(For $\varepsilon$ sufficiently small, the right-hand side is positive; otherwise the penultimate inequality is always true.)

Problem 2.4. Let $\left\{x_{n}\right\}$ be a convergent sequence with limit $x$. Show that every subsequence of $\left\{x_{n}\right\}$ converges to $x$.

Assume $\left\{x_{n}\right\} \rightarrow x$, and let $p(k)$ be a strictly increasing function from $\mathbb{N}$ to $\mathbb{N}$. We want to show that any subsequence $\left\{x_{p(k)}\right\}$ of $\left\{x_{n}\right\}$ converges to $x$. Because $\left\{x_{n}\right\} \rightarrow x$, we have

$$
\forall \varepsilon>0, \exists N(\varepsilon) \text { s.th. } n>N(\varepsilon) \Rightarrow d\left(x_{n}, x\right)<\varepsilon
$$

Because $p()$ is strictly increasing, $p(n)>n$ for all $n$ (by induction). Hence, given some $\varepsilon>0, n>N(\varepsilon)$ implies $p(n)>N(\varepsilon)$, and therefore

$$
d\left(x_{p(n)}, x\right)<\varepsilon
$$

The result is intuitively obvious: If all $x_{n}$ with $n>N(\varepsilon)$ are within a distance $\varepsilon$ of $x$, the same is true for all $x_{p(n)}$, provided that $p(n)>N(\varepsilon)$, for, since $p()$ is increasing, these terms are "farther along" in the sequence.

Problem 3.4. We want to show that every real sequence $\left\{x_{n}\right\}$ contained in $[a, b]$ has a subsequence that converges to a point $x$ in the interval. Because $\left\{x_{n}\right\}$ is bounded, the Bolzano-Weierstrass theorem ensures that it does indeed have a convergent subsequence. Assume that the limit of this subsequence lies outside $[a, b]$ (e.g., $x>b$ ). Show that this leads to a contradiction. (First, draw a picture.)

Intuitively, if $x>b$, then when $x_{n}$ gets sufficiently close to $x$ the sequence must leave the interval. Formally, assume $\left\{x_{n}\right\} \rightarrow x>b$. Then there exists some $N$ such that

$$
k>N \Rightarrow\left|x-x_{n}\right|=x-x_{n}<x-b
$$

But then $x_{n}>b$ for all $n>N$, which contradicts the assumption that $x_{n} \leq b$ for all $n$.

Problem 3.9. Prove Theorem 3.8: Let $\left\{x_{n}\right\}$ be a sequence of positive real numbers. Then $\left\{x_{n}\right\} \rightarrow \infty$ if and only if $\left\{1 / x_{n}\right\} \rightarrow 0$.

To show that $\left\{1 / x_{n}\right\} \rightarrow 0$, fix some arbitrary $\varepsilon>0$. Because $\left\{x_{n}\right\} \rightarrow \infty$, we know that there exists some $N$ such that $n>N \Rightarrow x_{n}>1 / \varepsilon$. Thus, $0<1 / x_{n}<\varepsilon$ for all $n>N$. For the converse, the same argument will work in reverse.

Problem 3.11. Convergence in product spaces. Let $\left(X, d_{1}\right)$ and $\left(Y, d_{2}\right)$ be metric spaces, and consider the product space $\left(Z=X \times Y, d_{\pi}\right)$, with the product metric $d_{\pi}$ defined by

$$
\begin{equation*}
d_{\pi}\left(z, z^{\prime}\right)=d_{\pi}\left[(x, y),\left(x^{\prime}, y^{\prime}\right)\right]=\sqrt{\left[d_{1}\left(x, x^{\prime}\right)\right]^{2}+\left[d_{2}\left(y, y^{\prime}\right)\right]^{2}} \tag{1}
\end{equation*}
$$

Show that the sequence $\left\{z_{n}\right\}=\left\{\left(x_{n}, y_{n}\right)\right\}$ converges to $z=(x, y)$ in $\left(X \times Y, d_{\pi}\right)$ if and only if $\left\{x_{n}\right\}$ converges to $x$ in $(X, d)$ and $\left\{y_{n}\right\}$ converges to $y$ in $(Y, d)$.

- $(\rightarrow)$ First, assume $\left\{z_{n}\right\} \rightarrow z$, and fix some $\varepsilon>0$. Because $\left\{z_{n}\right\} \rightarrow z$, there exists some $N$ such that $d_{n}\left(z_{n}, z\right)<\varepsilon$ for all $n>N$. That is,

$$
n>N \Rightarrow d_{\pi}\left(z_{n}, z\right)=\sqrt{\left[d_{1}\left(x_{n}, x\right)\right]^{2}+\left[d_{2}\left(y_{n}, y\right)\right]^{2}}<\varepsilon
$$

Now observe that

$$
d_{1}\left(x_{n}, x\right)=\sqrt{\left[d_{1}\left(x_{n}, x\right)\right]^{2}} \leq \sqrt{\left[d_{1}\left(x_{n}, x\right)\right]^{2}+\left[d_{2}\left(y_{n}, y\right)\right]^{2}}=d_{\pi}\left(z_{n}, z\right)
$$

and by a similar argument, $d_{2}\left(y_{n}, y\right) \leq d_{n}\left(z_{n}, z\right)$. Hence, for $n>N$ we have

$$
d_{1}\left(x_{n}, x\right)<\varepsilon \quad \text { and } \quad d_{2}\left(y_{n}, y\right)<\varepsilon
$$

That is, the component sequences $\left\{x_{n}\right\}$ and $\left\{y_{n}\right\}$ converge to $x$ and $y$, respectively, in the original spaces.

- $(\leftarrow)$ Now assume $\left\{x_{n}\right\} \rightarrow x$ in $\left(X, d_{1}\right)$ and $\left\{y_{n}\right\} \rightarrow y$ in $\left(Y, d_{2}\right)$, and fix some $\varepsilon>0$. By the convergence of these sequences, there exist positive integers $N_{1}$ and $N_{2}$ such that

$$
\begin{equation*}
n>N_{1} \Rightarrow d_{1}\left(x_{n}, x\right)<\varepsilon / \sqrt{2} \text { and } n>N_{2} \Rightarrow d_{2}\left(y_{n}, y\right)<\varepsilon / \sqrt{2} \tag{1}
\end{equation*}
$$

If we now define $N=\max \left\{N_{1}, N_{2}\right\}$, (1) holds for both sequences, provided that $n$ $>N$. We have, then,

$$
d_{\pi}\left(z_{n}, z\right)=\sqrt{\left[d_{1}\left(x_{n}, x\right)\right]^{2}+\left[d_{2}\left(y_{n}, y\right)\right]^{2}}<\sqrt{2 \varepsilon^{2} / 2}=\varepsilon \forall n>N
$$

Hence, $\left\{z_{n}\right\} \rightarrow z$ in $\left(X \times Y, d_{\pi}\right)$, as was to be shown.

Problem 3.12. Show that every bounded sequence in $\mathbb{E}^{m}$ contains at least one convergent subsequence.

For simplicity, we will work in $\mathbb{E}^{2}$. Let $\left\{x_{n}\right\}=\left\{\left(y_{n}, z_{n}\right)\right\}$ be a bounded sequence of 2 -vectors. Then the first component sequence $\left\{y_{n}\right\}$ is a bounded sequence of real numbers, and it follows by the Bolzano-Weierstrass theorem (Theorem 3.3) that this sequence has a convergent subsequence, say $\left\{y_{n_{k}}\right\}$ with limit $y$. Consider now the corresponding subsequence of the second component sequence, $\left\{z_{n_{k}}\right\}$. Because this is also a bounded sequence of real numbers, it too has a convergent subsequence, say $\left\{z_{n_{k}}\right\}$ with limit $z$. Going back to the first component sequence, the corresponding subsequence $\left\{y_{n_{k_{a}}}\right\}$ is still convergent to $y$ (because any subsequence of a convergent sequence is itself convergent). By Theorem 3.10, the subsequence $\left\{x_{n_{k_{k}}}\right\}=\left\{\left(y_{n_{k},}, z_{n_{k_{q}}}\right)\right\}$ of the original sequence converges to $(x, y)$. The argument can proceed in the same manner for vectors of any finite dimension.

Problem 3.14. Prove the Bernoulli inequality by induction: For each positive integer $n$ and any $x \geq-1,(1+x)^{n} \geq 1+n x$. Where in the proof do you need the assumption that $x \geq-1$ ?

For $n=1$, the inequality holds trivially. Now suppose $(1+x)^{n} \geq 1+n x$ and $1+x \geq 0$; then we can multiply both sides of the first inequality by $1+x$ without reversing its direction, and we get

$$
(1+x)^{n+1}=(1+x)^{n}(1+x) \geq(1+n x)(1+x)=1+(n+1) x+n x^{2} \geq 1+(n+1) x
$$

Problem 3.15. Prove Theorem 3.13: Let $a$ be a real number, and consider the sequence $\left\{a^{n}\right\}$. As $n \rightarrow \infty$, we have the following: (i) If $|a|<1$, then $\left\{a^{n}\right\} \rightarrow 0$. (ii) If $a>1$, then $\left\{a^{n}\right\} \rightarrow \infty$. (iii) If $a \leq-1$, then $\left\{a^{n}\right\}$ diverges.

Assume $|a|<1$. If $a=0$, then the result is immediate; otherwise we can write $|a|=1 /(1+x)$ for some $x>0$. By the Bernoulli inequality, $(1+x)^{n} \geq 1+n x>n x$, and hence

$$
\left|a^{n}-0\right|=\left|a^{n}\right|=\frac{1}{(1+x)^{n}}<\frac{1}{n x}
$$

Finally, fix some $\varepsilon>0$, and observe that

$$
\left|a^{n}\right|<\frac{1}{n x}<\varepsilon \text { provided that } n>\frac{1}{\varepsilon x}
$$

If $a>1$, we can write $a=1+x$ for some $x>0$. Then

$$
a^{n}=(1+x)^{n} \geq 1+n x>n x
$$

Given any $B>0$, we have $a^{n}>n x>B$ for all $n>B / x$.

Problem 3.19. Consider the sequence $\left\{a^{n} ; n=0,1, \ldots\right\}$, where $0<a<1$, and define $S_{N}$ as before. Verify that $(1-a) S_{N}=1-a^{N+1}$. Use this to show that $\Sigma_{n=0}^{\infty} a^{n}=1 /(1-a)$.

Notice that

$$
(1-a) S_{N}=\left(1+a+a^{2}+\ldots+a^{N}\right)-\left(a+a^{2}+\ldots+a^{N}+a^{N+1}\right)=1-a^{N+1}
$$

Hence,

$$
S_{N}=\frac{1-a^{N+1}}{1-a}
$$

Taking limits as $N \rightarrow \infty$,

$$
\sum_{n=0}^{\infty} a^{n}=\lim _{N \rightarrow \infty} \frac{1-a^{N+1}}{1-a}=\frac{1}{1-a}
$$

Problem 3.20. Given the function

$$
\begin{equation*}
f(x)=\frac{x^{2}+2}{2 x} \tag{1}
\end{equation*}
$$

define a sequence $\left\{x_{n}\right\}$ of rational numbers by

$$
\begin{equation*}
x_{1}=1 \quad \text { and } \quad x_{n+1}=f\left(x_{n}\right) \forall n>1 \tag{2}
\end{equation*}
$$

We have, then,

$$
\begin{equation*}
x_{2}=1.5, \quad x_{3}=1.417 \ldots \tag{3}
\end{equation*}
$$

(i) Prove that if $\left\{x_{n}\right\}$ converges, then its limit is $x=\sqrt{2}$. (Complete the following expression: $x=\lim _{n \rightarrow \infty} x_{n+1}=\lim _{n \rightarrow \infty} f\left(x_{n}\right)=\ldots$ )

We have

$$
x=\lim _{n \rightarrow \infty} x_{n+1}=\lim _{n \rightarrow \infty} f\left(x_{n}\right)=\lim _{n \rightarrow \infty} \frac{x_{n}^{2}+2}{2 x_{n}}=\frac{x^{2}+2}{2 x}
$$

from which

$$
2 x^{2}=x^{2}+2 \Rightarrow x^{2}=2 \Rightarrow x=\sqrt{2}
$$

(ii) Prove that for $n \geq 2$ we have $x_{n} \geq \sqrt{2}$. (Show that $f(x) \geq \sqrt{2}$ using $a^{2}+b^{2} \geq 2 a b$. Why?)

$$
(a-b)^{2}=a^{2}+b^{2}-2 a b \geq 0 \Rightarrow a^{2}+b^{2} \geq 2 a b
$$

Using this, we have

$$
f(x)=\frac{x^{2}+2}{2 x}=\frac{x^{2}+(\sqrt{2})^{2}}{2 x} \geq \frac{2 \sqrt{2} x}{2 x}=\sqrt{2}
$$

(iii) Calculate the value of $\left(x_{n+1}-x_{n}\right)$ as a function of $x_{n}$ and $x_{n-1}$. Use the resulting expression to prove that for $n \geq 2,\left\{x_{n}\right\}$ is decreasing (by induction).

By the analogue of Theorem 3.1 for decreasing sequences bounded below, $\left\{x_{n}\right\}$ converges to a real number. Hence, there is a real number $x$ such that $x^{2}=2$.

$$
\begin{aligned}
x_{n+1}-x_{n} & =f\left(x_{n}\right)-f\left(x_{n-1}\right)=\frac{x_{n}^{2}+2}{2 x_{n}}-\frac{x_{n-1}^{2}+2}{2 x_{n-1}}=\frac{x_{n-1}\left(x_{n}^{2}+2\right)-x_{n}\left(x_{n-1}^{2}+2\right)}{2 x_{n} x_{n-1}} \\
& =\frac{x_{n-1} x_{n}^{2}+2 x_{n-1}-x_{n} x_{n-1}^{2}-2 x_{n}}{2 x_{n} x_{n-1}}=\frac{\left(x_{n-1} x_{n}\right)\left(x_{n}-x_{n-1}\right)-2\left(x_{n}-x_{n-1}\right)}{2 x_{n} x_{n-1}} \\
& =\left(x_{n}-x_{n-1}\right)\left(\frac{1}{2}-\frac{1}{x_{n} x_{n-1}}\right)
\end{aligned}
$$

Because $x_{n} \geq \sqrt{2}$ for $n \geq 2$, we have

$$
\left(\frac{1}{2}-\frac{1}{x_{n} x_{n-1}}\right)>0 \text { for } n>2
$$

and therefore

$$
\operatorname{sign}\left(x_{n+1}-x_{n}\right)=\operatorname{sign}\left(x_{n}-x_{n-1}\right)
$$

Because $x_{3}-x_{2}=1.417-1.5<0$, the sequence is decreasing.

Problem 4.4. Prove Theorem 4.3: (i) $\varnothing$ and $X$ are closed in $X$. (ii) The intersection of an arbitrary collection of closed sets is closed. (iii) The union of a finite family of closed sets is closed.

(i) Because $X$ is open, its complement $\varnothing$ is closed, and vice versa.

(ii) and (iii) The proof is almost immediate using De Morgan's laws:

$$
\sim\left(\cup_{i} A_{i}\right)=\cap_{t}\left(\sim A_{i}\right) \quad \text { and } \quad \sim\left(\cap_{i} A_{t}\right)=\cup_{i}\left(\sim A_{i}\right)
$$

Consider the union of a finite number of closed sets, $\cup_{i=1}^{n} C_{i}$. By definition, the complement of each $C_{i}$ is open, and therefore so is the intersection

$$
\bigcap_{i=1}^{n}\left(\sim C_{i}\right)=\sim\left(\bigcup_{i=1}^{n} C_{i}\right)
$$

Hence its complement, $\cup_{i=1}^{n} C_{i}$, is closed. A similar argument can be used to prove (iii).

## Problem 4.7. Prove that $\partial A=\operatorname{cl} A \cap \operatorname{cl}(\sim A)$.

Pick an arbitrary boundary point of $A, x \in \partial A$. By definition, any open ball around $x$ interesects both $A$ and $\sim A$. Hence, a boundary point of $A$ is a closure point of both $A$ and $\sim A$, and it follows that $\operatorname{cl} A \cap \operatorname{cl}(\sim A) \supseteq \partial A$.

Let $y$ be an arbitrary point in $\operatorname{cl} A \cap \operatorname{cl}(\sim A)$. Because $y$ is a closure point of both $A$ and $\sim A$, we have, by definition, that for any $\varepsilon>0$,

$$
B_{\varepsilon}(x) \cap A \neq \varnothing \quad \text { and } \quad B_{\varepsilon}(x) \cap(\sim A) \neq \varnothing
$$

Thus, any point $y$ in $\operatorname{cl} A \cap \operatorname{cl}(\sim A)$ is a boundary point of $A$, that is, $\partial A \supseteq \operatorname{cl} A \cap$ $\mathrm{cl}(\sim A)$.

Problem 4.9. Prove parts (iii) and (iv) of Theorem 4.8:

(iii) $\mathrm{cl} A$ is the smallest closed set that contains $A$.

(iv) $A$ is closed if and only if $A=\mathrm{cl} A$.

First, we show that $\mathrm{cl} A$ is closed. It is obvious from the definitions that the interior, exterior, and boundary of a set are disjoint sets, and

$$
\text { int } A \cup \operatorname{ext} A \cup \partial A=X, \quad \text { cl } A=\operatorname{int} A \cup \partial A, \quad \text { ext } A=\operatorname{int}(\sim A)
$$

Hence,

$$
\operatorname{cl} A=\sim(\operatorname{ext} A)=\sim(\text { int } \sim A), \text { and so } \sim(\operatorname{cl} A)=\operatorname{int}(\sim A)
$$

and because int is open, so is $\sim(\mathrm{cl} A)$.

Next, we show that $\mathrm{cl} A$ is the smallest closed set that contains $A$. Let $B$ be a closed set containing $A$. Then $\sim B$ is open, and because $B \supseteq A$, we have $\sim A \supseteq \sim B$, that is, $\sim B$ is an open set contained in $\sim A$. Now, $\operatorname{int}(\sim A)$ is the largest open subset of $\sim A$; it follows that $\operatorname{int}(\sim A) \supseteq \sim B$. Moreover, we know that $\operatorname{int}(\sim A)=\sim(\operatorname{cl} A)$, from where $\sim(\mathrm{cl} A) \supseteq \sim B$; this, in turn, implies $B \supseteq \mathrm{cl} A$. Hence, any closed set $B$ that contains $A$ also contains $\mathrm{cl} A$.

Given this, it is obvious that if $A$ is closed, the smallest closed set that contains $A$ is $A$ itself. And if $A=\operatorname{cl} A$, then $A$ is closed, because $\operatorname{cl} A$ is closed.

Problem 4.14. Show that in a metric space the closed ball $B_{r}[x]$ is a closed set. (Take a limit point $a$ of $B_{r}[x]$ and consider an arbitrary sequence $\left\{x_{n}\right\}$ in $B_{r}[x]$ with limit $a$. Use the triangle inequality to show that $a$ must be in $B_{r}[x]$.)

Let $a$ be an arbitrary limit point of $B_{r}[x]$. We will show that $a \in B_{r}[x]$. By the definition of limit point, there exists a sequence $\left\{y_{n}\right\}$ in $B_{r}[x]$ that converges to $a$. Because $y_{n} \in B_{r}[x]$, we have $d\left(y_{n}, x\right) \leq r$ for all $n$. Using the triangle inequality,

$$
d(a, x) \leq d\left(a, y_{n}\right)+d\left(y_{n}, x\right) \leq d\left(a, y_{n}\right)+r
$$

Because $\left\{y_{n}\right\} \rightarrow a, d\left(a, y_{n}\right) \rightarrow 0$, and, taking limits, $d(a, x) \leq r$, i.e., $a \in B_{r}[x]$. Hence, $B_{r}[x]$ contains all its limit points and is therefore closed.

Problem 4.15. Let $B$ be a nonempty set of real numbers bounded above. Let $s=\sup B$. Show that $s \in \bar{B}$. Notice that this implies that $s \in B$ if $B$ is closed.

If $s \in B$, then $s \in \bar{B}$. Suppose $s \notin B$. Then for every $\varepsilon>0$ there exists some point $x \in B$ such that $s-\varepsilon<x<s$, for otherwise $s-\varepsilon$ would be an upper bound of $B$ smaller than $s$, and $s$ could not be the supremum. Thus, $s$ is a limit point of $B$, and therefore $s \in \bar{B}$.

Problem 4.16. Let $A$ be a set in a metric space $(X, d)$. Show that if $A$ is closed and $x \notin A$, then $d(x, A)>0$.

We will prove the contrapositive statement: Let $A$ be a closed set, and $x$ a point such that $d(x, A)=0$. Then $x \in A$. Because $d(x, A)=0$, for any given $\varepsilon>0$ there exists some point $a \in A$ such that $d(x, a)<\varepsilon$. That is, $B_{\varepsilon}(x) \cap A \neq \varnothing$ for every $\varepsilon>0$. Hence, either $x \in A$ (if $x=a$ ) or $x$ is a limit point of $A$ (otherwise). Because $A$ is closed (and therefore contains all its limit points), $x \in A$ in any event.

Problem 5.6. Use the definition of the limit of a function to show that if

$$
\lim _{x \rightarrow x^{0}} f(x)=a \text { and } \lim _{x \rightarrow x^{0}} g(x)=b
$$

then $\lim _{x \rightarrow x^{0}}[f(x)+g(x)]=a+b$. Prove the same result using the analogous theorem for limits of sequences.

(i) Direct proof: Fix some $\varepsilon>0$. Because $f$ has limit $a$ and $g$ has limit $b$ as $x \rightarrow x^{0}$, we can find positive numbers $\delta_{f}$ and $\delta_{g}$ such that

$$
\begin{gathered}
|f(x)-a|<\varepsilon / 2 \text { whenever }\left|x-x^{0}\right|<\delta_{f} \quad \text { and } \\
|g(x)-b|<\varepsilon / 2 \text { whenever }\left|x-x^{0}\right|<\delta_{g}
\end{gathered}
$$

Put $\delta=\min \left\{\delta_{f}, \delta_{g}\right\}$. Then for all $x$ such that $\left|x-x^{0}\right|<\delta$, we have

$$
\| f(x)+g(x)]-(a+b) \mid=\| f(x)-a]+[g(x)-b] \leq|f(x)-a|+|g(x)-b|<\varepsilon
$$

which shows that $\lim _{x \rightarrow x}[f(x)+g(x)]=a+b$.

(ii) Because $\lim _{x \rightarrow x^{0}} f(x)=a$ and $\lim _{x \rightarrow x^{0}} g(x)=b$, we must have $\left\{f\left(x_{n}\right)\right\} \rightarrow a$ and $\left\{g\left(x_{n}\right)\right\} \rightarrow b$ for any sequence $\left\{x_{n}\right\}$ with $\left\{x_{n}\right\} \rightarrow x^{0}$ and $x_{n} \neq x^{0}$ for all $n$ (Theorem 5.2, necessity). By Theorem 3.6, $\left\{f\left(x_{n}\right)+g\left(x_{n}\right)\right\} \rightarrow a+b$ for any such sequence, implying

$$
\lim _{x \rightarrow x^{0}}[f(x)+g(x)]=a+b
$$

by Theorem 5.2 (sufficiency).

Problem 6.2. Preservation of sign. Let $f$ be a continuous function from a metric space $(X, d)$ to $\mathbb{R}$, with the usual metric. Prove (directly) that the set $\{x \in X$; $f(x)>0\}$ is open. Intuitively, this result says that a continuous function that is strictly positive (or negative) at a point will maintain its sign within a sufficiently small ball around the original point.

Let $x$ be such that $f(x)>0$. By the continuity of $f$, for every $\varepsilon>0$ there exists some $\delta>0$ such that

$$
|f(y)-f(x)|<\varepsilon \forall y \in B_{\delta}(x)
$$

In particular, if we choose $\varepsilon=f(x) / 2$, continuity ensures that we can find some $\delta>0$ such that for $\mathrm{y} \in B_{\delta}(x)$

$$
f(x)-f(y)<f(x) / 2 \Rightarrow f(y)>f(x) / 2>0
$$

Hence, $f^{-1}(0, \infty)$ is open.

The robustness of the sign of a continuous real-valued function to small perturbations of its arguments is a property we will use quite often.

Problem 6.5. Let $f: \mathbb{R} \longrightarrow \mathbb{R}$ be the function defined by $f(x)=1$ for $x$ rational and by $f(x)=0$ for $x$ irrational. Show that $f$ is discontinuous everywhere. (Recall that any interval in the real line contains both rational and irrational numbers.)

Choose an arbitrary point $x^{0}$ in $\mathbb{R}$, and let $\varepsilon \leq 1$. Then, for any $\delta>0$, the interval $\left(x^{0}-\delta, x^{0}+\delta\right)$ contains both rational and irrational numbers and, in particular, some $x$ of the type opposite to $x^{0}$. For this $x$, we have $\left|f\left(x^{0}\right)-f(x)\right|=1 \geq \varepsilon$.

Problem 6.6. Given a function $f: \mathbb{R} \longrightarrow \mathbb{R}$, define $g: \mathbb{R} \longrightarrow \mathbb{R}^{2}$ by $g(x)=$ $(x, f(x))$. Use the sequential characterization of continuity to show that if $f$ is continuous at some point $x^{0}$, then so is $g$.

Consider an arbitrary sequence $\left\{x_{n}\right\}$ convergent to $x^{0}$. Because $f$ is continuous, $\left\{f\left(x_{n}\right)\right\} \rightarrow f\left(x^{0}\right)$. But then

$$
\left\{g\left(x_{n}\right)\right\}=\left\{\left(x_{n}, f\left(x_{n}\right)\right)\right\} \rightarrow\left(x, f\left(x^{0}\right)\right)=g\left(x^{0}\right)
$$

so $g$ is continuous at $x^{0}$.

Problem 6.7. Consider the finite-dimensional Euclidean space $E^{n}$. For any $k \in\{1$, $2, \ldots, n\}$, the $k$ th projection mapping, $p_{k}: \mathbb{R}^{\mathrm{n}} \rightarrow \mathbb{R}$, is defined for $x=\left(x_{1}, \ldots, x_{n}\right)$ by $p_{k}(x)=x_{k}$. Show that $p_{k}()$ is a continuous function.

Let $x=\left(x_{1}, \ldots, x_{n}\right)$ and $y=\left(y_{1}, \ldots, y_{n}\right)$ be points in $\mathbb{R}^{\mathrm{n}}$. For each $k=1, \ldots, n$ we have

$$
\begin{equation*}
\left|p_{k}(y)-p_{k}(x)\right|=\left|x_{k}-y_{k}\right|=\sqrt{\left(x_{k}-y_{k}\right)^{2}} \leq \sqrt{\sum_{i=1}^{n}\left(x_{i}-y_{t}\right)^{2}}=d_{E}(x, y) \tag{1}
\end{equation*}
$$

To establish continuity, we have to show that for any given $\varepsilon>0$, there exists a $\delta>0$ such that $d_{E}(x, y)<\delta$ implies $\left|p_{k}(y)-p_{k}(x)\right|<\varepsilon$. By (1), it is enough to take $\delta=\varepsilon$.

Problem 6.8. Show that in any normed vector space $(X,\|\cdot\|)$ the norm is a continuous function from $X$ to $\mathbb{R}$.

We know (Problem 1.14) that $\|x-y\| \geq\|x\|-\|y\|$. Reversing the roles of $x$ and $y$, we have $\|x-y\|=\|y-x\| \geq\|y\|-\|x\|$, and therefore $\|x\|-\|y\| \leq\|x-y\|$. Using the same argument as in the preceding problem, continuity follows directly.

Problem 6.9. Prove that if $f$ is a continuous function, then for any set $A, f(\mathrm{cl} A) \subseteq$ $\operatorname{cl}[f(A)]$.

We want to show that if $y \in f(\mathrm{cl} A)$, then it also belongs to $\mathrm{cl} f(A)$, that is, for any $\varepsilon>0, B_{\varepsilon}(y) \cap f(A) \neq \varnothing$. Take an arbitrary $y \in f(\mathrm{cl} A)$ and fix some $\varepsilon>0$. Because $y \in f(\mathrm{cl} A)$, we have $y=f(x)$ for some $x \in \operatorname{cl} A$, that is,

$$
\begin{equation*}
\forall \delta>0, B_{\delta}(x) \cap A \neq \varnothing \tag{1}
\end{equation*}
$$

By the continuity of $f$, we can choose some $\delta(\varepsilon)$ such that $f\left[B_{\hat{\alpha}(\varepsilon)}(x)\right] \subseteq B_{\varepsilon}(f(x))$. Because (1) continues to hold for this $\delta(\varepsilon), B_{\delta \varepsilon}(x) \cap A$ is not empty, and therefore neither is its image, $f\left[B_{\delta(\varepsilon)}(x) \cap A\right]$. Using Theorem 4.3 in Chapter 1,

$$
f\left[B_{\delta(\varepsilon)}(x) \cap A\right] \subseteq f\left[B_{\delta(\varepsilon)}(x)\right] \cap f(A) \subseteq B_{\varepsilon}(f(x)) \cap f(A)
$$

so $B_{\varepsilon}(f(x)) \cap f(A) \neq \varnothing$, which is what we wanted to show.

Problem 6.11. Let $f$ and $g$ be functions $\mathbb{R} \longrightarrow \mathbb{R}$, and assume that $f$ is continuous at $y^{0}$ and that $g(x) \rightarrow y^{0}$ as $x \rightarrow \infty$. Show that $\left.\lim _{x \rightarrow \infty}\right) f[g(x)]=f\left(y^{0}\right)$.

Fix an arbitrary $\varepsilon>0$. By the continuity of $f$ at $y^{0}$, there exists some $\delta_{\varepsilon}>0$ such that

$$
\begin{equation*}
\left|f(y)-f\left(y^{0}\right)\right|<\varepsilon \forall y \text { s.th. }\left|y-y^{0}\right|<\delta_{\varepsilon} \tag{1}
\end{equation*}
$$

Because $g(x) \rightarrow y^{0}$ as $x \rightarrow \infty$, we can find some number $B\left(\delta_{\varepsilon}\right)$ such that

$$
\left|g(x)-y^{0}\right|<\delta_{\varepsilon} \forall x>B\left(\delta_{\varepsilon}\right)
$$

For any $x>B\left(\delta_{\varepsilon}\right)$ we have, then, $\left|g(x)-y^{0}\right|<\delta_{\varepsilon}$, and therefore $\left|f[g(x)]-f\left(y^{0}\right)\right|<\varepsilon$, by (1). That is, $f[g(x)] \rightarrow f\left(y^{0}\right)$ as $x \rightarrow \infty$.

Problem 6.15. Using Theorem 6.13, prove Theorem 6.14: Let $(X, d)$ and $(Y, \rho)$ be metric spaces, and $f$ a function $X \longrightarrow Y$. Then $f$ is continuous if and only if for every set $A$ open in $(Y, \rho)$ the set $f^{-1}(A)$ is open in $(X, d)$.

Let $A$ be an arbitrary open set in $Y$, and $f$ a continuous function. Then $A^{c}$ is closed, and by the continuity of $f$, so is $f^{-1}\left(A^{c}\right)$. But then the complement of this set, $\sim f^{-1}\left(A^{c}\right)=f^{-1}(A)$, is open (see Problem 4.5 in Chapter 1). Conversely, let $f$ be a function such that $f^{-1}(A)$ is open for every set $A$ open in $Y$, and consider an arbitrary closed set $B$. The complement of $B, B^{c}$, is open, and, by assumption, this implies that $f^{-1}\left(B^{c}\right)$ is open. But then $\sim f^{-1}\left(B^{c}\right)=f^{-1}(B)$ is closed. Because $B$ is arbitrary, $f$ is continuous, by Theorem 6.13.

Problem 6.16. Let $(X, d)$ be a metric space, and $(Y,\|\cdot\|)$ a normed vector space with zero vector 0 . Given a continuous function $f: X \longrightarrow Y$, adapt the proof of the characterization of continuity in terms of the inverse images of closed sets to show that the set $f^{-1}(\underline{0})$ is closed.

We shall show that if $f$ is continuous, then $f^{-1}(\underline{0})$ is closed in $(X, d)$, by verifying that it contains all its limit points. Let $x$ be an arbitrary limit point of $f^{-1}(\underline{0})$; then there exists a sequence $\left\{x_{n}\right\}$ in $f^{-1}(\underline{0})$ that converges to $x$. Because $f$ is continuous, the sequence $\left\{f\left(x_{n}\right)\right\}$ converges to $f(x)$. By construction, $f\left(x_{n}\right)=\underline{0}$ for all $n$, and therefore $\left\{f\left(x_{n}\right)\right\} \rightarrow \underline{0}$. Thus, $f(x)=\underline{0}$, i.e., $x \in f^{-1}(\underline{0})$.

Problem 6.19. Show that a Lipschitz function is uniformly continuous (and therefore continuous).

Let $X$ and $Y$ be normed spaces, and $f: X \longrightarrow Y$ a function with Lipschitz constant $K$ on some subset $E$ of $X$. We want to show that $f$ is uniformly continuous on $E$, that is, that for all $x, y \in E$ and for any $\varepsilon>0$ there exists some number $\delta(\varepsilon)>0$, independent of $x$, such that

$$
\|y-x\|<\delta(\varepsilon) \Rightarrow\|f(y)-f(x)\|<\varepsilon
$$

Fix some arbitrary $\varepsilon>0$ and let

$$
\delta(\varepsilon)=\varepsilon / K
$$

Then for any $y$ such that

$$
\begin{equation*}
\|y-x\|<\delta(\varepsilon)=\varepsilon / K \tag{1}
\end{equation*}
$$

we have

$$
\|f(y)-f(x)\| \leq K\|y-x\|<\varepsilon
$$

where the first inequality holds by the definition of Lipschitz function, and the second follows from (1). Because $\delta(\varepsilon)$ is independent of $x$, we have shown that $f$ is uniformly continuous on $E$.

Problem 6.25. We will now give an alternative proof for the intermediate-value theorem. Let $f$ be a real function of one variable defined and continuous on an interval $[a, b]$. Assume that $f(a)<0<f(b)$. To show that there exists some point $c$ in $(a, b)$ such that $f(c)=0$, we construct two sequences $\left\{l_{n}\right\}$ and $\left\{u_{n}\right\}$ in the following way:

1. Put $l_{1}=a$ and $u_{1}=b$.
2. For each $n$, let $m_{n}=\left(l_{n}+u_{n}\right) / 2$ and evaluate $f$ at $m_{n}$. Then

(a) if $f\left(m_{n}\right)>0$, put $l_{n+1}=l_{n}$ and $u_{n+1}=m_{n}$,

(b) if $f\left(m_{n}\right)<0$, put $l_{n+1}=m_{n}$ and $u_{n+1}=u_{n}$, and

(c) if $f\left(m_{n}\right)=0$, stop.

(i) Prove that $\left\{l_{n}\right\}$ and $\left\{u_{n}\right\}$ converge, and call their limits $c^{\prime}$ and $c^{\prime \prime}:\left\{l_{n}\right\}$ is an increasing sequence bounded above by $b$, and $\left\{u_{n}\right\}$ a decreasing sequence bounded below by $a$. Hence, both converge: $\left\{l_{n}\right\} \rightarrow c^{\prime}$ and $\left\{u_{n}\right\} \rightarrow c^{\prime \prime}$, and therefore $\left\{u_{n}-l_{n}\right\} \rightarrow c^{\prime \prime}-c^{\prime}$.

(ii) We will now show that $\left\{u_{n}-l_{n}\right\} \rightarrow 0$, implying $c^{\prime}=c^{\prime \prime} \equiv c$. If $f\left(m_{n}\right)>0$, then $u_{n+1}-l_{n+1}=m_{n}-l_{n}$, and if $f\left(m_{n}\right)<0$, then $u_{n+1}-l_{n+1}=u_{n}-m_{n}$. In either case, $u_{n+1}-l_{n+1}=\left(u_{n}-l_{n}\right) / 2$, and iterating, we get

$$
0 \leq u_{n+1}-l_{n+1}=\frac{u_{n}-l_{n}}{2}=\frac{u_{n-1}-l_{n-1}}{4}=\ldots=\frac{b-a}{2^{n}}
$$

Taking limits, $(b-a) / 2^{n} \rightarrow 0$ as $n \rightarrow \infty$, and therefore $\left\{u_{n}-l_{n}\right\} \rightarrow 0$.

(iii) It remains to show that $f(c)=0$. By continuity, both $\left\{f\left(l_{n}\right)\right\}$ and $\left\{f\left(u_{n}\right)\right\}$ converge to $f(c)$. But $f\left(l_{n}\right) \leq 0$ for all $n$, so $\lim _{n \rightarrow \infty} f\left(l_{n}\right)=f(c) \geq 0$, and $f\left(u_{n}\right) \leq 0$ for all $n$, so $\lim _{n \rightarrow \infty} f\left(u_{n}\right)=f(c) \geq 0$. It follows that $f(c)=0$.

Problem 7.6. Prove Theorem 7.5: Any Cauchy sequence is bounded.

Let $\left\{x_{n}\right\}$ be a Cauchy sequence. Then

$$
\forall \varepsilon>0, \exists N(\varepsilon) \text { s.th. } m, n>N(\varepsilon) \Rightarrow d\left(x_{m}, x_{n}\right)<\varepsilon
$$

Because this holds for all $\varepsilon$, it will hold for $\varepsilon=1$; hence, for all $m, n>N(1)$, we have $d\left(x_{m}, x_{n}\right)<1$, and all the terms of the sequence of order higher than $N(1)$ fit inside an open ball of radius 1 . The number of terms of the sequence that lie outside the ball is finite, and therefore these points must also lie within a ball of finite radius. Hence the sequence is bounded.

Problem 7.7. Prove that the sequence $\left\{x_{n}\right\}$, defined in Problem 3.20, is Cauchy. We have

$$
\left|x_{n+1}-x_{n}\right|=\left|x_{n}-x_{n-1}\right|\left(\frac{1}{2}-\frac{1}{x_{n} x_{n-1}}\right)
$$

Because the sequence is decreasing and $x_{2}=3 / 2$, for $n \geq 3$ we have

$$
0<\left(\frac{1}{2}-\frac{1}{x_{n} x_{n-1}}\right)<\left(\frac{1}{2}-\frac{4}{9}\right)=\frac{1}{18}
$$

and therefore

$$
\left|x_{n+1}-x_{n}\right|<(1 / 18)\left|x_{n}-x_{n-1}\right|
$$

From now on, we can use the same argument as in the proof of the contraction mapping theorem.

Problem 7.17. Let $(X, d)$ be a complete metric space, and $T: X \longrightarrow X$ a function whose $n$th iteration $T^{n}$ is a contraction. Show that $T$ has a unique fixed point.

If $T^{n}$ is a contraction, there exists some $\beta \in(0,1)$ such that

$$
\begin{equation*}
d\left(T^{n} x, T^{n} y\right) \leq \beta d(x, y) \forall x, y \in X \tag{1}
\end{equation*}
$$

and by the contraction mapping theorem, $T^{n}$ has a unique fixed point that we will call $x^{*}$. Now, $T^{n} x^{*}=x^{*}$, and, using (1),

$$
d(T x *, x *)=d\left[T\left(T^{n} x *\right), T^{n} x *\right]=d\left[T^{n}(T x *), T^{n} x *\right] \leq \beta d(T x *, x *)
$$

Because $\beta<1$, we must have $d\left(T x^{*}, x^{*}\right)=0$, and therefore $T x^{*}=x^{*}$, that is, $x^{*}$ is a fixed point of $T$. Moreover, any fixed point of $T$ is a fixed point of $T^{n}$. It follows that $T$ has a unique fixed point, for if it had more than one, so would $T^{n}$, and we know that is not the case.

Problem 8.17. Show that a compact set in a metric space is complete.

Let $A$ be a compact set, and let $\left\{x_{n}\right\}$ be an arbitrary Cauchy sequence in $A$. To establish completeness, we need to show that $\left\{x_{n}\right\}$ converges to some point in $A$. Now, by the sequential compactness of $A,\left\{x_{n}\right\}$ has a convergent subsequence with limit $x$ in $A$. That $x$ must be the limit of the entire sequence follows by Theorem 7.8.

Problem 8.18. Let $A$ be a compact set, and let $\left\{A_{n}\right\}$ be a "decreasing sequence" of nonempty closed subsets of $A$ such that $A_{n} \subseteq A_{n+1}$. Show that $\cup_{n=1}^{\infty} A_{n}$ is not empty.

Let $\left\{x_{n}\right\}$ be a sequence constructed by taking a point in each $A_{n}$, i.e., $x_{n} \in A_{n} \subseteq$ $A$. Because $A$ is compact, $\left\{x_{n}\right\}$ has a convergent subsequence $\left\{x_{n_{k}}\right\}$ with limit $x$ in $A$. Consider the subsequences $\left\{x_{n}^{q}\right\}$ of $\left\{x_{n}\right\}$, with $\left\{x_{n}^{q}\right\}=\left\{x_{n} ; n \geq q\right\}$. Each such subsequence is contained in $A_{q}$ and has a convergent subsequence (the appropriate portion of $\left\{x_{n_{k}}\right\}$ ) with limit $x$. Hence, $x$ is a limit point of $A_{q}$ for each $q$. But because $A_{q}$ is closed by assumption, we have $x \in A_{q}$ for all $q$, i.e., $x \in \cap_{n=1}^{\infty} A_{n}$.

Problem 8.23. Give an alternative proof for Theorem 8.21 (the continuous image of a compact set is compact) using directly the definition of compactness.

Let $\left\{U_{i} ; i \in I\right\}$ be an open cover of $f(C)$. Because $f$ is continuous, each of the sets $f^{-1}\left(U_{i}\right)$ is open. The collection $\left\{f^{-1}\left(U_{i}\right) ; i \in I\right\}$ is an open cover of $C$. (Why?) Because $C$ is compact, there is a finite subcollection, say $\left\{f^{-1}\left(U_{k}\right) ; k=1, \ldots, n\right\}$, that still covers $C$, that is,

$$
C \subseteq f^{-1}\left(U_{1}\right) \cup \ldots \cup f^{-1}\left(U_{n}\right)
$$

Hence,

$$
f(C) \subseteq f\left[f^{-1}\left(U_{1}\right) \cup \ldots \cup f^{-1}\left(U_{n}\right)\right]=f\left[f^{-1}\left(U_{1}\right)\right] \cup \ldots \cup f\left[f^{-1}\left(U_{n}\right)\right] \subseteq U_{1} \cup \ldots \cup U_{n}
$$

and we have found a finite subcover for $f(C)$, which is therefore compact. (We are using Theorem 4.3 and Problem 4.5 in Chapter 1.)

Problem 8.26. Compactness of the product space. Let $\left(X, d_{1}\right)$ and $\left(Y, d_{2}\right)$ be metric spaces, and consider the product space $\left(Z=X \times Y, d_{\pi}\right)$, with the product metric $d_{\pi}$ defined by

$$
\begin{equation*}
d_{\pi}\left(z, z^{\prime}\right)=d_{\pi}\left[(x, y),\left(x^{\prime}, y^{\prime}\right)\right]=\sqrt{\left[d_{1}\left(x, x^{\prime}\right)\right]^{2}+\left[d_{2}\left(y, y^{\prime}\right)\right]^{2}} \tag{1}
\end{equation*}
$$

Show that the product space $\left(Z=X \times Y, d_{\pi}\right)$ is compact if and only if both $\left(X, d_{1}\right)$ and $\left(Y, d_{2}\right)$ are compact.

We will make use of the sequential characterization of compactness (see Definition 8.4 and Theorems 8.5 and 8.11) and of Problem 3.11 (on convergence in product spaces).

First, assume that $\left(Z=X \times Y, d_{\pi}\right)$ is (sequentially) compact, and let $\left\{x_{n}\right\}$ and $\left\{y_{n}\right\}$ be arbitrary sequences in $X$ and $Y$, respectively. We want to show that each of these sequences has a subsequence that converges to a point in the relevant set. By the sequential compactness of the product space, the sequence $\left\{\left(x_{n}, y_{n}\right)\right\}$ has a convergent subsequence $\left\{\left(x_{n_{k}}, y_{n_{k}}\right)\right\}$ with limit $(x, y) \in X \times Y$. By Problem 3.11 we have that $\left\{x_{n_{k}}\right\} \rightarrow x \in X$ and $\left\{y_{n_{k}}\right\} \rightarrow y \in Y$, so both $\left(X, d_{1}\right)$ and $\left(Y, d_{2}\right)$ are sequentially compact and therefore compact.

Conversely, assume that $\left(X, d_{1}\right)$ and $\left(Y, d_{2}\right)$ are sequentially compact, and let $\left\{\left(x_{n}, y_{n}\right)\right\}$ be an arbitrary sequence in $X \times Y$. By the sequential compactness of $\left(X, d_{1}\right)$, the first "component sequence" $\left\{x_{n}\right\}$ has a convergent subsequence $\left\{x_{n_{k}}\right\}$ with limit $x \in X$. Consider now the corresponding subsequence of the second component sequence, $\left\{y_{n_{k}}\right\}$. By the sequential compactness of $\left(Y, d_{2}\right)$, this sequence has a convergent subsequence $\left\{y_{n_{k_{q}}}\right\}$ with limit $y \in Y$. Moreover, the corresponding first component subsequence $\left\{x_{n_{k}}\right\}$ still converges to $x \in X$. By Problem 3.11, the subsequence $\left\{\left(x_{n_{k_{q}}}, y_{n_{k_{q}}}\right)\right\}$ converges to $(x, y) \in X \times Y$, which establishes the (sequential) compactness of the product space.

Problem 10.4. Prove Theorem 10.3: Let $X$ be a nonempty set, and $d_{1}$ and $d_{2}$ two metrics defined on it. Then a necessary and sufficient condition for $d_{1}$ and $d_{2}$ to be topologically equivalent is the following: $A$ subset $A$ of $X$ is $d_{1}$-open if and only if it is $d_{2}$-open.

- $(\leftarrow)$ Assume that the metrics $d_{1}$ and $d_{2}$ generate the same open sets in $X$, and let $(Y, \rho)$ be a metric space. Recall that by Theorem 6.14 a function $f: X \longrightarrow Y$ is continuous if and only if the inverse image of any open set is open. Because the open sets are the same in both cases, any $\left(d_{1}, \rho\right)$-continuous function is $\left(d_{2}, \rho\right)$-continuous, and vice versa. By Theorem 10.2, this implies that $d_{1}$ and $d_{2}$ are topologically equivalent.
- $(\rightarrow)$ Assume that $d_{1}$ and $d_{2}$ are topologically equivalent metrics. Then, by Theorem 10.2, they preserve continuity, and it follows that the identity mapping $I: X \rightarrow X$, with $I(x)=x$, being $\left(d_{1}, d_{1}\right)$-continuous, is also $\left(d_{1}, d_{2}\right)$-continuous. Now let $A$ be a $d_{2}$-open set; by Theorem 6.14, the set $I^{-1}(A)$ is $d_{1}$-open. But then $I^{-1}(A)=A$ is also $d_{1}$-open. A similar argument will work in the opposite direction.

Problem 10.6. Prove Theorem 10.5: Lipschitz equivalence implies topological equivalence.

Let $\left\{x_{n}\right\}$ be a $d_{1}$-convergent sequence with limit $x$. Given that $d_{1}$ and $d_{2}$ are Lipschitz-equivalent, we want to show that $\left\{x_{n}\right\}$ converges to $\mathrm{x}$ in $\left(X, d_{2}\right)$. Fix some $\varepsilon>0$. Then, by the $d_{1}$-convergence of $\left\{x_{n}\right\}$, there exists some integer $N$ such that

$$
\begin{equation*}
d_{1}\left(x_{n}, x\right) \leq \varepsilon / M \forall n>N \tag{2}
\end{equation*}
$$

Combining the Lipschitz condition (equation (1) in the theorem) and (2), we have

$$
d_{2}\left(x_{n}, x\right) \leq M d_{1}\left(x_{n}, x\right) \leq \varepsilon \forall n>N
$$

which shows that $\left\{x_{n}\right\}$ converges to $x$ in $\left(X, d_{2}\right)$.

Problem 11.5. Show that a closed correspondence is closed-valued.

Consider a sequence of points $\left\{y_{n}\right\}$ in $\Psi(x)$ converging to some point $y$ in $Y$. We want to show that $y$ lies in $\Psi(x)$ (in principle, it could be outside this set). Take a "constant" sequence $\left\{x_{n}\right\}$, with $x_{n}=x$ for all $n$, and notice that $\left\{y_{n}\right\}$ is a companion sequence of $\left\{x_{n}\right\}$. Clearly, $\left\{x_{n}\right\}$ converges to $x$, and because the correspondence is closed and $\left\{y_{n}\right\} \rightarrow y$, we have also that $y \in \Psi(x)$, which is what we wanted to show.

Problem 11.8. Prove Theorem 11.7: Let the correspondence $\Psi: X \rightarrow \rightarrow$ be compact-valued and uhc, and let $\Gamma: X \rightarrow \rightarrow Y$ be closed, and assume that $\Psi(x) \cap \Gamma(x) \neq \varnothing$. Then the intersection correspondence $\Psi \cap \Gamma$, defined by $(\Psi \cap \Gamma)(x)=\Psi(x) \cap \Gamma(x)$, is compact-valued and uhc.

The set $\Psi(x) \cap \Gamma(x)$ is compact because it is a closed subset of a compact set (Theorem 8.12). Let $\left\{x_{n}\right\}$ be a sequence converging to $x$, and $\left\{y_{n}\right\}$ an arbitrary companion sequence with $y_{n} \in \Psi\left(x_{n}\right) \cap \Gamma\left(x_{n}\right)$ for each $n$. To establish the desired result we have to show that $\left\{y_{n}\right\}$ has a convergent subsequence with limit in $\Psi(x) \cap \Gamma(x)$.

Because $\Psi$ is by assumption compact-valued and uhc, $\left\{y_{n}\right\}$ does have a convergent subsequence $\left\{y_{n_{k}}\right\}$ with limit $y$ in $\Psi(x)$. Consider now the sequence $\left\{x_{n_{k}}, y_{n_{k}}\right\}$. By construction, this sequence is contained in $G_{\Gamma}$, the graph of $\Gamma$, and converges to $(x, y)$. Because $G_{\Gamma}$ is closed by assumption, we know further that $(x, y) \in G_{\Gamma}$, i.e., that $y \in \Gamma(x)$. Hence, $y \in \Psi(x) \cap \Gamma(x)$, as was to be shown.

Problem 11.10. Prove Theorem 11.9: Let the correspondence $\Psi: X \rightarrow \rightarrow Y$ be compact-valued and uhc. Then the image under $\Psi$ of a compact set $C$, $\Psi(C)=\cup_{x \in C} \Psi(x)$, is compact.

Using the sequential characterization of compactness (Theorem 8.11), it is enough to show that every sequence $\left\{y_{n}\right\}$ contained in $\Psi(C)$ has a convergent subsequence with limit in $\Psi(C)$. Let $\left\{y_{n}\right\}$ be an arbitrary sequence in $\Psi(C)$. Then for each $y_{n}$ there exists some $x_{n} \in C$ such that $y_{n} \in \Psi\left(x_{n}\right)$. Because $C$ is compact, $\left\{x_{n}\right\}$ contains a convergent subsequence $\left\{x_{n_{k}}\right\}$ with limit $x$ in $C$. Because $\Psi$ is uhc and compact-valued, by Theorem 11.2 (sequential characterization of uhc) the sequence $\left\{y_{n_{k}}\right\}$ has a convergent subsequence with limit in $\Psi(x)$ and hence in $\Psi(C)$.

Problem 11.12. Prove Theorem 11.11: Let the correspondences $\Psi_{i}: X \rightarrow \rightarrow$, with $i=1, \ldots, n$, be compact-valued and uhc at $x$. Then the sum correspondence $\Psi$, defined by $\Psi(x)=\sum_{t=1}^{n} \Psi_{i}(x)$ for each $x$, is compact-valued and uhc at $x$.

Let $\left\{x_{n}\right\}$ be an arbitrary sequence converging to $x$, and consider a companion sequence $\left\{y_{n}\right\}$, with $y_{n} \in \sum_{i=1}^{n} \Psi_{i}\left(x_{n}\right)$ for each $n$. Notice that each $y_{n}$ is of the form

$$
y_{n}=\sum_{i=1}^{n} y_{n}^{i} \text {, with } y_{n}^{i} \in \Psi_{i}\left(x_{n}\right)
$$

By Theorem 11.2, each sequence $\left\{y_{n}^{i}\right\}$ has a convergent subsequence $\left\{y_{n_{k}}^{i}\right\}$, with limit $y^{i}$ in $\Psi_{i}(x)$. By Theorem 3.10 (equivalence of convergence and cootdinatewise convergence, it follows that $\left\{y_{n}\right\}$ has a convergent subsequence $\left\{y_{n_{k}}\right\}$, with limit $\Sigma_{i=1}^{n} y^{i} \in \sum_{i=1}^{n} \Psi_{i}(x)$.

Problem 11.15. Prove Theorem 11.14: Let $\Gamma^{i}: X \rightarrow \rightarrow Y$, with $i=1, \ldots, n$, be compact-valued and uhc correspondences. Then the product correspondence $\Gamma()$, with $\Gamma(x)=\Gamma^{1}(x) \times \ldots \times \Gamma^{n}(x)$ for each $x$ in $X$, is compact-valued and uhc.

Fix an arbitrary $x$ in $X$. Then the set $\Gamma(x)$ is compact because it is the Cartesian product of compact sets (Problem 8.26). Hence, $\Gamma()$ is compact-valued, and in order to establish its upper hemicontinuity it is sufficient to show that given any
sequence $\left\{x_{n}\right\}$ converging to $x$, every "companion sequence" $\left\{y_{n}\right\}$, with $y_{n} \in \Gamma\left(x_{n}\right)$ for all $n$, has a convergent subsequence $\left\{y_{n_{k}}\right\}$ with limit in $\Gamma(x)$.

To simplify a bit, suppose $n=2$. Then $y_{n} \in \Gamma\left(x_{n}\right)$ will be of the form $\left(y_{n}^{1}, y_{n}^{2}\right)$, with $y_{n}^{1} \in \Gamma^{1}\left(x_{n}\right)$ and $y_{n}^{2} \in \Gamma^{2}\left(x_{n}\right)$. By the upper hemicontinuity of $\Gamma^{1}()$, the sequence $\left\{y_{n}^{1}\right\}$ has a convergent subsequence $\left\{y_{n_{k}}^{1}\right\}$, with limit $y^{1} \in \Gamma^{1}(x)$. Consider now the corresponding second component sequence, $\left\{y_{n_{k}}^{2}\right\}$. By the upper hemicontinuity of $\Gamma^{2}()$, this sequence has a subsequence $\left\{y_{k_{k}}^{2}\right\}$ converging to a point $y^{2}$ in $\Gamma^{2}(x)$. Hence, the subsequence $\left\{y_{n_{k_{q}}}\right\}=\left\{\left(y_{n_{k_{q}}}^{1}, y_{n_{k_{q}}}^{2}\right)\right\}$ converges to a point $y=\left(y^{1}, y^{2}\right) \in \Gamma^{1}(x) \times \Gamma^{2}(x)=\Gamma(x)$. This proves the result.

## Chapter 3

Problem 1.6. Prove Theorem 1.5: Let $V$ be a vector space of dimension $n$. Then any linearly independent family of $n$ vectors in $V, \mathrm{v}=\left\{v_{1}, \ldots, v_{n}\right\}$, is a basis for $V$.

We want to show that $\mathbb{v}=\left\{v_{1}, \ldots, v_{n}\right\}$ spans $V$, that is, that each $x \in V$ can be written as a linear combination of the vectors in v. By Theorem 1.4, $\left\{v_{1}, \ldots, v_{n}, x\right\}$ is a linearly dependent family for any $x$; therefore, there exist scalars $\alpha_{1}, \ldots, \alpha_{n+1}$ not all zero such that

$$
\sum_{i=1}^{n} \alpha_{i} v_{i}+\alpha_{n+1} x=\underline{0}
$$

where, moreover, $\alpha_{n+1} \neq 0$ (otherwise, the $v_{i}$ 's could not be linearly independent). Hence, we can solve for $x$ and write it as a linear combination of the elements of $\mathbb{v}$ :

$$
x=\sum_{i=1}^{n} \frac{-\alpha_{i}}{\alpha_{n+1}} v_{i}
$$

Problem 1.8. Prove the following result: Let $X$ be a finite-dimensional normed linear space with basis $\left\{v_{1}, \ldots, v_{m}\right\}$ over the real field. A sequence $\left\{x_{n}\right\}$ in $X$, with $x_{n}=\sum_{i=1}^{m} \alpha_{i}^{n} v_{t}\left(\alpha_{i}^{n}\right.$ real), converges to $x=\sum_{i=1}^{m} \alpha_{t} \nu_{t}$ if and only if each coordinate sequence $\left\{\alpha_{i}^{n}\right\}$ converges to $\alpha_{i}$ for each $i=1, \ldots, m$.

It is sufficient to consider the case in which $x=\underline{0}$.

(i) Show that if $\left\{\alpha_{i}^{n}\right\} \rightarrow 0$ for all $i$, then $\left\{x_{n}\right\} \rightarrow 0$.

Suppose that each coordinate sequence $\left\{\alpha_{i}^{n}\right\}$ converges to zero, and fix some $\varepsilon>0$. For each $i$, there exists some integer $N_{i}$ such that

$$
\begin{equation*}
\left|\alpha_{i}^{n}\right|<\frac{\varepsilon}{\sum_{i=1}^{m}\left\|v_{t}\right\|} \forall n>N_{i} \tag{1}
\end{equation*}
$$

Putting $N=\max _{i} N_{i},(1)$ holds for all $n>N$ and all $i=1, \ldots, m$. Now, by the triangle inequality and the defining properties of the norm,

$$
\left\|x_{n}\right\|=\left\|\sum_{i=1}^{m} \alpha_{i}^{n} v_{i}\right\| \leq \sum_{i=1}^{m} \left\lvert\, \alpha_{i}^{n}\left\|v_{i}\right\| \leq \frac{\varepsilon}{\sum_{i=1}^{m}\left\|v_{i}\right\|}\left(\sum_{i=1}^{m}\left\|v_{i}\right\|\right)=\varepsilon\right.
$$

for all $n>N$, that is, $\left\{x_{n}\right\} \rightarrow \underline{0}$.

(ii) To prove the converse implication, suppose that $\left\{x_{n}\right\} \rightarrow \underline{0}$, but for some $k$ the coordinate sequence $\left\{\alpha_{k}^{n}\right\}$ does not converge to 0 . Then there exists a subsequence of $\left\{x_{n}\right\}$ (for convenience of notation, still referred to as $\left\{x_{n}\right\}$ ) and some $r>0$ such that $\left|\alpha_{k}^{n}\right|>r$ for all $n$. For each $n \in \mathbb{N}$, write

$$
M_{n}=\max _{i}\left\{\left|\alpha_{i}^{n}\right| ; 1 \leq i \leq m\right\}
$$

and consider the sequence $\left\{y_{n}\right\}$, with $y_{n}=x_{n} / M_{n}$ ). We will show that $\left\{y_{n}\right\} \rightarrow \underline{0}$. Because $M_{n}>r$ for all $n \in \mathbb{N}$, we have

$$
0 \leq\left\|y_{n}\right\|=\frac{1}{M_{n}}-\left\|x_{n}\right\|<\frac{1}{r}\left\|x_{n}\right\|
$$

and therefore $\left\|y_{n}\right\| \rightarrow 0$.

(iii) Use the Bolzano-Weierstrass theorem to show that from $\left\{y_{n}\right\}$ we can choose a subsequence that converges coordinate-wise, but to a nonzero element. By the first part of the theorem, we have a contradiction.

Observe that for each $n$, the coordinates of $y_{n}$ lie between -1 and +1 , and at least one of them is equal to -1 or +1 . The coordinate sequences $\left\{\alpha_{i}^{n}\right\}$ are therefore all bounded, and at least one of them has a convergent subsequence whose terms are all equal to +1 or -1 (there are infinite numbers of +1 's or -1 's or both to allocate among a finite number of coordinate sequences, so at least one contains an infinite number of one of these). For convenience, suppose this is the first coordinate sequence $\left\{\alpha_{1}^{n}\right\}$, and call the constant subsequence $\left\{\alpha_{1}^{q_{1}(k)}\right\}$.

Consider the corresponding subsequence of $\left\{y_{n}\right\},\left\{y_{q_{1}(k)}\right\}$, and its second coordinate sequence, $\left\{\alpha_{2}^{q_{2}(k)}\right\}$. By the Bolzano-Weierstrass theorem (B-W), this bounded real sequence has a convergent subsequence that we call $\left\{\alpha_{2}^{q_{2}(k)}\right\}$. Note that the corresponding first coordinate subsequence, $\left\{\alpha_{1}^{q_{2}(k)}\right\}$, still converges (any subsequence of a convergent sequence converges). Next, consider the corresponding subsequence of $\left\{y_{n}\right\},\left\{y_{q_{2}(k)}\right\}$, and its third coordinate sequence, $\left\{\alpha_{3}^{q_{2}(k}\right\}$. By B-W, it too has a convergent subsequence, say $\left\{\alpha_{3}^{q_{3}(k)}\right\}$, and $\left\{\alpha_{1}^{q_{3}(k)}\right\}$ and $\left\{\alpha_{2}^{q_{3}(k)}\right\}$ still converge. Continuing in this way for each of the $m$ coordinate sequences, we construct a subsequence $\left\{y_{q_{m}(k)}\right\}$ whose coordinate sequences $\left\{\alpha_{i}^{q_{m}(k)}\right\}$ are all convergent, but at least one of them (the first one) does not have limit zero. Hence, the coordinate-wise limit is not the zero vector, and by the first part of the theorem it follows that $\left\{y_{n_{k}}\right\} \nrightarrow \underline{0}$, which contradicts (ii).

Problem 1.9. Using the foregoing result and the completeness of $\mathbb{R}$, we will show that every finite-dimensional normed vector space over $\mathbb{R}$ is complete.

(i) First, show that if $\left\{x_{n}\right\}$ is Cauchy, then every coordinate sequence $\left\{\alpha_{i}^{n}\right\}$ is Cauchy. (Prove the contrapositive statement: If some coordinate sequence $\left\{\alpha_{k}^{n}\right\}$ is not Cauchy, then neither is $\left\{x_{n}\right\}$. Use the result in Problem 1.8.)

(ii) Using (i), Problem 1.8 again, and the completeness of $\mathbb{R}$, show that the desired result holds.

(i) Let $X$ be a normed vector space with a basis $\left\{v_{1}, \ldots, v_{m}\right\}$. Let $\left\{x_{n}\right\}$ be a sequence in $X$. Write it $x_{n}=\sum_{t=1}^{m} \alpha_{t}^{n} v_{i}\left(\alpha_{i}^{n}\right.$ real), and suppose that some coordinate sequence $\left\{\alpha_{k}^{n}\right\}$ is not Cauchy. We will show that $\left\{x_{n}\right\}$ cannot be Cauchy. If $\left\{\alpha_{k}^{n}\right\}$ is not Cauchy, then there exists some $r>0$ such that for each $q \in \mathbb{N}$, there exist $m_{q}, n_{q}>q$ such that

$$
\left|\alpha_{k}^{m_{q}}-\alpha_{k}^{n_{q}}\right|>r
$$

Hence, the subsequence $\left\{\alpha_{k}^{m_{q}}-\alpha_{k}^{n_{q}}\right\}$ does not converge to zero. But then, by Problem 1.8, the subsequence $\left\{x_{m_{q}}-x_{n_{q}}\right\}$ does not converge to the zero vector, implying that $\left\{x_{n}\right\}$ is not Cauchy.

(ii) Let $\left\{x_{n}\right\}$ be a Cauchy sequence in $X$. From part (i), each coordinate sequence $\left\{\alpha_{i}^{n}\right\}$ is a Cauchy sequence of real numbers, and by the completeness of $\mathbb{R}$, each converges to some real limit, say $\alpha_{i}$. By Problem 1.8, $\left\{x_{n}\right\}$ converges to $x=\sum_{i=1}^{m} \alpha_{i} v_{i}$.

Problem 2.2. Show that for any linear function $T, T(\underline{0})=\underline{0}$.

Because $0 x=\underline{0}$ for any vector $x$, we have, by the linearity of $T$, that $T(\underline{0})=T(0 x)$ $=0 T(x)=\underline{0}$.

## Problem 2.4. Show that the composition of two linear functions is linear.

Let $R: X \longrightarrow Y$ and $S: Y \longrightarrow Z$ be linear mappings, and let $T=S \circ R$ be their composition. Given any two vectors $x$ and $y$ in $X$ and arbitrary scalars $\alpha$ and $\beta$, we have, exploiting the linearity of $S$ and $T$,

$$
T(\alpha x+\beta y)=S[R(a x+\beta y)]=S[\alpha R(x)+\beta R(y)]=\alpha S[R(x)]+\beta S[R(y)]=\alpha T(x)+\beta T(y)
$$

Problem 2.8. Prove Theorem 2.7: Given a linear transformation $T: X \longrightarrow Y$, ker $T$ is a vector subspace of $X$.

Let $x_{1}$ and $x_{2}$ be two vectors in $\operatorname{ker} T$, that is, such that $T\left(x_{1}\right)=T\left(x_{2}\right)=\underline{0}$. Given any scalars $\alpha$ and $\beta$, we have, by the linearity of $T$,

$$
T\left(\alpha x_{1}+\beta x_{2}\right)=\alpha T\left(x_{1}\right)+\beta T\left(x_{2}\right)=\alpha \underline{0}+\beta \underline{0}=\underline{0}
$$

Hence, $\alpha x_{1}+\beta x_{2} \in \operatorname{ker} T$.

Problem 2.12. Prove Theorem 2.11: Let $T \in L(X, Y)$ be an invertible linear function. Then the inverse map $T^{-1}: Y \longrightarrow X$ is linear; that is, $T^{-1} \in L(Y, X)$.

Let $y$ and $y^{\prime}$ be two arbitrary points in $Y$. Because $T$ is invertible, there exist points $x$ and $x^{\prime}$ in $X$ such that

$$
\begin{equation*}
y=T(x), \quad x=T^{-1}(y), \quad y^{\prime}=T\left(x^{\prime}\right), \quad x^{\prime}=T^{-1}\left(y^{\prime}\right) \tag{1}
\end{equation*}
$$

Then, using the linearity of $T$, the definition of inverse, and (1), we have

$$
\begin{aligned}
T^{-1}\left(\alpha y+\beta y^{\prime}\right) & =T^{-1}\left[\alpha T(x)+\beta T\left(x^{\prime}\right)\right]=T^{-1}\left[T\left(\alpha x+\beta x^{\prime}\right)\right] \\
& =\alpha x+\beta x^{\prime}=\alpha T^{-1}(y)+\beta T^{-1}\left(y^{\prime}\right)
\end{aligned}
$$

which shows that $T^{-1}$ is linear.

Problem 2.14. Prove Theorem 2.13: A linear transformation $T: X \longrightarrow Y$ is oneto-one if and only if $T(x)=\underline{0} \Rightarrow x=\underline{0}$, that is, if $\operatorname{ker} T=\{\underline{0}\}$.

Recall that for any linear mapping $T$ we have $T(\underline{0})=\underline{0}$ (Problem 2.2). If ker $T \neq\{\underline{0}\}$, then there is at least one other element $x \neq 0$ in the kernel, and it follows that $T$ is not one-to-one, because it maps two different vectors into the zero vector.

Conversely, suppose $\operatorname{ker} T=\{\underline{0}\}$, and let $x$ and $x^{\prime}$ be two distinct elements of $X$. Then $x-x^{\prime} \neq \underline{0}$, implying $x-x^{\prime} \notin \operatorname{ker} T$, and therefore $T\left(x-x^{\prime}\right) \neq \underline{0}$. But then, by the linearity of $T$,

$$
T(x)-T\left(x^{\prime}\right)=T\left(x-x^{\prime}\right) \neq 0
$$

from where $T(x) \neq T\left(x^{\prime}\right)$

Problem 4.4. We will prove the following theorem: Given normed linear spaces $X$ and $Y$ and a linear function $T: X \longrightarrow Y$, the inverse function $T^{-1}$ exists and is a continuous linear mapping on $T(X)$ if and only if there exists some $m>0$ such that $m\|x\| \leq\|T x\|$.

(i) Using Theorem 2.13, show that if there exists some $m>0$ such that $m\|x\| \leq\|T x\|$, then $T$ is one-to-one (and therefore invertible on $T(X)$ ).

(ii) Use Theorem 4.3 to show that $T^{-1}$ is continuous on $T(X)$.

(iii) Using Theorem 4.3, show that if $T^{-1}$ is continuous on $T(X)$, then there exists some $m>0$ such that $m\|x\| \leq\|T x\|$.
(i) If $x \neq \underline{0}$, then $\|x\|>0$ and $\|T x\| \geq m\|x\|>0$, so $T x \neq \underline{0}$, implying that $T$ is one-toone (Theorem 2.13). Hence, $T^{-1}$ is defined on $T(X)$ and is linear (Problem 2.12).

(ii) To show that $T^{-1}$ is continuous on $T(X)$, write $\mathrm{x}=T^{-1}(y)$. For any $\mathrm{y}$ in $T(X)$, we have

$$
m\|x\|=m\left\|T^{-1}(y)\right\|=m\|x\| \leq\|T x\|=\|y\| \Rightarrow\left\|T^{-1}(y)\right\| \leq \frac{\|y\|}{m} \forall y \in T(X)
$$

Hence, $T^{-1}$ is bounded and therefore continuous (by Theorem 4.3).

(iii) Conversely, if $T^{-1}$ is continuous on $T(X)$, then by Theorem 4.3 there exists some $M>0$ such that

$$
\left\|T^{-1}(y)\right\| \leq M\|y\| \forall y \in T(X)
$$

Now, $y=T x$, so

$$
\left\|T^{-1}(T x)\right\| \leq M\|T x\| \Rightarrow \frac{\|x\|}{M} \leq\|T x\| \forall x \in X
$$

and the result follows with $m=1 / M$.

Problem 5.1. Show that the matrix $P$ that represents a coordinate change is invertible.

Let $x$ be an arbitrary vector in $V$, with coordinate vector $\alpha=\left(\alpha_{1}, \ldots, \alpha_{n}\right)^{T}$ in basis $\mathbb{d}$, and $\beta=\left(\beta_{1}, \ldots, \beta_{n}\right)^{T}$ in basis $\mathbb{b}$. We have seen that there is a matrix $P$ such that $\alpha=P \beta$. By the same argument, there is also a matrix $Z$ such that $\beta=Z \alpha$. Hence,

$$
\alpha=P \beta=P Z \alpha
$$

for any vector with (arbitrary coordinates) $\alpha$. Hence, $P Z=\mathbf{I}$, and by the same argument $Z P=\mathbf{I}$. Hence, $Z=P^{-1}$, and $P$ is invertible.

Problem 5.3. Show that similar matrices have the same determinant.

$$
|B|=\left|P^{-1} A P\right|=\left|P^{-1}\right||A||P|=|A|\left|P^{-1}\right||P|=|A| \text {, because } P^{-1} P=\mathbf{I},\left|P^{-1}\right||P|=|\mathbf{I}|=1
$$

Problem 6.2. Show that the eigenspace of $A$ corresponding to an eigenvalue $\lambda$ is a vector space.

Let $x$ and $y$ be any two vectors in the eigenspace of $A$ corresponding to $\lambda$. Then $A x=\lambda x, A y=\lambda y$, and we have, for any scalars $\alpha$ and $\beta$,

$$
A(\alpha x+\beta y)=\alpha(A x)+\beta(A y)=\alpha(\lambda x)+\beta(\lambda y)=\lambda(\alpha x+\beta y)
$$

so $\alpha x+\beta y$ lies in the eigenspace of $A$, which is therefore a vector (sub-) space.

Problem 6.3. Show that if $\lambda$ is an eigenvalue of $A$, then (i) $\lambda^{n}$ is an eigenvalue of $A^{n}$, and (ii) $\lambda^{-1}$ is an eigenvalue of $A^{-1}$.

(i) We proceed by induction. First, consider the case where $n=2$. Let $\lambda$ be an eigenvalue of $A$, and $x$ an eigenvector belonging to it; then $A x=\lambda x$, and

$$
A^{2} x=A(A x)=A(\lambda x)=\lambda(A x)=\lambda(\lambda x)=\lambda^{2} x
$$

so $\lambda^{2}$ is indeed an eigenvalue of $A^{2}$, and $x$ an eigenvector. Next, suppose that $\lambda^{n}$ is an eigenvalue of $A^{n}$, and $x$ an eigenvector belonging to it (i.e., $A^{n} x=\lambda_{x}^{n}$ ). Then

$$
A^{n+1} x=A^{n} A x=A^{n}(\lambda x)=\lambda\left(A^{n} x\right)=\lambda\left(\lambda^{n} x\right)=\lambda^{n+1} x
$$

(ii) Observe that $A x=\lambda x$ implies $x=\mathbf{I} x=A^{-1} A x=A^{-1} \lambda x$, and therefore $A^{-1} x=\lambda^{-1} x$.

Problem 6.4. Find the eigenvalues and eigenvectors of the matrix

$$
A=\left[\begin{array}{rrr}
3 & -2 & 0 \\
-2 & 3 & 0 \\
0 & 0 & 5
\end{array}\right]
$$

The characteristic equation of $A$ is of the form

$$
\begin{aligned}
|A-\lambda \mathbf{I}| & =\operatorname{det}\left[\begin{array}{ccc}
3-\lambda & -2 & 0 \\
-2 & 3-\lambda & 0 \\
0 & 0 & 5-\lambda
\end{array}\right]=(3-\lambda)^{2}(5-\lambda)-4(5-\lambda) \\
& =(5-\lambda)\left(5-6 \lambda+\lambda^{2}\right)=0
\end{aligned}
$$

Hence, $\lambda_{1}=5$, and

$$
\lambda_{2}, \lambda_{3}=\frac{6 \pm \sqrt{36-20}}{2}=5,1
$$

We have one repeated eigenvalue (5) and a second eigenvalue (1) with multiplicity 1.

By definition, $e=\left(e_{1}, e_{2}, e_{3}\right)^{T}$ is an eigenvector of $A$ belonging to the eigenvalue $\lambda$ if it is a nonzero solution of the equation

$$
(A-\lambda \mathbf{I}) e=\underline{0} \Leftrightarrow\left[\begin{array}{ccc}
3-\lambda & -2 & 0 \\
-2 & 3-\lambda & 0 \\
0 & 0 & 5-\lambda
\end{array}\right]\left[\begin{array}{l}
e_{1} \\
e_{2} \\
e_{3}
\end{array}\right]=\left[\begin{array}{l}
0 \\
0 \\
0
\end{array}\right]
$$

With $\lambda=1$, we have the system

$$
2 e_{1}-2 e_{2}=0, \quad-2 e_{1}+2 e_{2}=0, \quad 4 e_{3}=0
$$

Clearly, the first and second equations are not linearly independent. This leaves us with an undetermined system of two equations in three unknowns, and we have

$$
e_{3}=0 \text { and } e_{1}=e_{2}=r
$$

where $r$ is an arbitrary number different from zero. Hence, the eigenvectors of $A$ corresponding to the eigenvalue $\lambda=1$ are the nonzero vectors of the form

$$
e=\left[\begin{array}{l}
e_{1} \\
e_{2} \\
e_{3}
\end{array}\right]=\left[\begin{array}{l}
r \\
r \\
0
\end{array}\right]=r\left[\begin{array}{l}
1 \\
1 \\
0
\end{array}\right], \quad \text { with } r \neq 0
$$

## Chapter 4

Problem 1.2. Let $f$ and $g$ be functions $\mathbb{R} \longrightarrow \mathbb{R}$, and assume that they are both differentiable at the point $x^{0}$. Using the elementary properties of limits and the continuity of $f$ and $g$ at $x$, show that the product function $p$, defined by $p(x)=f(x) g(x)$, is differentiable at $x^{0}$ and that

$$
p^{\prime}\left(x^{0}\right)=f\left(x^{0}\right) g^{\prime}\left(x^{0}\right)+f^{\prime}\left(x^{0}\right) g\left(x^{0}\right)
$$

Observe that

$$
\begin{aligned}
f(x) g(x)-f\left(x^{0}\right) g\left(x^{0}\right) & =f(x) g(x)-f\left(x^{0}\right) g(x)+f\left(x^{0}\right) g(x)-f\left(x^{0}\right) g\left(x^{0}\right) \\
& =g(x)\left[f(x)-f\left(x^{0}\right)\right]+f\left(x^{0}\right)\left[g(x)-g\left(x^{0}\right)\right]
\end{aligned}
$$

Taking the limit of this expression as $x$ approaches $x^{0}$,

$$
\begin{aligned}
\lim _{x \rightarrow x^{0}} \frac{f(x) g(x)-f\left(x^{0}\right) g\left(x^{0}\right)}{x-x^{0}} & =\left(\lim _{x \rightarrow x^{0}} g(x)\right)\left(\lim _{x \rightarrow x^{0}} \frac{f(x)-f\left(x^{0}\right)}{x-x^{0}}\right)+f\left(x^{0}\right)\left(\lim _{x \rightarrow x^{0}} \frac{g(x)-g\left(x^{0}\right)}{x-x^{0}}\right) \\
& =g\left(x^{0}\right) f^{\prime}\left(x^{0}\right)+f\left(x^{0}\right) g^{\prime}\left(x^{0}\right)
\end{aligned}
$$

Problem 1.3. Let $f(x)=x^{n}$. Show by induction that $f^{\prime}(x)=n x^{n-1}$.

Let $f(x)=x^{2}$. Then

$$
f^{\prime}(x)=\lim _{h \rightarrow 0} \frac{f(x+h)-f(x)}{h}=\lim _{h \rightarrow 0} \frac{(x+h)^{2}-x^{2}}{h}=\lim _{h \rightarrow 0}(2 x+h)=2 x
$$

Next, suppose that $d x^{n} / d x=n x^{n-1}$; we want to show that then $d x^{n+1} / d x=(n+1) x^{n}$. Observe that

$$
(x+h)^{n+1}-x^{n+1}=(x+h)^{n}(x+h)-x^{n} x=x\left[(x+h)^{n}-x^{n}\right]+h(x+h)^{n}
$$

Hence,

$$
\begin{aligned}
\frac{x^{n+1}}{d x} & =\lim _{h \rightarrow 0} \frac{(x+h)^{n+1}-x^{n+1}}{h}=\lim _{h \rightarrow 0} \frac{x\left[(x+h)^{n}-x^{n}\right]+h(x+h)^{n}}{h} \\
& =x\left(\lim _{h \rightarrow 0} \frac{(x+h)^{n}-x^{n}}{h}\right)+\lim _{h \rightarrow 0}(x+h)^{n}=x \frac{d x^{n}}{d x}+x^{n}=x n x^{n-1}+x^{n}=(n+1) x^{n}
\end{aligned}
$$

Problem 1.8. Let $f: \mathbb{R} \longrightarrow \mathbb{R}$ be a differentiable function on an interval $I$. Show that (i) if $f^{\prime}(x)=0$ for each $x \in I$, then $f$ is constant on the interval, and (ii) if $f^{\prime}(x)>0$ on $(a, b)$, then $f$ is strictly increasing on $I$.

Let $x$ and $y$, with $x<y$, be two arbitrary points in $I$. We will use the mean-value theorem to show that $f(x)=f(y)$ (or $f(y)>f(x)$ ). Because $x$ and $y$ are arbitrary, the desired result follows.

By the mean-value theorem, there exists some point $z \in(x, y) \subseteq I$ such that

$$
f^{\prime}(z)=\frac{f(y)-f(x)}{y-x}
$$

In (i), $f^{\prime}(z)=0$, implying that $f(y)=f(x)$. In (ii), $f^{\prime}(z)>0$, implying that $f(y)>f(x)$.

Problem 1.10. A sufficient condition for a local maximum. Let $f: \mathbb{R} \longrightarrow \mathbb{R}$ be twice differentiable on some interval containing $x^{0}$. Assume, moreover, that $f^{\prime}\left(x^{0}\right)$ $=0, f^{\prime \prime}\left(x^{0}\right)<0$, and $f^{\prime \prime}$ is continuous at $x^{0}$. Use Problem 1.8 to show that $x^{0}$ is a local maximizer of $f$.

Because $f^{\prime \prime}\left(x^{0}\right)<0$ and $f^{\prime \prime}$ is continuous, $f^{\prime \prime}$ is negative on some interval $I$ containing $x^{0}$ (by the sign-preservation property of continuous functions, see Problem 6.2 in Chapter 2). By Problem 1.8, a negative second derivative implies a decreasing first derivative. Thus, $f^{\prime}(x)>0$ for $x$ to the left of $x^{0}$ in the interval $I$,
and $f^{\prime}(x)<0$ for $x$ to the right of $x^{0}$ in the same interval. By Problem 1.8 again, $f\left(\right.$ ) decreases to the left of $x^{0}$ and increases to its right, which proves the result.

Problem 1.11. Let $f: \mathbb{R} \longrightarrow \mathbb{R}$ be $m+1$ times differentiable on an interval around the point $x^{0}$. Assume that for some $m>1, f^{(m)}\left(x^{0}\right)$ is the first nonzero derivative of $f$ at $x^{0}$, that is,

$$
f^{\prime}\left(x^{0}\right)=f^{\prime \prime}\left(x^{0}\right)=f^{(3)}\left(x^{0}\right)=\ldots=f^{(m-1)}\left(x^{0}\right)=0 \quad \text { and } \quad f^{(m)}\left(x^{0}\right) \neq 0
$$

Use Taylor's theorem to show that

(i) if $m$ is even and $f^{(m)}\left(x^{0}\right)<0$, then $f$ has a local maximum at $x^{0}$,

(ii) if $m$ is even and $f^{(m)}\left(x^{0}\right)>0$, then $f$ has a local minimum at $x^{0}$,

(iii) if $m$ is odd, then $f$ has neither a local maximum nor a local minimum at $x^{0}$.

To simplify the notation, suppose $x^{0}=0$. By assumption, $f^{(m)}$ is differentiable and therefore continuous at $x^{0}=0$; hence, by the sign-preservation property of continuous functions, there exists some open interval $I$ around 0 in which $f^{(m)}$ does not change sign.

Next, by Taylor's theorem, we have, for each $x$ in $I$,

$$
f(x)=f(0)+\sum_{k=1}^{m-1} \frac{f^{(k)}(0)}{k !} x^{k}+\frac{f^{(m)}(\lambda x)}{m !} x^{m}=f(0)+\frac{f^{(m)}(\lambda x)}{m !} x^{m}
$$

where $\lambda \in(0,1)$, and therefore $\lambda x \in I$. Hence, for any $x \in I$, we have

$$
f(x)-f(0)=\frac{f^{(m)}(\lambda x)}{m !} x^{m}
$$

where the sign of $f^{(m)}(\lambda x)$ is the same as that of $f^{(m)}(0)$. Consider the sign of the right-hand side of this expression. If $m$ is even, $x^{m}>0$ for all $x \in I$ and different from zero. If $f^{(m)}(0)<0$, we have $f^{(m)}(\lambda x)<0$, and therefore $f(x)-f(0)<0$ for all $x$ in $I$ distinct from zero, implying that $x$ is a local maximizer of $f$. By a similar argument, the rest of the cases follow.

Problem 1.12. Cauchy's mean-value theorem. Prove the following result: Let $f$ and $g:[a, b] \longrightarrow \mathbb{R}$ be differentiable on $(a, b)$, and suppose that $g^{\prime}(x) \neq 0$ for all $x$ in $(a, b)$. Then there is a point $z$ in $(a, b)$ such that

$$
\frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f^{\prime}(z)}{g^{\prime}(z)}
$$

Define $\phi($ ) by

$$
\phi(x)=[g(b)-g(a)] f(x)-[f(b)-f(a)] g(x)
$$

and observe that $\phi()$ is differentiable, with $\phi(a)=g(b) f(a)-f(b) g(a)=\phi(b)$. Applying Rolle's theorem to $\phi()$, there exists some point $z$ in $(a, b)$ such that

$$
\begin{equation*}
\phi^{\prime}(z)=[g(b)-g(a)] f^{\prime}(z)-[f(b)-f(a)] g^{\prime}(z)=0 \tag{1}
\end{equation*}
$$

By assumption, $g^{\prime}(z) \neq 0$. Moreover, $g(a)-g(b) \neq 0$, for otherwise Rolle's theorem applied to $g\left(\right.$ ) would show that $g^{\prime}(x)=0$ for some $x$ in $(a, b)$, and that would contradict our assumption. Hence, we can divide by these two terms and rearrange (1) to get

$$
\frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f^{\prime}(z)}{g^{\prime}(z)}
$$

Problem 1.13. L'Hôpital's rule. Suppose $f$ and $g$ are continuous real-valued functions defined and differentiable on some open interval containing the point $a$ and such that $f(a)=g(a)=0$. Show that if $f^{\prime}(x) / g^{\prime}(x)$ tends to a limit as $x \rightarrow a$, so does $f(x) / g(x)$, and

$$
\lim _{x \rightarrow a} \frac{f(x)}{g(x)}=\lim _{x \rightarrow a} \frac{f^{\prime}(x)}{g^{\prime}(x)}
$$

Assume that $f^{\prime}(x) / g^{\prime}(x) \rightarrow L$ as $x \rightarrow a$, and fix some arbitrary $\varepsilon>0$. Then there exists some $\delta>0$ such that

$$
\begin{equation*}
\left|\frac{f^{\prime}(x)}{g^{\prime}(x)}-L\right|<\varepsilon \forall x \in B_{\delta}(a)=(a-\delta, a+\delta) \tag{1}
\end{equation*}
$$

Choose some $x$ in $(a, a+\delta)$ and apply the Cauchy mean-value theorem to $f$ and $g$ in the interval $[a, x]$ to show that there exists some number $z$ in $(a, x)$ such that

$$
\frac{f^{\prime}(z)}{g^{\prime}(z)}=\frac{f(x)-f(a)}{g(x)-g(a)}=\frac{f(x)}{g(x)}
$$

Because $z \in(a, x) \subseteq(a-\delta, a+\delta)$, we have, by (1),

$$
\left|\frac{f(x)}{g(x)}-L\right|=\left|\frac{f^{\prime}(z)}{g^{\prime}(z)}-L\right|<\varepsilon
$$

Because $x$ was an arbitrary point of $(a, a+\delta)$, we have shown that

$$
\left|\frac{f(x)}{g(x)}-L\right|<\varepsilon
$$

for all $x \in(a, a+\delta)$, and because $\varepsilon$ was arbitrary, this establishes that $f(x) / g(x) \rightarrow$ $L$ as $x$ approaches $a$ from above. A similar argument then yields that $f(x) / g(x) \rightarrow$ $L$ as $x \rightarrow a^{-}$, and the result follows.

Problem 2.2. Let $f\left(x_{1}, x_{2}\right)=x_{1} x_{2}, u=(3 / 5,4 / 5)$, and $x^{0}=(1,2)$. Compute $D f\left(x^{0} ; u\right)$ directly by taking the appropriate limits, and verify that the result is the same if you use the formula $D f\left(x^{0} ; u\right)=\nabla f\left(x^{0}\right) u$.

$$
\begin{aligned}
D f(x ; u) & =\lim _{\alpha \rightarrow 0} \frac{f(x+\alpha u)-f(x)}{\alpha}=\lim _{\alpha \rightarrow 0} \frac{\left(x_{1}+\frac{3 \alpha}{5}\right)\left(x_{2}+\frac{4 \alpha}{5}\right)-x_{21} x_{2}}{\alpha} \\
& =\lim _{\alpha \rightarrow 0}\left(\frac{4 x_{1}}{5}+\frac{3 x_{2}}{5}+\frac{12 \alpha}{25}\right)=\frac{4 x_{1}}{5}+\frac{3 x_{2}}{5}
\end{aligned}
$$

Therefore,

$$
D f\left(x^{0} ; u\right)=\frac{4}{5}+\frac{6}{5}=2
$$

On the other hand,

$$
\begin{aligned}
D f\left(x^{0} ; u\right) & =\nabla f\left(x^{0}\right) u=\left[\frac{\partial f\left(x^{0}\right)}{\partial x_{1}}, \frac{\partial f\left(x^{0}\right)}{\partial x_{1}}\right]\left[\begin{array}{l}
u_{1} \\
u_{2}
\end{array}\right]=\left(x_{2}^{0}, x_{1}^{0}\right)\left[\begin{array}{l}
u_{1} \\
u_{2}
\end{array}\right] \\
& =(2,1)(3 / 5,4 / 5)^{T}=2
\end{aligned}
$$

Problem 2.4. Given the functions

$$
\begin{gathered}
y=f\left(x_{1}, x_{2}\right)=\sin \left(x_{1} x_{2}+x_{2}^{2}\right), \quad y=f\left(x_{1}, x_{2}\right)=x_{1}^{2} x_{2}+x_{2}^{3} \ln x_{1}, \\
y=f\left(x_{1}, x_{2}\right)=\ln \left(x_{2}+e_{1}^{x} x_{2}\right)
\end{gathered}
$$

compute, for each of them, the partial derivatives $\partial y / \partial x_{1}$ and $\partial y / \partial x_{2}$.

$$
\begin{gathered}
y=\sin \left(x_{1} x_{2}+x_{2}^{2}\right), \quad \frac{\partial y}{\partial x_{1}}=\cos \left(x_{1} x_{2}+x_{2}^{2}\right) x_{2}, \quad \frac{\partial y}{\partial x_{2}}=\cos \left(x_{1} x_{2}+x_{2}^{2}\right)\left(x_{1}+2 x_{2}\right) \\
y=x_{1}^{2} x_{2}+x_{2}^{3} \ln x_{1}, \quad \frac{\partial y}{\partial x_{1}}=2 x_{1} x_{2}+\frac{x_{2}^{3}}{x_{1}}, \quad \frac{\partial y}{\partial x_{2}}=x_{1}^{2}+3 x_{2}^{2} \ln x_{1} \\
y=\ln \left(x_{2}+x_{2} e^{x_{1}}\right), \quad \frac{\partial y}{\partial x_{1}}=\frac{x_{2} e^{x_{1}}}{x_{2}+x_{2} e^{x_{1}}}, \quad \frac{\partial y}{\partial x_{2}}=\frac{1+e^{x_{1}}}{x_{2}+x_{2} e^{x_{1}}}
\end{gathered}
$$

Problem 2.5. Find the points where all the partial derivatives of the function

$$
f\left(x_{1}, x_{2}\right)=x_{1}^{4} x_{2}-x_{1}^{2} x_{2}^{3}
$$

are zero.

We have to solve the following system of equations:

$$
\begin{gather*}
\frac{\partial f(x)}{\partial x_{1}}=4 x_{1}^{3} x_{2}-2 x_{1} x_{2}^{3}=2 x_{1} x_{2}\left(2 x_{1}^{2}-x_{2}^{2}\right)=0  \tag{1}\\
\frac{\partial f(x)}{\partial x_{2}}=x_{1}^{4}-3 x_{1}^{2} x_{2}^{2}=x_{1}^{2}\left(x_{1}^{2}-3 x_{2}^{2}\right)=0 \tag{2}
\end{gather*}
$$

Therefore,

(i) if $x_{1}=0$, then $\partial f(x) / \partial x_{1}=\partial f(x) / \partial x_{2}=0$ for all $x_{2}$, and

(ii) if $x_{1} \neq 0$, then

(a) $\partial f(x) / \partial x_{1}=0$ if $x_{2}=0$ or $2 x_{1}^{2}-x_{2}^{2}=0$, and

(b) $\partial f(x) / \partial x_{2}=0$ if $x_{1}^{2}-3 x_{2}^{2}=0$

so we have to consider two cases:

- If $x_{2}=0$, then (b) reduces to $x_{1}^{2}=0$.
- The other possibility is to have

$$
2 x_{1}^{2}=x_{2}^{2} \text { and } x_{1}^{2}=3 x_{2}^{2}
$$

at the same time. Substituting the first expression into the second, $x_{1}^{2}=3\left(2 x_{1}^{2}\right)$, which holds only if $x_{1}=0$, so there are no other solutions.

Problem 3.6. Let $w=f(x, y, z)=x y^{2} z$, where

$$
x=r+2 s+t, \quad y=2 r+3 s+t, \quad z=3 r+s+t
$$

Use the chain rule to calculate $\partial w / \partial r, \partial w / \partial s$, and $\partial w / \partial t$.

We have

$$
\begin{array}{llll}
\frac{\partial w}{\partial x}=y^{2} z, & \frac{\partial x}{\partial r}=1, & \frac{\partial y}{\partial r}=2, & \frac{\partial z}{\partial r}=3 \\
\frac{\partial w}{\partial y}=2 x y z, & \frac{\partial x}{\partial s}=2, & \frac{\partial y}{\partial s}=3, & \frac{\partial z}{\partial s}=1 \\
\frac{\partial w}{\partial z}=x y^{2}, & \frac{\partial x}{\partial t}=-1, & \frac{\partial y}{\partial t}=1, & \frac{\partial z}{\partial t}=1
\end{array}
$$

Hence,

$$
\begin{aligned}
\frac{\partial w}{\partial s}= & \frac{\partial w}{\partial x} \frac{\partial x}{\partial s}+\frac{\partial w}{\partial y} \frac{\partial y}{\partial s}+\frac{\partial w}{\partial z} \frac{\partial z}{\partial s}=2\left(y^{2} z\right)+3(2 x y z)+1\left(x y^{2}\right) \\
= & 2(2 r+3 s+t)^{2}(3 r+s+t)+6(r+2 s+t)(2 r+3 s+t)(3 r+s+t) \\
& +1(r+2 s+t)(2 r+3 s+t)^{2}, \quad \text { etc. }
\end{aligned}
$$

Problem 3.8. Prove the following theorem: Let $f: \mathbb{R}^{\mathrm{n}} \longrightarrow \mathbb{R}^{\mathrm{m}}$ be differentiable on an open subset $X$ of $\mathbb{R}^{\mathrm{n}}$, and let $x$ and $y$ be two points in $X$ such that $L(x, y)$ is contained in $X$. Then for each vector $a$ in $\mathbb{R}^{\mathrm{m}}$ there exists a vector $z$ in $L(x, y)$ such that

$$
\begin{equation*}
a[f(y)-f(x)]=a[D f(z)(y-x)] \tag{2}
\end{equation*}
$$

Put $h=y-x$. As $X$ is open and contains $L(x, y)$, there exists some $\delta>0$ such that $x+\lambda h \in X$ for $\lambda \in(-\delta, 1+\delta)$. Fix an arbitrary vector $a=\left(a_{1}, \ldots, a_{m}\right) \in \mathbb{R}^{m}$, and define a real-valued function $\phi_{a}$ on the interval $(-\delta, 1+\delta)$ by

$$
\phi_{a}(\lambda)=a f(x+\lambda h)=\sum_{i=1}^{m} a_{i} f^{\prime}(x+\lambda h)
$$

By construction, $\phi_{a}()$ is differentiable on $(-\delta, 1+\delta)$, with derivative

$$
\phi_{a}^{\prime}(\lambda)=\sum_{i=1}^{m} a_{i}\left[\sum_{k=1}^{n} f_{k}^{i}(x+\lambda h) h_{k}\right]=\sum_{k=1}^{m} a_{i}\left[D f^{i}(x+\lambda h) h\right]=a[D f(x+\lambda h) h]
$$

Applying the mean-value theorem for univariate real functions to $\phi_{a}()$, we have

$$
\phi_{a}(1)-\phi_{a}(0)=\phi_{a}^{\prime}(\theta) \text { for some } \theta \in(0,1)
$$

which is equivalent to

$$
a[f(y)-f(x)]=\left[\phi_{a}(1)-\phi_{a}(0)=\phi_{a}^{\prime}(\theta)\right]=a[D f(x+\theta h) h]
$$

Putting

$$
z=x+\theta h
$$

we obtain the desired result. Note that the value of $z$ depends on the chosen vector $a$.

Problem 4.5. Prove Theorem 4.4: Let $f: \mathbb{R}^{\mathrm{n}} \longrightarrow \mathbb{R}$ be a $C^{2}$ function defined on an open and convex set $X$. If $x, x+h \in X$, then

$$
\begin{equation*}
f(x+h)=f(x)+D f(x) h+(1 / 2) h^{T} D^{2} f(x+\lambda h) h \tag{1}
\end{equation*}
$$

for some $\lambda \in(0,1)$. by

We apply the univariate version of Taylor's formula to the function $g$ defined

$$
g(\alpha)=f(x+\alpha h)
$$

Observe that because $X$ is open and convex and both $x$ and $x+h$ are in $X$, there exists some $\delta>0$ such that $x+\alpha h \in X$ for $\alpha \in(-\delta, 1+\delta)$ and such that $g$ is twice continuously differentiable on this interval. By Taylor's theorem for univariate real functions, we have

$$
\begin{equation*}
f(x+h)-f(x)=g(1)-g(0)=\sum_{k=1}^{n-1} \frac{g^{(k)}(0)}{k !}+\frac{g^{(n)}(\lambda)}{n !} \tag{2}
\end{equation*}
$$

for some $\lambda \in(0,1)$. Computing the derivatives of $g$, we can generalize the univariate result for any $n$. To obtain a formula with quadratic remainder, we set $n=2$ and observe that

$$
\begin{gathered}
g^{\prime}(\alpha)=\sum_{k=1}^{n} f_{k}(x+\alpha h) h_{k}=D f(x+\alpha h) h \\
g^{\prime \prime}(\alpha)=\sum_{k=1}^{n} h_{k}\left(\sum_{j=1}^{n} f_{k j}(x+\alpha h) h_{j}\right)=h^{T} D^{2} f(x+\alpha h) h
\end{gathered}
$$

Substituting these expressions in (2), we obtain the desired result:

$$
f(x+h)-f(x)=D f(x) h+(1 / 2) h^{T} D^{2} f(x+\lambda h) h \quad \text { for some } \lambda \in(0,1)
$$

Problem 4.7. Let $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}^{\mathrm{n}}$ be a continuously differentiable function on the open set $X$. Show that $f$ is locally Lipschitz on $X$.

Recall that the function $f$ is said to be locally Lipschitz on the set $X$ if for each point $x_{0}$ in $X$ there exists some $\varepsilon_{0}>0$ and some $K_{0}>0$ such that $B_{\varepsilon_{0}}\left(x_{0}\right) \subseteq X$, and for all $x$ and $\mathrm{y}$ in $B_{\varepsilon_{0}}\left(x_{0}\right)$,

$$
\begin{equation*}
\|f(x)-f(y)\| \leq K_{0}\|x-y\| \tag{1}
\end{equation*}
$$

Let $x_{0}$ be an arbitrary point in $X$. Because $X$ is open, there exists some $\varepsilon_{0}>0$ such that $B_{2 \varepsilon_{0}}\left(x_{0}\right) \subseteq X$. Because $f$ is continuously differentiable and the norm is a continuous function, the function $X \rightarrow \mathbb{R}$ defined by $\|D f(x)\|$ is continuous, and it therefore achieves a maximum on the compact set $B_{\varepsilon_{0}}\left[x_{0}\right] \subseteq X$. Let $K_{0}$ be this maximum, that is,

$$
K_{0}=\max \left\{\|D f(x)\| ; x \in B_{\varepsilon_{0}}\left[x_{0}\right]\right\}
$$

Let $x$ and $y$ be two arbitrary points in $B_{\varepsilon_{0}}\left(x_{0}\right)$. Because $B_{\varepsilon_{0}}\left(x_{0}\right)$ is a convex set, it contains the line segment $L(x, y)$. By Theorem 3.9, there exists a vector $z$ in $L(x, y) \subseteq B_{\varepsilon_{0}}\left(x_{0}\right)$ such that

$$
\begin{equation*}
\|f(y)-f(x)\| \leq\|D f(z)\|\|y-x\| \tag{2}
\end{equation*}
$$

Now, because $z \in L(x, y) \subseteq B_{\varepsilon_{0}}\left(x_{0}\right)$, we have

$$
\begin{equation*}
\|D f(z)\| \leq K_{0} \tag{3}
\end{equation*}
$$

and using (3) in (2),

$$
\|f(y)-f(x)\| \leq\|D f(z)\|\|y-x\| \leq K_{0}\|y-x\|
$$

Because $x$ and $y$ are arbitrary, $K_{0}$ is a Lipschitz constant for $f$ on $B_{\varepsilon_{0}}\left(x_{0}\right)$, which is the desired result.

Problem 5.3. Show that if $f$ is homogeneous of degree $k$ and is "sufficiently differentiable," then its first partial derivatives are homogeneous of degree $k-1$.

By the homogeneity of $f, f(\lambda x)=\lambda^{k} f(x)$ for all $\lambda>0$. Keeping $\lambda$ fixed, differentiate this expression with respect to $x_{i}$, obtaining

$$
\lambda f_{i}(\lambda x)=\lambda^{k} f_{i}(x)
$$

Dividing through by $\lambda$, we obtain the desired result.

## Problem 5.4

(i) Show that the Cobb-Douglas function $f(x)=A \prod_{i=1}^{n} x_{i}^{\alpha}$ is homogeneous of degree $\sum_{i=1}^{n} \alpha_{i}$.

(ii) Show that the CES function $g(x)=\mathrm{A}\left(\sum_{i=1}^{n} \delta_{i} x_{i}^{-\rho}\right)^{-v / \rho}$, where $A>0, v>0, \rho>-1$ and $\rho \neq 0, \delta_{i}>0$ for all $i$, and $\Sigma_{i=1}^{n} \delta_{i}=1$, is homogeneous of degree $v$.

$$
\begin{gathered}
f(\lambda x)=A \prod_{i=1}^{n}\left(\lambda x_{i}\right)^{\alpha_{i}}=A\left(\prod_{i=1}^{n} \lambda^{\alpha_{l}}\right)\left(\prod_{i=1}^{n} x_{i}^{\alpha_{i}}\right)=\lambda^{\Sigma_{i} \alpha_{l}} f(x) \\
g(\lambda x)=A\left(\sum_{i=1}^{n} \delta_{i}\left(\lambda x_{i}\right)^{-\rho}\right)^{-v / \rho}=A\left(\lambda^{-\rho} \sum_{i=1}^{n} \delta_{i} x_{i}^{-\rho}\right)^{-v / \rho}=A \lambda^{v}\left(\sum_{i=1}^{n} \delta_{i} x_{i}^{-\rho}\right)^{-v / \rho}=\lambda^{v} g(x)
\end{gathered}
$$

## Chapter 5

Problem 4.1. Given the IS-LM model

$$
\begin{align*}
& y=E_{0}+\alpha y-\beta r+G  \tag{A}\\
& M^{s} / P=M_{0}+\gamma y-\delta r \tag{B}
\end{align*}
$$

where $y$ is national income, $r$ is the interest rate, $G$ is public expenditure, $M^{s} / P$ is the money supply divided by a price index, and all the Greek letters are positive parameters.

(i) Analyze graphically the effects of increases in (a) government spending and (b) the price level on the equilibrium values of national income and the interest rate.

(ii) Write the model in matrix form. Use Cramer's rule to solve the model, writing the equilibrium values of $(y, r)$ as functions of the parameters $(G$, $M^{s} / P, E_{0}$, and $M_{0}$ ), and show that the result is compatible with the conclusions of the graphical analysis.

- $G \uparrow \Rightarrow I S$ shifts to the right. For any given level of $r$, planned expenditure $(y)$ increases, as can be seen in equation (A). Hence, the equilibrium level of national income increases, and so does the interest rate (Figure A5.1).
- $P \uparrow \Rightarrow\left(M^{s} / P\right) \downarrow \Rightarrow$ the real money supply decreases, so $L M$ shifts up (for any given $y$, the interest rate must increase in order to preserve the equality of money demand and supply, now reduced). Equilibrium income falls, and the interest rate increases.

Analytically, rewriting (A) and (B) with the endogenous variables $(y, r)$ on one side and the parameters on the other, we have
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-691.jpg?height=488&width=1218&top_left_y=1645&top_left_x=134)

Figure A5.1. Effects of increases in $G$ and $M$.

$$
\begin{align*}
& (1-\alpha) y+\beta r=E_{0}+G \\
& \gamma y-\delta r=\left(M^{s} / P\right)-M_{0}
\end{align*}
$$

or, in matrix form,

$$
\left[\begin{array}{cc}
1-\alpha & \beta \\
\gamma & -\delta
\end{array}\right]\left[\begin{array}{l}
y \\
r
\end{array}\right]=\left[\begin{array}{c}
E_{0}+G \\
\left(M^{s} / P\right)-M_{0}
\end{array}\right] \Leftrightarrow A x=d
$$

Using Cramer's rule, we can solve for the equilibrium values of the endogenous variables. For each $x_{i}$, we have

$$
x_{i}^{*}=\frac{\left|A_{i}\right|}{|A|}
$$

where $A_{i}$ is obtained by replacing the $i$ th column of the coefficient matrix $A$ by the vector on the right-hand side of the equation. Using this formula,

$$
y^{*}=\frac{\left|A_{y}\right|}{|A|}=\frac{\left|\begin{array}{cc}
E_{0}+G & \beta \\
\left(M^{s} / P\right)-M_{0} & -\delta
\end{array}\right|}{\left|\begin{array}{cc}
1-\alpha & \beta \\
\gamma & -\delta
\end{array}\right|}=\frac{\delta\left(G+E_{0}\right)+\beta\left[\left(M^{s} / P\right)-M_{0}\right]}{(1-\alpha) \delta+\beta \gamma}
$$

from where

$$
\frac{\partial y^{*}}{\partial G}=\frac{\delta}{(1-\alpha) \delta+\beta \gamma}>0 \text { and } \frac{\partial y^{*}}{\partial P}=\frac{\partial y^{*}}{\partial\left(M^{s} / P\right)} \frac{\partial\left(M^{s} / P\right)}{\partial P}=\frac{\beta}{(1-\alpha) \delta+\beta \gamma} \frac{-M^{s}}{P^{2}}<0
$$

Similarly,

$$
r^{*}=\frac{\left|A_{r}\right|}{|A|}=\frac{\left|\begin{array}{cc}
(1-\alpha) & \begin{array}{c}
G+E_{0} \\
\gamma
\end{array} \\
\left(M^{s} / P\right)-M_{0}
\end{array}\right|}{\left|\begin{array}{cc}
1-\alpha & \beta \\
\gamma & -\delta
\end{array}\right|}=\frac{\gamma\left(G+E_{0}\right)-(1-\alpha)\left[\left(M^{s} / P\right)-M_{0}\right]}{(1-\alpha) \delta+\beta \gamma}
$$

implying

$\frac{\partial r^{*}}{\partial G}=\frac{\gamma}{(1-\alpha) \delta+\beta \gamma}>0$ and $\frac{\partial r^{*}}{\partial P}=\frac{\partial r^{*}}{\partial\left(M^{s} / P\right)} \frac{\partial\left(M^{s} / P\right)}{\partial P}=\frac{-(1-\alpha)}{(1-\alpha) \delta+\beta \gamma} \frac{-M^{s}}{P^{2}}>0$

The signs of the partials give the same comparative-statics results as the graphical analysis.

Problem 4.2. The seller of a product pays a proportional tax at a flat rate $\theta \in$ $(0,1)$. Hence, the effective price received by the seller is $(1-\theta) P$, where $P$ is the market price for the good. Market supply and demand are given by the differentiable functions

$$
\begin{array}{ll}
Q^{d}=D(P), & \text { with } D^{\prime}()<0 \\
Q^{s}=S((1-\theta) P), & \text { with } S^{\prime}()>0
\end{array}
$$

and equilibrium requires market clearing, that is, $Q^{s}=Q^{d}$.

Analyze, graphically and analytically, the effects of a decrease in the tax rate on the quantity transacted and the equilibrium price.

Market clearing requires

$$
\begin{equation*}
S((1-\theta) P)=D(P) \tag{1}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-693.jpg?height=603&width=878&top_left_y=180&top_left_x=297)

Figure A5.2. Effect of a tax reduction.

This equation implicitly defines the equilibrium price as a function $P^{*}=P(\theta)$ of the parameter $\theta$. Substituting the solution function $P()$ back into (1), we have the identity

$$
\begin{equation*}
S[(1-\theta) P(\theta)] \equiv D[P(\theta)] \tag{2}
\end{equation*}
$$

Differentiating with respect to the parameter and solving for $P^{\prime}(\theta)$,

$$
S^{\prime}()\left[(1-\theta) P^{\prime}(\theta)-P\right]=D^{\prime}() P^{\prime}(\theta) \Rightarrow P^{\prime}(\theta)=\frac{-P S^{\prime}()}{D^{\prime}()-(1-\theta) S^{\prime}()}=\frac{(-)}{(-)}>0
$$

Next, the quantity transacted in equilibrium is given by $Q^{*}=D[P(\theta)]$, and therefore

$$
\frac{d Q^{*}}{d \theta}=D^{\prime}\left(P^{*}\right) P^{\prime}(\theta)<0
$$

Graphically, a reduction in the tax rate increases the effective price received by sellers for any given market price; these are therefore willing to sell any given quantity at a lower market price. Hence, the supply curve shifts down. The equilibrium price falls, and the equilibrium quantity increases, as shown in Figure A5.2.

Problem 4.3. A competitive firm chooses the quantity of labor $L$ to be hired in order to maximize profits, taking as given the salary $w$ and the value of a productivity parameter $\theta$. That is, the firm solves

$$
\max _{L}(\theta f(L)-w L)
$$

Assume that the production function $f()$ is twice continuously differentiable, increasing, and strictly concave (i.e., $f^{\prime}>0, f^{\prime \prime}<0$ ).

(i) Write the first-order condition for the firm's problem, and verify that the second-order sufficient condition for a maximum holds.

(ii) Interpret the first-order condition as an equation that implicitly defines a labor demand function of the form $L^{*}=L(w, \theta)$. Show, using the implicitfunction theorem, that

$$
\partial L^{*} / \partial w<0 \text { and } \partial L^{*} / \partial \theta>0
$$

Putting

$$
\pi(L)=\theta f(L)-w L
$$

we have

$$
\pi^{\prime}(L)=\theta f^{\prime}(L)-w \quad \text { and } \quad \pi^{\prime \prime}(L)=\theta f^{\prime \prime}(L)<0
$$

Therefore, $\pi(L)$ is strictly concave, and the first-order condition $\pi^{\prime}(L)=0$ characterizes a maximum. Write the first-order condition in the form

$$
F(L ; w, \theta)=\theta f^{\prime}(L)-W=0
$$

and observe that

$$
F_{L}=\theta f^{\prime \prime}(L)<0, \quad F_{W}=-1<0, \quad \text { and } \quad F_{\theta}=f^{\prime}(L)>0
$$

By the implicit-function theorem, the derivatives of the solution function $L^{*}=L(w, \theta)$ are given by

$$
\frac{\partial L^{*}}{\partial w}=\frac{-F_{W}}{F_{L}}=-\frac{(-)}{(-)}<0 \text { and } \frac{\partial L^{*}}{\partial \theta}=\frac{-F_{\theta}}{F_{L}}=-\frac{(+)}{(-)}>0
$$

Hence, the demand for labor decreases with the wage rate, and increases with the productivity parameter $\theta$.

Problem 4.4. Consider an individual who lives for two periods and consumes a single good ("output"). The agent is endowed with $y_{1}$ units of output in youth, and $y_{2}$ units in old age. There exists a perfectly competitive market for output loans in which the agent may borrow or lend at an interest rate $r$ that he takes as given. Call $c_{1}$ and $c_{2}$ his consumption levels during the first and second periods of life, and let $s$ denote his first-period savings, $s=y_{1}-c_{1}$ (note that $s$ will be negative if the agent is a net borrower).

The agent's preferences are represented by a utility function of the form

$$
U\left(c_{1}\right)+\beta U\left(c_{2}\right)
$$

where $U$ is a strictly increasing and strictly concave $C^{2}$ function that satisfies the following "corner" conditions:

$$
U^{\prime}(c) \rightarrow 0 \quad \text { as } c \rightarrow \infty \quad \text { and } \quad U^{\prime}(c) \rightarrow \infty \quad \text { as } c \rightarrow 0
$$

Suppose also that

$$
y_{1}, y_{2}>0, \quad \beta \in(0,1), \text { and } R \equiv 1+r>0
$$

The individual solves the following problem:

$$
\max _{c_{1}, c_{2}}\left\{U\left(c_{1}\right)+\beta U\left(c_{2}\right) \text { subject to } c_{1}=y_{1}-s, c_{2}=y_{2}+s R\right\}
$$

Substituting the constraints into the objective function, we obtain a maximization problem in a single decision variable, $s$.

(i) Write the first-order condition for this problem and check that the secondorder sufficient condition for a maximum holds.

Substituting the constraints into the objective function, the agent solves

$$
\max _{s} v(s)=U\left(y_{1}-s\right)+\beta U\left(y_{2}+s R\right)
$$

The first-order condition for this problem is

$$
\begin{equation*}
v^{\prime}(s)=-U^{\prime}\left(y_{1}-s\right)+\beta U^{\prime}\left(y_{2}+s R\right) R=0 \tag{1}
\end{equation*}
$$

Differentiating again,

$$
v^{\prime \prime}(s)=U^{\prime \prime}\left(y_{1}-s\right)+\beta U^{\prime \prime}\left(y_{2}+s R\right) R^{2}<0
$$

we see that the second-order condition holds by the strict concavity of $U()$.

We will interpret the first-order condition as an equation that implicitly defines a savings function of the form $s^{*}=s\left(y_{1}, y_{2}, R\right)$. We fix the values of $\left(y_{1}, y_{2}\right)$ and study the behavior of $s^{*}$ as a function of $R$.

(ii) Show that for a given value of $R$, the first-order condition has a unique solution $s^{*}$. (Use the intermediate-value theorem, and think of what will happen in extreme cases, e.g., if the agent decides not to eat during one of the periods.)

Fix $\left(y_{1}, y_{2}, R\right)$, with $0<R<\infty$, and write the first-order condition in the form

$$
F(s)=\beta R U^{\prime}\left(y_{2}+s R\right)-U^{\prime}\left(y_{1}-s\right)=\beta R U^{\prime}\left(c_{2}\right)-U^{\prime}\left(c_{1}\right)=0
$$

To apply the intermediate-value theorem, we will use the assumption that $U^{\prime}(c) \rightarrow \infty$ as $c \rightarrow 0$, that is, the marginal utility of consumption goes to infinity as consumption approaches zero.

If the consumer does not eat during the first period $\left(c_{1}=0\right.$ and $\left.s=y_{1}\right)$, then (abusing the notation somewhat)

$$
F\left(y_{1}\right)=\beta R U^{\prime}\left(y_{2}+y_{1} R\right)-U^{\prime}(0)=-\infty
$$

On the other hand, if the consumer is willing to eat nothing during the second period, he can borrow an amount $s=-y_{2} / R$ in the first period, and we have

$$
F\left(-y_{2} / R\right)=\beta R U^{\prime}(0)-U^{\prime}\left(y_{1}+\left(y_{2} / R\right)\right)=+\infty
$$

Hence, taking $s^{\prime \prime}$ close to $y_{1}$ and $s^{\prime}$ close to $-y_{2} / R$, and using the continuity of $U^{\prime}($ ), we can invoke the intermediate-value theorem to conclude that there exists a solution $s^{*}$ of ( $\left.1^{\prime}\right)$ for any bounded $R>0$ (Figure A5.3).

Moreover, we know that $F()$ is a monotonic function, because

$$
\begin{equation*}
F^{\prime}(s)=\beta R^{2} U^{\prime \prime}\left(y_{2}+s R\right)+U^{\prime \prime}\left(y_{1}-s\right)<0 \tag{2}
\end{equation*}
$$

Hence, the intersection is unique, and it follows that for each $R$ there exists a unique optimal level of savings.

(iii) From (ii), we know that $s(R)$ is a well-defined function for $R>0$. The implicit-function theorem guarantees that $s(R)$ is also differentiable. (Why? Which of our assumptions are we using here?) Substituting $s(R)$ back into the first-order condition, we have an identity. Hence, we can differentiate both sides of it with respect to $R$, and the equality will continue to hold. Differentiate implicitly with respect to $R$, and solve for $s^{\prime}(R)$ in the resulting expression.

What can we say about the sign of $s^{\prime}(R)$ ? That is, does $s^{*}$ increase or decrease with the interest factor $R$ ? Does it matter whether or not the agent is a net borrower? (It should. In one of the cases you should not be able to sign the derivative. Why?)

Expression (2) guarantees that we can apply the implicit-function theorem. Substituting the solution function $s^{*}=s(R)$ in the first-order condition, we obtain the identity

$$
\begin{equation*}
\beta R U^{\prime}\left[y_{2}+s(R) R\right] \equiv U^{\prime}\left[y_{1}-s(R)\right] \tag{3}
\end{equation*}
$$

Differentiating with respect to $R$,

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-696.jpg?height=799&width=966&top_left_y=181&top_left_x=262)

Figure A5.3. Existence and uniqueness of the optimal level of savings.

$$
\beta\left\{U^{\prime}\left(c_{2}\right)+R U^{\prime \prime}\left(c_{2}\right)\left[s^{\prime}(R) R+s^{*}\right]\right\}=-U^{\prime \prime}\left(c_{1}\right) s^{\prime}(R)
$$

and solving for $s^{\prime}(R)$,

$$
s^{\prime}(R)=\frac{\beta U^{\prime}\left(c_{2}\right)+\beta R U^{\prime \prime}\left(c_{2}\right) s^{*}}{U^{\prime \prime}\left(c_{1}\right)+\beta R^{2} U^{\prime \prime}\left(c_{2}\right)}
$$

The denominator is negative, but the sign of the numerator is ambiguous, because $s^{*}$ may be positive or negative. We have

$$
\operatorname{sign} s^{\prime}(R)=\operatorname{sign}\left[\beta U^{\prime}\left(c_{2}\right)+\beta R U^{\prime \prime}\left(c_{2}\right) s^{*}\right]=(+)+(-) \operatorname{sign}\left(s^{*}\right)
$$

Hence we have the following:

- If $s^{*} \leq 0$, then $s^{\prime}(R)>0$. That is, if the agent is a net borrower, then an increase in the interest rate makes him borrow less. In this case, the income and substitution effects of the change in $R$ work in the same direction. An increase in $R$ (which can be interpreted as the premium the market pays for postponing consumption) makes consumption in the second period relatively cheaper, which tends to reduce the agent's borrowing. Moreover, the same increase in $R$ makes the agent (who is a net debtor) poorer. In response, the agent will tend to reduce his level of consumption in both periods, thus increasing his savings (or, rather, reducing the amount of his dissaving).
- If $s^{*}>0$, then the sign of $s^{\prime}(R)$ may be positive or negative. Now the substitution and income effects work in opposite directions. As before, the change in the relative prices of current consumption and future consumption tends to favor the second alternative (and hence induces higher savings). On the other hand, because the agent is now a net saver, the increase in the interest rate makes him richer, pushing his consumption level up in both periods and lowering savings. The net result of these two effects is uncertain.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-697.jpg?height=824&width=1103&top_left_y=180&top_left_x=178)

Figure A5.4. Determination of the autarkic interest factor.

(iv) Show that there exists some value of $R$ (say $R^{0}$ ) for which the agent neither borrows nor lends, but consumes precisely his endowment each period. We say that $R^{0}$ is the agent's autarkic interest factor.

(Go back to the original formulation of the agent's decision problem and think in terms of indifference curves and budget constraints in the $\left(c_{1}, c_{2}\right)$ plane. Plot the indifference curve that goes through the endowment point $\left(y_{1}, y_{2}\right)$. What value of $R$ will make the agent "happy" eating precisely his endowment each period?)

Let us return to the original formulation of the problem:

$$
\max _{c_{1}, c_{2}}\left\{U\left(c_{1}\right)+\beta U\left(c_{2}\right) \text { s.t. } c_{1}=y_{1}-s, c_{2}=y_{2}+s R\right\}
$$

Solving for $s$ in one of the constraints, and substituting the result in the other, we can consolidate the two restrictions into a single lifetime budget constraint:

$$
\begin{equation*}
c_{2}+c_{1} R=y_{2}+y_{1} R \tag{4}
\end{equation*}
$$

That is, the future value of lifetime consumption is equal to the future value of total income. Plotting the budget constraint (4) and the indifference curves on the plane $\left(c_{1}, c_{2}\right)$, the optimal solution corresponds to a tangency point, as shown in Figure A5.4.

Observe that for given values of $\left(y_{1}, y_{2}\right)$, changes in $R$ make the budget line rotate about the point $\left(y_{1}, y_{2}\right)$, which is always feasible (you can always eat your endowment during each period). Hence, for the agent to decide to remain at this point, it is enough to rotate the budget line until it is tangent to the indifference curve through $\left(y_{1}, y_{2}\right)$. Because the slope of the budget line is $-R$, we need $R^{0}=-$ slope of $I C$ at $\left(y_{1}, y_{2}\right)$.

An indifference curve is the locus of all combinations $\left(c_{1}, c_{2}\right)$ that yield the same utility level $u_{0}$; hence the equation of an indifference curve is

$$
U\left(c_{1}\right)+\beta U\left(c_{2}\right)=u_{0}
$$

Differentiating implicitly with respect to $c_{1}$,

$$
U^{\prime}\left(c_{1}\right)+\beta U^{\prime}\left(c_{2}\right) \frac{d c_{2}}{d c_{1}}=\left.0 \Rightarrow \frac{d c_{2}}{d c_{1}}\right|_{I C}=\frac{-U^{\prime}\left(c_{1}\right)}{\beta U^{\prime}\left(c_{2}\right)}
$$

and therefore, evaluating this expression at the endowment point,

$$
R^{0}=\frac{U^{\prime}\left(y_{1}\right)}{\beta U^{\prime}\left(y_{2}\right)}
$$

(v) Show that on one side of $R^{0}$ the agent is always a net saver in youth, and on the other always a net borrower. (What is the sign of $s^{\prime}\left(R^{0}\right)$ ? Note that this does not imply that $s()$ is always monotonic.)

We have seen before that if $s^{*} \leq 0$, then $s^{\prime}(R)>0$. In particular, if $R=R^{0}$, then $s^{*}=0$, and therefore $s^{\prime}\left(R^{0}\right)>0$. Hence, the savings function $s(R)$ crosses the horizontal axis with strictly positive slope and therefore can cross it only once. Although $s($ ) may very well not be monotonic in the region in which it is positive, it is true that

- if $R<R^{0}$, the agent is a net borrower $\left(s^{*}<0\right)$, and
- if $R>R^{0}$, he is a net saver $\left(s^{*}>0\right)$.

Problem 4.5. Consider now an economy in which there are two different types of agents who face the decision analyzed in Problem 4.4, but may have different endowment streams, discount factors, or utility functions. To simplify, assume that there is only one agent of each type, but they both behave competitively (i.e., taking the value of $R$ as given).

Let $s_{1}(R)$ and $s_{2}(R)$ be the savings functions for the two agents. In equilibrium, the credit market must clear (i.e., if one is a net borrower, the other must be a net lender), and aggregate savings must be zero. That is, we must have

$$
\begin{equation*}
Z(R) \equiv s_{1}(R)+s_{2}(R)=0 \tag{1}
\end{equation*}
$$

Show that under the assumptions of Problem 4.4 there exists at least one competitive equilibrium, that is, a value of $R$ for which (1) holds. (Let $R_{1}^{0}$ and $R_{2}^{0}$ be the autarkic interest factors for the two agents. Without loss of generality, we can assume that $R_{1}^{0}>R_{2}^{0}$. What happens when $R=R_{1}^{0}, R_{2}^{0}$ ?)

If $R=R^{\prime \prime}>R_{1}^{0}$, both agents want to save, and therefore $Z\left(R^{\prime \prime}\right)>0$. With $R=R^{\prime}<R_{2}^{0}$, both want to borrow, and $Z\left(R^{\prime}\right)<0$. By the intermediate-value theorem, there exists at least one $R^{*} \in\left(R^{\prime}, R^{\prime \prime}\right)$ such that $Z\left(R^{*}\right)=0$. That is, there exists at least one equilibrium interest rate (Figure A5.5).

## Chapter 6

Problem 1.3. Prove Theorem 1.2: Any intersection of convex sets is convex.

Let $\left\{X_{t}\right\}$ be a collection of convex sets, and consider two points in their intersection: $x^{\prime}$ and $x^{\prime \prime} \in \cap_{i} X_{i}$. Because $x^{\prime}$ and $x^{\prime \prime}$ belong to each of the $X_{i}^{\prime} \mathrm{s}$, and these are convex sets, we have, for any $\lambda \in[0,1]$, that

$$
x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{\prime \prime} \in X_{i} \forall
$$

implying that $x^{\lambda} \in \cap_{i} X_{i}$, as was to be shown.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-699.jpg?height=643&width=1072&top_left_y=176&top_left_x=207)

Figure A5.5. Existence of an equilibrium interest factor.

Problem 1.7. Prove Theorem 1.6: A set $X$ is convex if and only if every convex combination of points of $X$ lies in $X$.

The sufficiency result is obvious. If any convex combination of points in $X$ lies in $X$, then, in particular, any convex combination of two points of $X$ lies in $X$, which establishes the convexity of the set.

To prove the necessity part, observe first that the convexity of $X$ implies that any convex combination of two points of $X$ lies in $X$. We will now assume that this property holds for all convex combinations involving $k$ or fewer points of $X$ and show that the result follows for the case of $k+1$ points.

Consider a convex combination of $k+1$ points of $X, x_{1}, \ldots, x_{k+1}$,

$$
\begin{equation*}
y=\sum_{i=1}^{k+1} \lambda_{i} x_{i} \tag{1}
\end{equation*}
$$

with $\lambda_{i} \in[0,1]$ for all $i$ and $\sum_{i=1}^{k+1} \lambda_{i}=1$. We want to show that $y \in X$. If $\lambda_{k+1}=1$, then $\Sigma_{i=1}^{k} \lambda_{i}=0$, and because all $\lambda_{i}$ 's are nonnegative, it must be that $\lambda_{i}=0$ for all $i=1, \ldots, k$. Hence, $y=x_{k+1} \in X$, and we are done. Otherwise, $\lambda_{k+1}<1$, and

$$
\begin{equation*}
\sum_{i=1}^{k} \lambda_{i}=1-\lambda_{k+1}>0 \tag{2}
\end{equation*}
$$

We can then write (1) in the form

$$
\begin{equation*}
y=\sum_{i=1}^{k} \lambda_{i} x_{i}+\lambda_{k+1} x_{k+1}=\left(\sum_{i=1}^{k} \lambda_{i}\right)\left(\sum_{i=1}^{k} \frac{\lambda_{i}}{\sum_{j=1}^{k} \lambda_{j}} x_{i}\right)+\lambda_{k+1} x_{k+1} \tag{3}
\end{equation*}
$$

Now, because

$$
\sum_{i=1}^{k} \frac{\lambda_{i}}{\sum_{j=1}^{k} \lambda_{j}}=1
$$

the point

$$
\begin{equation*}
z=\sum_{i=1}^{k} \frac{\lambda_{i}}{\sum_{j=1}^{k} \lambda_{j}} x_{i} \tag{4}
\end{equation*}
$$

is a convex combination of $k$ points of $X$ and therefore lies in $X$ (by assumption). Using (2) and (4), equation (3) reduces to

$$
\begin{equation*}
y=\left(1-\lambda_{k+1}\right) z+\lambda_{k+1} x_{k+1} \tag{5}
\end{equation*}
$$

Hence, $y$ is a linear combination of two points in $X$, and it follows (again by assumption) that $y \in X$. This concludes the proof.

Problem 1.12. Show that the closure of a convex set is convex.

Let $X$ be a convex set. Given two points $x$ and $y$ in cl $X$, let $z=\lambda x+(1-\lambda) y$ for some $\lambda \in(0,1)$. We will show that $z$ is a closure point of $X$, that is, that for any $\varepsilon>0$ the ball $B_{\varepsilon}(z)$ contains at least one point of $X$.

Fix an arbitrary $\varepsilon>0$. Because $x$ and $y$ are both closure points of $X, B_{\varepsilon}(x) \cap X$ and $B_{\varepsilon}(y) \cap X$ are both nonempty. Take two points, $x^{\prime} \in B_{\varepsilon}(x) \cap X$ and $y^{\prime} \in$ $B_{\varepsilon}(y) \cap X$, and define

$$
z^{\prime}=\lambda x^{\prime}+(1-\lambda) y^{\prime}
$$

Then $z^{\prime} \in X$, by the convexity of $X$. Moreover, $z^{\prime} \in B_{\varepsilon}(z)$, for

$$
\begin{aligned}
\left\|z-z^{\prime}\right\|= & \left\|\lambda x+(1-\lambda) y-\lambda x^{\prime}-(1-\lambda) y^{\prime}\right\|=\left\|\lambda\left(x-x^{\prime}\right)+(1-\lambda)\left(y-y^{\prime}\right)\right\| \\
& \leq \lambda\left\|x-x^{\prime}\right\|+(1-\lambda)\left\|y-y^{\prime}\right\|<\varepsilon
\end{aligned}
$$

Hence, $B_{\varepsilon}(z) \cap X$ is nonempty for any $\varepsilon>0$, establishing that any linear combination of closure points of $X$ is also a closure point of $X$.

Problem 1.14. Using Theorem 1.13, show that given a convex set $X$ and an interior point $x$ of $X$, any ray emanating from $x$ contains at most one boundary point of $X$.

Suppose there are two boundary points of $X$ on this ray, say $y$ and $z$, with $z$ farther away from $x$ than $y$. Then $y \in[x, z)$, and because $x$ is an interior point and $z$ a closure point of $X, y$ is an interior point of $X$, by Theorem 1.13, contrary to our assumption.

Problem 1.17. Let $X$ be a convex set with a nonempty interior. Show that $\operatorname{int}(\mathrm{cl} X)=\operatorname{int} X$.

Because $X \subseteq \operatorname{cl} X$, it follows immediately that int $X \subseteq \operatorname{int}(\mathrm{cl} X$ ) without any further assumptions. Conversely, suppose $X$ is convex, with a nonempty interior, and let $x$ be an interior point of $\mathrm{cl} X$. Then $x$ is not a boundary point of $\mathrm{cl} X$, so by Theorem 1.16 it is not a boundary point of $X$ either. But $x$ is a closure point of $X$, and because $\operatorname{cl} X=$ int $X \cup$ bdy $X$, it must be an interior point.

Problem 1.22. Show that a point $x_{i}$ in a convex set $X$ is a relative interior point of $X$ if and only if either or both of the two following (equivalent) conditions hold:

(i) For any line $L$ in aff $X$, with $x_{i} \in L$, there exist points $x^{\prime}$ and $x^{\prime \prime}$ in $L \cap$ aff $X$ such that $x_{i} \in\left(x^{\prime}, x^{\prime \prime}\right)$.

(ii) For any point $x^{\prime} \in X$, with $x^{\prime} \neq x_{i}$, there is a point $x^{\prime \prime} \in X$ such that $x_{i} \in\left(x^{\prime}, x^{\prime \prime}\right)$. That is, the segment $\left[x^{\prime}, y\right]$ in $X$ can be extended beyond $x_{i}$ without leaving the set.

It is obvious that $x_{1} \in$ rint $X$ implies (i) (because $X$ contains a ball in aff $X$ around $x_{i}$ ) and that (i) implies (ii). We show that (ii) implies that $x_{i}$ is a relative interior point. We know that rint $X$ is not empty, so there exists some point $y \in \operatorname{rint} X$. If $y=x_{i}$, there is nothing further to prove. Otherwise there exists a point $z$ in $X$ such that $x_{i} \in(y, z)$, by (ii). But then $x_{i} \in$ rint $X$, by part (i) of Theorem 1.20.

Problem 1.23. Let $X$ be a convex set in $\mathbb{R}^{\mathrm{n}}$, with $\operatorname{int}(\mathrm{cl} X) \neq \varnothing$. Show that int $X$ is nonempty.

We prove the contrapositive statement. Suppose int $X$ is empty. Then, by Theorem 1.19, the affine hull of $X$ is contained in an ( $n-1)$-dimensional hyperplane $H$. Because $H$ is a closed set that contains $X$, it also contains cl $X$. And because $H$ has an empty interior, so does $\operatorname{cl} X$. Hence, int $(\mathrm{cl} X)$ is empty whenever int $X$ is empty.

Problem 2.6. Prove Theorem 2.5: Given a function $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}$, where $X$ is a convex set, define for each pair of points $x^{\prime}$ and $x^{\prime \prime}$ in $X$ the function $\phi$ by

$$
\phi(\lambda)=f\left[\lambda x^{\prime}+(1-\lambda) x^{\prime \prime}\right]
$$

Then $f$ is concave if and only if $\phi()$ is concave for all $x^{\prime}$ and $x^{\prime \prime}$ in $X$.

- First assume that $\phi$ is concave, and fix two arbitrary points $x^{\prime}$ and $x^{\prime \prime}$ in $X$. Then for each $\lambda \in[0,1]$, we have

$$
\phi(\lambda)=\phi[\lambda 1+(1-\lambda) 0] \geq \lambda \phi(1)+(1-\lambda) \phi(0)
$$

but then

$$
\phi(\lambda)=f\left[\lambda x^{\prime}+(1-\lambda) x^{\prime \prime}\right] \geq \lambda f\left(x^{\prime}\right)+(1-\lambda) f\left(x^{\prime \prime}\right)=\lambda \phi(1)+(1-\lambda) \phi(0)
$$

for all $\lambda \in[0,1]$. That is, $f()$ is concave.

- Assume that $f$ is concave, and fix two arbitrary points $x^{\prime}$ and $x^{\prime \prime}$ in $X$. We have to show that for any $\mu_{1}, \mu_{2} \in \mathbb{R}$ and all $\lambda \in[0,1]$,

$$
\begin{equation*}
\phi\left(\lambda \mu_{1}+(1-\lambda) \mu_{2}\right) \geq \lambda \phi\left(\mu_{1}\right)+(1-\lambda) \phi\left(\mu_{2}\right) \tag{1}
\end{equation*}
$$

To verify that this expression holds by the concavity of $f$, put

$$
\begin{aligned}
y^{1} & =\mu_{1} x^{\prime}+\left(1-\mu_{1}\right) x^{\prime \prime} \\
y^{2} & =\mu_{2} x^{\prime}+\left(1-\mu_{2}\right) x^{\prime \prime} \\
t & =\lambda \mu_{1}+(1-\lambda) \mu_{2}
\end{aligned}
$$

Then

$$
\begin{gathered}
\phi\left(\mu_{1}\right)=f\left[\mu_{1} x^{\prime}+\left(1-\mu_{1}\right) x^{\prime \prime}\right]=f\left(y^{1}\right) \\
\phi\left(\mu_{2}\right)=f\left[\mu_{2} x^{\prime}+\left(1-\mu_{2}\right) x^{\prime \prime}\right]=f\left(y^{2}\right) \\
\phi\left[\lambda \mu_{1}+(1-\lambda) \mu_{2}\right]=\phi(t)=f\left[t x^{\prime}+(1-t) x^{\prime \prime}\right]
\end{gathered}
$$

but notice that

$$
\begin{aligned}
t x^{\prime}+(1-t) x^{\prime \prime} & =\left[\lambda \mu_{1}+(1-\lambda) \mu_{2}\right] x^{\prime}+\left[1-\lambda \mu_{1}-(1-\lambda) \mu_{2}\right] x^{\prime \prime} \\
& =\lambda \mu_{1} x^{\prime}+(1-\lambda) \mu_{2} x^{\prime}+(1-\lambda+\lambda) x^{\prime \prime}-\lambda \mu_{1} x^{\prime \prime}-(1-\lambda) \mu_{2} x^{\prime \prime} \\
& =\lambda\left[\mu_{1} x^{\prime}+x^{\prime \prime}-\mu_{1} x^{\prime \prime}\right]+(1-\lambda)\left[\mu_{2} x^{\prime}+x^{\prime \prime}-\mu_{2} x^{\prime \prime}\right] \\
& =\lambda\left[\mu_{1} x^{\prime}+\left(1-\mu_{1}\right) x^{\prime \prime}\right]+(1-\lambda)\left[\mu_{2} x^{\prime}+\left(1-\mu_{2}\right) x^{\prime \prime}\right] \\
& =\lambda y^{1}+(1-\lambda) y^{2}
\end{aligned}
$$

Hence, (1) becomes

$$
f\left[\lambda y^{1}+(1-\lambda) y^{2}\right] \geq \lambda f\left(y^{1}\right)+(1-\lambda) f\left(y^{2}\right)
$$

which holds by the concavity of $f$.

Problem 2.9. Prove Theorem 2.8: Let $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}$ be a concave function and $g: \mathbb{R} \longrightarrow \mathbb{R}$ an increasing and concave function defined on an interval $I$ containing $f(X)$. Then the function $g[f(x)]$ is concave.

Because $f$ is concave on $X$, we have

$$
\begin{gather*}
(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right) \leq f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right] \equiv f\left(x^{\lambda}\right) \\
\quad \text { for any } x^{\prime} \text { and } x^{\prime \prime} \text { in } X \text { and any } \lambda \in[0,1] \tag{1}
\end{gather*}
$$

Using the facts that $g$ is nondecreasing and concave, we have

$$
g\left[f\left(x^{\lambda}\right)\right] \geq g\left[(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right)\right] \geq(1-\lambda) g\left[f\left(x^{\prime}\right)\right]+\lambda g\left[f\left(x^{\prime \prime}\right)\right]
$$

which shows that $g[f(x)]$ is concave.

Problem 2.11. Prove Theorem 2.10: Let $f$ and $g$ be concave functions $\mathbb{R}^{\mathrm{n}} \supseteq X$ $\longrightarrow \mathbb{R}$. Given arbitrary scalars $\alpha$ and $\beta \geq 0$, the function $h=\alpha f+\beta g$ is concave.

Take any two points $x^{\prime}$ and $x^{\prime \prime}$ in $X$. By the concavity of $f$ and $g$, we have

$$
\begin{aligned}
h\left(x^{\lambda}\right) & =\alpha f\left(x^{\lambda}\right)+\beta g\left(x^{\lambda}\right) \geq \alpha\left[(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right)\right]+\beta\left[(1-\lambda) g\left(x^{\prime}\right)+\lambda g\left(x^{\prime \prime}\right)\right] \\
& =(1-\lambda)\left[\alpha f\left(x^{\prime}\right)+\beta g\left(x^{\prime}\right)\right]+\lambda\left[\alpha f\left(x^{\prime}\right)+\beta g\left(x^{\prime}\right)\right]=(1-\lambda) h\left(x^{\prime}\right)+\lambda h\left(x^{\prime \prime}\right)
\end{aligned}
$$

for any $\lambda \in[0,1]$, which establishes the concavity of $h$.

Problem 2.13. Prove Theorem 2.12: Let $\left\{f^{s} ; s \in S\right\}$ be a (possibly infinite) family of concave functions $\mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}$, all of which are bounded below. Then the function $f$ defined on $X$ by $f(x)=\inf _{s \in S} f^{s}(x)$ is concave.

Because each $f^{i}$ is concave, its hypograph

$$
\operatorname{hyp} f^{i}=\left\{(y, x) \in \mathbb{R}^{\mathrm{n}+1} ; x \in X, y \leq f^{i}(x)\right\}
$$

is a convex set. Now, the hypograph of $f=\inf _{\mathrm{i} \in I} f^{l}$ is the intersection of the hypographs of all the $f^{i}$ s, because $y \leq f(x)$ if and only if $y \leq f^{i}(x)$ for all $i$. By the preceding result, $\operatorname{hyp} f$ is a convex set, and by Theorem $1.2, f$ is concave.

Problem 3.3. Prove Theorem 3.2: Let $f: \mathbb{R}^{\mathrm{n}} \supseteq X \longrightarrow \mathbb{R}$ be a real-valued function defined on a convex set $X \subseteq \mathbb{R}^{n}$. Then $f$ is quasiconcave if and only if the upper contour sets of $f$ are all convex, that is, if for any $\alpha \in \mathbb{R}$ the set $U_{\alpha}=\{x \in X$; $f(x) \geq \alpha\}$ is convex.

- Assume $U_{\alpha}$ is convex for all $\alpha$. Given any two points $x^{\prime}$ and $x^{\prime \prime}$ in $X$, put $m=\min \left\{f\left(x^{\prime}\right), f\left(x^{\prime \prime}\right)\right\}$. By assumption, $U_{m}=\{x \in X ; f(x) \geq m\}$ is convex, so $(1-\lambda) x^{\prime}+\lambda x^{\prime \prime} \in U_{m}$ for all $\lambda \in(0,1)$, but this means that

$$
f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right] \geq m=\min \left\{f\left(x^{\prime}\right), f\left(x^{\prime \prime}\right)\right\} \quad \text { (i.e., } f \text { is quasiconcave) }
$$

- Let $f$ be quasiconcave, and fix some arbitrary real number $\alpha$. If $U_{\alpha}$ is empty or consists of a single point, then it is convex by definition. Otherwise, choose $x^{\prime}$ and $x^{\prime \prime}$ in $U_{\alpha}$. Then $f\left(x^{\prime}\right) \geq \alpha$ and $f\left(x^{\prime \prime}\right) \geq \alpha$, and the quasiconcavity of $f$ implies that for any $\lambda \in(0,1)$,

$$
f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right] \geq \min \left\{f\left(x^{\prime}\right), f\left(x^{\prime \prime}\right)\right\} \geq \alpha
$$

Hence, for any $x^{\prime}$ and $x^{\prime \prime}$ in $U_{\alpha}$,

$$
(1-\lambda) x^{\prime}+\lambda x^{\prime \prime} \in U_{\alpha}
$$

which says that $U_{\alpha}$ is a convex set.

Problem 3.5. Prove Theorem 3.4: Let $f: \mathbb{R}^{\mathrm{n}} \supseteq X \rightarrow \mathbb{R}$ be a quasiconcave function defined on a convex set $X \subseteq \mathbb{R}^{\mathrm{n}}$, and let $g: \mathbb{R} \longrightarrow \mathbb{R}$ be a weakly increasing function defined on an interval $I$ that contains $f(X)$. Then the composite function $g[f(x)]$ is quasiconcave in $X$.

By the quasiconcavity of $f$ in $X$ we have, for any two points $x^{\prime}$ and $x^{\prime \prime}$ in $X$,

$$
f\left(x^{\prime}\right) \geq f\left(x^{\prime \prime}\right) \Rightarrow f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right] \geq f\left(x^{\prime \prime}\right) \forall \lambda \in(0,1)
$$

Because $g$ is nondecreasing, it does not reverse rankings, that is,

$$
f\left(x^{\prime}\right) \geq f\left(x^{\prime \prime}\right) \Leftrightarrow g\left[f\left(x^{\prime}\right)\right] \geq g\left[f\left(x^{\prime \prime}\right)\right]
$$

Now, $f\left(x^{\prime}\right) \geq f\left(x^{\prime \prime}\right)$ implies $f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right] \geq f\left(x^{\prime \prime}\right)$, and this in turn implies that

$$
g\left[f\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right]\right] \geq g\left[f\left(x^{\prime \prime}\right)\right] \forall \lambda \in(0,1)
$$

so $g(f)$ is quasiconcave.

Problem 3.6. Show that the Cobb-Douglas function

$$
f(x)=A \prod_{i=1}^{n} x_{i}^{\alpha_{i}}, \quad \text { where } \alpha_{i}>0 \forall i
$$

is quasiconcave for $x \gg \underline{0}$.

Consider the function

$$
g(x)=\ln f(x)=\ln A+\sum_{i=1}^{n} \alpha_{i} \ln x_{i}
$$

Then

$$
g_{i}(x)=\frac{\alpha_{i}}{x_{i}}, \quad g_{i i}(x)=\frac{-\alpha_{i}}{x_{i}^{2}}, \quad \text { and } \quad g_{i k}(x)=0 \quad \text { for } k \neq i
$$

Hence, the Hessian of $g, D^{2} g(x)$, is a diagonal matrix with entries of the form $-\alpha_{i} / x_{i}^{2}<0$, and its leading principal minors are of the form

$$
d_{1}=\frac{-\alpha_{1}}{x_{1}^{2}}<0, \quad d_{2}=\frac{\alpha_{1} \alpha_{2}}{x_{1}^{2} x_{2}^{2}}>0, \quad d_{3}=\frac{-\alpha_{1} \alpha_{2} \alpha_{3}}{x_{1}^{2} x_{2}^{2} x_{3}^{2}}<0, \ldots
$$

Thus, $g$ is (strictly) concave, by Theorems 2.18 and A.4, and $f(x)=e^{g(x)}$ is a monotonically increasing transformation of a concave function and therefore quasiconcave, by Theorem 3.4.

Problem 3.9. A $C^{1}$ function that has no critical points (i.e., such that $D f(x) \neq \underline{0}$ for all $x$ ) is said to be nonstationary. Show that a nonstationary $C^{1}$ quasiconcave function is pseudoconcave.

Let $x^{\prime}$ and $x^{\prime \prime}$ be any two points in the domain of $f$ such that $f\left(x^{\prime}\right)>f\left(x^{\prime \prime}\right)$. We will show that if

$$
\begin{equation*}
D f\left(x^{\prime \prime}\right)\left(x^{\prime}-x^{\prime \prime}\right) \leq 0 \tag{1}
\end{equation*}
$$

then we arrive at a contradiction. By the nonstationarity of $f$, at least one of the components of $D f\left(x^{\prime \prime}\right)$ is nonzero. For concreteness, suppose that $f_{1}\left(x^{\prime \prime}\right)>0$, and define the point $\hat{x}$ by

$$
\hat{x}_{1}=x_{1}^{\prime}-\varepsilon \text { and } \hat{x}_{i}=x_{i}^{\prime} \text { for } i=2, \ldots, n
$$

For $\varepsilon>0$ and sufficiently small, we have, by continuity, that $f(\hat{x})>f\left(x^{\prime \prime}\right)$, but, using expression (1),

$$
\begin{aligned}
D f\left(x^{\prime \prime}\right)\left(\hat{x}-x^{\prime \prime}\right) & =f_{1}\left(x^{\prime \prime}\right)\left(\hat{x}_{1}-x_{1}^{\prime \prime}\right)+\sum_{i=2}^{n} f_{i}\left(x^{\prime \prime}\right)\left(\hat{x}_{i}-x_{i}^{\prime \prime}\right) \\
& =f_{1}\left(x^{\prime \prime}\right)\left(x_{1}^{\prime}-x_{1}^{\prime \prime}-\varepsilon\right)+\sum_{i=2}^{n} f_{i}\left(x^{\prime \prime}\right)\left(x_{i}^{\prime}-x_{i}^{\prime \prime}\right) \\
& =-\varepsilon f_{1}\left(x^{\prime \prime}\right)+\sum_{i=1}^{n} f_{i}\left(x^{\prime \prime}\right)\left(x_{i}^{\prime}-x_{i}^{\prime \prime}\right) \\
& =-\varepsilon f_{1}\left(x^{\prime \prime}\right)+D f\left(x^{\prime \prime}\right)\left(x^{\prime}-x^{\prime \prime}\right) \leq-\varepsilon f_{1}\left(x^{\prime \prime}\right)+0<0
\end{aligned}
$$

(using assumption (1)). Hence, $f(\hat{x})>f\left(x^{\prime \prime}\right)$, but $D f\left(x^{\prime \prime}\right)\left(\hat{x}-x^{\prime \prime}\right)<0$, which contradicts the quasiconcavity of $f$.

Problem 3.10. Suppose $f: \mathbb{R}_{++}^{\mathrm{n}} \longrightarrow \mathbb{R}$ is $C^{1}$, homogeneous of degree 1 , and positive-valued. Show that $f$ is concave if and only if it is quasiconcave.

Concavity always implies quasiconcavity. To prove the other part of the theorem, let $x^{\prime}$ and $x^{\prime \prime}$ be two points in $\mathbb{R}_{++}^{\mathrm{m}}$. Because $f \geq 0$, we can define $\lambda$ by $\lambda=f\left(x^{\prime}\right) / f\left(x^{\prime \prime}\right)$ and $\lambda>0$. Because $f$ is homogeneous of degree 1 , we have

$$
\begin{equation*}
f\left(\lambda x^{\prime \prime}\right)=\lambda f\left(x^{\prime \prime}\right)=f\left(x^{\prime}\right) \tag{1}
\end{equation*}
$$

and quasiconcavity therefore implies that

$$
\begin{equation*}
D f\left(\lambda x^{\prime \prime}\right)\left(x^{\prime}-\lambda x^{\prime \prime}\right) \geq 0 \tag{2}
\end{equation*}
$$

Exploiting the properties of homogeneous functions, we will show that (1) implies $D f\left(x^{\prime \prime}\right)\left(x^{\prime}-x^{\prime \prime}\right) \geq f\left(x^{\prime}\right)-f\left(x^{\prime \prime}\right)$ and therefore the concavity of $f$.

First, notice that because $f$ is homogeneous of degree 1, its partial derivatives are homogeneous of degree 0 . Hence,

$$
\begin{equation*}
D f\left(\lambda x^{\prime \prime}\right)=D f\left(x^{\prime \prime}\right) \tag{3}
\end{equation*}
$$

Moreover, by Euler's theorem,

$$
\begin{equation*}
D f\left(x^{\prime \prime}\right) x^{\prime \prime}=f\left(x^{\prime \prime}\right) \tag{4}
\end{equation*}
$$

form

Using (1), (3), (4), and the definition of $\lambda$, expression (2) can be rewritten in the

$$
D f\left(\lambda x^{\prime \prime}\right)\left(x^{\prime}-\lambda x^{\prime \prime}\right)=D f\left(x^{\prime \prime}\right)\left(x^{\prime}-\lambda x^{\prime \prime}\right)=D f\left(x^{\prime \prime}\right) x^{\prime}-\lambda f\left(x^{\prime \prime}\right)=D f\left(x^{\prime \prime}\right) x^{\prime}-f\left(x^{\prime}\right) \geq 0
$$

from where

$$
\begin{equation*}
D f\left(x^{\prime \prime}\right) x^{\prime} \geq f\left(x^{\prime}\right) \tag{5}
\end{equation*}
$$

Finally, subtracting (4) from (5),

$$
D f\left(x^{\prime \prime}\right)\left(x^{\prime}-x^{\prime \prime}\right) \geq f\left(x^{\prime}\right)-f\left(x^{\prime \prime}\right)
$$

Because $x^{\prime}$ and $x^{\prime \prime}$ are arbitrary points in the positive orthant, $f$ is concave in this set.

Problem 3.12. Let $f: \mathbb{R}^{2} \supseteq X \longrightarrow \mathbb{R}$ be a $C^{2}$ function defined on an open and convex set $X \subseteq \mathbb{R}^{\mathrm{n}}$, with $f_{x}(x, y)>0$ and $f_{y}(x, y)>0$ for all $(x, y)$ in $X$. Show that $f(x, y)$ is quasiconcave in $X$ if and only if

$$
|B|=\left|\begin{array}{ccc}
0 & f_{x} & f_{y} \\
f_{x} & f_{x x} & f_{x y} \\
f_{y} & f_{x y} & f_{y y}
\end{array}\right|>0 \forall x \in X
$$

First, notice that

$$
\begin{aligned}
|B| & =\left|\begin{array}{ccc}
0 & f_{x} & f_{y} \\
f_{x} & f_{x x} & f_{x y} \\
f_{y} & f_{x y} & f_{y y}
\end{array}\right|=0+(-1)^{2+1} f_{x}\left|\begin{array}{ll}
f_{x} & f_{y} \\
f_{x y} & f_{y y}
\end{array}\right|+(-1)^{3+1} f_{y}\left|\begin{array}{cc}
f_{x} & f_{y} \\
f_{x x} & f_{x y}
\end{array}\right| \\
& =-f_{x}\left(f_{x} f_{y y}-f_{y} f_{x y}\right)+f_{y}\left(f_{x} f_{x y}-f_{y} f_{x x}\right)=2 f_{x y} f_{x} f_{y}-f_{x}^{2} f_{y y}-f_{y}^{2} f_{x x}
\end{aligned}
$$

Now, recall that the function $f$ is quasiconcave if and only if its upper contour sets, $U_{\alpha}=\{(x, y) \in X ; f(x, y) \geq \alpha\}$, are convex. Applying the implicit-function theorem to the equation $f(x, y)=\alpha$, we obtain a function $y=g(x)$, whose graph coincides with the $\alpha$ level set of $f$. Because the function $f()$ is increasing, $y \geq g(x)$ implies that $(x, y)$ lies in $U_{\alpha}$, and vice versa. Hence, the level set $U_{\alpha}$ is precisely the epigraph of the function $g()$. By Theorem 2.2, epi $g=U_{\alpha}$ is convex if and only
if $g()$ is a convex function. Because $g()$ is twice differentiable under our assumptions, we can check its concavity by computing its second derivative.

Substituting the function $y=g(x)$ into the equation of the level set, we obtain the identity $f(x, g(x))=\alpha$. Differentiating with respect to $x$,

$$
f_{x}(x, g(x))+f_{y}(x, g(x)) g^{\prime}(x)=0
$$

from where

$$
\begin{equation*}
g^{\prime}(x)=\frac{-f_{x}(x, g(x))}{f_{y}(x, g(x))} \tag{1}
\end{equation*}
$$

Differentiating this expression again,

$$
\begin{align*}
g^{\prime \prime}(x) & =\frac{-f_{y}\left[f_{x x}+f_{x y} g^{\prime}(x)\right]+f_{x}\left[f_{x y}+f_{y y} g^{\prime}(x)\right]}{f_{y}^{2}} \\
& =\frac{-f_{y} f_{x x}+f_{y} f_{x y}\left(f_{x} / f_{y}\right)+f_{x} f_{x y}-f_{x} f_{y y}\left(f_{x} / f_{y}\right)}{f_{y}^{2}} \\
& =\frac{-f_{y} f_{x x}+f_{x y} f_{x}+f_{x} f_{x y}-f_{x} f_{y y}\left(f_{x} / f_{y}\right)}{f_{y}^{2}} \frac{f_{y}}{f_{y}} \\
& =\frac{-f_{y}^{2} f_{x x}+2 f_{x y} f_{x} f_{y}-f_{x}^{2} f_{y y}}{f_{y}^{3}}=\frac{|B|}{f_{y}^{3}} \tag{2}
\end{align*}
$$

Because $f_{y}>0, g^{\prime \prime}(x)$ has the same sign as $|B|$. Hence, $g()$ is convex (and $f$ is therefore quasiconcave) if and only if $|B|>0$.

Problem 3.15. Show that the function $f(x)=x^{3}$ cannot be concavified in any set that has zero as an interior point.

Let $h$ be a $C^{1}$ and strictly increasing function, and define the function $g()$ on some interval $I=(-2 a, 2 a)$, with $a>0$, by $g(x)=h\left(x^{3}\right)$. We will show that for any such function, there exist two points in $I, x$ and $x_{0}$, such that

$$
\begin{equation*}
g(x)>g\left(x_{0}\right)+g^{\prime}\left(x_{0}\right)\left(x-x_{0}\right) \tag{1}
\end{equation*}
$$

(This inequality implies that $g()$ is not concave, by Theorem 2.17.)

In particular, let $x^{0}=0$ and $x=a$. Then

$$
g^{\prime}\left(x_{0}\right)=3 x^{3} h^{\prime}\left(x_{0}\right)=0
$$

and (1) becomes

$$
g(a)=h\left(a^{3}\right)>h(0)+0 a=h(0)
$$

Because $a^{3}>0$ and $h()$ is strictly increasing, this inequality holds.

## Chapter 7

Problem 1.5. Let $f: \mathbb{R}^{\mathrm{n}} \longrightarrow \mathbb{R}$ be a $C^{2}$ function. Show that if $f$ achieves a local maximum at $x^{*}$, then the Hessian of $f$ at $x^{*}$ is negative semidefinite, that is,

$$
h^{T} D^{2} f\left(x^{*}\right) h \leq 0 \forall h \in \mathbb{R}^{\mathrm{n}}
$$

Fix an arbitrary $h \in \mathbb{R}^{\mathrm{n}}$. For any given $\alpha>0$ we can use Taylor's theorem to write

$$
\begin{equation*}
f\left(x^{*}+\alpha h\right)-f\left(x^{*}\right)=D f\left(x^{*}\right)(\alpha h)+\frac{\alpha^{2}}{2} \Delta x^{T} D^{2} f\left(x^{*}+\lambda_{\alpha} \alpha h\right) h \tag{1}
\end{equation*}
$$

for some $\lambda_{\alpha} \in(0,1)$. If $x^{*}$ is a local maximizer, we have $D f\left(x^{*}\right)=\underline{0}$, and (1) reduces to

$$
\begin{equation*}
f\left(x^{*}+\alpha h\right)-f\left(x^{*}\right)=\frac{\alpha^{2}}{2} h^{T} D^{2} f\left(x^{*}+\lambda_{\alpha} \alpha h\right) h \tag{2}
\end{equation*}
$$

Moreover, it must be true that for any sufficiently small $\alpha$ we have

$$
f\left(x^{*}+\alpha h\right) \leq f\left(x^{*}\right)
$$

Hence,

$$
\frac{\alpha^{2}}{2} h^{T} D^{2} f\left(x^{*}+\lambda_{\alpha} \alpha h\right) h \leq 0
$$

for any sufficiently small $\alpha$. Taking limits as $\alpha \rightarrow 0$, we obtain the desired result.

Problem 1.7. Let $f: \mathbb{R}^{n} \longrightarrow \mathbb{R}$ be a $C^{1}$ concave function. Show that if $x^{*}$ is a critical point of $f$, then it is a global maximizer of $f$.

Let $x^{*}$ be a critical point of $f()$, and consider an arbitrary point $x$ in $\mathbb{R}^{n}$. By the concavity of $f$, we have

$$
\begin{equation*}
f(x) \leq f\left(x^{*}\right)+D f\left(x^{*}\right)\left(x-x^{*}\right) \tag{1}
\end{equation*}
$$

Because $x^{*}$ is a critical point, $D f\left(x^{*}\right)=\underline{0}$, and (1) reduces to

$$
f\left(x^{*}\right) \geq f(x)
$$

Because $x$ is an arbitrary point in $\mathbb{R}^{\mathrm{n}}, x^{*}$ is a global maximizer of $f()$.

Problem 1.8. Let $f: \mathbb{R}^{n} \longrightarrow \mathbb{R}$ be a concave function. Show that if $x^{*}$ is a local maximizer of $f$, then it is also a global maximizer.

By contradiction. Assume that $f$ attains a global maximum at $x^{\prime} \neq x^{*}$. Then $f\left(x^{\prime}\right)>f\left(x^{*}\right)$, and the concavity of $f()$ implies

$$
f\left(x^{\lambda}\right)=f\left[(1-\lambda) x^{\prime}+\lambda x^{*}\right] \geq(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{*}\right)>f\left(x^{*}\right) \forall \lambda \in(0,1)
$$

Now, for any given $\varepsilon>0$ we can choose $\lambda$ small enough that $x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{*}$ $\in B_{\varepsilon}\left(x^{*}\right)$, and we still have that $f\left(x^{\lambda}\right)>f\left(x^{*}\right)$. Hence, $x^{*}$ cannot be a local maximizer.

Problem 1.10. Let $A=\left[a_{i k}\right]$ be an $n \times n$ matrix, and consider the quadratic form $h^{T} A h=\Sigma_{i} \Sigma_{k} h_{i} a_{i k} h_{k}$. Using the Cauchy-Schwarz inequality, show that

$$
\left|h^{T} A h\right| \leq \sqrt{\sum_{i} \sum_{k} a_{i k}^{2}}\|h\|^{2}
$$

where $\|\cdot\|$ is the Euclidean norm. Using this result, verify that the function $Q(\alpha)$ in the proof of Theorem 1.9 is continuous at zero (provided $f$ is $C^{2}$ ) by showing that $|Q(\alpha)-Q(0)| \rightarrow 0$ as $\alpha \rightarrow 0$.

Let $\alpha_{i}$ and $\beta_{i}, i=1, \ldots, n$, be real numbers; then, by the Cauchy-Schwarz inequality (taking roots of both sides), we have

$$
\left|\sum_{i=1}^{n} \alpha_{i} \beta_{l}\right| \leq \sqrt{\sum_{i=1}^{n} \alpha_{i}^{2}} \sqrt{\sum_{i=1}^{n} \beta_{l}^{2}}
$$

Using this inequality twice, and the triangle inequality, we can write

$$
\begin{aligned}
\left|h^{T} A h\right|= & \left|\sum_{i} h_{i}\left(\sum_{k} a_{i k} h_{k}\right)\right| \leq\left|\sum_{i} h_{i}\left(\sqrt{\sum_{k} a_{i k}^{2}} \sqrt{\sum_{k} h_{k}^{2}}\right)\right| \\
& \leq\|h\| \sum_{i}\left|h_{i}\right| \sqrt{\sum_{k} a_{i k}^{2}} \leq\|h\| \sqrt{\sum_{i} h_{i}^{2}} \sqrt{\sum_{i}\left(\sqrt{\sum_{k} a_{i k}^{2}}\right)^{2}} \\
& =\|h\|^{2} \sqrt{\sum_{i} \sum_{k} a_{i k}^{2}}
\end{aligned}
$$

Next, for any fixed $h$ we have

$$
\begin{aligned}
0 \leq|Q(\alpha)-Q(0)|= & \left|h^{T}\left[D^{2} f\left(x^{*}+\lambda_{\alpha} \alpha h\right)-D^{2} f\left(x^{*}\right)\right] h\right| \\
& \leq\|h\|^{2} \sqrt{\sum_{l} \sum_{k}\left[f_{i k}\left(x^{*}+\lambda_{\alpha} \alpha h\right)-f_{i k}\left(x^{*}\right)\right]^{2}}
\end{aligned}
$$

Because $f$ is $C^{2}$, the partial derivatives are continuous functions. As $\alpha \rightarrow 0$, $x^{*}+\lambda_{\alpha} \alpha h \rightarrow x^{*}$ (because $0 \leq \lambda_{\alpha} \alpha \leq \alpha$ ), and by the continuity of the second partials, $\left|f_{i k}\left(x^{*}+\lambda_{\alpha} \alpha h\right)-f_{t k}\left(x^{*}\right)\right| \rightarrow 0$, implying that $Q(\alpha) \rightarrow Q(0)$, that is, $Q$ is continuous at zero.

Problem 1.12. Derivation of factor demand functions. Consider a competitive firm that produces a single output $y$ using two inputs $x_{1}$ and $x_{2}$. The firm's production technology is described by a Cobb-Douglas function

$$
y=f\left(x_{1}, x_{2}\right)=x_{1}^{\alpha} x_{2}^{\beta}, \quad \text { where } \beta+\alpha<1, \beta>0, \text { and } \alpha>0
$$

Taking as given the price of its output $p$ and input prices $w_{1}$ and $w_{2}$, the firm maximizes its profits, given by

$$
\Pi\left(x_{1}, x_{2}\right)=p x_{1}^{\alpha} x_{2}^{\beta}-w_{1} x_{1}-w_{2} x_{2}
$$

Write the first-order conditions for the firm's problem, and check that the sufficient conditions for a maximum are satisfied. Using the first-order conditions, solve for the firm's optimal factor demands $x_{i}^{*}$ as functions of input and output prices.

The first-order conditions (FOCs) for the firm's problem,

$$
\max _{x_{1}, x_{2}} \Pi=p x_{1}^{\alpha} x_{2}^{\beta}-w_{1} x_{1}-w_{2} x_{2}
$$

are given by

$$
\begin{align*}
& \frac{\partial \Pi}{\partial x_{1}}=p \alpha x_{1}^{\alpha-1} x_{2}^{\beta}-w_{1}=0  \tag{1}\\
& \frac{\partial \Pi}{\partial x_{2}}=p \beta x_{1}^{\alpha} x_{2}^{\beta-1}-w_{2}=0 \tag{2}
\end{align*}
$$

To establish that (1) and (2) actually characterize a maximum rather than a minimum, we show that the production function $f()$ is strictly concave provided that $\alpha+\beta<1$, as assumed. As discussed elsewhere, $f()$ will be concave provided its Hessian is negative definite. One way to check this is to show that the leading principal minors, $d_{1}$ and $d_{2}$, alternate in sign, with $d_{1}<0$ and $d_{2}>0$.

The first and second partial derivatives of $f()$ are given by

$$
\begin{gathered}
f_{1}=\alpha x_{1}^{\alpha-1} x_{2}^{\beta}=\frac{\alpha y}{x_{1}} \\
f_{2}=\beta x_{1}^{\alpha} x_{2}^{\beta-1}=\frac{\beta y}{x_{2}} \\
f_{11}=\alpha(\alpha-1) x_{1}^{\alpha-2} x_{2}^{\beta}=\frac{\alpha(\alpha-1) y}{x_{1}^{2}} \\
f_{22}=\beta(\beta-1) x_{1}^{\alpha} x_{2}^{\beta-2}=\frac{\beta(\beta-1) y}{x_{2}^{2}} \\
f_{12}=f_{21}=\alpha \beta x_{1}^{\alpha-1} x_{2}^{\beta-1}=\frac{\alpha \beta y}{x_{1} x_{2}}
\end{gathered}
$$

We can now check the sign of the leading principal minors:

$$
\begin{gathered}
d_{1}=f_{11}=\frac{\alpha(\alpha-1) y}{x_{1}^{2}}<0 \\
d_{2}=|H|=\left|D^{2} f(x)\right|=\left|\begin{array}{l}
f_{11} f_{12} \\
f_{21} f_{22}
\end{array}\right|=f_{11} f_{22}-f_{12} f_{21}=\frac{\alpha \beta(1-\alpha-\beta) y^{2}}{x_{1}^{2} x_{2}^{2}}>0
\end{gathered}
$$

provided $\alpha+\beta<1$.

Hence, the production function is concave, and this implies that the objective function

$$
\Pi=p f\left(x_{1}, x_{2}\right)-w_{1} x_{1}-w_{2} x_{2}
$$

is also concave (why?), which guarantees that the FOCs characterize a maximum.

To derive the input demand functions we need to solve the FOCs for $x_{1}$ and $x_{2}$ as functions of input and output prices. From (1) and (2) we have

$$
\begin{align*}
& \frac{p \alpha y}{x_{1}}=w_{1}  \tag{3}\\
& \frac{p \beta y}{x_{2}}=w_{2} \tag{4}
\end{align*}
$$

Dividing (3) by (4),

$$
\begin{equation*}
\frac{w_{1}}{w_{2}}=\frac{\alpha x_{2}}{\beta x_{1}} \Rightarrow x_{2}=\frac{\beta w_{1} x_{1}}{\alpha w_{2}} \tag{5}
\end{equation*}
$$

Substituting (5) back into (1),

$$
\begin{aligned}
w_{1} & =p \alpha x_{1}^{\alpha-1} x_{2}^{\beta}=p \alpha x_{1}^{\alpha-1} \frac{\left(\beta w_{1} x_{1}\right)^{\beta}}{\left(\alpha w_{2}\right)^{\beta}}=p \alpha^{1-\beta} w_{1}^{\beta} w_{2}^{-\beta} \beta^{\beta} x_{1}^{\alpha+\beta-1} \\
& \Rightarrow x_{1}^{*}=x_{1}\left(p, w_{1}, w_{2}\right)=\left(\frac{p \alpha^{1-\beta} \beta^{\beta} w_{1}^{\beta}}{w_{2}^{\beta}}\right)^{1 /(1-\alpha-\beta)}
\end{aligned}
$$

which is the demand for $x_{1}$. The demand for the other input can be obtained in the same way.

Problem 1.15. Prove Theorem 1.14: Let $f()$ be pseudoconcave, and all $g^{\prime}(x)$ quasiconcave. If $\left(x^{*}, \lambda^{*}\right)$ satisfy the Lagrange condition, $D f\left(x^{*}\right)+\lambda^{* T} D g\left(x^{*}\right)=\underline{0}$, with $x^{*}$ feasible and $\lambda * \geq \underline{0}$, then $x^{*}$ is an optimal solution to the Lagrange problem (P.L).

Assume that $f$ is pseudoconcave, the constraint functions are all quasiconcave, and $\lambda^{*} \geq 0$. We will show that if $x^{*}$ is not optimal, then it cannot satisfy the Lagrange condition.

Suppose $x^{*}$ is not an optimal solution of (P.L). Then there exists some feasible $x \neq x^{*}$ such that $f(x)>f\left(x^{*}\right)$. By the pseudoconcavity of $f$,

$$
\begin{equation*}
f(x)>f\left(x^{*}\right) \Rightarrow D f\left(x^{*}\right)\left(x-x^{*}\right)>0 \tag{1}
\end{equation*}
$$

Because $x$ and $x^{*}$ are both feasible, $g^{j}(x)=g^{j}\left(x^{*}\right)=0$ for all $j=1, \ldots, c$. By the quasiconcavity of the constraint functions, this implies

$$
\begin{equation*}
D g^{j}\left(x^{*}\right)\left(x-x^{*}\right) \geq 0 \forall j \Rightarrow D g\left(x^{*}\right)\left(x-x^{*}\right) \geq \underline{0} \tag{2}
\end{equation*}
$$

Now we form the expression that appears in the Lagrange condition and evaluate it at $x^{*}$. From (1) and (2) we have, for any $\lambda^{*} \geq \underline{0}$,

$$
0<D f\left(x^{*}\right)\left(x-x^{*}\right)+\lambda^{* T} D g\left(x^{*}\right)\left(x-x^{*}\right)=\left[D f\left(x^{*}\right)+\lambda^{* T} D g\left(x^{*}\right)\right]\left(x-x^{*}\right)
$$

from where

$$
D f\left(x^{*}\right)+\lambda *^{T} D g\left(x^{*}\right) \neq \underline{0}
$$

Hence, the Lagrange condition does not hold at $x^{*}$.

Problem 1.17. Solve the problem $\max _{x, y, z}\left\{2 x-2 y+z\right.$ s.t. $\left.x^{2}+y^{2}+z^{2}=9\right\}$ by the method of Lagrange multipliers. Use the sufficient second-order conditions for a strict maximum to determine which of the two solutions to the system of firstorder conditions yields a maximum. Verify that this is correct by comparing the values of the objective function in both cases.

The Lagrangian is

$$
£=2 x-2 y+z+\lambda\left[x^{2}+y^{2}+z^{2}-9\right]
$$

Differentiating $£$ with respect to the choice variables and the multiplier, we obtain the first-order necessary conditions for the problem:

$$
\begin{align*}
& \frac{\partial £}{\partial x}=2+2 \lambda x=0 \Rightarrow x=\frac{-1}{\lambda}  \tag{1}\\
& \frac{\partial £}{\partial y}=-2+2 \lambda y=0 \Rightarrow y=\frac{1}{\lambda}  \tag{2}\\
& \frac{\partial £}{\partial z}=1+2 \lambda z=0 \Rightarrow z=\frac{-1}{2 \lambda}  \tag{3}\\
& \frac{\partial £}{\partial \lambda}=0 \Rightarrow x^{2}+y^{2}+z^{2}=9 \tag{4}
\end{align*}
$$

Substituting (1)-(3) into (4),

$$
\left(\frac{1}{\lambda^{2}}+\frac{1}{\lambda^{2}}+\frac{1}{4 \lambda^{2}}\right)=\frac{9}{4 \lambda^{2}}=9 \Rightarrow \lambda= \pm \frac{1}{2}
$$

Hence, we have two candidate solutions:

$$
\begin{aligned}
& \lambda_{1}=\frac{1}{2}, \quad x_{1}=-2, \quad y_{1}=2, \quad z_{1}=-1 \\
& \lambda_{2}=-\frac{1}{2}, \quad x_{2}=2, \quad y_{2}=-2, \quad z_{2}=1
\end{aligned}
$$

Substituting them into the objective function,

$$
f\left(x_{1}, y_{1}, z_{1}\right)=-4-4-1=-9 \text { and } f\left(x_{2}, y_{2}, z_{2}\right)=4+4+1=9
$$

so the second point is the maximizer we seek.

To apply Theorem 1.16 (sufficient conditions for a strict local maximum), we have to check the leading principal minors of the bordered Hessian:

$$
H=\left[\begin{array}{cccc}
0 & g_{x} & g_{y} & g_{z} \\
g_{x} & £_{x x} & \mathfrak{£}_{x y} & \mathfrak{£}_{x z} \\
g_{y} & £_{y x} & \mathfrak{£}_{y y} & \mathfrak{£}_{y z} \\
g_{z} & \mathfrak{£}_{z x} & \mathfrak{£}_{z y} & \mathfrak{£}_{z z}
\end{array}\right]=\left[\begin{array}{cccc}
0 & 2 x & 2 y & 2 z \\
2 x & 2 \lambda & 0 & 0 \\
2 y & 0 & 2 \lambda & 0 \\
2 z & 0 & 0 & 2 \lambda
\end{array}\right]
$$

For a maximum, we need this matrix to be negative definite subject to the constraints $D g\left(x^{*}\right) h=0$. This requires that the last three principal minors of $H$ alternate in sign, with $(-1)^{r} H_{r}>0$ for $r=1,2,3$.

Now

$$
\begin{aligned}
& (-1)\left|H_{1}\right|=-\left|\begin{array}{cc}
0 & 2 x \\
2 x & 2 \lambda
\end{array}\right|=4 x^{2}>0 \\
& (-1)^{2}\left|H_{2}\right|=\left|\begin{array}{ccc}
0 & 2 x & 2 y \\
2 x & 2 \lambda & 0 \\
2 y & 0 & 2 \lambda
\end{array}\right|=-8 \lambda y^{2}-8 \lambda x^{2}=-8 \lambda\left(x^{2}+y^{2}\right)>0, \quad \text { with } \lambda_{2}=-\frac{1}{2} \\
& \left.(-1)^{3}\left|H_{3}\right|=-(-1)^{3} 2 x\left|\begin{array}{ccc}
2 x & 2 y & 2 z \\
0 & 2 \lambda & 0 \\
0 & 0 & 2 \lambda
\end{array}\right|+(-1)^{4} 2 y\left|\begin{array}{ccc}
2 x & 2 y & 2 z \\
2 \lambda & 0 & 0 \\
0 & 0 & 2 \lambda
\end{array}\right|+(-1)^{5} 2 z\left|\begin{array}{ccc}
2 x & 2 y & 2 z \\
2 \lambda & 0 & 0 \\
0 & 2 \lambda & 0
\end{array}\right|\right) \\
& =-\left\{(-1) 2 x\left(8 x \lambda^{2}\right)+2 y\left(-8 y \lambda^{2}\right)-2 z\left(8 z \lambda^{2}\right)\right\}=16 \lambda^{2}\left(x^{2}+y^{2}+z^{2}\right)>0
\end{aligned}
$$

Problem 1.21. Integral objective and constraint functions. Let $f: \mathbb{R}^{\mathrm{n}+1} \rightarrow \mathbb{R}$ and $g: \mathbb{R}^{\mathrm{n}+1} \longrightarrow \mathbb{R}$ be $C^{1}$ functions, and consider the problem

$$
\begin{equation*}
\max _{x(s), s \in[a, b]}\left\{\int_{a}^{b} f[x(s), s] d s \text { s.t. } \int_{a}^{b} g[x(s), s] d s \geq 0\right\} \tag{P.I}
\end{equation*}
$$

(i) Let $x^{*}(s)$ be an optimal solution function for (P.I), and let us consider a feasible variation from this function. In particular, we will consider a two-parameter family of functions of the form

$$
\tilde{x}(s)=x^{*}(s)+\alpha y(s)+\beta z(s)
$$

where $y(s)$ and $z(s)$ are arbitrary functions from $\mathbb{R}$ to $\mathbb{R}^{\mathrm{n}}$, and the parameters $\alpha$ and $\beta$ will be chosen so that, given $y()$ and $z()$, the constraint holds.

Now consider the problem

$$
\begin{equation*}
\max _{\alpha, \beta}\left\{F(\alpha, \beta)=\int_{a}^{b} f[\tilde{x}(s), s] d s \text { subject to } G(\alpha, \beta)=\int_{a}^{b} g[\tilde{x}(s), s] d s \geq 0\right\} \tag{P.I'}
\end{equation*}
$$

and observe that the solution of the transformed problem involves setting $\alpha$ and $\beta$ equal to zero. Introducing a multiplier $\lambda$, we define the Lagrangian

$$
£(\alpha, \beta, \lambda)=\int_{a}^{b} £_{s}[\tilde{x}(s), \lambda, s] d s=\int_{a}^{b}(f[\tilde{x}(s), s]+\lambda g[\tilde{x}(s), s]) d s
$$

Use the Kuhn-Tucker theorem to derive the following first-order conditions:

$$
\begin{gather*}
D_{x} £_{s}\left[x^{*}(s), \lambda, s\right]=D_{x} f\left[x^{*}(s), s\right]+\lambda D_{x} g\left[x^{*}(s), s\right]=\underline{0}  \tag{K-T}\\
\int_{a}^{b} g\left[x^{*}(s), s\right] d s \geq 0 \text { and } \int_{a}^{b} g\left[x^{*}(s), s\right] d s=0 \quad \text { if } \lambda>0 \\
\lambda \geq 0 \text { and } \lambda=0 \text { if } \int_{a}^{b} g\left[x^{*}(s), s\right] d s>0 \tag{C-S}
\end{gather*}
$$

Applying the Kuhn-Tucker theorem to (P.I') and evaluating the resulting conditions at $\alpha=\beta=0$, we have

$$
\begin{align*}
D_{\alpha} £(\alpha, \beta, \lambda) & =\int_{a}^{b} D_{x} £_{s}\left(x_{s}^{*}, \lambda, s\right) y(s) d s \\
& =\int_{a}^{b}\left[D_{x} f\left(x_{s}^{*}, s\right)+\lambda D_{x} g\left(x_{s}^{*}, s\right)\right] y(s) d s=0  \tag{1}\\
D_{\beta} £(\alpha, \beta, \lambda) & =\int_{a}^{b} D_{x} £_{s}\left(x_{s}^{*}, \lambda, s\right) z(s) d s \\
& =\int_{a}^{b}\left[D_{x} f\left(x_{s}^{*}, s\right)+\lambda D_{x} g\left(x_{s}^{*}, s\right)\right] z(s) d s=0 \tag{2}
\end{align*}
$$

$$
\begin{gather*}
\int_{a}^{b} g\left(x_{s}^{*}, s\right) d s \geq 0 \text { and } \int_{a}^{b} g\left(x_{s}^{*}, s\right) d s=0 \text { if } \lambda>0 \\
\lambda \geq 0 \text { and } \lambda=0 \text { if } \int_{a}^{b} g\left(x_{s}^{*}, s\right) d s>0 \tag{C-S}
\end{gather*}
$$

Notice, moreover, that (1) and (2) must hold for any functions $y(s)$ and $z(s)$. This implies that the terms inside the brackets must be zero for each $s$.

(ii) Assume that $f(x, s)$ and $g(x, s)$ are concave in $x$ for each $s$, and let $x *(s)$ be a choice function that satisfies the first-order conditions for the problem. Show that $x^{*}(s)$ solves (P.I).

Let $x_{s}$ be an arbitrary feasible choice function. By the concavity of $f()$ and $g($ ), we have, for each $s$,

$$
\begin{align*}
& f_{s}\left(x_{s}\right) \leq f_{s}\left(x_{s}^{*}\right)+D_{x} f_{s}\left(x_{s}^{*}\right)\left(x_{s}-x_{s}^{*}\right) \Rightarrow f_{s}\left(x_{s}^{*}\right)-f_{s}\left(x_{s}\right) \geq-D_{x} f_{s}\left(x_{s}^{*}\right)\left(x_{s}-x_{s}^{*}\right)  \tag{3}\\
& g_{s}\left(x_{s}\right) \leq g_{s}\left(x_{s}^{*}\right)+D_{x} g_{s}\left(x_{s}^{*}\right)\left(x_{s}-x_{s}^{*}\right) \Rightarrow D_{x} g_{s}\left(x_{s}^{*}\right)\left(x_{s}-x_{s}^{*}\right) \geq g_{s}\left(x_{s}\right)-g_{s}\left(x_{s}^{*}\right) \tag{4}
\end{align*}
$$

Integrating (3) between $a$ and $b$, and using (4) and (K-T), we have

$$
\begin{aligned}
& \int_{a}^{b}\left[f_{s}\left(x_{s}^{*}\right)-f_{s}\left(x_{s}\right)\right] d s \geq-\int_{a}^{h} D_{x} f_{s}\left(x_{s}^{*}\right)\left(x_{s}-x_{s}^{*}\right) d s=\lambda \int_{a}^{b} D_{x} g_{s}\left(x_{s}^{*}\right)\left(x_{s}-x_{s}^{*}\right) d s \\
& \quad \geq \lambda \int_{a}^{b}\left[g_{s}\left(x_{s}\right)-g_{s}\left(x_{s}^{*}\right)\right] d s=\lambda \int_{a}^{b} g_{s}\left(x_{s}\right) d s-\lambda \int_{a}^{b} g_{s}\left(x_{s}^{*}\right) d s=\lambda \int_{a}^{b} g_{s}\left(x_{s}\right) d s-0 \geq 0
\end{aligned}
$$

Notice that $\lambda \int_{a}^{b} g_{s}\left(x_{s}^{*}\right) d s=0$, by (C-S), and that the last inequality follows because $\lambda \geq 0$, by (C-S), and $\int_{a}^{b} g_{s}\left(x_{s}\right) d s \geq 0$, by the feasibility of $x_{s}$. Hence we conclude that

$$
\int_{a}^{b} f_{s}\left(x_{s}^{*}\right) d s \geq \int_{a}^{b} f_{s}\left(x_{s}\right) d s
$$

for any feasible but otherwise arbitrary choice function $x_{s}$. This establishes the desired result.

Problem 2.5. Extend the proof of Lemmas 2.3 and 2.4 to the case of several constraints.

- Lemma 2.3: We know that there exists some $x^{\prime} \in C\left(\alpha^{0}\right)$ such that $g^{i}\left(x^{\prime}, \alpha^{0}\right)=m_{i}$ $>0$ for each $i$. Let $m=\min _{i}\left\{m_{i}\right\}$, and choose $\lambda$ so that

$$
\begin{equation*}
(1-\lambda) m-\lambda \varepsilon>0 \tag{1}
\end{equation*}
$$

Construct the sequence $\left\{y_{n}\right\}$ as before, with

$$
y_{n}=(1-\lambda) x^{\prime}+\lambda x_{n}
$$

and use the concavity of $g^{i}()$ in $x$ to establish that

$$
g^{i}\left(y_{n}, \alpha^{0}\right) \geq(1-\lambda) g^{2}\left(x^{\prime}, \alpha^{0}\right)+\lambda g^{i}\left(x_{n}, \alpha^{0}\right) \geq(1-\lambda) m_{i}-\lambda \varepsilon \geq(1-\lambda) m-\lambda \varepsilon>0
$$

for all $i=1, \ldots, c$. Hence $y_{n} \in C\left(\alpha^{0}\right)$ for all $n$, and the rest of the argument is as before.

- Lemma 2.4: Conditions (1)-(3) in the proof of Lemma 2.4 now become

$$
\begin{gather*}
g^{i}\left(x_{n}, \alpha_{n}\right) \geq 0 \\
g^{i}\left(x_{n}, \alpha^{0}\right)<-\varepsilon \\
g^{i}\left(x^{\prime}, \alpha^{0}\right)>0
\end{gather*}
$$

for all $n$ and all $i=1, \ldots, c$. As before, ( $\left(^{\prime}\right)$ implies that there exists some $N$ such that

$$
g^{i}\left(x^{\prime}, \alpha_{n}\right)>0 \forall i \text { and } \forall n>N
$$

Define the function

$$
g(x)=\min _{i} g^{i}\left(x, \alpha^{0}\right)
$$

and observe that $g()$ is continuous and concave, by the continuity of the $g^{i}()$ 's and their concavity in $x$, and that (2) and (3) imply that

$$
\begin{equation*}
g\left(x_{n}\right)<-\varepsilon \forall n \text { and } g\left(x^{\prime}\right)>0 \tag{5}
\end{equation*}
$$

Using this expression, the continuity of $g()$ implies that for each $n$ there is a point $y_{n}$ of the form

$$
\begin{equation*}
y_{n}=\left(1-\lambda_{n}\right) x^{\prime}+\lambda_{n} x_{n}, \quad \text { with } \lambda_{n} \in(0,1) \tag{6}
\end{equation*}
$$

such that

$$
g\left(y_{n}\right)=\min _{i} g^{i}\left(y_{n}, \alpha^{0}\right)=-\varepsilon
$$

Hence,

$$
\begin{equation*}
g^{i}\left(y_{n}, \alpha^{0}\right) \geq-\varepsilon \forall i=1, \ldots, c \tag{7}
\end{equation*}
$$

which implies that $y_{n} \in C_{\varepsilon}\left(\alpha^{0}\right)$ for all $n$, and for each $n$ there exists some $j_{n} \in\{1, \ldots, c\}$ such that

$$
g^{j_{n}}\left(y_{n}, \alpha^{0}\right)=-\varepsilon
$$

Because we have only a finite number of constraints, moreover, at least one of the $i$ 's will be repeated an infinite number of times in the sequence $\left\{j_{n}\right\}$. Hence, there exists some $j \in\{1, \ldots, c\}$ and a subsequence $\left\{y_{n_{k}}\right\}$ of $\left\{y_{n}\right\}$ with the property that

$$
\begin{equation*}
g^{j}\left(y_{n_{k}}, \alpha^{0}\right)=-\varepsilon \forall n_{k} \tag{8}
\end{equation*}
$$

Consider next the subsequence $\left\{\left(y_{n_{k}}, \alpha_{n_{k}}\right)\right\}$. The concavity of $g^{i}()$ in $x$ implies that

$$
\begin{equation*}
g^{i}\left(y_{n_{k}}, \alpha_{n_{k}}\right)=g^{i}\left(\left(1-\lambda_{n_{k}}\right) x^{\prime}+\lambda_{n_{k}} x_{n_{k}}, \alpha_{n_{k}}\right) \geq\left(1-\lambda_{n_{k}}\right) g^{i}\left(x^{\prime}, \alpha_{n_{k}}\right)+\lambda_{n} g^{i}\left(x_{n_{k}}, \alpha_{n_{k}}\right)>0 \tag{9}
\end{equation*}
$$

for all $i$ and all $\mathrm{n}_{k}>N$, and it follows that

$$
y_{n_{k}} \in C\left(\alpha_{n_{k}}\right) \forall n_{k}>N
$$

Now, because $\left\{y_{n_{k}}\right\}$ is contained in $C_{\varepsilon}\left(\alpha^{0}\right)$ and this set is compact, by Lemma 2.3, it follows (by Theorem 8.5 in Chapter 2) that this sequence has a convergent subsequence $\left\{y_{n_{k}}\right\}$ with limit $y$ in $C_{\varepsilon}\left(\alpha^{0}\right)$.

Finally, consider the limit of this subsequence. By (8) and the continuity of $g^{\prime}($ ), we have

$$
g^{l}\left(y, \alpha^{0}\right)=\lim _{q \rightarrow \infty} g\left(y_{n_{k_{q}}}, \alpha^{0}\right)=-\varepsilon
$$

On the other hand, (9) implies that

$$
g^{i}\left(y, \alpha^{0}\right)=\lim _{q \rightarrow \infty} g\left(y_{n_{k_{q}}}, \alpha_{n_{k q}}\right) \geq 0 \forall i \text { (including } j \text { ) }
$$

which contradicts the previous statement.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-713.jpg?height=489&width=747&top_left_y=174&top_left_x=369)

Figure A7.1.

Problem 2.6. We will give an alternative proof of the lower hemicontinuity of $C($ ) under the assumptions of Theorem 2.2.

- One constraint: Let $\left\{\alpha_{n}\right\} \rightarrow \alpha$, and consider an arbitrary point $x \in C(\alpha)$. We want to show that there exists a companion sequence $\left\{x_{n} ; x_{n} \in C\left(\alpha_{n}\right)\right\}$ that converges to $x$.

We will construct a sequence $\left\{x_{n}\right\}$ of the form

$$
x_{n}=\left\{\begin{array}{l}
x \quad \text { if } x \in C\left(\alpha_{n}\right) \quad \text { i.e., if } g\left(x, \alpha_{n}\right) \geq 0  \tag{1}\\
x_{n} \in C\left(\alpha_{n}\right) \text { s.th. } g\left(x_{n}, \alpha_{n}\right)=0 \quad \text { if } g\left(x, \alpha_{n}\right)<0
\end{array}\right.
$$

for $n$ larger than some $N$, and set $x_{n}$ equal to an arbitrary point in $C\left(\alpha_{n}\right)$ for $n \leq N$. To set $N$, recall that by assumption there exists a point $x^{\prime} \in C(\alpha)$ such that $g\left(\alpha, x^{\prime}\right)>0$. Because $\left\{\alpha_{n}\right\} \rightarrow \alpha$ and $g()$ is continuous in $\alpha$ for given $x$, there is some $N$ such that $g\left(x^{\prime}, \alpha_{n}\right)>0$ for all $n>N$. We will now show that for $n>N$ we can construct a sequence of the form (1).

Given some $x$, suppose $g\left(x, \alpha_{n}\right)<0$ for $n>N$. For each such $n$ define the function $\phi_{n}:[0,1] \longrightarrow \mathbb{R}$ by

$$
\phi_{n}(\lambda)=g\left[(1-\lambda) x+\lambda x^{\prime}, \alpha_{n}\right]
$$

and observe that this function is continuous (because it is the composition of two continuous functions) and satisfies

$$
\phi_{n}(1)=g\left(x^{\prime}, \alpha_{n}\right)>0 \quad \text { and } \phi_{n}(0)=g\left(x, \alpha_{n}\right)<0
$$

By the intermediate-value theorem (Theorem 6.24 in Chapter 2), for each $n$ there exists a number $\lambda_{n} \in[0,1]$ such that $\phi_{n}\left(\lambda_{n}\right)=0$ (Figure A7.1). Hence, we can put

$$
x_{n}=\left(1-\lambda_{n}\right) x+\lambda_{n} x^{\prime}
$$

in (1) whenever $g\left(x, \alpha_{n}\right)<0$, for then $g\left(x_{n}, \alpha_{n}\right)=0$, and this implies that $x_{n} \in C\left(\alpha_{n}\right)$.

To complete the proof, we have to show that $\left\{x_{n}\right\} \rightarrow x$. Suppose first that there exists some integer $M$ such that $g\left(x, \alpha_{n}\right)>0$ for all $n>M$. Then, according to (1), we have $x_{n}=x$ for all $n>M$, and the sequence clearly converges to the desired point. If this is not the case, then $\left\{\alpha_{n}\right\}$ must have a subsequence $\left\{\alpha_{n_{k}}\right\}$ with the property that $g\left(x, \alpha_{n_{k}}\right)<0$ for all $n_{k}$, and because $g()$ is continuous and $\left\{\alpha_{n_{k}}\right\} \rightarrow \alpha$, we have

$$
\lim _{n_{k} \rightarrow \infty} g\left(x, \alpha_{n_{k}}\right)=g(x, \alpha) \leq 0
$$

Because $x \in C(\alpha)$ implies $g(x, \alpha) \geq 0$, moreover, it must be the case that

$$
\begin{equation*}
g(x, \alpha)=0 \tag{2}
\end{equation*}
$$

To show that $\left\{x_{n}=\left(1-\lambda_{n}\right) x+\lambda_{n} x^{\prime}\right\} \rightarrow x$, consider the sequence $\left\{\lambda_{n}\right\}$, and notice that $\left\{x_{n}\right\} \rightarrow x$ if and only if $\left\{\lambda_{n}\right\} \rightarrow 0$. We will assume that $\left\{\lambda_{n}\right\} \rightarrow 0$ and obtain a contradiction. If $\left\{\lambda_{n}\right\} \nrightarrow 0$, then there exists some $\varepsilon>0$ and a subsequence $\left\{\lambda_{n_{p}}\right\}$ of $\left\{\lambda_{n}\right\}$ such that $\lambda_{n_{p}}>\varepsilon$ for all $n_{p}$. Because $\left\{\lambda_{n_{p}}\right\}$ is a bounded sequence of real numbers, it will contain a convergent subsequence, say $\left\{\lambda_{n_{p_{q}}}\right\}$, with limit $\mu \geq \varepsilon>$ 0 . Using the concavity of $g()$ in $x$, we can then write

$0=g\left(x_{n_{p q}}, \alpha_{n_{p q}}\right)=g\left[\left(1-\lambda_{n_{p q}}\right) x+\lambda_{n_{p q}} x^{\prime}, \alpha_{n_{p q}}\right] \geq\left(1-\lambda_{n_{p q}}\right) g\left(x, \alpha_{n_{p q}}\right)+\lambda_{n_{p q}} g\left(x^{\prime}, \alpha_{n_{p q}}\right)$ where the first equality holds by the definition of $x_{n_{p_{q}}}$. Taking limits of this
expression and using (2), we have

$$
(1-\mu) g(x, \alpha)+\mu g\left(x^{\prime}, \alpha\right)=0+\mu g\left(x^{\prime}, \alpha\right) \leq 0
$$

which is a contradiction, because both $\mu$ and $g\left(x^{\prime}, \alpha\right)$ are strictly positive.

- Several constraints: We will prove the result for $c=2$, and the general case will then follow by induction on $c$. Notice that we can write $C(\alpha)=C^{1}(\alpha) \cap C^{2}(\alpha)$, where

$$
C^{i}(\alpha)=\left\{x \in \mathbb{R}^{\mathrm{m}} ; g^{i}(\alpha, x) \geq 0\right\}
$$

Let $\left\{\alpha_{n}\right\} \rightarrow \alpha$, and consider an arbitrary point $x \in C(\alpha)=C^{1}(\alpha) \cap C^{2}(\alpha)$. We want to show that there exists a companion sequence $\left\{x_{n} ; x_{n} \in C\left(\alpha_{n}\right)=C^{1}\left(\alpha_{n}\right) \cap\right.$ $\left.C^{2}\left(\alpha_{n}\right)\right\}$ that converges to $x$. Proceeding as in the proof of the preceding theorem, we can construct two sequences $\left\{x_{n}^{1} ; x_{n}^{1} \in C^{1}\left(\alpha_{n}\right)\right\}$ and $\left\{x_{n}^{2} ; x_{n}^{2} \in C^{2}\left(\alpha_{n}\right)\right\}$ that both converge to $x$. (See the proof of Theorem 2.2 for the construction of these sequences.) We will use these two sequences to construct a sequence $\left\{x_{n}\right\}$ contained in $C(\alpha)=C^{1}(\alpha) \cap C^{2}(\alpha)$ with limit $x$.

Recall that $x_{n}^{i}$ is of the form $\left(1-\lambda_{n}^{i}\right) x+\lambda_{n}^{i} x^{\prime}$, with $\lambda_{n}^{i} \in[0,1]$, and refer to Figure A7.2. Notice that both $x_{n}^{1}$ and $x_{n}^{2}$ lie on the line segment $\left[x, x^{\prime}\right]$, and consider the intersections of this segment with $C^{1}\left(\alpha_{n}\right), C^{2}\left(\alpha_{n}\right)$, and $C\left(\alpha_{n}\right)$. By the concavity of $g^{i}$ in $x$ for given $\alpha$, both $C^{1}\left(\alpha_{n}\right)$ and $C^{2}\left(\alpha_{n}\right)$ are convex sets, and therefore so is $C\left(\alpha_{n}\right)=C^{1}\left(\alpha_{n}\right) \cap C^{2}\left(\alpha_{n}\right)$. Moreover, we have $x_{n}^{1} \in C^{1}\left(\alpha_{n}\right)$ and $x_{n}^{2} \in C^{2}\left(\alpha_{n}\right)$ by construction, and $x^{\prime} \in C^{1}\left(\alpha_{n}\right) \cap C^{2}\left(\alpha_{n}\right)$, for $n$ sufficiently large, by the continuity of $g^{1}()$ and $g^{2}()$ and the fact that $g^{i}\left(x^{\prime}, \alpha\right)>0$ for $i=1,2$ (and $\left\{\alpha_{n}\right\} \rightarrow \alpha$ ). By the convexity of $C^{i}\left(\alpha_{n}\right)$, the line segment $\left[x_{n}^{i}, x^{\prime}\right]$ is contained in $C^{i}\left(\alpha_{n}\right)$, because both of its end points lie on this set, and the segment $\left[x_{n}^{1}, x^{\prime}\right] \cap\left[x_{n}^{2}, x^{\prime}\right]$ is contained in the intersection $C\left(\alpha_{n}\right)$.

Using these facts, we can now construct a sequence $\left\{x_{n}\right\}$, with $x_{n} \in C\left(\alpha_{n}\right)$ and converging to $x$. Let $\lambda_{n}=\max \left\{\lambda_{n}^{1}, \lambda_{n}^{2}\right\}$, put $x_{n}=\left(1-\lambda_{n}\right) x+\lambda_{n} x^{\prime}$, and notice that $\left[x_{n}^{1}, x^{\prime}\right] \cap\left[x_{n}^{2}, x^{\prime}\right]=\left[x_{n}, x^{\prime}\right] \subseteq C\left(\alpha_{n}\right)$. Hence $x_{n} \in C\left(\alpha_{n}\right)$ for each $n$. It remains to show that $\left\{x_{n}\right\} \rightarrow x$.

For this, define the function $g()$ by $g(x, \alpha)=\min \left\{g^{1}(x, \alpha), g^{2}(x, \alpha)\right\}$, and observe that this function is concave in $x$ and continuous (by the concavity and continuity of the $\left.g^{i \prime} s\right)$. Next, notice that if there exists some $N$ such that $g\left(x, \alpha_{n}\right)>0$ (i.e., $g^{1}\left(x, \alpha_{n}\right)>0$ and $g^{2}\left(x, \alpha_{n}\right)>0$ ) for all $n>N$, then we have $x_{n}=x$ for all $n>N$, and the sequence converges trivially to the desired point. If this is not the case, we can proceed exactly as before, exploiting the concavity in $x$ of $g(x, \alpha)$ to obtain a contradiction if $\left\{x_{n}\right\} \nrightarrow x$.

Problem 2.7. Given sets $X \subseteq \mathbb{R}^{\mathrm{n}}$ and $\Omega \subseteq \mathbb{R}^{\mathrm{p}}$, let $g^{i}(x, \alpha): X \times \Omega \longrightarrow \mathbb{R}$ be a continuous function for all $i=1, \ldots, c$, and define the correspondence $C: \Omega \rightarrow \rightarrow$ $X$ by

Figure A7.2. Construction of $\left\{x_{n}\right\}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-715.jpg?height=364&width=583&top_left_y=185&top_left_x=789)

$$
C(\alpha)=\left\{x \in X ;\|x\| \leq B \text { and } g^{i}(x, \alpha) \geq 0 \forall i=1, \ldots, c\right\}
$$

Show that $C()$ is uhc at each $\alpha$.

- First, we show that $C(\alpha)$ is compact-valued (i.e., that the set $C(\alpha)$. is compact for each $\alpha$ ). Fix an arbitrary $\alpha$ in $\Omega$. Because $C(\alpha)$ is contained in a ball of radius $B$, it is bounded. To establish that it is also closed (and therefore compact), observe that $C(\alpha)$ is defined as the intersection of closed sets, namely, a closed ball and sets of the form $\left\{x \in \mathrm{X} ; g^{i}(x, \alpha) \geq 0\right\}$ that are inverse images of a closed set under a continuous function.
- Because the correspondence $C()$ is compact-valued, to establish its upper hemicontinuity at $\alpha$ it suffices to show that given any sequence $\left\{\alpha_{n}\right\}$ converging to $\alpha$, every companion sequence $\left\{x_{n}\right\}$, with $x_{n} \in C\left(\alpha_{n}\right)$ for each $n$, has a convergent subsequence with limit in $C(\alpha)$.

Let $\left\{\alpha_{n}\right\} \rightarrow \alpha$, and consider a companion sequence $\left\{x_{n}\right\}$, with $x_{n} \in C\left(\alpha_{n}\right)$ for each $n$. Because all the sets $C\left(\alpha_{n}\right)$ are contained within a ball of radius $B$, the sequence $\left\{x_{n}\right\}$ is bounded. By the Bolzano-Weierstrass theorem (see Problem 3.12 in Chapter 2), $\left\{x_{n}\right\}$ has a convergent subsequence, say $\left\{x_{n_{k}}\right\}$, with limit $z$. Because $\left\|x_{n_{k}}\right\| \leq B$ and $g^{i}\left(x_{n_{k}}, \alpha_{n_{k}}\right) \geq 0$ for all $i$ and $k$, we can take limits, and, using the continuity of the Euclidean norm $\|\cdot\|$ and $g^{i}()$, we conclude that

$$
\begin{gathered}
\|x\|=\lim _{k \rightarrow \infty}\left\|x_{n_{k}}\right\| \leq B \\
g^{i}(z, \alpha)=\lim _{k \rightarrow \infty} g^{i}\left(x_{n_{k}}, \alpha_{n_{k}}\right) \geq 0 \forall i=1, \ldots, c
\end{gathered}
$$

Hence, $z \in C(\alpha)$, and this establishes the desired result.

Problem 2.8. Given sets $X \subseteq \mathbb{R}^{\mathrm{n}}$ and $\Omega \subseteq \mathbb{R}^{p}$, with $X \times \Omega$ convex, let $g^{i}(x, \alpha): X \times$ $\Omega \rightarrow \mathbb{R}$ be a continuous and concave function (in $(x, \alpha)$ ) for all $i=1, \ldots, c$, and define the correspondence $C: \Omega \rightarrow \rightarrow$ by

$$
C(\alpha)=\left\{x \in X ; g^{i}(x, \alpha) \geq 0 \forall i=1, \ldots, c\right\}
$$

Fix a value $\alpha^{0}$ of the parameter vector and assume that $C\left(\alpha^{0}\right)$ is bounded. Let $\left\{\alpha_{n}\right\}$ be an arbitrary sequence converging to $\alpha^{0}$, and consider a companion sequence $\left\{x_{n}\right\}$, with $x_{n} \in C\left(\alpha_{n}\right)$ for each $n$. Show that $\left\{x_{n}\right\}$ is bounded.

By contradiction. Suppose $\left\{x_{n}\right\}$ is unbounded. Then it has a subsequence that diverges to infinity in norm. To simplify the notation, assume that the sequence itself diverges in norm (i.e., that $\left\{\left\|x_{n}\right\|\right\} \rightarrow \infty$ ). Consider the sequence $\left\{X_{n}\right\}=$ $\left\{\left(x_{n}, \alpha_{n}\right)\right\}$. Because $\left\{\left\|x_{n}\right\|\right\} \rightarrow \infty$, it follows that $\left\{\left\|X_{n}\right\|\right\} \rightarrow \infty$.

We will construct a new sequence $\left\{Y_{n}\right\}$ by projecting $\left\{X_{n}\right\}$ onto the boundary of a ball in $X \times \Omega$ that contains the set $C\left(\alpha^{0}\right) \times\left\{\alpha^{0}\right\}$. The resulting sequence will be

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-716.jpg?height=759&width=927&top_left_y=179&top_left_x=268)

Figure A7.3. Construction of $\left\{Y_{n}\right\}$.

bounded and therefore will have a convergent subsequence. Taking the limit of this subsequence, we will obtain a contradiction.

Let

$$
\bar{X}=\left(\bar{x}, \alpha^{0}\right) \in \arg \max _{x \in C\left(\alpha^{0}\right)}\left\|\left(x, \alpha^{0}\right)\right\|
$$

For a fixed $\alpha,\left\|\left(\cdot, \alpha^{0}\right)\right\|$ is a continuous function of $x$, and because $C\left(\alpha^{0}\right)$ is compact (bounded by assumption and closed by the continuity of $\left.g^{i}()\right)$, the function achieves a maximum in the set. Let

$$
M_{\alpha}=\|\bar{X}\|=\left\|\left(\bar{x}, \alpha^{0}\right)\right\|
$$

be this maximum.

Fix an arbitrary $\hat{x} \in C\left(\alpha^{0}\right)$. Let $\hat{X}=\left(\hat{x}, \alpha^{0}\right)$, and observe that for any $X=\left(x, \alpha^{0}\right)$, with $x \in C\left(\alpha^{0}\right)$, we have

$$
d(X, \hat{X}) \leq d(X, \underline{0})+d(\underline{0}, \hat{X})=\|x\|+\|\hat{X}\| \leq 2\|\bar{X}\|=2 M_{\alpha}
$$

Hence the set $C\left(\alpha^{0}\right) \times\left\{\alpha^{0}\right\}$ is contained in the interior of the closed ball $B_{d}[\hat{X}]$, with $d=2 M_{\alpha}+1$, and any point in the boundary of this ball lies outside $C\left(\alpha^{0}\right) \times\left\{\alpha^{0}\right\}$.

We will now use $\left\{X_{n}\right\}$ to construct a new sequence $\left\{Y_{n}\right\}=\left\{\left(y_{n}, \beta_{n}\right)\right\}$ that will lie in $B_{d}[\hat{X}]$. We proceed as follows: If $X_{n} \in B_{d}[\hat{X}]$, then we set $Y_{n}=X_{n}$. Because $\left\{\left\|X_{n}\right\|\right\} \rightarrow \infty$, there will be some $N$ such that $X_{n}$ lies outside $B_{d}[\hat{X}]$ for all $n>N$. For these points, we obtain $Y_{n}$ by "projecting" $X_{n}$ onto the boundary of the ball $B_{d}[\hat{X}]$ (Figure A7.3). For $n>N$, the terms of $\left\{Y_{n}\right\}$ will be of the form

$$
\begin{equation*}
Y_{n}=\left(y_{n}, \beta_{n}\right)=\left(1-\lambda_{n}\right) \hat{X}+\lambda_{n} X_{n}=\hat{X}+\lambda_{n}\left(X_{n}-\hat{X}\right), \quad \text { with } \lambda_{n} \in[0,1] \tag{1}
\end{equation*}
$$

We will, moreover, choose $\lambda_{n}$ so that $Y_{n}$ lies on the boundary of $B_{d}[\hat{X}]$. That is, we want

$$
\begin{equation*}
\left\|Y_{n}-\hat{X}\right\|=d \forall n>N \tag{2}
\end{equation*}
$$

Because $\left\|Y_{n}-\hat{X}\right\|=\lambda_{n}\left\|X_{n}-\hat{X}\right\|$, by (1), we need to set

$$
\begin{equation*}
\lambda_{n}=\frac{d}{\left\|X_{n}-\hat{X}\right\|} \tag{3}
\end{equation*}
$$

Notice that $\left\{\lambda_{n}\right\} \rightarrow 0$. By the concavity of $g^{i}()$, and using the fact that $\hat{X} \in C\left(\alpha^{0}\right)$ and $x_{n} \in C\left(\alpha_{n}\right)$, we have

$$
\begin{equation*}
g^{i}\left(Y_{n}\right)=g^{i}\left(y_{n}, \beta_{n}\right) \geq\left(1-\lambda_{n}\right) g^{i}(\hat{X})+\lambda_{n} g^{i}(X n) \geq 0 \forall i=1, \ldots, c \text { and } \forall n>N \tag{4}
\end{equation*}
$$

Because the sequence $\left\{Y_{n}\right\}$ is bounded by construction, it has a convergent subsequence $\left\{Y_{n_{k}}\right\}=\left\{\left(y_{n_{k}}, \beta_{n_{k}}\right)\right\}$. Observe that $\left\{\beta_{n_{k}}=\left(1-\lambda_{n_{k}}\right) \alpha^{0}+\lambda_{n_{k}} \alpha_{n_{k}}\right\} \rightarrow \alpha^{0}$, because $\left\{\lambda_{n}\right\} \rightarrow 0$ and $\left\{\alpha_{n}\right\} \rightarrow \alpha^{0}$. Hence, the limit of $\left\{Y_{n_{k}}\right\}$ is of the form $Y=\left(y, \alpha^{0}\right)$. By (4), and using the continuity of $g^{i}()$, we have

$$
\begin{equation*}
g^{i}\left(y, \alpha^{0}\right)=\lim _{\mathrm{k} \rightarrow \infty} g^{i}\left(y_{n_{k}}, \beta_{n_{k}}\right) \geq 0 \forall i=1, \ldots, c \tag{5}
\end{equation*}
$$

which implies that $y \in C\left(\alpha^{0}\right)$. On the other hand, using (2) and the continuity of the norm, we see that

$$
\|Y-\hat{X}\|=\lim _{k \rightarrow \infty}\left\|Y_{n_{k}}-\hat{X}\right\|=d>2 M_{\alpha}
$$

which implies that $Y=\left(y, \alpha^{0}\right)$ lies on the boundary of $B_{d}[\hat{X}]$ and therefore outside $C\left(\alpha^{0}\right) \times\left\{\alpha^{0}\right\}$. It follows that $y \notin C\left(\alpha^{0}\right)$, which contradicts our previous statement.

Problem 2.9. For each $\alpha$ and each $\varepsilon>0$, define the set $\underline{C}_{\varepsilon}(\alpha)$ by

$$
\underline{C}_{\varepsilon}(\alpha)=\left\{x \in X ; g^{i}(x, \alpha)-\varepsilon \geq 0 \forall i=1, \ldots, c\right\}
$$

Show that, under the assumptions of Theorem 2.2, for every $\varepsilon>0$ there exists some $\delta>0$ such that $C(\alpha) \supseteq \underline{C}_{\varepsilon}\left(\alpha^{0}\right)$ for all $\alpha \in B_{\delta}\left(\alpha^{0}\right)$.

Notice that if $\varepsilon$ is sufficiently large, $\underline{C}_{\varepsilon}(\alpha)$ will be empty, but the result still holds, because the empty set is a subset of every set, by convention.

We will prove the result under the assumption that there is a single constraint of the form $g(x, \alpha) \geq 0$. The extension to the general case is straightforward (see the solution to Problem 2.5).

We will proceed by contradiction. Suppose the result does not hold. Then, negating the statement, there exists some $\varepsilon>0$ such that

$$
\begin{equation*}
\forall \delta>0 \exists \alpha \in B_{\delta}\left(\alpha^{0}\right) \text { s.th. } C(\alpha) \not \underline{C}_{\varepsilon}\left(\alpha^{0}\right) \tag{1}
\end{equation*}
$$

By (1) there exists a sequence $\left\{\alpha_{n}\right\} \rightarrow \alpha^{0}$ such that for each $n$ the set $C\left(\alpha_{n}\right)$ does not contain $\underline{C}_{\varepsilon}\left(\alpha^{0}\right)$. Hence, for each $n$ there exists a point $x_{n} \in \underline{C}_{\varepsilon}\left(\alpha^{0}\right)$ with the property that $x_{n} \notin C\left(\alpha_{n}\right)$. For the resulting sequence $\left\{\left(\alpha_{n}, x_{n}\right)\right\}$ we have:

$$
\begin{align*}
& x_{n} \in \underline{C}_{\varepsilon}\left(\alpha^{0}\right) \Rightarrow g\left(x_{n}, \alpha^{0}\right) \geq \varepsilon \forall n  \tag{2}\\
& x_{n} \notin C\left(\alpha_{n}\right) \Rightarrow g\left(x_{n}, \alpha_{n}\right)<0 \forall n \tag{3}
\end{align*}
$$

Notice that $x_{n} \in \underline{C_{f}}\left(\alpha^{0}\right) \subseteq C\left(\alpha^{0}\right)$ for all $n$. Because $C\left(\alpha^{0}\right)$ is compact by assumption, $\left\{x_{n}\right\}$ has a convergent subsequence, say $\left\{x_{n_{k}}\right\}$, with limit $x \in C\left(\alpha^{0}\right)$. Using the continuity of $g()$, we have

$$
g\left(x, \alpha^{0}\right)=\lim _{k \rightarrow \infty} g\left(x_{n k}, \alpha^{0}\right) \geq \varepsilon>0
$$

by (2), and

$$
g\left(x, \alpha^{0}\right)=\lim _{k \rightarrow \infty} g\left(x_{n_{k}}, \alpha_{n_{k}}\right) \leq 0
$$

by (3), contradicting the previous statement.

Problem 2.10. An agent consumes two goods, $x_{1}$ and $x_{2}$, with prices $p_{1}$ and $p_{2}$, respectively. Her utility function is of the form $U\left(x_{1}, x_{2}\right)=\alpha\left(x_{1}^{\alpha}+x_{2}^{\alpha}\right)$, with $\alpha<1$. Verify that $U()$ is strictly concave. Derive the demand function of the agent. In what direction does the demand for good 1 change if there is an increase in the price of good 2 ?

To obtain the first-order conditions for the agent's problem,

$$
\max _{x_{1}, x_{2}}\left\{\alpha\left(x_{1}^{\alpha}+x_{2}^{\alpha}\right) \text { s.t. } p_{1} x_{1}+p_{2} x_{2}=y\right\}
$$

we write the Lagrangian function

$$
£=\alpha\left(x_{1}^{\alpha}+x_{2}^{\alpha}\right)+\lambda\left[y-p_{1} x_{1}-p_{2} x_{2}\right]
$$

and differentiate with respect to the choice variables, obtaining

$$
\begin{align*}
& \frac{\partial £}{\partial x_{1}}=\alpha^{2} x_{1}^{\alpha-1}-\lambda p_{1}=0 \Rightarrow \lambda=\frac{\alpha^{2}}{p_{1} x_{1}^{1-\alpha}}  \tag{1}\\
& \frac{\partial £}{\partial x_{2}}=\alpha^{2} x_{2}^{\alpha-1}-\lambda p_{2}=0 \Rightarrow \lambda=\frac{\alpha^{2}}{p_{2} x_{2}^{1-\alpha}} \tag{2}
\end{align*}
$$

To check the second-order conditions we compute the second-order partial derivatives of $U\left(x_{1}, x_{2}\right)=\alpha\left(x_{1}^{\alpha}+x_{2}^{\alpha}\right)$ :

$$
\begin{gathered}
U_{1}=\alpha^{2} x_{1}^{\alpha-1}, \quad U_{2}=\alpha^{2} x_{2}^{\alpha-1} \\
U_{11}=\alpha^{2}(\alpha-1) x_{1}^{\alpha-2}, \quad U_{22}=\alpha^{2}(\alpha-1) x_{2}^{\alpha-2}, \quad U_{12}=U_{21}=0
\end{gathered}
$$

Hence, the Hessian matrix is

$$
H=\left[\begin{array}{ll}
U_{11} & U_{12} \\
U_{21} & U_{22}
\end{array}\right]=\left[\begin{array}{cc}
\alpha^{2}(\alpha-1) x_{1}^{\alpha-2} & 0 \\
0 & \alpha^{2}(\alpha-1) x_{2}^{\alpha-2}
\end{array}\right]
$$

and the leading principal minors are given by

$$
\begin{gathered}
\left.d_{1}=\alpha^{2}(\alpha-1) x_{1}^{\alpha-2}<0 \quad \text { (because } \alpha<1\right) \\
d_{2}=\alpha^{4}(\alpha-1)^{2} x_{1}^{\alpha-2} x_{2}^{\alpha-2}>0
\end{gathered}
$$

Hence, $H$ is negative definite, and the sufficient conditions for a strict local maximum are satisfied.

To find the demand function, notice that, using (1) and (2),

$$
\begin{equation*}
\frac{\alpha^{2}}{p_{1} x_{1}^{1-\alpha}}=\frac{\alpha^{2}}{p_{2} x_{2}^{1-\alpha}} \Rightarrow\left(\frac{x_{2}}{x_{1}}\right)^{1-\alpha}=\frac{p_{1}}{p_{2}} \Rightarrow \frac{x_{2}}{x_{1}}\left(\frac{p_{1}}{p_{2}}\right)^{1 /(1-\alpha)} \tag{3}
\end{equation*}
$$

Substituting (3) into the constraint,

$$
p_{1} x_{1}+p_{2} x_{1}\left(\frac{p_{1}}{p_{2}}\right)^{1 /(1-\alpha)}=y
$$

from where

$$
x_{1 . .}^{*}=x_{1}\left(p_{1}, p_{2}, y\right)=\frac{y}{p_{1}+p_{2}\left(\frac{p_{1}}{p_{2}}\right)^{1 /(1-\alpha)}}=\frac{y}{p_{1}\left(1+\left(\frac{p_{1}}{p_{2}}\right)^{\alpha /(1-\alpha)}\right)}
$$

The demand for the other good is almost identical, but with the roles of $p_{1}$ and $p_{2}$ reversed. Differentiating the demand for the first good with respect to $p_{2}$,

$$
\frac{\partial x_{1}^{*}}{\partial p_{2}}=\frac{y}{p_{1}} \frac{-\frac{\alpha}{1-\alpha}\left(\frac{p_{1}}{p_{2}}\right)^{[\alpha /(1-\alpha)]-1} p_{1} \frac{-1}{p_{2}^{2}}}{\left(1+\left(\frac{p_{1}}{p_{2}}\right)^{\alpha /(1-\alpha)}\right)^{2}}
$$

Because $1-\alpha>0$, the sign of this derivative is the same as the sign of $\alpha$. If $\alpha>0$, the goods are substitutes (an increase in the price of one of them induces the agent to switch to the other, increasing its demand), and if $\alpha<0$ they are complements, as an increase in the price of either good reduces the demand for both.

Problem 2.11. A competitive firm maximizes profits, $\Pi(x)=p f(x)-w x$, taking as given the price of its output $p$ and the vector $w \in \mathbb{R}^{\mathrm{n}}$ of factor prices. Assume that the production function $f$ is $C^{2}$ and strictly concave, with positive but diminishing marginal products $\left(f_{i}>0, f_{i i}<0, i=1, \ldots, n\right)$.

Write the first-order conditions for the firm's problem, and apply the implicitfunction theorem (IFT) to the resulting system to show that the demand for each factor is a decreasing function of its price (i.e., that $\partial x_{i}^{*} / \partial w_{i}<0$ ).

The first-order conditions for the firm's problem are

$$
\begin{equation*}
\frac{\partial \Pi(x)}{\partial x_{i}}=p f_{i}(x)-w_{i}=0 \forall i=1, \ldots, n \tag{1}
\end{equation*}
$$

which is the familiar condition that the value of the marginal product of each input should be equal to its price.

In vector notation,

$$
D_{x} \Pi(x ; p, w)=p D f(x)-w=\underline{0} \Leftrightarrow F(x ; w, p)=\underline{0}
$$

The strict concavity of $f$ (and therefore of $\Pi$ ) ensures that ( $\left.1^{\prime}\right)$ does indeed characterize a maximum, rather than a minimum. Moreover, this automatically ensures that we are dealing with a regular maximum, and the Jacobian of endogenous variables of $F()$ does not vanish, as

$$
|J|=\left|D_{x} F(x ; w, p)\right|=\left|D_{x}^{2} \Pi(x ; p, w)\right|=p^{n}\left|D^{2} f(x)\right| \neq 0
$$

by the strict concavity of $f[f$ strictly concave $\Rightarrow$ Hessian negative definite $\Rightarrow$ $\left|D_{x}^{2} f(x)\right|$ has sign $(-1)^{n}$, and $\left.p>0\right]$.

Since the conditions of the IFT are satisfied, we can use the determinant rule to solve for the partial derivatives of the factor demand functions. For example,

$$
\frac{\partial x_{1}(p, w)}{\partial w_{1}}=-\frac{\left|J_{11}\right|}{|J|}
$$

where

$$
|J|=\left|p D^{2} f()\right|=\left|\begin{array}{cccc}
\frac{\partial^{2} \Pi}{\partial x_{1} \partial x_{1}} & \frac{\partial^{2} \Pi}{\partial x_{1} \partial x_{2}} & \cdots & \frac{\partial^{2} \Pi}{\partial x_{1} \partial x_{n}} \\
\frac{\partial^{2} \Pi}{\partial x_{2} \partial x_{1}} & \frac{\partial^{2} \Pi}{\partial x_{2} \partial x_{2}} & \cdots & \frac{\partial^{2} \Pi}{\partial x_{2} \partial x_{n}} \\
\cdots & \cdots & \cdots & \cdots \\
\frac{\partial^{2} \Pi}{\partial x_{n} \partial x_{1}} & \frac{\partial^{2} \Pi}{\partial x_{n} \partial x_{2}} & \cdots & \frac{\partial^{2} \Pi}{\partial x_{n} \partial x_{n}}
\end{array}\right|=\left|\begin{array}{cccc}
p f_{11} & p f_{12} & \ldots & : p f_{1 n} \\
p f_{21} & p f_{22} & \ldots & p f_{2 n} \\
\cdots & \ldots & \ldots & \ldots \\
p f_{n 1} & p f_{n 2} & \ldots & p f_{n n}
\end{array}\right|=p^{n} d_{n}
$$

$$
\left|J_{11}\right|=\left|\begin{array}{cccc}
\frac{\partial^{2} \Pi}{\partial x_{1} \partial w_{1}} & \frac{\partial^{2} \Pi}{\partial x_{1} \partial x_{2}} & \cdots & \frac{\partial^{2} \Pi}{\partial x_{1} \partial x_{n}} \\
\frac{\partial^{2} \Pi}{\partial x_{2} \partial w_{1}} & \frac{\partial^{2} \Pi}{\partial x_{2} \partial x_{2}} & \cdots & \frac{\partial^{2} \Pi}{\partial x_{2} \partial x_{n}} \\
\cdots & \cdots & \cdots & \cdots \\
\frac{\partial^{2} \Pi}{\partial x_{n} \partial w_{1}} & \frac{\partial^{2} \Pi}{\partial x_{n} \partial x_{2}} & \cdots & \frac{\partial^{2} \Pi}{\partial x_{n} \partial x_{n}}
\end{array}\right|=\left|\begin{array}{cccc}
-1 & p f_{12} & \cdots & p f_{1 n} \\
0 & p f_{22} & \cdots & p f_{2 n} \\
\cdots & \cdots & \cdots & \cdots \\
0 & p f_{n 2} & \cdots & p f_{n n}
\end{array}\right|=(-1)(-1)^{1+1} p^{n-1} d_{n-1}
$$

where $d_{r}$ refers to the $r$ th leading principal minor of the Hessian of the production function $D^{2} f()$. By concavity, this is a negative definite matrix. Hence, its $r$ th leading principal minor will have sign $(-1)^{r}$. This allows us to establish the sign of the (own price) partials of the factor demand functions. For example

$$
\operatorname{sign} \frac{\partial x_{1}(p, w)}{\partial w_{1}}=\operatorname{sign} \frac{-\left|J_{11}\right|}{|J|}=\frac{-(-1)(-1)^{n-1}}{(-1)^{n}}=(-)
$$

that is, the factor demand functions are downward-sloping in their own price.

In this particular case, this result can also be obtained without that much manipulation of determinants. By the IFT, we can write the optimal input vector as a function of input and output prices, $x(p, w)$. This function must satisfy the first-order necessary conditions identically, so we have

$$
\begin{equation*}
p D f[x(p, w)]-w \equiv \underline{0} \Leftrightarrow F[x(p, w) ; w, p] \equiv \underline{0} \tag{2}
\end{equation*}
$$

Differentiating with respect to $w$, we get

$$
\begin{equation*}
p D^{2} f(x) D_{w} x(p, w)-\mathbf{I}=\underline{0} \quad \text { (where } \mathbf{I} \text { is the identity matrix) } \tag{3}
\end{equation*}
$$

which we can solve for the "substitution matrix"

$$
\begin{equation*}
D_{w} x(p, w)=\left[p D^{2} f(x)\right]^{-1} \tag{4}
\end{equation*}
$$

Because the substitution matrix is the inverse of the Hessian of the production function times $p$ (and the inverse of a negative definite matrix is itself negative definite), its diagonal entries must be negative, and we conclude that

$$
\begin{equation*}
\frac{\partial x_{i}(p, w)}{\partial w_{i}}<0 \tag{5}
\end{equation*}
$$

Problem 2.14. Prove Theorem 2.13: Consider the following problem and the associated value function:

$$
V(\alpha)=\max _{x}\{f(x ; \alpha) ; g(x) \geq \underline{0}\}
$$

where $\alpha \in \Omega$, a convex set. (Note that the parameters do not enter the constraint function.) If the objective function is convex in the parameters $\alpha$ for any given $x$, then $V()$ is convex.

As in the preceding theorem, given two arbitrary values of the parameter vector $\alpha^{\prime}$ and $\alpha^{\prime \prime}$, let $x^{\prime}=x\left(\alpha^{\prime}\right)$ and $x^{\prime \prime}=x\left(\alpha^{\prime \prime}\right)$ be the corresponding optimal choices of $x$. To establish the convexity of $V()$, we need to show that for any $\lambda \in(0,1)$ we have

$$
(1-\lambda) V\left(\alpha^{\prime}\right)+\lambda V\left(\alpha^{\prime \prime}\right) \geq V\left(\alpha^{\lambda}\right)
$$

Consider the optimal choice of $x$ for $\alpha^{\lambda}, x\left(\alpha^{\lambda}\right)$, where $\alpha^{\lambda}=(1-\lambda) \alpha^{\prime}+\lambda \alpha^{\prime \prime} \in \Omega$, by the convexity of $\Omega$. Because the constraint set does not depend on the parameters, $x\left(\alpha^{\lambda}\right)$ is feasible but not necessarily optimal for $\alpha^{\prime}$ or $\alpha^{\prime \prime}$. Therefore,

$$
f\left(x^{\prime}, \alpha^{\prime}\right) \geq f\left[x\left(a^{\lambda}\right), \alpha^{\prime}\right] \text { and } f\left(x^{\prime \prime}, \alpha^{\prime \prime}\right) \geq f\left[x\left(\alpha^{\lambda}\right), \alpha^{\prime \prime}\right]
$$

from where

$$
\begin{aligned}
& (1-\lambda) V\left(\alpha^{\prime}\right)+\lambda V\left(\alpha^{\prime \prime}\right)=(1-\lambda) f\left(x^{\prime}, \alpha^{\prime}\right)+\lambda f\left(x^{\prime \prime}, \alpha^{\prime \prime}\right) \\
& \quad \geq(1-\lambda) f\left[x\left(\alpha^{\lambda}\right), \alpha^{\prime}\right]+\lambda f\left[x\left(\alpha^{\lambda}\right), \alpha^{\prime \prime}\right] \geq f\left[x\left(\alpha^{\lambda}\right), \alpha^{\lambda}\right]=V\left(\alpha^{\lambda}\right)
\end{aligned}
$$

where the last inequality follows from the convexity of $f$ as a function of $\alpha$.

Problem 3.1. An agent lives for two periods and has an endowment of one unit of a homogeneous consumption good in the first period, and $\gamma$ units in the second period. His utility function is given by

$$
\ln c_{1}+\ln c_{2}
$$

where $c_{i}$ is consumption in period $i$. The agent can store any feasible quantity of his first-period endowment for consumption at a later time and can get an interest-free loan of up to $\beta$ units of the good (i.e., $s \geq-\beta$ and $R=1$ ).

(i) Calculate the agent's saving function, ignoring the constraint $s \geq-\beta$.

(ii) For what combinations of parameter values will the constraint be binding? In what regions of the $(\beta, \gamma)$ plane will we have an interior solution and a corner solution? Write the agent's saving function, taking into account the constraint.

(iii) Write the maximum-value function for the problem as a function of $\gamma, V(\gamma)$. Verify that $V(\gamma)$ is continuous at the point at which there is a regime change (i.e., as we go from an interior solution to one in which the constraint is binding). Is the value function differentiable at this point?

(i) Substituting the constraints $c_{1}+s=1$ and $c_{2}=s+\gamma$ into the objective function, the agent solves

$$
\max _{s} f(s)=\ln (1-s)+\ln (\gamma+s)
$$

The first-order condition for an optimum is

$$
f^{\prime}(s)=\frac{-1}{1-s}+\frac{1}{s+\gamma}=0
$$

It is easy to check that the sufficient conditions for a maximum are satisfied. Solving for $s$, we obtain the unconstrained saving function

$$
s^{*}=s(\gamma)=\frac{1-\gamma}{2}
$$

(ii) If the unconstrained optimal solution obtained earlier does not violate the constraint, then it is also the constrained optimum. If the agent would like to borrow more than $\beta$ and he cannot, then he will take the largest feasible loan, and we have a corner solution. Hence, the solution function for the complete problem is given by

$$
\begin{aligned}
s^{*}=s(\beta, \gamma) & =\frac{1-\gamma}{2} \quad \text { if } \frac{1-\gamma}{2} \geq-\beta \\
& =-\beta \quad \text { if } \frac{1-\gamma}{2} \leq-\beta
\end{aligned}
$$

and the restriction will be binding if and only if

$$
\frac{1-\gamma}{2} \leq-\beta \Rightarrow \gamma \geq 1+2 \beta
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-722.jpg?height=450&width=1156&top_left_y=180&top_left_x=162)

Figure A7.4.

(iii) To recover the value function, we substitute the optimal solution into the objective function:

$$
V(\beta, \gamma)=\ln [1-s(\beta, \gamma)]+\ln [\gamma+s(\beta, \gamma)]
$$

Now, because $s(\beta, \gamma)$ has two different "segments," so will $V($ ). If the constraint is not binding, we have

$$
V^{n}(\gamma)=\ln \left(1-\frac{1-\gamma}{2}\right)+\ln \left(\gamma+\frac{1-\gamma}{2}\right)=2 \ln \left(\frac{1+\gamma}{2}\right)
$$

and if it is binding,

$$
V^{b}(\gamma, \beta)=\ln (1+\beta)+\ln (\gamma-\beta)
$$

The "complete function" is

$$
\begin{aligned}
V(\gamma, \beta) & =V^{n}(\gamma) & & \text { if } \gamma<1+2 \beta \\
& =V^{b}(\gamma, \beta) & & \text { if } \gamma \geq 1+2 \beta
\end{aligned}
$$

To verify the continuity of $V$, we check that its two segments have a common end point. Put $\gamma^{0}=1+2 \beta$ (the point at which there is a regime switch) and note that

$$
\begin{gathered}
V^{n}\left(\gamma^{0}\right)=2 \ln \left(\frac{1+\gamma^{0}}{2}\right)=2 \ln (1+\beta) \\
V^{b}\left(\gamma^{0}, \beta\right)=\ln (1+\beta)+\ln \left(\gamma^{0}-\beta\right)=2 \ln (1+\beta)
\end{gathered}
$$

Hence, $V^{n}\left(\gamma^{0}\right)=V^{b}\left(\gamma^{0}, \beta\right)$, and $V()$ is continuous at $\left(\gamma^{0}, \beta\right)$, which is the only point at which there could be trouble.

To check whether or not $V()$ is differentiable at $\left(\gamma^{0}, \beta\right)$, we compute its right and left derivatives at this point,

$$
\begin{gathered}
\frac{d V^{n}\left(\gamma^{0}\right)}{d \gamma}=2 \frac{1 / 2}{\left(1+\gamma^{0}\right) / 2}=\frac{2}{1+\gamma^{0}} \\
\frac{\partial V^{n}\left(\gamma^{0}, \beta\right)}{\partial \gamma}=\frac{1}{\gamma^{0}-\beta}=\frac{1}{\gamma^{0}-\left(\gamma^{0}-1\right) / 2}=\frac{2}{1+\gamma^{0}}
\end{gathered}
$$

where we have made use of the fact that $\gamma^{0}=1+2 \beta$, implying $\beta=\left(\gamma^{0}-1\right) / 2$. Because the two one-sided derivatives coincide, the value function is differentiable at this point.

Problem 3.2. Show that if $f$ is strictly concave, then $(\mathrm{P})$ has a unique solution for a given price vector $q$.

Suppose there are two distinct optimal production plans $z^{\prime}=\left(y^{\prime},-x^{\prime}\right)$ and $z^{\prime \prime}=\left(y^{\prime \prime},-x^{\prime \prime}\right)$. Then both plans must yield the same profit, given by

$$
\begin{equation*}
q z^{\prime}=q z^{\prime \prime}=\pi_{0} \tag{1}
\end{equation*}
$$

We will show that if $z^{\prime} \neq z^{\prime \prime}$ and $f()$ is strictly concave, then it is possible to construct a feasible plan that will yield a profit strictly larger than $\pi_{0}$.

For any $\lambda \in(0,1)$, consider the input vector

$$
x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}
$$

Because $\left\{x \in \mathbb{R}_{+}^{\mathrm{n}} ;\|x\| \leq B\right\}$ is a convex set, $x^{\lambda}$ is an admissible input vector, and $\left(f\left(x^{\lambda}\right), x^{\lambda}\right)$ is a feasible production plan. Moreover, by the strict concavity of $f()$, we have

$$
\begin{equation*}
f\left(x^{\lambda}\right)>(1-\lambda) f\left(x^{\prime}\right)+\lambda f\left(x^{\prime \prime}\right) \geq(1-\lambda) y^{\prime}+\lambda y^{\prime \prime} \tag{2}
\end{equation*}
$$

where the second inequality follows by the feasibility of $z^{\prime}$ and $z^{\prime \prime}$. This expression implies that $\left(f\left(x^{\lambda}\right), x^{\lambda}\right)$ yields a profit strictly larger than the supposedly optimal plans,

$$
p f\left(x^{\lambda}\right)-w x^{\lambda}>p\left[(1-\lambda) y^{\prime}+\lambda y^{\prime \prime}\right]-w\left[(1-\lambda) x^{\prime}+\lambda x^{\prime \prime}\right]=(1-\lambda) q z^{\prime}+\lambda q z^{\prime \prime}=\pi_{0}
$$

so we have reached a contradiction.

Problem 3.3. Under the assumptions of Problem 3.2, the firm's production plans (i.e., its output level and factor demands) are well-defined functions of the price vector $q$. We will show that these functions are continuous.

Fix a vector $q^{0}$ of prices, and consider a sequence of price vectors $\left\{q_{n}\right\}$ convergent to $q^{0}$ and the corresponding sequence of optimal production plans $\left\{z_{n}\right\}$, with $z_{n}=z\left(q_{n}\right)$ for each $n$. We want to show that $\left\{z_{n}\right\}$ converges to $z\left(q^{0}\right)=z^{\prime}$. To establish this result, we shall proceed by contradiction. Suppose $\left\{z_{n}\right\}$ does not converge to $z^{\prime}$.

(i) Then $\left\{z_{n}\right\}$ has a convergent subsequence $\left\{z_{n_{k}}\right\}$ with limit $z^{0}$ different from $z^{\prime}$. Explain why this is true.

Because $\left\{z_{n}\right\}$ is bounded (by the second constraint), it has a convergent subsequence $\left\{z_{n_{k}}\right\}$ with limit $z^{0}$. Moreover, we can take $z^{0}$ different from $z^{\prime}$. Why? Fix some $\varepsilon>0$. Then, because $\left\{z_{n}\right\}$ does not converge to $z^{\prime}$, for any $N$ there is some $n>N$ such that $z_{n}$ is outside $B_{\varepsilon}\left(z^{\prime}\right)$. In this manner we can construct a subsequence of $\left\{z_{n}\right\}$ with the property that none of its subsequences converge to $z^{\prime}$. But because this sequence is still bounded, it has a convergent subsequence that must therefore converge to some other point.

(ii) Let $\left\{q_{n_{k}}\right\}$ be the price subsequence corresponding to $\left\{z_{n_{k}}\right\}$. We have that

$$
\left\{q_{n_{k}}\right\} \rightarrow q^{0} \quad \text { and } \quad\left\{z_{n_{k}}\right\} \rightarrow z^{0} \neq z^{\prime}=z\left(q^{0}\right)
$$

Show that we arrive at the following contradiction: Given any price vector $q_{n_{k}}$ sufficiently close to $q^{0}, z^{\prime}$ is strictly better than the optimal plan $\left\{z_{n_{k}}\right\}$.

We will now obtain a contradiction. Because $z^{\prime}$ is optimal for $q^{0}$, but $z^{0}$ is not (but it is feasible, because feasibility does not depend on prices), we have

$$
\begin{equation*}
q^{0} z^{\prime}>q^{0} z^{0} \tag{1}
\end{equation*}
$$

and therefore $d=q^{0} z^{\prime}-q^{0} z^{0}>0$. Because $\left\{q_{n_{k}}\right\} \rightarrow q^{0},\left\{z_{n_{k}}\right\} \rightarrow z^{0}$, and $q z$ is a continuous function, we have that

$$
\begin{equation*}
\left\{q_{n_{k}} z_{n_{k}}\right\} \rightarrow q^{0} z^{0} \quad \text { and } \quad\left\{q_{n_{k}} z^{\prime}\right\} \rightarrow q^{0} z^{\prime} \tag{2}
\end{equation*}
$$

We want to show that there exists some integer $K$ such that for all $k>K$ we have

$$
q_{n_{k}} z^{\prime}>q_{n_{k}} z_{n_{k}}
$$

That is, $z^{\prime}$ is better than the optimum for $q_{n_{k}}$ sufficiently close to $q^{0}$. The idea is simple: By (2) and (1), we have

$$
q_{n_{k}} z^{\prime} \sim q^{0} z^{\prime}>q^{0} z^{0} \sim q_{n_{k}} z_{n_{k}}
$$

where " $\sim$ " means "very close to," and this holds for sufficiently high $k$.

Formally,

$$
\begin{aligned}
q_{n_{k}} z^{\prime}-q_{n_{k}} z_{n_{k}} & =\left(q_{n_{k}} z^{\prime}-q^{0} z^{\prime}\right)+\left(q^{0} z^{\prime}-q^{0} z^{0}\right)+\left(q^{0} z^{0}-q_{n_{k}} z_{n_{k}}\right) \\
& =\left(q_{n_{k}} z^{\prime}-q^{0} z^{\prime}\right)+d+\left(q^{0} z^{0}-q_{n_{k}} z_{n_{k}}\right)
\end{aligned}
$$

Now, $d>0$, and by (2) there exist integers $K_{1}$ and $K_{2}$ such that the absolute values of the other two terms are smaller than $d / 2$ for $k>K_{i}$. Hence, for $k>\max \left\{K_{1}, K_{2}\right\}$, the right-hand side is strictly positive, and the desired result follows. But this is a contradiction, for we have found a production plan $z^{\prime}$ that is better than the optimum for prices $q_{n_{k}}$.

Problem 3.4. Consider two price vectors $q_{1}$ and $q_{0}$ and the corresponding optimal production plans $z_{1}$ and $z_{0}$. Because $z_{1}$ is feasible but not necessarily optimal for $q_{0}$, it must yield a lower profit than $z_{0}$ at this price vector. Using this observation, show that for any $i, \Delta q_{i} \Delta z_{l} \geq 0$ (e.g., for the first component of these vectors we have $\Delta p \Delta y \geq 0$, i.e., an increase in the price of output must yield an increase in supply).

We have

$$
\begin{aligned}
& q_{1} z_{1} \geq q_{1} z_{0} \\
& q_{0} z_{0} \geq q_{0} z_{1}
\end{aligned}
$$

Adding these two inequalities side by side,

$$
q_{1} z_{1}+q_{0} z_{0} \geq q_{1} z_{0}+q_{0} z_{1}
$$

from where

$$
\begin{gathered}
q_{1}\left(z_{1}-z_{0}\right)+q_{0}\left(z_{0}-z_{1}\right) \geq 0 \\
\left(q_{1}-q_{0}\right)\left(z_{1}-z_{0}\right) \geq 0
\end{gathered}
$$

Consider changes in the price vector that affect only one component, such as

$$
q_{1}=\left(p_{1}, w_{1}\right)=\left(p_{0}+\Delta p, w_{0}\right)
$$

Then all terms but one in the product vanish, and we have

$$
\left(q_{1}-q_{0}\right)\left(z_{1}-z_{0}\right)=\Delta p \Delta y \geq 0
$$

so supply increases with output price. More generally,

$$
\Delta q_{i} \Delta z_{i} \geq 0
$$

so

$$
-\Delta w_{i} \Delta x_{i} \geq 0
$$

and factor demands are downward-sloping in their "own price."

Problem 3.5. Show that the profit function $\pi(q)$ is convex. Can you give an economic interpretation of this property?

Let $q^{\prime}$ and $q^{\prime \prime}$ be two arbitrary price vectors, and $z^{\prime}$ and $z^{\prime \prime}$ the corresponding optimal production plans. Define $q^{\lambda}$ by $q^{\lambda}=(1-\lambda) q^{\prime}+\lambda q^{\prime \prime}$ for $\lambda \in(0,1)$, and let $z^{\lambda}=z\left(q^{\lambda}\right)$ be the corresponding optimal production plan. By definition,

$$
\begin{equation*}
\pi\left(q^{\lambda}\right)=q^{\lambda} z^{\lambda}=(1-\lambda) q^{\prime} z^{\lambda}+\lambda q^{\prime \prime} z^{\lambda} \tag{1}
\end{equation*}
$$

Observe that $z^{\lambda}$ is feasible but not necessarily optimal for prices $q^{\prime}$ and $q^{\prime \prime}$; hence,

$$
\begin{align*}
q^{\prime} z^{\lambda} & \leq q^{\prime} z^{\prime}  \tag{2}\\
q^{\prime \prime} z^{\lambda} & \leq q^{\prime \prime} z^{\prime \prime} \tag{3}
\end{align*}
$$

Substituting (2) and (3) into (1), we get

$$
\pi\left(q^{\lambda}\right)=(1-\lambda) q^{\prime} z^{\lambda}+\lambda q^{\prime \prime} z^{\lambda} \leq(1-\lambda) q^{\prime} z^{\prime}+\lambda q^{\prime \prime} z^{\prime \prime} \equiv(1-\lambda) \pi\left(q^{\prime}\right)+\lambda \pi\left(q^{\prime \prime}\right)
$$

so $\pi(q)$ is convex.

The convexity of the profit function can be given an intuitive economic interpretation. Suppose that an optimizing firm initially faces prices $q^{0}$ and chooses an optimal plan $z^{0}$. We force the firm to keep its production plan $z^{0}$ constant, allow the price of output to vary, and plot profit as a function of $p$. The resulting "no-adjustment" profit function will be a straight line. If we now allow the firm to adjust its production plan optimally as $p$ changes, it certainly will do no worse and probably will do better. Hence, the profit function will be above the straight (no-adjustment) line. It will, however, be tangent to it at the value of $p^{0}$ for which the original $z^{0}$ is optimal (so no adjustment is needed anyway). This property of staying above their tangents characterizes convex functions.

Problem 3.6. If the profit function is differentiable, the envelope theorem implies that $D \pi(q)=z(q)$, that is, the derivative of the profit function at a point is simply the optimal production plan (this is Hotelling's lemma). We will show that the profit function is differentiable whenever $f()$ is strictly concave.

Fix a price vector $q$, and consider the behavior of the profit function as we move away from this point. By definition, for any change $h$ in the price vector,

$$
\begin{gather*}
\pi(q+h)=(q+h) z(q+h) \geq(q+h) z(q)=q z(q)+h z(q)=\pi(q)+h z(q)  \tag{1}\\
\pi(q)=q z(q) \geq q z(q+h)=(q+h) z(q+h)-h z(q+h)=\pi(q+h)-h z(q+h) \tag{2}
\end{gather*}
$$

Rearranging these expressions,

$$
\pi(q+h)-\pi(q)-h z(q) \geq 0 \quad \text { and } \quad h z(q+h) \geq \pi(q+h)-\pi(q)
$$

and therefore, subtracting $h z(q)$ from the right-hand side of the second inequality, and using the first one,

$$
h[z(q+h)-z(q)] \geq \pi(q+h)-\pi(q)-h z(q) \geq 0
$$

Dividing through by $\|h\|$ and taking limits as $\|h\| \rightarrow 0$, we obtain the desired result: Because $z(q+h) \rightarrow z(q)$, by the continuity of $z()$, and $h /(\|h\|)$ is bounded, the left-hand side goes to zero. Hence, so does the term in the middle, but this is just the definition of differentiability.

Problem 3.7. Suppose the profit function is $C^{2}$. Using the convexity of $\pi(q)$ and the fact that $D \pi(q)=z(q)$, show once more that factor demand functions are downward-sloping.

If the profit function

$$
\pi(p, w)=\max _{x, y}\{p y-w x \text { s.t. }(y,-x) \in Y\}=p y(p, w)-w x(p, w)
$$

is differentiable, the envelope theorem yields

$$
\frac{\partial \pi(p, w)}{\partial p}=y(p, w) \text { and } \frac{\partial \pi(p, w)}{\partial w_{j}}=-x_{j}(p, w)
$$

That is, the first partial derivative of the profit function with respect to the price of output gives us the supply schedule, and differentiation with respect to the jthfactor price yields -1 times the corresponding factor demand function.

From before, we know that $\pi(p, w)$ is convex on input and output prices; hence, if $\pi(p, w)$ is $C^{2}$ (implying that $y(p, w)$ and $x(p, w)$ are differentiable), we have the following:

By convexity, the Hessian matrix $D^{2} \pi(p, w)$ is positive semidefinite, which implies that its diagonal elements must be nonnegative. Hence

$$
\begin{array}{cc}
\frac{\partial^{2} \pi(p, w)}{\partial p^{2}}=\frac{\partial y(p, w)}{\partial p} \geq 0 & \text { (upward-sloping supply functions) } \\
\frac{\partial^{2} \pi(p, w)}{\partial w_{j}^{2}}=-\frac{\partial x_{j}(p, w)}{\partial w_{j}} \geq 0 & \text { (downward-sloping factor demands) }
\end{array}
$$

Problem 3.8. Show that the optimal contract involves no layoffs (i.e., $n_{t}=1$ for all $i$ ). Hint: Suppose we have a contract that specifies some layoffs in certain states of nature. Then workers face a lottery between working and being laid off in each of these states, and, being risk-averse, they do not like it. Show that it is possible to construct another contract with no layoffs that will yield the same profit in each state and will be strictly preferred by workers. A contract featuring slightly lower pay will be acceptable to workers and strictly preferred by firms. Does the argument rely in any way on the firm's risk neutrality?

Consider a contract $C$ that specifies layoffs in some state of nature:

$$
C\left(x_{i}\right)=\left[n_{i}<1, h_{i}, c_{i}^{e}, c_{i}^{u}\right]
$$

In state $i$, each worker faces a lottery: With probability $n_{i}$ he will be employed and will get $\left(h_{i}, c_{\imath}^{e}\right)$, and with probability $1-n_{\imath}$ he will get $\left(0, c_{i}^{\mu}\right)$. His expected utility, before he knows whether or not he will be laid off, is given by

$$
W_{i}=n_{i}\left[U\left(c_{i}^{e}\right)+V\left(1-h_{i}\right)\right]+\left(1-n_{i}\right)\left[U\left(c_{i}^{u}\right)+V(1)\right]
$$

A risk-averse worker will strictly prefer another contract $C^{\prime}$ that will guarantee him, with certainty, the expected hours and the expected consumption level under $C$, that is, a contract with

$$
n_{i}^{\prime}=1, \quad h_{i}^{\prime}=n_{i} h_{i}, \quad \text { and } c_{i}^{\prime}=n_{i} c_{i}^{e}+\left(1-n_{i}\right) c_{i}^{u}
$$

That is, by the strict concavity of $U$ and $V$, we have

$$
\begin{gathered}
n_{i} U\left(c_{t}^{e}\right)+\left(1-n_{i}\right) U\left(c_{i}^{u}\right)<U\left[n_{i} c_{i}^{e}+\left(1-n_{i}\right) c_{i}^{u}\right] \\
n_{i} V\left(1-h_{i}\right)+\left(1-n_{i}\right) V(1)<V\left[n_{i}\left(1-h_{i}\right)+\left(1-n_{i}\right) 1\right]
\end{gathered}
$$

This new contract, however, will yield exactly the same profit in this state as would the previous one, for the total number of hours worked and the total wage bill will be exactly the same in the two cases. Because firms are indifferent between the two contracts and workers are strictly better off, the initial contract would not have been Pareto-optimal.

Alternatively, risk-averse workers will be willing to pay an insurance premium (work at a lower expected wage) to eliminate layoff-related uncertainty within each state. The firm can provide this service at no cost by allocating optimal work hours equally among workers and make a profit in the process.

Notice that the assumption of the firm's risk neutrality is not required for this result: Because the new contract involves exactly the same profit in each state as the previous one, even a risk-averse firm would be indifferent between them. Hence, the crucial assumption is the workers' risk aversion, but we have also made some implicit assumptions that are needed for the result. In particular, we have assumed that men and hours are "perfect substitutes," in the sense (i) that the only thing that matters is total hours, so that we can write the production function in the form $f(n h)$, (ii) that compensation per employed worker involves no "fixed-cost" elements, and (iii) that there are no legal obstacles to varying work hours.

Problem 3.9. We will now investigate some properties of the optimal contract.

(i) Write the first-order conditions for $\left(\mathrm{P}^{\prime}\right)$, and show that they imply the following conditions:

$$
\begin{array}{ll}
c_{H}=c_{L} & \text { (efficient risk-sharing) } \\
x_{i} f^{\prime}\left(h_{i}\right)=\frac{V^{\prime}\left(1-h_{i}\right)}{U^{\prime}\left(c_{i}\right)} \text { for each } i=H, L & \text { (efficient hours) }
\end{array}
$$

Interpret these two conditions.

(ii) Show that $h_{H} \geq h_{L}$ (i.e., more hours are worked when productivity is high).

(iii) Show that $h_{H}>h_{L}$ (by contradiction again, suppose $h_{H}=h_{L}$ ).

Differentiating the Lagrangian function for $\left(\mathrm{P}^{\prime}\right)$,

$$
£=\sum_{i} q_{i}\left[x_{i} f\left(h_{i}\right)-c_{i}\right]+\mu\left[\sum_{i} q_{i}\left\{U\left(c_{i}\right)+V\left(1-h_{i}\right)\right\}-W_{0}\right]
$$

we obtain the first-order necessary conditions:

$$
\begin{align*}
& \frac{\partial £}{\partial h_{i}}=q_{i} x_{i} f^{\prime}\left(h_{i}\right)-\mu q_{i} V^{\prime}\left(1-h_{i}\right)=0 \text { for each } i \\
& \quad \Rightarrow x_{i} f^{\prime}\left(h_{i}\right)=\mu V^{\prime}\left(1-h_{i}\right)  \tag{1}\\
& \quad \frac{\partial £}{\partial c_{i}}=-q_{i}+\mu q_{i} U^{\prime}\left(c_{i}\right)=0 \text { for each } i \\
& \quad \Rightarrow \mu=\frac{1}{U^{\prime}\left(c_{i}\right)} \tag{2}
\end{align*}
$$

Notice that by (2) and the fact that $U()$ is strictly increasing, the multiplier $\mu$ is strictly positive, implying that the (participation) constraint is always binding.

Substituting (2) into (1), we obtain the efficient-hours condition:

$$
x_{i} f^{\prime}\left(h_{i}\right)=\frac{V^{\prime}\left(1-h_{i}\right)}{U^{\prime}\left(c_{i}\right)}
$$

That is, efficiency in employment requires that we equate the marginal product of labor (the marginal rate of transformation of time into output) to the marginal rate of substitution between leisure and consumption for the worker.

Next, (2) implies $U^{\prime}\left(c_{H}\right)=U^{\prime}\left(c_{L}\right)$, and by the strict concavity of $U()$ (which implies that $U^{\prime}()$ is strictly decreasing), consumption must be the same in both states. It is efficient for risk-neutral firms to completely insure consumption for risk-averse workers. (With a more general specification, e.g., risk-averse firms, efficient risk-sharing would require that the marginal rate of substitution of consumption across states be the same for all agents. Notice that if the workers' utility function is not separable, consumption need not be the same in all states,
even with risk-neutral firms. What is equalized is only marginal utility, but this may vary with leisure.)

From the first-order conditions, we have $\mu>0$ and

$$
\begin{gathered}
x_{H} f^{\prime}\left(h_{H}\right)=\mu V^{\prime}\left(1-h_{H}\right) \\
x_{L} f^{\prime}\left(h_{L}\right)=\mu V^{\prime}\left(1-h_{L}\right)
\end{gathered}
$$

Subtracting the second expression from the first, we obtain

$$
\begin{equation*}
x_{H} f^{\prime}\left(h_{H}\right)-x_{L} f^{\prime}\left(h_{L}\right)=\mu\left[V^{\prime}\left(1-h_{H}\right)-V^{\prime}\left(1-h_{L}\right)\right] \tag{3}
\end{equation*}
$$

To show that $h_{H} \geq h_{L}$, we proceed by contradiction. Using the concavity of $U$ and $V$, we will show that (3) cannot hold if $h_{L}>h_{H}$.

If $h_{L}>h_{H}$, then, by the strict concavity of $f$,

$$
f^{\prime}\left(h_{L}\right)<f^{\prime}\left(h_{H}\right)
$$

and because $x_{L}<x_{H}$, the left-hand side of (3) is strictly positive:

$$
x_{H} f^{\prime}\left(h_{H}\right)-x_{L} f^{\prime}\left(h_{L}\right)>0
$$

On the other hand, $h_{L}>h_{H}$ implies $1-h_{L}<1-h_{H}$. It follows, by the decreasing marginal utility of leisure, that

$$
V^{\prime}\left(1-h_{L}\right)>V^{\prime}\left(1-h_{H}\right)
$$

which implies that the right-hand side of (3) is strictly negative,

$$
\mu\left[V^{\prime}\left(1-h_{H}\right)-V^{\prime}\left(1-h_{L}\right)\right]<0
$$

Hence, the two sides of (3) have different signs, and the equality cannot hold. We have reached a contradiction.

Finally, we show that $h_{H}>h_{L}$. If $h_{H}=h_{L}=h$, equation (3) becomes

$$
\left(x_{H}-x_{L}\right) f^{\prime}(h)=\mu 0=0
$$

implying that $x_{H}=x_{L}$, a contradiction.

Problem 3.10. Show that under the first-best contract characterized in Problem 3.9 , the firm has an incentive to lie in one of the states. Which one? Why?

Under the first-best contract the firm will always announce $x_{H}$ and therefore will lie in the bad state. Because compensation is the same in all states, and more hours are worked when high productivity is announced, the firm's profits will be higher if it announces $x_{H}$ even when the true state is $x_{L}$.

Problem 3.11. Show that the incentive compatibility constraints, by themselves, imply that $c_{H} \geq c_{L}$ and $h_{H} \geq h_{L}$.

Rearranging the incentive compatibility constraints, we obtain

$$
\begin{align*}
& (\mathrm{IC} . L) \Rightarrow c_{H}-c_{L} \geq x_{L}\left[f\left(h_{H}\right)-f\left(h_{L}\right)\right]  \tag{1}\\
& (\mathrm{IC} . H) \Rightarrow x_{H}\left[f\left(h_{H}\right)-f\left(h_{L}\right)\right] \geq c_{H}-c_{L} \tag{2}
\end{align*}
$$

Adding these two inequalities, term by term,

$$
\left(c_{H}-c_{L}\right)+x_{H}\left[f\left(h_{H}\right)-f\left(h_{L}\right)\right] \geq\left(c_{H}-c_{L}\right)+x_{L}\left[f\left(h_{H}\right)-f\left(h_{L}\right)\right]
$$

from where

$$
\left(x_{H}-x_{L}\right)\left[f\left(h_{H}\right)-f\left(h_{L}\right)\right] \geq 0
$$

implying that

$$
f\left(h_{H}\right) \geq f\left(h_{L}\right)
$$

Hence, $h_{H} \geq h_{L}$, because $f()$ is increasing. The second inequality, $c_{H} \geq c_{L}$, then follows by (1).

Problem 3.12. Write the first-order conditions for $\left(\mathrm{P}^{\prime \prime}\right)$. Use them and the preceding results in the following:

(i) Show that $c_{H}>c_{L}$ and $h_{H}>h_{L}$. Hint: Suppose not. Then two of the first-order conditions imply $\lambda_{L}=\lambda_{H}$; use this and the other first-order conditions to obtain a contradiction, $x_{L}>x_{H}$.

(ii) Show that both incentive constraints cannot be binding at the same time. (If they are, $h_{H}=h_{L}$, contradicting the previous result.)

Hence, precisely one incentive compatibility constraint must be binding. Why?

(iii) Show that the active incentive compatibility constraint is the one corresponding to the low-productivity state.

(iv) Show that the employment level is also distorted, but only in one state. That is, for the given $c_{i}$, compare the employment level in each state with the one that would be implied by the efficient-hours condition, $x_{i} f^{\prime}\left(h_{i}\right)=V^{\prime}\left(1-h_{i}\right) / U^{\prime}\left(c_{i}\right)$.

Differentiating the Lagrangian for $\left(\mathrm{P}^{\prime}\right)$,

$$
\begin{aligned}
\mathcal{E}= & q_{L}\left[x_{L} f\left(h_{L}\right)-c_{L}\right]+q_{H}\left[x_{H} f\left(h_{H}\right)-c_{H}\right] \\
& +\mu\left\{q_{L}\left[U\left(c_{L}\right)+V\left(1-h_{L}\right)\right]+q_{H}\left[U\left(c_{H}\right)+V\left(1-h_{H}\right)\right]-W_{0}\right\} \\
& +\lambda_{L}\left\{x_{L} f\left(h_{L}\right)-c_{L}-x_{L} f\left(h_{H}\right)+c_{H}\right\}+\lambda_{H}\left\{x_{I} f\left(h_{H}\right)-c_{H}-x_{H} f\left(h_{L}\right)+c_{L}\right\}
\end{aligned}
$$

with respect to the choice variables, we obtain the first-order conditions

$$
\begin{gather*}
\frac{\partial £}{\partial h_{L}}=q_{L} x_{L} f^{\prime}\left(h_{L}\right)-\mu q_{L} V^{\prime}\left(1-h_{L}\right)+\lambda_{L} x_{L} f^{\prime}\left(h_{L}\right)-\lambda_{H} x_{H} f^{\prime}\left(h_{L}\right)=0  \tag{L}\\
\frac{\partial £}{\partial h_{H}}=q_{H} x_{H} f^{\prime}\left(h_{H}\right)-\mu q_{H} V^{\prime}\left(1-h_{H}\right)-\lambda_{L} x_{L} f^{\prime}\left(h_{H}\right)+\lambda_{H} x_{H} f^{\prime}\left(h_{H}\right)=0  \tag{H}\\
\frac{\partial £}{\partial c_{L}}=-q_{L}+\mu q_{L} U^{\prime}\left(c_{L}\right)-\lambda_{L}+\lambda_{H}=0  \tag{L}\\
\frac{\partial £}{\partial c_{H}}=-q_{H}+\mu q_{H} U^{\prime}\left(c_{H}\right)-\lambda_{H}+\lambda_{L}=0 \tag{H}
\end{gather*}
$$

or, rearranging,

$$
\begin{gather*}
f^{\prime}\left(h_{L}\right)\left[q_{L} x_{L}+\lambda_{L} x_{L}-\lambda_{H} x_{H}\right]=\mu q_{L} V^{\prime}\left(1-h_{L}\right)  \tag{L}\\
f^{\prime}\left(h_{H}\right)\left[q_{H} x_{H}-\lambda_{L} x_{L}+\lambda_{H} x_{H}\right]=\mu q_{H} V^{\prime}\left(1-h_{H}\right)  \tag{H}\\
\mu q_{L} U^{\prime}\left(c_{L}\right)=q_{L}+\lambda_{L}-\lambda_{H}  \tag{L}\\
\mu q_{H} U^{\prime}\left(c_{H}\right)=q_{H}+\lambda_{H}-\lambda_{L} \tag{H}
\end{gather*}
$$

In addition, we have the incentive compatibility and participation constraints and their corresponding complementary slackness conditions:

$$
\begin{array}{ll}
x_{L} f\left(h_{L}\right)-c_{L} \geq x_{L} f\left(h_{H}\right)-c_{H} & \text { with equality if } \lambda_{L}>0 \\
x_{H} f\left(h_{H}\right)-c_{H} \geq x_{H} f\left(h_{L}\right)-c_{L} & \text { with equality if } \lambda_{H}>0 \\
\sum_{i} q_{i}\left[U\left(c_{i}\right)+V\left(1-h_{L}\right)\right] \geq W_{0} & \text { with equality if } \mu>0 \tag{PART}
\end{array}
$$

$\lambda_{L} \geq 0$ with equality if (IC. $L$ ) is not binding

$\lambda_{H} \geq 0$ with equality if (IC. $H$ ) is not binding

$\mu \geq 0 \quad$ with equality if (PART) is not binding

This looks like a mess, but it is not so bad. Often, the best strategy is to guess the result and then prove it by contradiction.

(i) By contradiction (recall that the desired inequality holds, at least nonstrictly, by Problem 3.11). Suppose $c_{H}=c_{L} \equiv c$ and $h_{H}=h_{L} \equiv h$. Then the first-order conditions imply

$$
\begin{aligned}
& \left(\mathrm{F} . c_{L}^{\prime}\right) \Rightarrow \mu U^{\prime}(c)=1+\frac{\lambda_{L}-\lambda_{H}}{q_{L}} \\
& \left(\mathrm{~F} . c_{H}^{\prime}\right) \Rightarrow \mu U^{\prime}(c)=1+\frac{\lambda_{H}-\lambda_{L}}{q_{H}}
\end{aligned}
$$

Hence,

$$
\frac{\lambda_{L}-\lambda_{H}}{q_{L}}=\frac{\lambda_{H}-\lambda_{L}}{q_{H}} \Rightarrow\left(\lambda_{H}-\lambda_{L}\right)\left(\frac{1}{q_{L}}+\frac{1}{q_{H}}\right)=0 \Rightarrow \lambda_{H}=\lambda_{L} \equiv \lambda
$$

Then the other first-order conditions imply that

$$
\begin{aligned}
& \left(\mathrm{F} . h_{L}\right) \Rightarrow x_{L} f^{\prime}(h)-\mu V^{\prime}(1-h)=\frac{\lambda\left(x_{H}-x_{L}\right) f^{\prime}(h)}{q_{L}}>0 \\
& \left(\mathrm{~F} . h_{H}\right) \Rightarrow x_{H} f^{\prime}(h)-\mu V^{\prime}(1-h)=\frac{\lambda\left(x_{L}-x_{H}\right) f^{\prime}(h)}{q_{H}}<0
\end{aligned}
$$

Subtracting the second from the first inequality,

$$
\left(x_{L}-x_{H}\right) f^{\prime}(h)>0 \Rightarrow x_{L}>x_{H}
$$

which is a contradiction.

(ii) Next, we show that the two incentive compatibility constraints cannot both be binding at the same time. Suppose they are. Then

$$
\begin{aligned}
& (\text { IC. } L) \Rightarrow c_{H}-c_{L}=x_{L}\left[f\left(h_{H}\right)-f\left(h_{L}\right)\right] \\
& (\mathrm{IC} . H) \Rightarrow c_{H}-c_{L}=x_{H}\left[f\left(h_{H}\right)-f\left(h_{L}\right)\right]
\end{aligned}
$$

and subtracting these two expressions,

$$
\left(x_{H}-x_{L}\right)\left[f\left(h_{H}\right)-f\left(h_{L}\right)\right]=0
$$

which implies $h_{H}=h_{L}$, contradicting the previous claim.

(iii) Hence, at most one of the incentive constraints binds. Moreover, at least one of them does, for if it did not we would be back to the first-best contract, and we know that the firm has an incentive to lie in the bad state.

To show that this constraint is always binding at a (second-best) optimum, we proceed by contradiction. If (IC. $L$ ) doesn't bind, then (IC. $H$ ) must be binding, and we have $\lambda_{L}=0$ and $\lambda_{H} \geq 0$. Then

$$
\begin{aligned}
& \left(\mathrm{F} . c_{L}^{\prime}\right) \Rightarrow \mu U^{\prime}\left(c_{L}\right)=1-\frac{\lambda_{H}}{q_{L}} \\
& \left(\mathrm{~F} . c_{H}^{\prime}\right) \Rightarrow \mu U^{\prime}\left(c_{H}\right)=1+\frac{\lambda_{H}}{q_{H}}
\end{aligned}
$$

implying $U^{\prime}\left(c_{L}\right) \leq U^{\prime}\left(c_{H}\right)$. Hence $c_{L} \geq c_{H}$, contradicting (i).

(iv) Hence, (IC. $L$ ) is binding, and (IC. $H$ ) is not, implying $\lambda_{H}=0, \lambda_{L} \geq 0$, and

$$
\begin{gathered}
\left(\mathrm{F} \cdot h_{L}^{\prime}\right) \Rightarrow f^{\prime}\left(h_{L}\right) x_{L}\left(q_{L}+\lambda_{L}\right)=\mu q_{L} V^{\prime}\left(1-h_{L}\right) \\
\left(\mathrm{F} \cdot c_{L}^{\prime}\right) \Rightarrow \mu q_{L} U^{\prime}\left(c_{L}\right)=q_{L}+\lambda_{L}
\end{gathered}
$$

Combining these two expressions, we obtain the efficient-hours condition:

$$
x_{L} f^{\prime}\left(h_{L}\right)=\frac{V^{\prime}\left(1-h_{L}\right)}{U^{\prime}\left(c_{L}\right)}
$$

Thus, employment is efficient in the low-productivity state. In the highproductivity state, however, we have

$$
\begin{gather*}
\left(\mathrm{F} . c_{H}^{\prime}\right) \Rightarrow \mu q_{H} U^{\prime}\left(c_{H}\right)=q_{H}-\lambda_{L}>0  \tag{1}\\
\left(\mathrm{~F} . h_{H}^{\prime}\right) \Rightarrow f^{\prime}\left(h_{H}\right)\left(q_{H} x_{H}-\lambda_{L} x_{L}\right)=\mu q_{H} V^{\prime}\left(1-h_{H}\right)
\end{gather*}
$$

Combining these two expressions,

$$
\begin{aligned}
& f^{\prime}\left(h_{H}\right)\left[q_{H} x_{H}-\lambda_{L}\left(x_{L}+x_{H}-x_{H}\right)\right]=\left(q_{H}-\lambda_{L}\right) \frac{V^{\prime}\left(1-h_{H}\right)}{U^{\prime}\left(c_{H}\right)} \\
& \quad \Rightarrow f^{\prime}\left(h_{H}\right) x_{H}\left(q_{H}-\lambda_{L}\right)+f^{\prime}\left(h_{H}\right) \lambda_{L}\left(x_{H}-x_{L}\right)=\left(q_{H}-\lambda_{L}\right) \frac{V^{\prime}\left(1-h_{H}\right)}{U^{\prime}\left(c_{H}\right)} \\
& \quad \Rightarrow x_{H} f^{\prime}\left(h_{H}\right)=\frac{V^{\prime}\left(1-h_{H}\right)}{U^{\prime}\left(c_{H}\right)}-f^{\prime}\left(h_{H}\right) \frac{\lambda_{L}\left(x_{H}-x_{L}\right)}{q_{H}-\lambda_{L}}
\end{aligned}
$$

Because $q_{H}-\lambda_{L}>0$, by (1), we have

$$
x_{H} f^{\prime}\left(h_{H}\right)<\frac{V^{\prime}\left(1-h_{H}\right)}{U^{\prime}\left(c_{H}\right)}
$$

and, by the concavity of $f(), h_{H}$ is higher than the efficient number of hours. Hence, the second distortion induced by the incentive compatibility constraint takes the form of "overemployment" in the high-productivity state.

Different assumptions about worker and firm preferences and the nature of the private information lead to different predictions concerning the direction of the distortion generated by the incentive constraints. For example, Stiglitz (1984, pp. 19ff.) notes that if firms are more risk-averse than workers, underemployment becomes the more likely outcome. Cooper (1987, pp. 36-9) considers a model in which the stochastic state variable has to do with preferences rather than with output prices or productivity and is observed only by workers. He writes worker utility as $U(c, 1-h, x)$ and shows that if leisure is normal and $U_{13} \geq 0$, then underemployment will result in most states.

## Chapter 8

Problem 1.5. Let " $\geq$ " be a continuous and monotonic preference preorder defined on a subset $X$ of $\mathbb{R}^{\mathrm{n}}$. Show that $\partial \geq=\mathrm{I} \equiv\{(x, y) \in X \times X ; x \sim y\}$.

Take some arbitrary point $(x, y)$ in the boundary of " $\geq$." By continuity, " $\geq$ " is closed and therefore contains its boundary. Hence, $(x, y) \in \geq$ (i.e., $x \geq y$ ). If $x>y$, continuity also implies that all points close enough to $(x, y)$ will be in " $\geq$ " (i.e.,

" $>$ " is open) and hence in " $\geq$." This, however, would contradict the assumption that $(x, y)$ is a boundary point of " $\geq$ ". Hence, we must have $x \sim y$, and it follows that any boundary point of " $\geq$ " lies on $I$, i.e., that $\partial \geq \subseteq I$.

For the converse, take $(x, y)$ such that $x \sim y$. By monotonicity, there exists some $y^{\prime}>y$ arbitrarily close to $y$ such that $y^{\prime}>y \sim x$. Hence $\left(x, y^{\prime}\right) \notin \geq$, even though it is arbitrarily close to $(x, y)$. Hence, $(x, y)$ is a boundary point of " $\geq$," which implies that $I \subseteq \partial \geq$, because $(x, y)$ is an arbitrary point of $I$.

Problem 1.7. Let " $\geq$ " be a convex preference preorder defined on a convex set $X$. Show that the better-than sets induced by these preferences, $B(y)=\{x \in X ; x \geq y\}$, are convex.

Fix an arbitrary point $y$ in $X$, and consider the set $B(y)=\{x \in X ; x \geq y\}$. Let $x^{\prime}$ and $x^{\prime \prime}$ be any two points in $B(y)$, and (relabeling them if necessary) assume that $x^{\prime} \geq x^{\prime \prime}$. Then, by the convexity of preferences, we have

$$
x^{\lambda}=(1-\lambda) x^{\prime}+\lambda x^{\prime \prime} \geq x^{\prime \prime} \text { for any } \lambda \in(0,1)
$$

Because $x^{\prime \prime} \in B(y)$, moreover, we have $x^{\prime \prime} \geq y$. By transitivity,

$$
(1-\lambda) x^{\prime}+\lambda x^{\prime \prime} \geq x^{\prime \prime} \geq y \text { for any } \lambda \in(0,1)
$$

Hence, $(1-\lambda) x^{\prime}+\lambda x^{\prime \prime} \in B(y)$, and it follows that $B(y)$ is a convex set.

Problem 1.13. Let " $\geq$ " be a continuous and strictly monotone preference preorder defined on $X=\mathbb{R}_{+}^{\mathrm{n}}$, and let $z$ be an arbitrary point in $X$. We will show that the indifference set $I(z)$ is connected.

A standard way to show that a set $A$ is connected is by showing that it is homeomorphic to another set $B$ that is known to be connected - that is, that there exists an invertible continuous function $h()$ with a continuous inverse that maps $A$ onto $B$. Then $A=h^{-1}(B)$ is the continuous image of a connected set and therefore is connected itself (by Theorem 9.3 in Chapter 2).

In this case, let $B$ be the open unit simplex

$$
\Delta=\left\{z \in \mathbb{R}_{++}^{\mathfrak{n}} ; z e=1\right\}
$$

where $e=\underline{1}$ and $\mathbb{R}_{+}^{\mathrm{n}}=\left\{x \in \mathbb{R}^{\mathrm{n}} ; x_{t}>0 \forall i=1, \ldots, n\right\}$. Given an indifference set $I(z)$, we "project" it onto $\Delta$ by following a ray through the origin from each point $x$ in $I$ until it intersects the simplex (Figure 8.4). Hence, the function $h()$ is of the form

$$
h(x)=\frac{1}{x e} x=\frac{1}{\sum_{i=1}^{n} x_{i}} x
$$

Show that $h()$ is a homeomorphism.

We have to show that the function $h: I \longrightarrow \Delta$ is a homeomorphism. It is clear that $h()$ is one-to-one, for two points $x$ and $x^{\prime}$ in $I$ would have the same image only if they lay on the same ray through the origin; but then these two points could not be on the same indifference curve, because the "higher" one would be preferred, by the strict monotonicity of preferences. Second, $h()$ maps $I$ onto $\Delta$ (i.e., each point $y$ in $\Delta$ has a preimage in $I$ ). This is easily seen by taking an arbitrary point $y$ in $\Delta$ and considering the ray from the origin that goes through it. The argument in the proof of Lemma 1.12 then shows that this ray must intersect the indifference set precisely once. It is also easy to check that $h()$ is a continuous function.

It only remains, then, to show that the inverse function $h^{-1}$ is continuous. Using
the sequential characterization of continuity, this means that given any $y^{0}$ in $\Delta$ and an arbitrary convergent sequence $\left\{y_{n}\right\}$ in $\Delta$, with $\left\{y_{n}\right\} \rightarrow \mathrm{y}^{0}$, the companion sequence $\left\{x_{n}\right\}$, with $x_{n}=h^{-1}\left(y_{n}\right) \in I$, converges to $x^{0}=h^{-1}\left(y^{0}\right) \in I$.

We will establish this result by contradiction. Suppose that $\left\{y_{n}\right\} \rightarrow y^{0}$, but $\left\{x_{n}\right\}$ does not converge to $x^{0}=h^{-1}\left(y^{0}\right)$. Notice that because $y$ and $x=h^{-1}(y)$ lie on the same ray through the origin for any $y \in \Delta$, we can write

$$
x_{n}=h^{-1}\left(y_{n}\right)=\lambda_{n} y_{n} \quad \text { for each } n \quad \text { and } \quad x^{0}=h^{-1}\left(y^{0}\right)=\lambda^{0} y^{0}
$$

for some nonnegative real numbers $\lambda_{n}$ and $\lambda^{0}$. Notice also that $\left\{x_{n}\right\}$ and $x^{0}$ lie on the same indifference set, $I(z)$. On the other hand, we have

$$
x_{n}=\lambda_{n} y_{n} \nrightarrow \lambda^{0} y^{0}
$$

but because $\left\{y_{n}\right\} \rightarrow y^{0}$, it must be that $\left\{\lambda_{n}\right\} \nrightarrow \lambda^{0}$. Now, $\left\{\lambda_{n}\right\}$ is a sequence of real numbers bounded below by zero. Hence, if $\left\{\lambda_{n}\right\} \nrightarrow \lambda^{0}$, there are only two possibilities:

(i) $\left\{\lambda_{n}\right\}$ is bounded above. Then $\left\{\lambda_{n}\right\}$ contains a convergent subsequence $\left\{\lambda_{n_{k}}\right\}$, with limit $\mu \neq \lambda^{0}$. (Because $\left\{\lambda_{n}\right\} \rightarrow \lambda^{0}$, there is some $\varepsilon>0$ and a subsequence of $\left\{\lambda_{n}\right\}$ that lies outside $B_{\varepsilon}\left(\lambda^{0}\right)$. Because this subsequence is bounded, it contains a convergent subsequence (with limit $\mu \neq \lambda^{0}$ ), by the Bolzano-Weierstrass theorem (Theorem 3.3 in Chapter 2).

(ii) $\left\{\lambda_{n}\right\}$ is not bounded above. Then $\left\{\lambda_{n}\right\}$ contains a subsequence $\left\{\lambda_{n_{k}}\right\}$ with $\left\{\lambda_{n}\right\} \rightarrow \infty$.

We will consider each case in turn and seek a contradiction.

(i) Assume that $\left\{\lambda_{n_{k}}\right\} \rightarrow \mu \neq \lambda^{0}$. Then, because $\left\{y_{n_{k}}\right\} \rightarrow y^{0} \in \Delta$, we have

$$
x_{n_{k}}=h^{-1}\left(y_{n_{k}}\right)=\lambda_{n_{k}} y_{n_{k}} \rightarrow \mu y^{0} \neq \lambda^{0} y^{0}=x^{0}=h^{-1}\left(y^{0}\right)
$$

Observe that $\left\{x_{n_{k}}\right\}$ is a convergent sequence contained in the set $I(z)=B(z) \cap$ $W(z)$. Because both $B(z)$ and $I(z)$ are closed, by the continuity of preferences, $I(z)$ is also closed, and it follows that the limit of $\left\{x_{n_{k}}\right\}, \mu y^{0}$, lies in $I(z)$. Hence, we have that $\mu y^{0}$ and $\lambda y^{0}=x^{0}$ lie on the same indifference curve $I(z)$ and on the same ray through the origin. Because we know that there is precisely one point of intersection between these two sets, it follows that $\mu=\lambda^{0}$, which contradicts the fact that $\mu \neq \lambda^{0}$. Hence, if $\left\{\lambda_{n}\right\}$ is bounded, we have $\left\{\lambda_{n}\right\} \rightarrow \lambda^{0}$, implying that $\left\{x_{n}=h^{-1}\left(y_{n}\right)\right\} \rightarrow x^{0}=h^{-1}\left(y^{0}\right)$. Because $y^{0}$ was an arbitrary point of $\Delta$, this establishes the continuity of $h^{-1}()$.

(ii) Suppose now that $\left\{\lambda_{n_{k}}\right\} \rightarrow \infty$, and fix some $\varepsilon>0$. Because $\left\{y_{n_{k}}\right\} \rightarrow y^{0}$, there is some $N$ such that $y_{n_{k}} \geq y^{0}-\varepsilon \underline{1}$ for all $n_{k}>N$. Because $\left\{\lambda_{n_{k}}\right\} \rightarrow \infty$, moreover, we have

$$
x_{n_{k}}=h^{-1}\left(y_{n_{k}}\right)=\lambda_{n_{k}} y_{n_{k}} \geq \lambda_{n_{k}}\left(y^{0}-\varepsilon \underline{1}\right)>\lambda^{0} y^{0}=h^{-1}\left(y^{0}\right)
$$

for all $n_{k}$ sufficiently large. Notice that $x_{n_{k}}$ lies on the same indifference curve as $h^{-1}\left(y^{0}\right)$, but it also dominates the latter point, which contradicts the monotonicity of preferences. Hence, $\left\{\lambda_{n}\right\}$ cannot be unbounded.

Problem 2.2. Give a direct proof of the continuity of the budget correspondence. Hint: Use the sequential characterizations of upper and lower hemicontinuity. For upper hemicontinuity, consider a sequence $x_{n} \in B\left(p_{n}, y_{n}\right)$ converging to a point $(p, y) \gg \underline{0}$. Show that it is bounded, and apply the Bolzano-Weierstrass theorem. For lower hemicontinuity, construct the sequence as in Problem 2.6 in Chapter 7.

- Upper hemicontinuity. First, it is clear that for given $(p, y)$ with $(p, y) \gg \underline{0}$ (i.e., all components of the vector must be strictly positive), $B(p, y)$ is a compact set.

Hence $B()$ is compact-valued, and to establish its upper hemicontinuity it suffices to show that given any price-income sequence $\left\{\left(p_{n}, y_{n}\right)\right\}$ converging to $(p, y) \gg \underline{0}$, any companion sequence of feasible consumption bundles $\left\{x_{n}\right\}$, with $x_{n} \in B\left(p_{n}, y_{n}\right)$, has a convergent subsequence $\left\{x_{n_{k}}\right\}$ whose limit is a feasible consumption bundle $x \in B(p, y)$.

We first show that there is some integer $N$ such that $\left\{x_{n} ; n>N\right\}$ is bounded (which implies that the whole sequence is bounded). Let $x_{n}^{g}$ denote the $g$ th component of the consumption bundle $x_{n}$ (i.e., the consumption of the gth good). Then, given income $y_{n}$ and the price of this good $p_{n}^{g}$, the maximum feasible consumption of good $g$ is bounded by $y_{n} / p_{n}^{g}$. Hence,

$$
0 \leq x_{n}^{g} \leq y_{n} / p_{n}^{g}
$$

Now, because $\left\{\left(p_{n}, y_{n}\right)\right\} \rightarrow(p, y) \gg \underline{0}$, there is some $N$ such that for all $n>N$ we have

$$
y_{n} \leq y+1 \quad \text { and } p_{n}^{g} \geq p^{g} / 2 \geq p_{\min } / 2, \quad \text { where } p_{\min }=\min _{g} p^{g}>0
$$

Hence, each of the components of $x_{n}$ is bounded by

$$
0 \leq x_{n}^{g} \leq \frac{2(y+1)}{p_{\min }}
$$

for $n>N$. Hence, $\left\{x_{n}\right\}$ is a bounded sequence, and therefore it contains a convergent subsequence (by Problem 3.12 in Chapter 2). Call this convergent subsequence $\left\{x_{n_{k}}\right\}$, and let $x$ be its limit. Because $x_{n_{k}} \in B\left(p_{n_{k}}, y_{n_{k}}\right)$, we have $p_{n_{k}} x_{n_{k}} \leq$ $y_{n_{k}}$ for each $n_{k}$. Taking limits of both sides of the inequality as $n_{k} \rightarrow \infty$, we have $p x$ $\leq y$. Hence, $x \in B(p, y)$, which establishes the upper hemicontinuity of $B()$.

- To establish that $B()$ is an lhc correspondence, we need to show that given any price-income sequence $\left\{\left(p_{n}, y_{n}\right)\right\}$ converging to $(p, y) \gg \underline{0}$ and an arbitrary point $x \in B(p, y)$, there exists a companion sequence of consumption bundles $\left\{x_{n}\right\}$, with $x_{n} \in B\left(p_{n}, y_{n}\right)$ for all $n$, that converges to $x$.

We will construct such a sequence. Let

$$
\begin{aligned}
& x_{n}=x \quad \text { if } x \in B\left(p_{n}, y_{n}\right) \\
& x_{n}=\frac{y_{n}}{p_{n} x} x \text { otherwise }
\end{aligned}
$$

Notice that $x_{n}$ is feasible for $\left(p_{n}, y_{n}\right)$ by construction, because (whenever $x$ is not feasible) $x_{n}$ is defined as the largest fraction of the bundle $x$ that the consumer can afford with income $y_{n}$ and prices $p_{n}$. It is also clear that $\left\{x_{n}\right\} \rightarrow x$. If $x$ lies in the interior of the budget set (i.e., if $p x<y$ ), then we have $x_{n}=x$ for $n$ sufficiently large. Otherwise, $y=p x$, and

$$
\lim _{n \rightarrow \infty} x_{n}=\lim _{n \rightarrow \infty} \frac{y_{n}}{p_{n} x} x=\frac{y}{p x} x=x
$$

Problem 2.4. Show that if $U()$ is homothetic, then demand is linear in income, that is, $x(p, y)=y x(p, 1)$.

Recall that a function is said to be homothetic if it is a monotonically increasing transformation of a homogeneous function (Section 5 of Chapter 4). Because monotone increasing transformations of a utility function represent the same preferences, we can, without loss of generality, assume that $U$ is homogeneous of degree $k$. That is,

$$
\forall \lambda>0, U(\lambda x)=\lambda^{k} U(x)
$$

Let

$$
\begin{equation*}
x^{*} \in x(p, 1)=\arg \max _{x}\{U(x) ; p x \leq 1\} \tag{1}
\end{equation*}
$$

so that $U\left(x^{*}\right) \geq U(x)$ for any bundle $\mathrm{x}$ whose value does not exceed 1 . Now consider a consumer with income $y$, and observe that $y x^{*}$ is feasible for this agent. Using the homogeneity of $U()$, we have

$$
U\left(y x^{*}\right)=y^{k} U\left(x^{*}\right) \geq y^{k} U(x)=U(y x)
$$

for any bundle $x$ whose value does not exceed 1 . But note that any bundle whose value does not exceed $y$ can be written in the form $y x$, where $p x \leq 1$. Hence $y x^{*}$ is optimal, given income $y$, and it follows that $y x(p, 1) \subseteq x(p, y)$. The same argument in reverse yields the opposite inclusion.

Problem 2.6. Roy's identity. Assume that the indirect utility function is differentiable. Show that then

$$
x_{i}(p, y)=\frac{-\partial V(p, y) / \partial p_{i}}{\partial V(p, y) / \partial y}
$$

Recall that $V$ is defined as

$$
V(p, y)=\max _{x}\{U(x) ; y-p x=0\}
$$

The Lagrangian function for the consumer problem is

$$
£(x, \lambda ; p, y)=U(x)+\lambda\left(y-\sum_{i=1}^{G} p_{i} x_{i}\right)
$$

By the envelope theorem,

$$
\begin{aligned}
& \frac{\partial V(p, y)}{\partial p_{i}}=\frac{\partial £\left(x^{*}, \lambda^{*}\right)}{\partial p_{i}}=-\lambda^{*} x_{i}^{*}=-\lambda^{*} x_{i}(p, y) \\
& \frac{\partial V(p, y)}{\partial y}=\frac{\partial £\left(x^{*}, \lambda *\right)}{\partial y}=\lambda^{*}
\end{aligned}
$$

Dividing these two expressions, we get the desired result.

Problem 2.7. Consider the following indirect utility function:

$$
V(p, y)=\frac{y-\sum_{k} p_{k} b_{k}}{\prod_{k} p_{k}^{a_{k}}}, \quad \text { where } \sum_{k} a_{k}=1
$$

Use Roy's identity to find the ordinary demand functions.

$$
\begin{aligned}
\frac{\partial V(p, y)}{\partial p_{i}} & =\frac{-b_{i}\left(\prod_{k} p_{k}^{a_{k}}\right)-\left(y-\sum_{k} p_{k} b_{k}\right)\left(a_{i} p_{i}^{a_{i}-1} \prod_{k \neq i} p_{k}^{a_{k}}\right)}{\left(\prod_{k} p_{k}^{a_{k}}\right)^{2}} \\
& =\frac{-b_{i}\left(\prod_{k} p_{k}^{a_{k}}\right)-\left(y-\sum_{k} p_{k} b_{k}\right)\left(a_{i} p_{\imath}^{-1} \prod_{k} p_{k}^{a_{k}}\right)}{\left(\prod_{k} p_{k}^{a_{k}}\right)^{2}}=\frac{-b_{i}-\left(y-\sum_{k} p_{k} b_{k}\right)\left(a_{i} p_{i}^{-1}\right)}{\prod_{k} p_{k}^{a_{k}}}
\end{aligned}
$$

and

$$
\frac{\partial V(p, y)}{\partial y}=\frac{1}{\prod_{k} p_{k}^{a_{k}}}
$$

By Roy's identity, the demand for the $i$ th good will be given by

$$
x_{i}(p, y)=\frac{-\partial V(p, y) / \partial p_{i}}{\partial V(p, y) / \partial y}=b_{1}+a_{i} \frac{y-\sum_{k} p_{k} b_{k}}{p_{i}}
$$

Problem 2.9. To complete the proof of Theorem 2.8, show that under the given assumptions, we have the following:

(i) Compensated demand is homogeneous of degree 0 in prices, and the expenditure function is homogeneous of degree 1 in $p$.

(ii) The solution to the expenditure-minimization problem yields no excess utility.

(iii) The expenditure function is concave in prices. Give an intuitive interpretation of this fact.

(i) Homogeneity. Notice that the feasible set $\{U(x) \geq u\}$ does not change with prices. Consider an arbitrary real number $\mu>0$, and notice that minimizing $p x$ or $\mu p x$ in the same set yields the same solution. Hence $h(p, u)=h(\mu p, u)$ for any $\mu>0$, and the compensated demands are homogeneous of degree 0 . Now let $x^{*}$ be a point in $h(p, u)$ and therefore in $h(\mu p, u)$. Then

$$
e(\mu p, u)=(\mu p) x^{*}=\mu(p x)^{*}=\mu e(p, u)
$$

so the expenditure function is homogeneous of degree 1

(ii) No excess utility. Let $x$ be a solution of (C.E), that is, $x \in h(p, u)$. To show that $U(x)=u$, we proceed by contradiction. Suppose this is not the case, that is, that $U(x)>u$, and consider a consumption bundle of the form $x-\varepsilon 1$, with $\varepsilon>0$. By the continuity of $U()$, we can choose $\varepsilon$ small enough that $U(x-\varepsilon \underline{1})$ $>u$, and because $\varepsilon>0$ and $p \gg \underline{0}$, we have $p(x-\varepsilon \underline{1})<p x$. Hence, $x$ cannot be optimal, because we have found another consumption bundle that will yield the required level of utility and will cost less than $x$.

(iii) Concavity of $e(p, u)$ in prices. Let $p^{\prime}$ and $p^{\prime \prime}$ be two arbitrary price vectors, and define

$$
p^{\lambda}=(1-\lambda) p^{\prime}+\lambda p^{\prime \prime} \quad \text { for } \lambda \in[0,1]
$$

Let $x^{\lambda}, x^{\prime}$, and $x^{\prime \prime}$ be optimal solutions to the expenditure-minimization problem for a given $u$ and prices $p^{\lambda}, p^{\prime}$, and $p^{\prime \prime}$ (i.e., $x^{\prime} \in h\left(p^{\prime}, u\right)$, etc.). We want to show that

$$
E\left(p^{\lambda}, u\right) \geq(1-\lambda) E\left(p^{\prime}, u\right)+\lambda E\left(p^{\prime \prime}, u\right)
$$

Now, by definition,

$$
\begin{equation*}
E\left(p^{\lambda}, u\right)=p^{\lambda} x^{\lambda}=(1-\lambda) p^{\prime} x^{\lambda}+\lambda p^{\prime \prime} x^{\lambda} \tag{1}
\end{equation*}
$$

Observe that $x^{\lambda}$ is not necessarily the optimal (cost-minimizing) bundle for prices $p^{\prime}$ or $p^{\prime \prime}$. Hence, its value at prices other than $p^{\lambda}$ is not necessarily the lowest one among the feasible bundles, and we have

$$
\begin{align*}
p^{\prime} x^{\lambda} & \geq p^{\prime} x^{\prime}  \tag{2}\\
p^{\prime \prime} x^{\lambda} & \geq p^{\prime \prime} x^{\prime \prime} \tag{3}
\end{align*}
$$

Using (2) and (3) in (1), we get

$$
\begin{aligned}
E\left(p^{\lambda}, u\right) & =(1-\lambda) p^{\prime} x^{\lambda}+\lambda p^{\prime \prime} x^{\lambda} \geq(1-\lambda) p^{\prime} x^{\prime}+\lambda p^{\prime \prime} x^{\prime \prime} \\
& \equiv(1-\lambda) E\left(p^{\prime}, u\right)+\lambda E\left(p^{\prime \prime}, u\right)
\end{aligned}
$$

which is what we wanted to show.

The concavity of the expenditure function has a very intuitive interpretation. Hold utility and all other prices constant and plot $E()$ as a
function of one price. As $p_{i}$ rises, minimum expenditure would increase linearly if the agent chose to always consume the same bundle. Generally, however, consumers will minimize the expenditure needed to reach a given indifference curve by rearranging purchases so as to take advantage of substitution possibilities among goods. Through this process the consumer cannot do worse than if no substitution were allowed, and will generally do better. Hence, $E()$ is below the linear function described earlier, except at one point at which they are tangent; thus $E$ is concave.

Problem 2.10. Show that the sequence $\left\{z_{n_{k}}\right\}$ constructed in the last part of the proof of Theorem 2.8 converges to $x$.

Choose $z$ so that $z \gg x$, and observe that each $z_{n_{k}}$ is of the form

$$
z_{n_{k}}=\left(1-\lambda_{k}\right) x+\lambda_{k} z, \quad \text { with } \lambda_{k} \in[0,1]
$$

Hence $z_{n_{k}} \gg x$ for all $\lambda_{k} \in(0,1]$, and $\left\{z_{n_{k}}\right\} \rightarrow x$ if and only if $\left\{\lambda_{k}\right\} \rightarrow 0$. We will assume that $\left\{\lambda_{k}\right\} \nrightarrow 0$ and obtain a contradiction.

Because $\left\{\lambda_{k}\right\}$ is contained in the compact interval $[0,1]$, it contains a convergence subsequence $\left\{\lambda_{k_{q}}\right\}$, with limit $\mu \in[0,1]$. Suppose $\left\{\lambda_{k}\right\} \nrightarrow 0$. Then $\mu>0$, and the subsequence $\left\{z_{n_{k_{q}}}\right\}$ converges to

$$
\hat{z}=(1-\mu) x+\mu z \gg>x
$$

By the strict monotonicity of the utility function, we have $U(\hat{z})>U(x) \geq u$. On the other hand, we have $U\left(z_{n_{k_{q}}}\right)=u_{n_{k_{q}}}$ for all $q$, and $\left\{u_{n_{k_{q}}}\right\} \rightarrow u$, implying that $U(\hat{z})=u$, contradicting the previous statement.

Problem 2.14. Prove Theorem 2.13: Equivalence between utility maximization and expenditure minimization.

- By contradiction. Let $x_{u}$ solve (C.U), and suppose $x_{u}$ does not solve (C.E) with required utility $u=U\left(x_{u}\right)$. Then there exists some consumption bundle that costs less than $x_{u}$ and yields at least as much utility, that is, there exists some $z$ such that $p z<p x_{u} \leq y$ and $U(z) \geq U\left(x_{u}\right)$. Because $z$ does not exhaust income $y$, we can find some real number $\varepsilon>0$ such that $p(z+\varepsilon \underline{1})<y$, and by the strict monotonicity of $U$ we have $U(z+\varepsilon \underline{1})>U(z) \geq U\left(x_{u}\right)$. Notice that this contradicts the assumption that $x_{u}$ solves (C.U), for we have found a bundle $z+\varepsilon 1$ that is feasible with income $y$ and yields greater utility than $x_{u}$. Hence, we conclude that $x_{u}$ must solve (C.E) when the required utility is $U\left(x_{u}\right)$, and we have $e\left(p, U\left(x_{u}\right)\right)=p x_{u}$. Finally, because $x_{u}$ solves (C.U) and we have, from Theorem 2.3, that $p x_{u}=y$, we conclude that $e\left(p, U\left(x_{u}\right)\right)=p x_{u}=y$.
- Let $x_{e}$ solve (C.E), with $u \in(\underline{u}, \bar{u})$, and observe that $u>U(\underline{0})$ implies $x_{e} \neq \underline{0}$, and therefore $p x_{e}>0$. Suppose $x_{e}$ does not solve (C.U) with income $p x_{e}$. Then there exists some consumption bundle that costs no more than $x_{e}$ and yields greater utility, that is, there exists some $z$ such that $U(z)>U\left(x_{e}\right)$ and $p z \leq p x_{e}$. Consider a bundle $z=z-\varepsilon \underline{1}$. By the continuity of $U()$ we can choose $\varepsilon>0$ small enough that $U(z-\varepsilon \underline{1})>U\left(x_{e}\right)$; moreover, $p(z-\varepsilon \underline{1})<p z \leq p x_{e}$ because $p>\underline{0}$. This contradicts the assumption that $x_{e}$ solves (C.E), for we have found a bundle $z-\varepsilon 1$ that yields more than the required utility and costs strictly less than $x_{e}$. Hence, $x_{e}$ must solve (C.U) with income $p x_{e}$. Finally, because $x_{e}$ solves (C.E) and we have, from Theorem 2.7, that $U\left(x_{e}\right)=u$, we conclude that $V\left(p, p x_{e}\right)=U\left(x_{e}\right)=u$.

Problem 3.5. Define a mapping $F: \Delta \longrightarrow \Delta$ by

$$
F(p)=\frac{p_{1}+\max \left[0, Z_{1}(p)\right], \ldots, p_{G}+\max \left[0, Z_{G}(p)\right]}{\sum_{g=1}^{G}\left(p_{g}+\max \left[0, Z_{g}(p)\right]\right)}
$$

where $Z(p)=Z_{1}(p), \ldots, Z_{G}(p)$ is an aggregate excess-demand function satisfying Walras's law, $p Z(p)=0$ for all $p$. Show that any fixed point of $F()$ is a competitive-equilibrium price vector. That is, if $p^{*}=F\left(p^{*}\right)$, then we have

$$
Z_{g}\left(p^{*}\right) \leq 0 \forall g \quad \text { and } \quad Z_{g}\left(p^{*}\right)=0 \quad \text { whenever } p_{g}^{*}>0
$$

Let $p$ be a fixed point of $F()$, that is, a point such that $p_{g}=F_{g}\left(p_{g}\right)$ for $g=1, \ldots$, $G$. Substituting this expression into Walras's law, we get

$$
\sum_{g=1}^{G} p_{g} Z_{g}(p)=\sum_{g=1}^{G} F_{g}(p) Z_{g}(p)=0
$$

which implies that

$$
\begin{aligned}
& \sum_{g=1}^{G}\left\{Z_{g}(p) \frac{p_{g}+\max \left[0, Z_{g}(p)\right]}{\sum_{i=1}^{G}\left(p_{i}+\max \left[0, Z_{i}(p)\right]\right)}\right\} \\
& \quad=\sum_{g=1}^{G}\left\{\frac{p_{g} Z_{g}(p)}{\sum_{i=1}^{G}\left(p_{i}+\max \left[0, Z_{i}(p)\right]\right)}\right\}+\sum_{g=1}^{G}\left\{\frac{Z_{g}(p) \max \left[0, Z_{g}(p)\right]}{\sum_{i=1}^{G}\left(p_{i}+\max \left[0, Z_{i}(p)\right]\right)}\right\}=0
\end{aligned}
$$

Because the first term in the middle part of this expression must be zero, by Walras's law, the second term must also be equal to zero. This implies that

$$
\begin{equation*}
\sum_{g=1}^{G} Z_{g}(p) \max \left\{0, Z_{g}(p)\right\}=0 \tag{1}
\end{equation*}
$$

Notice that each individual term in this sum must be nonnegative. If $Z_{8}(p)>0$, the term becomes $\left[Z_{\mathrm{g}}(p)\right]^{2}>0$; if $Z_{g}(p)<0$, on the other hand, the term becomes zero. If any of the $Z_{g}(p)$ 's were strictly positive, the sum in (1) could not be zero, because there would be no negative terms to offset them. It follows that each of the terms must be zero, and therefore we must have $Z_{g}\left(p^{*}\right) \leq 0$ for all $g$.

Moreover, by Walras's law, we have

$$
\begin{equation*}
\sum_{g=1}^{G} p_{g} Z_{g}(p)=0 \tag{2}
\end{equation*}
$$

Now, by assumption, $p_{g} \geq 0$, and we have just shown that $Z_{g}(p) \leq 0$. Hence, (2) is a sum of nonpositive terms. As before, it can be zero only if all terms are zero; hence $p_{g} Z_{g}(p)=0$ for all $g$, and it follows that

$$
p_{g}>0 \Rightarrow Z_{g}(p)=0 \quad \text { and } \quad Z_{g}(p)<0 \Rightarrow p_{g}=0
$$

Thus, $p$ is indeed an equilibrium price vector, as it clears all markets, except possibly those for goods that are in excess supply when their price is zero.

Problem 3.8. Let $S$ be a closed and convex subset of the open unit simplex in $\mathbb{R}^{\mathrm{C}}$, and $\phi: S \rightarrow \rightarrow \mathbb{R}^{G}$ a uhc and convex-valued correspondence with the following properties:
(i) $\phi()$ is bounded (i.e., there exists a bounded set $B$ in $\mathbb{R}^{\mathbb{G}}$ such that $\phi(p) \subseteq B$ for all $s \in S$ ), and

(ii) for all $p \in S$ we have $p z \leq 0$ for every $z \in \phi(p)$.

Show that there exists some $p^{*} \in S$ and $z^{*} \in \phi\left(p^{*}\right)$ such that

$$
p z^{*} \leq 0 \forall p \in S
$$

Define the correspondence $\mu: B \rightarrow \rightarrow S$ by

$$
\begin{equation*}
\mu(z)=\arg \max _{q \in S} q z \tag{1}
\end{equation*}
$$

for each $z \in B$. As in the proof of Lemma 3.6, $\mu($ ) is nonempty, convex- and compact-valued, and uhc. Consider now the correspondence $\mu() \times \phi(): B \times S$ $\rightarrow \rightarrow B \times S$. By Theorem 11.14 in Chapter 2, this mapping will be compact-valued and uhc, because it is defined as the Cartesian product of two compact-valued uhc correspondences. Because we can take the bounded set $B$ to be convex (if it is not, consider its convex hull), the correspondence $\mu() \times \phi()$ satisfies the conditions of Kakutani's fixed-point theorem.

Hence, there exists some point $\left(z^{*}, p^{*}\right) \in B \times S$ such that $z^{*} \in \phi\left(p^{*}\right)$ and

$$
p^{*} \in \mu\left(z^{*}\right)=\arg \max _{q \in S} q z^{*}
$$

This implies that

$$
p^{*} z^{*} \geq p z^{*}
$$

for any $p \in S$. But because $p z \leq 0$ for all $z \in \phi(p)$ by assumption (ii), we have $p^{*} z^{*} \leq 0$, and it follows that

$$
p z^{*} \leq 0 \forall p \in S
$$

Problem 3.12. Consider an island economy populated by a representative individual who lives for two periods and has preferences described by the utility function

$$
\begin{equation*}
U(c, x)=\ln c+\beta \ln x \tag{1}
\end{equation*}
$$

where $c$ and $x$ are first- and second-period consumptions. In period 1 , the individual has an endowment of $e$ units of a homogeneous consumption/capital good. He consumes part of it and uses the rest $(k)$ as input for a production technology of the form $y=k^{\alpha}$, with $\alpha<1$. Hence, the consumption-possibilities schedule for the economy is of the form

$$
\begin{equation*}
x \leq k^{\alpha}=(e-c)^{\alpha} \tag{2}
\end{equation*}
$$

(i) Draw the consumption-possibilities frontier and indifference curves on the $(x, c)$ plane. Where is the optimum? Solve the planning problem

$$
\begin{equation*}
\max _{c, x}\left\{\ln c+\beta \ln x \text { s.t. }(e-c)^{\alpha}-x \geq 0\right\} \tag{p.1}
\end{equation*}
$$

Write the first-order conditions. Is the constraint binding? Why? Or why not? Solve for the optimal values of $c$ and $k=e-c$. (Don't worry about the second-order conditions. They hold.)

(ii) Next, consider a competitive version of the same economy. The agent now owns all the shares of a competitive firm that has access to the same technology as before, and he can lend part of his endowment to the firm, which maximizes profits, taking as given the market interest factor $R=1+r$ (capital depreciates completely upon use), and then distributes its profits to
the shareholder. We will verify that the competitive allocation coincides with the planning optimum.

Solve the firm's profit maximization problem,

$$
\begin{equation*}
\max _{k} \pi=k^{\alpha}-R k \tag{P.F}
\end{equation*}
$$

and write the firm's maximized profit as a function of $k$.

Next, write the first-order conditions for the household's utilitymaximization problem,

$$
\begin{equation*}
\max _{s} v(s)=\ln (e-s)+\beta \ln (s R+\pi) \tag{P.H}
\end{equation*}
$$

(the agent takes as given both the market interest rate and the firm's profits), and solve for the optimal levels of saving and consumption.

Finally, in equilibrium, the desired savings of the household must be the same as the desired level of capital input by the firm (i.e., $s=k$ ). Solve for the equilibrium values of saving/investment and consumption. They should be the same as in the first part of the problem.

(i) Differentiating the Lagrangian for the planner's problem,

$$
\mathfrak{E}(c, x, \lambda)=\ln c+\beta \ln x+\lambda\left[(e-c)^{\alpha}-x\right]
$$

we obtain the following first-order conditions:

$$
\begin{gather*}
\frac{\partial £()}{\partial c}=\frac{1}{c}-\lambda \alpha(e-c)^{\alpha-1}=0 \Rightarrow \frac{1}{c}=\lambda \alpha(e-c)^{\alpha-1}  \tag{1}\\
\frac{\partial £()}{\partial x}=\frac{\beta}{x}-\lambda=0 \Rightarrow \frac{\beta}{x}=\lambda \\
\frac{\partial £()}{\partial \lambda}=(e-c)^{\alpha}-x \geq 0 \quad \text { with equality if } \lambda>0 \tag{2}
\end{gather*}
$$

Observe that (2) implies that $\lambda>0$ for any finite $x$. Hence, the constraint holds as an equality, and we have

$$
\begin{equation*}
x=(e-c)^{\alpha} \tag{3}
\end{equation*}
$$

Substituting (2) into (1), we have

$$
\begin{equation*}
\frac{1}{c}=\frac{\beta}{x} \alpha(e-c)^{\alpha-1} \quad \text { or } \quad \frac{x}{\beta c}=\alpha(e-c)^{\alpha-1} \tag{4}
\end{equation*}
$$

The left-hand side of this expression is the slope of an indifference curve for the representative consumer (i.e., the marginal rate of substitution between $x$ and $c$ ), and the right-hand side is the slope of the production-possibilities frontier (PPF) (i.e., the marginal rate of transformation between present consumption and future consumption). Hence, equations (3) and (4) imply that the optimum $\left(c^{*}, x^{*}\right)$ must lie at the point of tangency between an indifference curve and the PPF, as illustrated in Figure A8.1.

Substituting (3) into (4), we can solve for $c$ :

$$
\begin{equation*}
\frac{(e-c)^{\alpha}}{\beta c}=\alpha(e-c)^{\alpha-1} \Rightarrow e-c=\alpha \beta c \Rightarrow c^{*}=\frac{e}{1+\alpha \beta} \tag{5}
\end{equation*}
$$

(ii) In the competitive version of the economy, the first-order condition for the firm's problem is

$$
\begin{equation*}
\pi^{\prime}(k)=\alpha k^{\alpha-1}-R=0 \Rightarrow R=\alpha k^{\alpha-1} \tag{6}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-741.jpg?height=563&width=799&top_left_y=180&top_left_x=339)

Figure A8.1. Planning optimum.

Substituting (6) into the firm's objective function, profits are given by

$$
\begin{equation*}
\pi(k)=k^{\alpha}-R k=k^{\alpha}-\alpha k^{\alpha-1} k=(1-\alpha) k^{\alpha} \tag{7}
\end{equation*}
$$

On the other hand, the consumer's problem yields

$$
\begin{equation*}
v^{\prime}(s)=\frac{-1}{e-s}+\frac{\beta R}{s R+\pi}=0 \Rightarrow s^{*}=\frac{e \beta R-\pi}{(1+\beta) R} \tag{8}
\end{equation*}
$$

In equilibrium, we have $s^{*}=k$. Using this expression, together with (6) and (7), equation (8) yields

$$
\begin{gather*}
(1+\beta) R k=e \beta R-\pi \Rightarrow(1+\beta) \alpha k^{\alpha-1} k=e \beta \alpha k^{\alpha-1}-(1-\alpha) k^{\alpha} \Rightarrow \\
{[(1+\beta) \alpha+(1-\alpha)] k^{\alpha}=e \beta \alpha k^{\alpha-1} \Rightarrow k^{*}=\frac{\alpha \beta e}{1+\alpha \beta}} \tag{9}
\end{gather*}
$$

Using this expression, we can calculate $c^{*}$ :

$$
c^{*}=e-s^{*}=e-k^{*}=\left(1-\frac{\alpha \beta}{1+\alpha \beta}\right) e=\frac{e}{1+\alpha \beta}
$$

As expected, the result is the same as in part (i) of the problem.

Problem 4.4. Cournot duopoly. Two firms compete in the market for a homogeneous good. The inverse demand function, which gives the price that consumers are willing to pay as a function of the total output of the good, is of the form

$$
\begin{equation*}
P\left(q_{1}+q_{2}\right)=\theta-q_{1}-q_{2} \tag{1}
\end{equation*}
$$

where $\theta>0$ is a given parameter, and $q_{i}$ is the level of output of the $i$ th firm.

Each firm maximizes its profits, taking as given the function (1) and the output level of its competitor. For example, firm 1 solves

$$
\begin{equation*}
\max _{q_{1}} P\left(q_{1}+q_{2}\right) q_{1}-c_{1} q_{1} \tag{2}
\end{equation*}
$$

where $c_{1}$ is its (constant) marginal cost, treating $q_{2}$ as a given constant.

(i) Solve firm 1's problem for its reaction function, that is, a function of the form $q_{1}=\phi_{1}\left(q_{2} ; c_{1}, \theta\right)$ that will give the optimal level of output as a function of its rival's output and the parameters $\left(c_{1}, \theta\right)$.
(ii) Firm 2's reaction function will have the same form as the one you have just derived. In a Nash equilibrium, each firm maximizes its profit, taking as given the other's output level. To find the equilibrium, we solve the system

$$
\begin{equation*}
q_{1}^{*}=\phi_{1}\left(q_{2}^{*} ; c_{1}, \theta\right), \quad q_{2}^{*}=\phi_{2}\left(q_{1}^{*} ; c_{2}, \theta\right) \tag{3}
\end{equation*}
$$

Draw the two reaction functions (their intersection corresponds to the equilibrium). Solve (3) explicitly to obtain the solution mapping for the model,

$$
q^{*}=\left(q_{1}^{*}, q_{2}^{*}\right)=\Psi\left(\theta, c_{1}, c_{2}\right)
$$

What conditions must be imposed on the parameters for the system to have an interior solution (i.e., one in which both firms produce)? Analyze, graphically and analytically, the effect of changes in $\theta$ and $c_{1}$ on equilibrium output levels.

(iii) Compute the equilibrium price and industry output and the equilibrium profit of each firm.

Firm 1 solves

$$
\max _{q_{1}} \pi_{1}=P\left(q_{1}+q_{2}\right) q_{1}-c_{1} q_{1}=\left(\theta-q_{1}-q_{2}\right) q_{1}-c_{1} q_{1}=\left(\theta-c_{1}-q_{2}\right) q_{1}-q_{1}^{2}
$$

Differentiating $\pi_{1}$ with respect to the firm's choice variable, we obtain the firstorder condition

$$
\begin{equation*}
\frac{\partial \pi_{1}}{\partial q_{1}}=\left(\theta-c_{1}-q_{2}\right)-2 q_{1}=0 \tag{1}
\end{equation*}
$$

Moreover,

$$
\frac{\partial^{2} \pi_{1}}{\partial q_{1}^{2}}=-2<0
$$

so the objective function is concave, and the first-order condition characterizes a maximum. Solving (1) for $q_{1}$, firm 1's reaction function is of the form

$$
\begin{equation*}
q_{1}=\phi_{1}\left(q_{2} ; c_{1}, \theta\right)=\frac{\theta-c_{1}-q_{2}}{2} \tag{2}
\end{equation*}
$$

By symmetry, firm 2's reaction function will be

$$
\begin{equation*}
q_{2}=\phi_{2}\left(q_{1} ; c_{2}, \theta\right)=\frac{\theta-c_{2}-q_{1}}{2} \tag{3}
\end{equation*}
$$

To solve for the equilibrium, substitute (3) into (2), obtaining

$$
\begin{equation*}
2 q_{1}=\frac{2\left(\theta-c_{1}\right)-\theta+c_{2}+q_{1}}{2} \Rightarrow q_{1}^{*}=\frac{\theta-2 c_{1}+c_{2}}{3} \tag{4}
\end{equation*}
$$

and

$$
\begin{equation*}
q_{2}^{*}=\frac{\theta-2 c_{2}+c_{1}}{3} \tag{5}
\end{equation*}
$$

Hence, $q_{1}^{*}$ and $q_{2}^{*} \geq 0$ if

$$
c_{1} \leq \frac{\theta-c_{2}}{2} \quad \text { and } \quad c_{2} \leq \frac{\theta-c_{1}}{2}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-743.jpg?height=632&width=873&top_left_y=179&top_left_x=302)

Figure A8.2. Cournot equilibrium.

From (4) and (5), it is clear that an increase in $\theta$ shifts both reaction functions upward and increases the equilibrium level of output for both firms. An increase in $c_{1}$ affects only the reaction function for firm 1 , which shifts down. Hence, in the new equilibrium, the output of firm 2 increases, whereas that of firm 1 decreases.

In equilibrium industry output is given by

$$
Q^{*}=q_{1}^{*}+q_{2}^{*}=\frac{\theta-2 c_{1}+c_{2}}{3}+\frac{\theta-2 c_{2}+c_{1}}{3}=\frac{2 \theta-c_{1}-c_{2}}{3}
$$

and the market price is

$$
P^{*}=P\left(Q^{*}\right)=\theta-Q^{*}=\frac{\theta+c_{1}+c_{2}}{3}
$$

Hence, equilibrium profits are given by

$$
\begin{aligned}
& \pi_{1}^{*}=\left(P^{*}-c_{1}\right) q_{1}^{*}=\frac{\theta-2 c_{1}+c_{2}}{3} \frac{\theta-2 c_{1}+c_{2}}{3}=\frac{\left(\theta-2 c_{1}+c_{2}\right)^{2}}{9} \\
& \pi_{2}^{*}=\left(P^{*}-c_{2}\right) q_{2}^{*}=\frac{\theta-2 c_{2}+c_{1}}{3} \frac{\theta-2 c_{2}+c_{1}}{3}=\frac{\left(\theta-2 c_{2}+c_{1}\right)^{2}}{9}
\end{aligned}
$$

Problem 4.5. Stackelberg duopoly. We will now analyze a market much like the one described in the preceding problem, but in which the timing of the actions is slightly different. Instead of assuming that both firms move simultaneously, we now assume that firm 1 moves first. This gives firm 1 a strategic advantage:

Because it knows how its rival will behave, it can maximize its own profits taking as given firm 2's reaction function. Firm 2 then observes firm 1's output choice and behaves accordingly. Solve for the equilibrium of this game, and compare it to the Cournot equilibrium analyzed in Problem 4.4.

Firm 1 now solves

$$
\max _{q_{1}} \pi_{1}=P\left(q_{1}+q_{2}\right) q_{1}-c_{1} q_{1}=\left(\theta-q_{1}-q_{2}-c_{1}\right) q_{1}
$$

subject to firm 2's reaction function

$$
q_{2}=\phi_{2}\left(q_{1} ; c_{2}, \theta\right)=\frac{\theta-c_{2}-q_{1}}{2}
$$

Substituting $\phi_{2}($ ) into firm 1's objective function,

$$
\pi_{1}=\left[\theta-q_{1}-\phi_{2}\left(q_{1}\right)-c_{1}\right] q_{1}=\left(\theta-q_{1}-c_{1}-\frac{\theta-c_{2}-q_{1}}{2}\right) q_{1}=\frac{\theta+c_{2}-2 c_{1}}{2} q_{1}-\frac{1}{2} q_{1}^{2}
$$

The first-order condition for this problem,

$$
\frac{\partial \pi_{1}}{\partial q_{1}}=\frac{\theta+c_{2}-2 c_{1}}{2}-q_{1}=0
$$

yields

$$
q_{1}^{*}=\frac{\theta+c_{2}-2 c_{1}}{2}
$$

Substituting this expression into $\phi_{2}()$,

$$
q_{2}^{*}=\phi_{2}\left(q_{1}^{*} ; c_{2}, \theta\right)=\frac{\theta-c_{2}-q_{1}^{*}}{2}=\frac{\theta-3 c_{2}+2 c_{1}}{4}
$$

Hence,

$$
\begin{gathered}
Q^{*}=q_{1}^{*}+q_{2}^{*}=\frac{\theta+c_{2}-2 c_{1}}{2}+\frac{\theta-3 c_{2}+2 c_{1}}{4}=\frac{3 \theta-2 c_{1}-c_{2}}{4} \\
P^{*}=P\left(Q^{*}\right)=\theta-Q^{*}=\frac{\theta+2 c_{1}+c_{2}}{4} \\
\pi_{1}^{*}=\left(P^{*}-c_{1}\right) q_{1}^{*}=\left(\frac{\theta+2 c_{1}+c_{2}}{4}-c_{1}\right) q_{1}^{*}=\frac{\left(\theta+c_{2}-2 c_{1}\right)^{2}}{8} \\
\pi_{2}^{*}=\left(P^{*}-c_{2}\right) q_{2}^{*}=\frac{\left(\theta-3 c_{2}+2 c_{1}\right)^{2}}{16}
\end{gathered}
$$

Comparing these expressions with those obtained in the preceding problem, we see that firm 1 has greater output and higher profits when it acts as a leader.

Problem 5.1. Consider first the behavior of final-goods producers. Although firm size is indeterminate with constant returns and perfect competition, each firm minimizes the cost of producing its desired level of output $y$, taking as given the prices $\mathbf{p}=\{p(s) ; 0 \leq s \leq n\}$ of the different inputs $x(s)$. That is, each firm solves

$$
\min _{x_{s} ; s \in[0, n]} \int_{0}^{n} p_{s} x_{s} d s \text { s.t. } y^{\alpha}=\int_{0}^{n} x_{s}^{\alpha} d s
$$

Using the first-order conditions for this problem, derive the conditional demand for intermediate goods as a function of final output and input prices and the firm's unit-cost function (see Problem 1.21 in Chapter 7). Verify that after aggregating over all final producers, the market demand function is of the form

$$
\begin{equation*}
x_{s}(\mathbf{p}, Y)=\phi p_{s}^{-\varepsilon}, \quad \text { where } \phi=\frac{Y}{\left(\int_{0}^{n} p_{t}^{1-\varepsilon} d t\right)^{1 / \alpha}} \tag{4}
\end{equation*}
$$

and $Y$ is the aggregate output of final goods, with unit costs being given by

$$
\begin{equation*}
c(\mathbf{p})=\left(\int_{0}^{n} p_{s}^{1-\varepsilon} d s\right)^{1 /(1-\varepsilon)} \tag{5}
\end{equation*}
$$

Differentiating the Lagrangian for the firm's problem,

$$
£=p_{s} x_{s}+\lambda\left(y^{\alpha}-x_{s}^{\alpha}\right)
$$

with respect to $x_{s}$, we obtain the first-order condition

$$
\begin{equation*}
p_{s}=\lambda \alpha x_{s}^{\alpha-1} \Rightarrow x_{s}=\left(\frac{\lambda \alpha}{p_{s}}\right)^{\varepsilon}, \quad \text { where } \varepsilon=\frac{1}{1-\alpha}>1 \tag{1.1}
\end{equation*}
$$

Substituting (1.1) into the production constraint, we can solve for the multiplier,

$$
\begin{equation*}
y^{\alpha}=\int_{0}^{n} x_{s}^{\alpha} d s=\int_{0}^{n}\left(\frac{\lambda \alpha}{p_{s}}\right)^{\alpha \varepsilon} d s \Rightarrow^{1}(\lambda \alpha)^{\alpha \varepsilon}=\frac{y^{\alpha}}{\int_{0}^{n} p_{s}^{1-\varepsilon} d s} \tag{1.2}
\end{equation*}
$$

and substituting this expression in (1.1), we obtain the conditional demand for intermediate input $x(s)$ as a function of input prices and final output,

$$
\begin{equation*}
x_{s}(\mathbf{p}, y)=(\lambda \alpha)^{\varepsilon} p_{s}^{-\varepsilon}=\frac{y p_{s}^{-\varepsilon}}{\left(\int_{0}^{n} p_{t}^{1-\varepsilon} d t\right)^{1 / \alpha}} \tag{1.3}
\end{equation*}
$$

Substituting (1.3) into the objective function, the (minimum) cost of producing output $y$ is given by

$$
\begin{gather*}
C(\mathbf{p}, y)=\int_{0}^{n} p_{s} x_{s} d s=\int_{0}^{n} p_{s} \frac{y p_{s}^{-\varepsilon}}{\left(\int_{0}^{n} p_{t}^{1-\varepsilon} d t\right)^{1 / \alpha}} d s={ }^{2}  \tag{1.4}\\
y\left(\int_{0}^{n} p_{s}^{1-\varepsilon} d s\right)^{1 /(1-\varepsilon)} \equiv c(\mathbf{p}) y
\end{gather*}
$$

Aggregating over final-goods producers, the market demand for component $s$ is given by

$$
\begin{equation*}
x_{s}(\mathbf{p}, Y)=\phi p_{s}^{-\varepsilon}, \quad \text { where } \phi=\frac{Y}{\left(\int_{0}^{n} p_{t}^{1-\varepsilon} d t\right)^{1 / \alpha}} \tag{1.5}
\end{equation*}
$$

and $Y$ is the aggregate output of final goods.

Problem 5.2. Taking the market demand schedule (4), the wage rate, and the prices set by its competitors as given, each component producer maximizes operating profits, given by

$$
\begin{equation*}
\Pi_{s}=p_{s} x_{s}-w x_{s}=\phi\left(p_{s}^{1-\varepsilon}-w p_{s}^{-\varepsilon}\right) \tag{6}
\end{equation*}
$$

Solve this problem for the firm's optimal output level and the implied level of profits.

Differentiating $\Pi_{s}$ with respect to $p_{s}$, the first-order condition for the firm's problem yields a constant-markup pricing rule,

$$
\begin{equation*}
(1-\varepsilon) p_{s}^{-\varepsilon}+w \varepsilon p_{s}^{-\varepsilon-1}=0 \Rightarrow(\varepsilon-1)=w \varepsilon p_{s}^{-1} \Rightarrow p_{s}^{*}=\frac{\varepsilon w}{\varepsilon-1}=\frac{w}{\alpha} \tag{2.1}
\end{equation*}
$$

Using (2.1) and the market demand schedule (4), we can compute optimal output,

$$
\begin{equation*}
x_{s}^{*}=\phi p_{s}^{-\varepsilon}=\phi \alpha^{\varepsilon} \mathbf{w}^{-\varepsilon} \tag{2.2}
\end{equation*}
$$

and the firm's operating profits,

$$
\begin{equation*}
\pi=\left(p_{s}-w\right) x_{s}=\frac{1-\alpha}{\alpha} w x_{s}^{*}=\frac{1-\alpha}{\alpha} \phi \alpha^{\varepsilon} w^{1-\varepsilon} \tag{2.3}
\end{equation*}
$$

Problem 5.3. In equilibrium, free entry will ensure that profits will be zero in the perfectly competitive final-goods sector. Hence, the price of final output, which we will normalize to 1 , must be equal to its unit cost. Using this condition, together with previous results, show that equilibrium wages and profits are given by

$$
\begin{equation*}
\pi=\frac{(1-\alpha) Y}{n} \text { and } \quad w=\frac{\alpha Y}{n l_{x}} \tag{7}
\end{equation*}
$$

where $l_{x}=L_{x} / n$ is "variable employment" in a representative component producer. Hence, output is divided between wages and profits. Profits per firm decrease with the number of competitors $n$ and with the difficulty of substituting one input for another, measured by $\alpha$.

In a symmetric equilibrium, all component producers set the same price $(p)$ and produce the same output $(x)$. Hence, each firm employs $l_{x}=L_{x} / n$ workers and produces the same quantity of components. Hence,

$$
\begin{equation*}
Y=\left(\int_{0}^{n} x_{s}^{\alpha} d s\right)^{1 / \alpha}=n^{1 / \alpha} x=n^{1 / \alpha} l_{x}=n^{(1 / \alpha)-1} L_{x} \tag{3.1}
\end{equation*}
$$

where $(1 / \alpha)-1>0$ because $\alpha<1$. Given the total variable employment, final output is an increasing function of the number of component varieties.

Specialization improves overall efficiency.

With equal component prices, the unit cost of final output can be written

$$
\begin{equation*}
c(\mathbf{p})=\left(\int_{0}^{n} p_{s}^{1-\varepsilon} d s\right)^{1 /(1-\varepsilon)}=\left(n p^{1-\varepsilon}\right)^{1 /(1-\varepsilon)}=p n^{1 /(1-\varepsilon)} \tag{3.2}
\end{equation*}
$$

where it can be seen that for a given component price, the unit cost of final output decreases with the number of component varieties (because $\varepsilon>1$ ). Free entry will ensure that profits will be zero in the perfectly competitive final-goods sector. Hence, the price of final output, which we will normalize to 1 , must be equal to its unit cost. That is,

$$
\begin{equation*}
p n^{1 /(1-\varepsilon)}=1 \Rightarrow p=n^{1 /(\varepsilon-1)} \tag{3.3}
\end{equation*}
$$

and therefore, using (2.1) and (3.1),

$$
\begin{equation*}
w=\alpha p=\alpha n^{1 /(\varepsilon-1)}=\alpha n^{(1 / \alpha)-1}=\frac{\alpha Y}{L_{x}} \tag{3.4}
\end{equation*}
$$

Using (3.3), we see that

$$
\left(\int_{0}^{n} p_{t}^{1-\varepsilon} d t\right)^{1 / \alpha}=\left(n p^{1-\varepsilon}\right)^{1 / \alpha}=\left(n n^{-1}\right)^{1 / \alpha}=1
$$

implying that

$$
\phi=\frac{Y}{\left(\int_{0}^{n} p_{t}^{1-\varepsilon} d t\right)^{1 / \alpha}}=Y
$$

Hence, using (2.1), (2.2) $(w=\alpha p)$, and (3.3),

$$
\begin{equation*}
x^{*}=\phi \alpha^{\varepsilon} w^{-\varepsilon}=\alpha^{\varepsilon}\left(\alpha n^{1 /(\varepsilon-1)}\right)^{-\varepsilon} Y \Rightarrow n^{-\varepsilon /(\varepsilon-1)} Y \Rightarrow x^{*}=n^{-1 / \alpha} Y \tag{3.5}
\end{equation*}
$$

as expected, and by (2.3),

$$
\begin{equation*}
\pi=\frac{1-\alpha}{\alpha} \phi \alpha^{\varepsilon} w^{1-\varepsilon}=\frac{1-\alpha}{\alpha} \alpha^{\varepsilon}\left(\alpha n^{1 /(\varepsilon-1)}\right)^{1-\varepsilon} Y \Rightarrow \pi=\frac{(1-\alpha) Y}{n} \tag{3.6}
\end{equation*}
$$

Problem 5.4. We have assumed that anybody willing to pay a fixed cost of $c$ units of labor can set up shop and start producing a new component variety. Compute the total demand for labor, and set it equal to the fixed labor supply $L$. Using this condition and the assumption of free entry into the sector, solve for the equilibrium number of firms $n^{*}$ as a function of $L$ and $c$, and use (3) to derive a reduced-form aggregate production function giving output per capita as a function of the same variables. Verify that this function exhibits increasing returns to labor when $\alpha<1$.

Because production of a component variety requires $c$ units of labor for setup, the total labor demand by a representative firm is $l_{x}+c$, and labor-market clearing requires

$$
\begin{equation*}
n\left(l_{x}+c\right)=L \tag{4.1}
\end{equation*}
$$

where $L$ is the aggregate labor force. Firms will enter until total profits are zero (i.e., until operating profits are equal to entry costs). Using (3.4) and (3.6),

$$
\begin{equation*}
\pi=c w \Rightarrow \frac{(1-\alpha) Y}{n}=c \frac{\alpha Y}{n l_{x}} \tag{4.2}
\end{equation*}
$$

Solving for $l_{x}$ in (4.2), the equilibrium firm size is given by

$$
\begin{equation*}
l_{x}=\frac{\alpha c}{1-\alpha} \tag{4.3}
\end{equation*}
$$

and substituting (4.3) into (4.1), the equilibrium number of firms is given by

$$
\begin{equation*}
n c\left(1+\frac{\alpha}{1-\alpha}\right)=L \Rightarrow n=\frac{(1-\alpha) L}{c} \tag{4.4}
\end{equation*}
$$

Hence, the number of component varieties increases proportionately with market size, as measured by $L$. Total "variable labor" employed in production is

$$
L_{x}=L-n c=L-(1-\alpha) L=\alpha L
$$

Substituting this expression into (3), final output can be written as a function of the aggregate labor supply and the entry cost,

$$
\begin{equation*}
Y=n^{(1 / \alpha)-1} L_{x}=\left(\frac{(1-\alpha) L}{c}\right)^{(1 / \alpha)-1} \alpha L=\left(\frac{(1-\alpha)}{c}\right)^{(1 / \alpha)-1} \alpha L^{1 / \alpha} \tag{4.5}
\end{equation*}
$$

Notice that this function exhibits increasing returns in labor when $\alpha<1$. If there are fixed entry costs, the size of the market limits the degree of specialization and, therefore, average productivity. Dividing (4.5) by $L$, we have

$$
\begin{equation*}
Q=\frac{Y}{L}=\left(\frac{(1-\alpha)}{c}\right)^{(1 / \alpha)-1} \alpha L^{(1 / \alpha)-1} \tag{4.6}
\end{equation*}
$$

All things considered, output per capita increases with $L$ whenever $\alpha<1$.

Problem 5.5. Consider a free-entry equilibrium in which sector $y$ is competitive, and $x$ producers compete à la Cournot. Zero profits in the competitive sector imply that the salary will be equal to the price of $y$, which we have normalized to 1. Let us focus on the market for $x$ and characterize a symmetric Cournot equilibrium. Aggregating over consumers, the total demand for $x$ can be written

$$
X=\frac{\alpha Q}{p}
$$

where $Q=L I$ is aggregate income. Inverting this function, and assuming that there are $n+1$ producers in this sector, we can write the inverse demand schedule perceived by a representative producer $i$ in the form

$$
\begin{equation*}
p\left(x_{i}\right)=\frac{\alpha Q}{n x_{-i}+x_{i}} \tag{5}
\end{equation*}
$$

where $x_{i}$ denotes his own output level, and $x_{-i}$ that of an arbitrary competitor.

Producer $i$ maximizes profits

$$
\Pi_{i}=p\left(x_{i}\right) x_{t}-x_{i}-c=\frac{\alpha Q x_{i}}{n x_{-i}+x_{t}}-x_{t}-c
$$

taking as given the salary $(w=1)$, aggregate income $Q$, and the outputs of his $n$ competitors $\left(x_{-i}\right)$. Using the first-order conditions for this problem, derive a reaction function giving optimal output for the $i$ th producer as a function of those of his rivals. In a symmetric equilibrium, all firms will choose the same output level. Set $x_{i}=x_{-t} \equiv x$, and find (i) the equilibrium level of output, (ii) the equilibrium price of good $x$, and (iii) the equilibrium level of firm profits - all written as functions of aggregate income and the number of firms in the sector.

Now, in a free-entry equilibrium, profits are zero, and it follows that aggregate income is given by

$$
\begin{equation*}
Q=L w=L \tag{10}
\end{equation*}
$$

Using this last expression and setting $\pi=0$, find (i) the equilibrium number of $x$ producers (ignoring integer constraints), (ii) the equilibrium price of good $x$, (iii) total $x$ output, (iv) total fixed costs, and (v) total $y$ output - all written as functions of "market size," measured by $\alpha L$, and the fixed cost $c$.

The first-order condition for the problem faced by a representative producer in the $x$ sector,

$$
\begin{equation*}
\frac{\partial \Pi_{i}}{\partial x_{i}}=\alpha Q \frac{n x_{-t}+x_{i}-x_{t}}{\left(n x_{-i}+x_{i}\right)^{2}}-1=0 \Rightarrow \alpha Q \frac{n x_{-i}}{\left(n x_{-i}+x_{t}\right)^{2}}=1 \tag{6}
\end{equation*}
$$

implicitly defines a reaction function giving optimal output for the $i$ th producer as a function of those of his rivals. In a symmetric equilibrium, all firms will choose the same output level. Hence, we can set $x_{t}=x_{-i} \equiv x$ and solve (6) explicitly for the equilibrium level of output as a function of aggregate income and the number of firms in the sector:

$$
\begin{equation*}
\alpha Q \frac{n x}{(n+1)^{2} x^{2}}=1 \Rightarrow x=\frac{\alpha Q n}{(n+1)^{2}} \tag{7}
\end{equation*}
$$

Not surprisingly, $x$ is a decreasing function of the number of firms in the sector.

Substituting (7) back into the industry demand function (5), we obtain the equilibrium price

$$
\begin{equation*}
p(x)=\frac{\alpha Q}{(n+1) x}=\frac{n+1}{n} \tag{8}
\end{equation*}
$$

Hence, the price (or, actually, the price/wage ratio) decreases with the number of competitors. Notice that $p \rightarrow 1$ as $n \rightarrow \infty$, that is, the price approaches its competitive level (= marginal cost) as the number of firms in the industry gets very large. Finally, using (7) and (8), we see that the firm's profits are given by

$$
\begin{equation*}
\pi=(p-1) x-c=\frac{1}{n} \frac{\alpha Q n}{(n+1)^{2}}-c=\frac{\alpha Q}{(n+1)^{2}}-c \tag{9}
\end{equation*}
$$

Now, in an equilibrium with free entry, profits are zero, and it follows that aggregate income is given by

$$
\begin{equation*}
Q=L w=L \tag{10}
\end{equation*}
$$

Using this last expression and setting $\pi=0$ in (9), the equilibrium number of $x$ producers (ignoring integer constraints) is given by

$$
\begin{equation*}
(n+1)^{2}=\frac{\alpha L}{c} \Rightarrow 1+n=\sqrt{\frac{\alpha L}{c}} \tag{11}
\end{equation*}
$$

and is therefore an increasing function of "market size," measured by $\alpha L$, and a decreasing function of the fixed cost $c$.

Using (10), (11), (7), and (8), we can compute the equilibrium price,

$$
\begin{equation*}
\frac{1}{p}=\frac{n}{n+1}=\frac{\sqrt{\frac{\alpha L}{c}}-1}{\sqrt{\frac{\alpha L}{c}}}=1-\sqrt{\frac{c}{\alpha L}} \tag{12}
\end{equation*}
$$

total industry output,

$$
\begin{equation*}
X=(1+n) x=(1+n) \frac{\alpha Q n}{(n+1)^{2}}=\frac{\alpha L n}{n+1}=\alpha L\left(1-\sqrt{\frac{c}{\alpha L}}\right) \tag{13}
\end{equation*}
$$

and total fixed costs,

$$
\begin{equation*}
(1+n) c=\sqrt{\frac{\alpha L}{c}} c=\sqrt{\alpha L c} \tag{14}
\end{equation*}
$$

Finally, total $y$ output (and consumption) is given by

$$
\begin{equation*}
Y=Q-p X=L-\alpha L=(1-\alpha) L \tag{15}
\end{equation*}
$$

(the reader can check that the same result is obtained, after some manipulation, by subtracting total employment in the $X$ sector, including "fixed costs," from the aggregate labor supply). Notice that the price distortion decreases with $L$, as do total fixed costs per capita.

Problem 5.6. Using a diagram similar to Figure 8.8, compare the equilibrium percapita allocation and the social optimum, illustrating the two sources of inefficiency we have identified. Using your results from Problem 5.5, discuss how things change as "market size" (measured by $L$ ) increases.

The inefficiencies due to the existence of market power and excess entry are illustrated in Figure A8.3, which compares the equilibrium (EQ) and first-best (FB) per-capita allocations. As shown in the figure, the "true" per capita social budget constraint (PPF) and that perceived by the representative consumer (BCP) are different, for two reasons. First, the existence of several $(N=n+1)$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-750.jpg?height=757&width=1069&top_left_y=182&top_left_x=206)

Figure A8.3. Equilibrium versus social optimum.

suppliers of $x$ goods, with the implied duplication of fixed costs, forces the economy to produce inside its PPF, putting it on a second-best social budget constraint (BCS) with a lower vertical intercept and the same slope. Given the equilibrium number of firms, the second-best optimum would correspond to the tangency of BCS and an indifference curve (point SB). This allocation, however, will not be attained, because oligopolistic markup pricing raises the relative price of $x$ above its social opportunity cost in terms of $y$. Hence, the private budget line perceived by consumers (with slope $1 / p$ ) is flatter than the social resource constraint, and the equilibrium allocation (EQ) involves an inefficiently low level of $x$ consumption.

Market enlargement tends to reduce both of these distortions. To see why, consider the effect of an increase in the labor force $L$. As shown in Problem 5.5, an increase in $L$ leads to an increase in the number of firms, which translates into a lower markup. Moreover, because the number of firms increases less than proportionately with market size, fixed costs per capita are reduced. Hence, both average costs and markups will be smaller in a larger economy. In terms of Figure A8.3, an increase in the size of the market will shift both the social and private budget constraints outward, by reducing per-capita fixed costs, and will rotate the private budget line clockwise, bringing the relative price of $x$ close to its social opportunity cost.

## Notes

$11-\varepsilon=1-\frac{1}{1-\alpha}=\frac{-\alpha}{1-\alpha}=-\alpha \varepsilon$

$21-\frac{1}{\varepsilon}=1-(1-\alpha)=\alpha$ and $1-\frac{1}{\alpha}=\frac{\alpha-1}{\alpha}=\frac{1}{1-\varepsilon}$.

## Chapter 9

Problem 2.6. Let $\phi\left(t, x^{0}\right)$ be the flow of the continuous-time system (CS), $\dot{x}=f(x)$. Show that if

$$
\lim _{t \rightarrow \infty} \phi\left(t, x^{0}\right)=x^{*}
$$

then $x^{*}$ must be a constant solution of (CS), i.e., $f\left(x^{*}\right)=\underline{0}$.

Put $t=r+s$ for some fixed but otherwise arbitrary $s$. Then, using the continuity of $\phi($ ),

$$
x^{*}=\lim _{r \rightarrow \infty} \phi\left(t, x^{0}\right)=\lim _{r \rightarrow \infty} \phi\left(s+r, x^{0}\right)=\lim _{r \rightarrow \infty} \phi\left(s, \phi\left(r, x^{0}\right)\right)=\phi\left(s, \lim _{r \rightarrow \infty} \phi\left(r, x^{0}\right)\right)=\phi\left(s, x^{*}\right)
$$

Hence $x^{*}=\phi\left(s, x^{*}\right)$ for any $s$. This implies that $\phi\left(s, x^{*}\right)$ is constant, i.e., $f\left(x^{*}\right)=\underline{0}$.

Problem 3.2. When $a=0$, the nonhomogeneous system is of the form $\dot{x}=b$. Using the method of separation of variables, find the general solution of this equation.

Rearranging the equation

$$
\frac{d x}{d t}=b
$$

we have

$$
d x=b d t
$$

Integrating both sides of this expression, we obtain the general solution

$$
\int d x=\int b d t \Rightarrow x(t)=c+b t
$$

Setting $t$ equal to zero, we have $c=x(0)$. Hence, the general solution can also be written in the form

$$
x(t)=x(0)+b t
$$

Problem 3.3. Rewrite the general solution of the system $(\mathrm{CN})$ as a function of $x(s)$, the value of $x$ at some arbitrary time $s$.

We have seen that the general solution of the nonhomogeneous system (CN) is of the form

$$
\begin{equation*}
x^{g}(t, c)=\bar{x}+c e^{a t} \tag{G.S}
\end{equation*}
$$

Because (G.S) must hold for $t=s$, we have

$$
x(s)=\bar{x}+c e^{a s}
$$

and solving for $c$,

$$
c=[x(s)-\bar{x}] e^{-a s}
$$

Substituting this expression back into (G.S), we can write the general solution in the form

$$
\begin{equation*}
x\left(t, x_{s}\right)=\bar{x}+[x(s)-\bar{x}] e^{a(t-s)} \tag{G.S'}
\end{equation*}
$$

Problem 4.3. Comparative dynamics for discrete systems. Let $x(t, \alpha)$ be the solution function of the parameterized discrete system $(\mathrm{DS}(\alpha)), x_{t+1}=g\left(x_{t}, \alpha\right)$, where $g()$ is a $C^{1}$ function. Proceeding as in Section 3(c), show that the partial derivative of the solution function with respect to the parameter

$$
x_{\alpha}(t, \alpha)=\frac{\partial x(t, \alpha)}{\partial \alpha}
$$

satisfies a linear difference equation. Write the solution of this equation for the special case where $x(t, \alpha)$ is a steady-state solution of (DS $(\alpha)$ ).

As before, the solution function $x(t, \alpha)$ satisfies identically the original system, i.e.,

$$
\begin{equation*}
x(t+1, \alpha) \equiv g[x(t, \alpha), \alpha] \tag{1}
\end{equation*}
$$

Differentiating both sides of (1) with respect to the parameter vector $\alpha$, we obtain a linear difference equation in $x_{\alpha}$ :

$$
\begin{equation*}
x_{\alpha}(t+1, \alpha)=g_{x}[x(t, \alpha), \alpha] x_{\alpha}(t, \alpha)+g_{\alpha}[x(t, \alpha), \alpha] \tag{2}
\end{equation*}
$$

If $x(t, \alpha)=x^{*}$ is a steady-state solution, then the coefficients of (2) are constant, and its solution is given by

$$
\begin{equation*}
x_{\alpha}(t)=x_{\alpha}(\infty)+\left[x_{\alpha}(0)-x_{\alpha}(\infty)\right]\left[g_{x}\left(x^{*}, \alpha\right)\right]^{t} \tag{3}
\end{equation*}
$$

where $x_{\alpha}(\infty)=\partial \bar{x} / \partial \alpha$ is the solution of

$$
x_{\alpha}=g_{x}\left(x^{*}, \alpha\right) x_{\alpha}+g_{\alpha}\left(x^{*}, \alpha\right)
$$

Problem 5.1. Consider the first-order difference equation

$$
\begin{equation*}
x_{t}=a x_{t-1}+b_{t-1} \tag{1}
\end{equation*}
$$

Iterating (1) backward and forward, derive the discrete-time analogues of equations (7) and (11) in the text.

Iterating (1) backward, we have

$$
\begin{aligned}
x_{t} & =a x_{t-1}+b_{t-1}=a\left(a x_{t-2}+b_{t-2}\right)+b_{t-1}=a^{2} x_{t-2}+a b_{t-2}+b_{t-1} \\
& =a^{2}\left(a x_{t-3}+b_{t-3}\right)+a b_{t-2}+b_{t-1}=a^{3} x_{t-3}+a^{2} b_{t-3}+a b_{t-2}+b_{t-1}=\ldots \\
& =a^{n} x_{t-n}+a^{n-1} b_{t-n}+\ldots+a^{2} b_{t-3}+a b_{t-2}+b_{t-1} \\
& =a^{n} x_{t-n}+\sum_{i=t-n}^{t-1} a^{t-1-i} b_{i}
\end{aligned}
$$

after $n$ iterations. Letting $n=t$, we have

$$
\begin{equation*}
x_{t}=a^{t} x_{0}+\sum_{t=0}^{t-1} a^{t-1-i} b_{i} \tag{2}
\end{equation*}
$$

which is the backward solution of the given equation.

To derive the forward solution, notice that leading (1) one period,

$$
x_{t+1}=a x_{t}+b_{t}
$$

and solving for $x_{t}$ we have

$$
\begin{equation*}
x_{t}=(1 / a) x_{t+1}-(1 / a) b_{t} \tag{3}
\end{equation*}
$$

Iterating (3) forward for $n$ periods, we obtain

$$
\begin{align*}
x_{t} & =(1 / a) x_{t+1}-(1 / a) b_{t}=(1 / a)\left[(1 / a) x_{t+2}-(1 / a) b_{t+1}\right]-(1 / a) b_{t} \\
& =(1 / a)^{2} x_{t+2}-(1 / a)^{2} b_{t+1}-(1 / a) b_{t} \\
& =(1 / a)^{2}\left[(1 / a) x_{t+3}-(1 / a) b_{t+2}\right]-(1 / a)^{2} b_{t+1}-(1 / a) b_{t} \\
& =(1 / a)^{3} x_{t+3}-(1 / a)^{3} b_{t+2}-(1 / a)^{2} b_{t+1}-(1 / a) b_{t}=\ldots \\
& =(1 / a)^{n} x_{t+n}-\left[(1 / a)^{n} b_{t+n-1}+(1 / a)^{n-1} b_{t+n-2}+\ldots+(1 / a)^{2} b_{t+1}+(1 / a) b_{t}\right] \\
& =(1 / a)^{n} x_{t+n}-(1 / a) \sum_{j=t}^{t+n-1}(1 / a)^{j-t} b_{j} \tag{4}
\end{align*}
$$

Letting $n \rightarrow \infty$, and putting $s=n+t$, the forward solution is given by

$$
\begin{equation*}
x_{t}=a^{t}\left(\lim _{s \rightarrow \infty}(1 / a)^{s} x_{s}\right)-(1 / a) \sum_{j=t}^{\infty}(1 / a)^{j-t} b_{J} \tag{5}
\end{equation*}
$$

Now define

$$
\begin{equation*}
F(t)=-(1 / a) \sum_{j=t}^{\infty}(1 / a)^{j-t} b_{j} \tag{6}
\end{equation*}
$$

Using the backward solution (2), we have

$$
(1 / a)^{s} x_{s}=x_{0}+(1 / a)^{s} \sum_{l=0}^{s-1} a^{s-1-t} b_{i}=x_{0}+(1 / a) \sum_{i=0}^{s-1} a^{-i} b_{i}=x_{0}+(1 / a) \sum_{i=0}^{s-1}(1 / a)^{i} b_{i}
$$

and taking limits as $s \rightarrow \infty$,

$$
\begin{equation*}
\lim _{s \rightarrow \infty}(1 / a)^{s} x_{s}=x_{0}-F(0) \tag{7}
\end{equation*}
$$

Substituting (6) and (7) into (5), the forward solution can be written

$$
\begin{equation*}
x_{t}=a^{t}\left[x_{0}-F(0)\right]+F(t) \tag{8}
\end{equation*}
$$

Problem 6.4. Show that the function $f(x)=3 x^{2 / 3}$ is not Lipschitz in any neighborhood of zero.

Negating the definition of (locally) Lipschitz function, we have to show that given any $K>0$ and any $\varepsilon>0$, there exist points $x$ and $y$ in $B_{\varepsilon}(0)$ such that $\mid f(y)-$ $f(x)|>K| y-x \mid$.

Fix some arbitrary $K>0$ and $\varepsilon>0$, and let $y>0$ be a point in $B_{\varepsilon}(0)$. Then $x=\lambda y$ $>0$ is also a point in $B_{\varepsilon}(0)$ for any $\lambda \in[0,1]$. We have, then,

$$
|y-x|=y-x=y-\lambda y=(1-\lambda) y
$$

and

$$
|f(y)-f(x)|=\left|3 y^{2 / 3}-3 \lambda^{2 / 3} y^{2 / 3}\right|=3\left(1-\lambda^{2 / 3}\right)\left|y^{2 / 3}\right|=3\left(1-\lambda^{2 / 3}\right) y^{2 / 3}
$$

Hence, we have $|f(y)-f(x)|>K|y-x|$ if and only if we can find a pair $(\lambda, y)$ such that

$$
3\left(1-\lambda^{2 / 3}\right) y^{2 / 3}>K(1-\lambda) y \Leftrightarrow g(\lambda, y)=3\left(1-\lambda^{2 / 3}\right)-K(1-\lambda) y^{1 / 3}>0
$$

Set $y^{*}>0$, so that $K y^{1 / 3}<1$, i.e., $y^{*}<K^{-3}$. Then

$$
g\left(\lambda, y^{*}\right)=3\left(1-\lambda^{2 / 3}\right)-K(1-\lambda)\left(y^{*}\right)^{1 / 3}>G(\lambda) \equiv 3\left(1-\lambda^{2 / 3}\right)-(1-\lambda)>0
$$

Notice that $G()$ is a continuous function of $\lambda$, with

$$
G(0)=3-1=2>0
$$

Hence, $g\left(\lambda, y^{*}\right)>G(\lambda)>0$ for $\lambda^{*}$ strictly positive but sufficiently small, and it follows that $x^{*}=\lambda^{*} y^{*}$ and $y^{*}$ are points in $B_{\varepsilon}(0)$ with the property that
$\left|f\left(y^{*}\right)-f\left(x^{*}\right)\right|>K\left|y^{*}-x^{*}\right|$. Because $K>0$ and $\varepsilon>0$ were arbitrary, this establishes that $f()$ is not locally Lipschitz around zero.

Problem 6.5. Continuous dependence on initial conditions and parameters. Let $f(x, \alpha, t)$ be a continuous function defined on the set $B=B_{x} \times B_{\alpha} \times I$, where $B_{x}, B_{\alpha}$, and $I=[-a, a]$ are closed intervals in the real line. Assume further that $f()$ is Lipschitz in $(x, \alpha)$ on $B$, i.e., that there exists some positive constant $K$ such that

$$
\begin{equation*}
|f(y, \beta, t)-f(x, \alpha, t)| \leq K\|(y, \beta)-(x, \alpha)\| \forall(y, \beta, t) \text { and }(x, \alpha, t) \text { in } B \tag{L}
\end{equation*}
$$

Show the following:

(i) For each $\left(x^{0}, \alpha\right)$ in the interior of $B_{x} \times B_{\alpha}$, the initial-value problem

$$
\begin{equation*}
\dot{x}=f(x, \alpha, t), \quad x(0)=x^{0} \tag{0}
\end{equation*}
$$

has a unique solution defined on a closed interval $J\left(x^{0}\right) \subseteq I$ containing zero.

(ii) The function $\phi_{t}\left(x^{0}, \alpha\right)$ that gives the solution to $\left(\mathrm{PC}\left(x^{0}, 0, \alpha\right)\right)$ as a function of initial conditions and parameters is continuous.

Because $f$ is continuous on the compact set $B$, it is bounded; i.e., there exists some $M>0$ such that

$$
\begin{equation*}
|f(x, \alpha, t)| \leq M \forall(x, \alpha, t) \in B \tag{1}
\end{equation*}
$$

For each $x$ in the interior of $B_{x}$, let $r(x)$ be such that

$$
\begin{equation*}
0<r(x)<\min \left\{a, \frac{1}{K}, \frac{b(x)}{M}\right\} \tag{2}
\end{equation*}
$$

where $b(x)>0$ is the distance from the interior point $x$ to the boundary of $B_{x}$. By the same argument as in the proof of Theorem 6.2, a unique solution to ( $\mathrm{PC}\left(x^{0}, 0\right.$, $\alpha)$ ) defined on the interval $\left[-r\left(x^{0}\right),\left(r\left(x^{0}\right)\right]\right.$ exists for any given $\left(x^{0}, \alpha\right)$, with $x^{0}$ in the interior of $B_{x}$.

Now, fix some point $\left(x^{0}, \alpha^{0}\right)$, with $x^{0} \in$ int $B_{x}$ and $\alpha^{0} \in$ int $B_{\alpha}$. Then there is some number $\varepsilon>0$ such that $B_{2 \varepsilon}\left[x^{0}\right]$ is contained in the interior of $B_{x}$, and $B_{\varepsilon}\left(\alpha^{0}\right) \subseteq B_{\alpha}$. Let $y$ be an arbitrary point in $B_{\varepsilon}\left[x^{0}\right]$, and observe that $b(y)>\varepsilon$. Hence, there is some number $r_{0}$ such that

$$
\begin{equation*}
0<r_{0}<\min \left\{a, \frac{1}{K}, \frac{\varepsilon}{M}\right\} \leq r(y) \text { for any } y \in B_{\varepsilon}\left[x^{0}\right] \tag{3}
\end{equation*}
$$

and it follows that solutions to ( $\mathrm{PC}\left(x^{0}, 0, \alpha\right)$ ) starting in $B_{\varepsilon}\left[x^{0}\right]$ will be defined over the common interval $J_{0}=\left[-r_{0}, r_{0}\right]$.

For each $y \in B_{\varepsilon}\left[x^{0}\right]$, let

$$
B_{M_{0}}[y]=\left\{\varphi(t) \in C\left(J_{0}\right) ;\|\varphi-y\| \leq M r_{0}\right\}
$$

and define the set $F$ by

$$
F=\bigcup_{y \in B_{\varepsilon}\left[x^{0}\right]} B_{M_{r_{0}}}[y]
$$

Notice that for any $\varphi(t)$ in $F$ we have, by (3),

$$
|\varphi(t)-y| \leq M r_{0}<\varepsilon
$$

for some $y \in B_{\varepsilon}\left[x^{0}\right]$. Hence $\varphi(t)$ stays inside $B_{2 \varepsilon}\left[x^{0}\right] \subseteq B_{x}$. Hence, $\varphi(t)$ stays inside $B_{x}$ for all $t$ in $J_{0}$, and it follows that $f[\varphi(t), \alpha, t]$ is Lipschitz. Observe that (L) implies that $f()$ is Lipschitz in $x=\varphi$ for given $\alpha$, because

$$
\|(y, \alpha)-(x, \alpha)\|=|y-x|
$$

Define now the function $T$ on $B_{\varepsilon}\left[x^{0}\right] \times B_{\varepsilon}\left(\alpha^{0}\right) \times F$ by

$$
\begin{equation*}
T(y, \alpha) \varphi(t)=y+\int_{0}^{t} f[\varphi(s), s] d s \quad \text { for each } t \in J_{0} \tag{4}
\end{equation*}
$$

Then, by the argument in the proof of Theorem 6.2, $T(y, \alpha)$ is a contraction mapping a closed ball in $C\left(J_{0}\right)$ into itself, and it follows that $T(y, \alpha)$ has a fixed point that is the unique solution to the initial-value problem $(\operatorname{PC}(y, 0, \alpha)$ ) on the interval $\left[-r_{0}, r_{0}\right]$.

We want to show that this fixed point varies continuously with $(y, \alpha)$. By Theorem 7.18 in Chapter 2, it is enough to show that $T$ is a continuous function of $(y, \alpha)$. To establish the continuity of $T$ in $(y, \alpha)$, let $\varphi(t)$ be an arbitrary function in $F$, and consider two points $(y, \alpha)$ and $(x, \beta)$ in $B_{\varepsilon}\left[x^{0}\right] \times B_{\varepsilon}\left(\alpha^{0}\right)$. Because $\varphi(t)$ stays within $B_{x}$, we have

$$
|f(\varphi(t), \alpha, t)-f(\varphi(t), \beta, t)| \leq K|\alpha-\beta| \forall t \text { in } J_{0}
$$

by (L). Hence,

$$
\begin{aligned}
|T(y, \alpha) \varphi(t)-T(x, \beta) \varphi(t)|= & \left|y-x+\int_{0}^{t}[f[\varphi(s), \alpha, s]-f[\varphi(s), \beta, s]] d s\right| \\
& \leq|y-x|+|t| K|\alpha-\beta| \leq|y-x|+r_{0} K|\alpha-\beta|
\end{aligned}
$$

for all $t$ in $J_{0}$. Hence,

$$
\|T(y, \alpha)-T(x, \beta)\| \leq|y-x|+r_{0} K|\alpha-\beta|
$$

Finally, observe that $T(y, \beta) \rightarrow T(x, \alpha)$ as $(y, \alpha) \rightarrow(x, \beta)$, which establishes the continuity of $T$.

Problem 6.8. Prove Lemma 6.7. By the local existence and uniqueness theorem (Theorem 6.2) we know that $\phi(t)$ and $\varphi(t)$ coincide over some interval containing $t_{0}$. Let $J_{m}$ be the largest subinterval of $J=J_{\phi} \cap J_{\varphi}$ over which the two solutions coincide. To show that $J_{m}=J$, we assume that $J_{m}$ is strictly contained in $J$ and obtain a contradiction. If $J_{m}$ is strictly contained in $J$, then $J_{m}$ has at least one end point $t_{1} \in J$ that either belongs to $J \sim J_{m}$ or lies in the interior of $J$. For concreteness, assume that $t_{1}$ is the right end point of $J_{m}$. Observe that by the continuity of $\phi(t)$ and $\varphi(t)$ in $J$ we have

$$
\left.\phi\left(t_{1}\right)=\lim _{t \rightarrow t_{\overline{\mathrm{T}}}} \phi(t)=\lim _{t \rightarrow t_{\overline{\mathrm{T}}}} \varphi(t)=\varphi\left(t_{1}\right) \equiv x^{1} \in X \quad \text { (because } t_{1} \in J\right)
$$

Hence, $t_{1}$ is the "last point" for which $\phi(t)=\varphi(t)$, and it follows that $t_{1} \in J_{m}$ lies in the interior of $J$. Notice, however, that both $\phi(t)$ and $\varphi(t)$ are solutions to the initial-value problem

$$
\dot{x}=f(x, t), \quad x\left(t_{1}\right)=x^{1} \quad\left(\mathrm{PC}\left(\mathrm{x}^{1}, \mathrm{t}_{1}\right)\right)
$$

where $\left(x^{1}, t_{1}\right) \in D$. It follows, by the local uniqueness of solutions, that $\phi(t)=\varphi(t)$ for all $t$ in some interval $\left[t_{1}-r_{1}, t_{1}+r_{1}\right]$, with $r_{1}>0$. Hence, $t_{1}$ is not the "last point" for which $\phi(t)=\varphi(t)$, and we have reached a contradiction.

Problem 6.15. Let $c(t)$ be a continuous real-valued function defined on an open interval $I=(\alpha, \beta)$ containing $t_{0}$. Consider the initial-value problem defined by the linear system $\dot{x}=c(t) x$ and the initial condition $x\left(t_{0}\right)=x^{0} \in \mathbb{R}$. Show that the solution to this problem is defined on the whole of $I$.

Under our assumptions, the function $f(x, t)=c(t) x$ is clearly continuous and locally Lipschitz in the open set $\mathbb{R} \times I$. It follows by Theorem 6.9 that the given boundary-value'problem will have a unique maximal solution $\phi(t)$ defined on some maximal open interval $(a, b) \subseteq I=(\alpha, \beta)$ containing $t_{0}$. We will assume that
$(a, b) \neq I$ and obtain a contradiction. Assume, for concreteness, that $b<\beta$, so that $b$ is an interior point of $I$, and $c(t)$ is defined on $\left[t_{0}, b\right]$. Because $c()$ is a continuous function, it is bounded in the compact set $\left[t_{0}, b\right]$. Let

$$
M=\max \left\{|c(s)| ; s \in\left[t_{0}, b\right]\right\}
$$

and observe that for any $t$ in $\left[t_{0}, b\right)$ we have

$$
|\phi(t)|=\left|x^{0}+\int_{t_{0}}^{t} c(s) \phi(s) d s\right| \leq\left|x^{0}\right|+\int_{t_{0}}^{t}|c(s) \phi(s)| d s \leq\left|x^{0}\right|+M \int_{t_{0}}^{t}|\phi(s)| d s
$$

By Gronwall's lemma,

$$
|\phi(t)| \leq\left|x^{0}\right| e^{M\left|t-t_{0}\right|}<\left|x^{0}\right| e^{M\left|b-t_{0}\right|}
$$

Hence, the solution stays within a compact set for all $t$ in $\left[t_{0}, b\right)$. Because $b$ is an interior point of $I$, this contradicts Theorem 6.12.

Problem 6.18. Prove Lemma 6.17.

Because $\phi\left(t, y^{0}\right)$ and $\phi\left(t, x^{0}\right)$ are solutions of $(\operatorname{CS}(t))$ going through $y^{0}$ and $x^{0}$, respectively, at time $t_{0}$, we have

$$
\begin{equation*}
\phi\left(t, y^{0}\right)=y^{0}+\int_{t_{0}}^{t} f\left[\phi\left(s, y^{0}\right), s\right] d s \text { and } \phi\left(t, x^{0}\right)=x^{0}+\int_{t_{0}}^{t} f\left[\phi\left(s, x^{0}\right), s\right] d s \tag{1}
\end{equation*}
$$

and because both solutions stay in $X$, we have $\left(s, \phi\left(s, y^{0}\right)\right)$ and $\left(s, \phi\left(s, x^{0}\right)\right) \in D$ for all $s \in J_{m}\left(x^{0}\right) \cap J_{m}\left(y^{0}\right) \subseteq I$. This implies that for all such $s$,

$$
\begin{equation*}
\left|f\left[\phi\left(s, y^{0}\right), s\right]-f\left[\phi\left(s, x^{0}\right), s\right]\right| \leq\left|\phi\left(s, y^{0}\right)-\phi\left(s, x^{0}\right)\right| \tag{2}
\end{equation*}
$$

by the Lipschitz condition on $f()$.

Define the function $\varphi(t)$ in $J_{m}\left(x^{0}\right) \cap J_{m}\left(y^{0}\right)$ by

$$
\varphi(t)=\left|\phi\left(t, y^{0}\right)-\phi\left(t, x^{0}\right)\right|
$$

Then, using (1) and (2), we have

$$
\begin{aligned}
\varphi(t)= & \left|y^{0}-x^{0}+\int_{t_{0}}^{t}\left[f\left[\phi\left(s, y^{0}\right), s\right]-f\left[\phi\left(s, x^{0}\right), s\right]\right] d s\right| \\
& \leq\left|y^{0}-x^{0}\right|+\int_{t_{0}}^{t}\left|f\left[\phi\left(s, y^{0}\right), s\right]-f\left[\phi\left(s, x^{0}\right), s\right]\right| d s \\
& \leq\left|y^{0}-x^{0}\right|+\int_{t_{0}}^{t} K\left|\phi\left(s, y^{0}\right)-\phi\left(s, x^{0}\right)\right| d s \\
= & \left|y^{0}-x^{0}\right|+K \int_{t_{0}}^{t} \varphi(s) d s
\end{aligned}
$$

for all $t \in J_{m}\left(x^{0}\right) \cap J_{m}\left(y^{0}\right)$.

Hence, $\varphi(t)$ satisfies the conditions of Gronwall's lemma, and it follows that

$$
\left|\phi\left(t, y^{0}\right)-\phi\left(t, x^{0}\right)\right|=\varphi(t) \leq\left|y^{0}-x^{0}\right| e^{K\left|t-t_{0}\right|}
$$

for all $t$ in $J_{m}\left(x^{0}\right) \cap J_{m}\left(y^{0}\right)$, which is the desired result.

## Chapter 10

Problem 2.3. Derive the equation

$$
x^{h}(t ; c)=E e^{\Lambda t} c, \quad \text { where } e^{\Lambda t}=\left[\begin{array}{ccc}
\exp \left(\lambda_{1} t\right) & \ldots \ldots . & 0  \tag{4}\\
\ldots . . & \ldots . . & \ldots \\
0 & \ldots \ldots . & \exp \left(\lambda_{n} t\right)
\end{array}\right]
$$

by diagonalizing the coefficient matrix of $(\mathrm{CH})$.

Given the homogeneous continuous system

$$
\begin{equation*}
\dot{x}=A x \tag{CH}
\end{equation*}
$$

we premultiply both sides by the inverse of the eigenvector matrix, $E^{-1}$ :

$$
E^{-1} \dot{x}=E^{-1} A x
$$

Noting that $E E^{-1}=I$ (the identity matrix), this is equivalent to

$$
E^{-1} \dot{x}=E^{-1} A E E^{-1} x
$$

Now, because $E^{-1} A E=\Lambda$, we have

$$
\begin{equation*}
E^{-1} \dot{x}=\Lambda E^{-1} x \tag{1}
\end{equation*}
$$

Define $y$ by

$$
\begin{equation*}
y=E^{-1} x \tag{2}
\end{equation*}
$$

and observe that

$$
\begin{equation*}
\dot{y}=E^{-1} \dot{x} \tag{3}
\end{equation*}
$$

Using (2) and (3), the system can be written

$$
\begin{equation*}
\dot{y}=\Lambda y \tag{4}
\end{equation*}
$$

where $\Lambda=\operatorname{diag}\left(\lambda_{1}, \ldots, \lambda_{n}\right)$. Because (4) is an uncoupled system, its solution is of the form

$$
\begin{equation*}
y(t)=e^{\Lambda t} c \tag{5}
\end{equation*}
$$

where $c$ is a vector of arbitrary constants. To recover the solution in terms of the original variables $x$, we premultiply (5) by $E$ :

$$
x(t)=E y(t)=E e^{\Lambda t} c
$$

Problem 2.4. Derive the following equation:

$$
\begin{equation*}
x_{t}^{h}(c)=c_{1} r^{t}(d \cos \theta t-f \sin \theta t)+c_{2} r^{t}(f \cos \theta t+d \sin \theta t)+\sum_{i=3}^{n} c_{i} \lambda_{i}^{t} e_{i} \tag{6}
\end{equation*}
$$

Because the coefficient matrix $A$ is a real matrix, its eigenvalues and eigenvectors come in conjugate pairs. Hence, if $\lambda_{1}$ and $\lambda_{2}$ are complex eigenvalues of $A$, they are of the form ${ }^{1}$

$$
\begin{gather*}
\lambda_{1}=\alpha+i \mu=r(\cos \theta+i \sin \theta)=r e^{i \theta} \\
\lambda_{2}=\alpha-i \mu=r(\cos \theta-i \sin \theta)=r e^{-i \theta} \tag{1}
\end{gather*}
$$

where $\theta$ is the angle formed by the vector $\lambda_{1}=(\alpha, \mu)$ and the horizontal axis of the complex plane. Moreover, the corresponding eigenvectors will be given by

$$
\begin{equation*}
e_{1}=d+\text { if } \text { and } e_{2}=d-\text { if } \tag{2}
\end{equation*}
$$

where $d$ and $f$ are vectors. The elementary solutions associated with these eigenvalues are then

$$
\begin{equation*}
z_{t}^{1}=\lambda_{1}^{t} e_{1} \quad \text { and } \quad z_{\mathrm{t}}^{2}=\lambda_{2}^{t} e_{2} \tag{3}
\end{equation*}
$$

Using (1) and (2), the elementary solutions can be written

$$
\begin{aligned}
z_{t}^{1} & =\lambda_{1}^{t} e_{1}=\left(r e^{i \theta}\right)^{t}(d+i f)=r^{t}(\cos \theta t+i \sin \theta t)(d+i f) \\
& =r^{t}\left(d \cos \theta t+i d \sin \theta t+i f \cos \theta t+i^{2} f \sin \theta t\right) \\
& =r^{t}(d \cos \theta t-f \sin \theta t)+i r^{t}(d \sin \theta t+f \cos \theta t)
\end{aligned}
$$

and

$$
\begin{aligned}
z_{t}^{2} & =\lambda_{2}^{t} e_{2}=\left(r e^{-i \theta}\right)^{t}(d-i f)=r^{t}(\cos \theta t-i \sin \theta t)(d-i f) \\
& =r^{\prime}\left(d \cos \theta t-i d \sin \theta t-i f \cos \theta t+i^{2} f \sin \theta t\right) \\
& =r^{t}(d \cos \theta t-f \sin \theta t)-i r^{t}(d \sin \theta t+f \cos \theta t)
\end{aligned}
$$

Hence, the elementary solutions are complex conjugates themselves. Putting

$$
u_{t}=r^{t}(d \cos \theta t-f \sin \theta t) \text { and } \quad v_{t}=r^{t}(d \sin \theta t+f \cos \theta t)
$$

we have

$$
z_{t}^{1}=u_{t}+i v_{t}, \quad z_{t}^{2}=u_{t}-i v_{t}
$$

By the same argument used in Section 2(b), it can be shown that the real functions (sequences) $u_{t}$ and $v_{t}$ are solutions of the system (DH), $x_{t+1}=A x_{t}$. It can also be shown that these functions are linearly independent from each other and from the rest of the elementary solutions of the system. Hence, we can use them to complete a fundamental set of solutions and write the general solution of the system in the form (6).

Problem 2.5. Given the linear system $(\mathrm{CH}), \dot{x}=A x$, assume that there is one eigenvalue $\xi$ of multiplicity $2\left(\lambda_{1}=\lambda_{2}=\xi\right)$, and the rest of the eigenvalues $\lambda_{3}, \ldots$, $\lambda_{n}$ of $A$ are all different from each other. Associated with the repeated eigenvalue we have two elementary solutions:

$$
x^{1}(t)=\exp \left(\lambda_{1} t\right) e_{1}=e^{\xi t} e_{1} \quad \text { and } \quad x^{2}(t)=\exp \left(\lambda_{2} t\right) e_{2}=e^{\xi t} e_{2}
$$

Clearly, if $e_{1}$ and $e_{2}$ are linearly independent eigenvectors associated with $\xi$, the elementary solutions $x^{1}(t)$ and $x^{2}(t)$ are also independent from each other and from the rest of the elementary solutions $x^{3}(t), \ldots, x^{n}(t)$. Hence the set of elementary solutions is still a basis for the solution space of the homogeneous system, and we can write the general solution as before:

$$
\begin{equation*}
x^{g}(t)=c_{1} x^{1}(t)+\ldots+c_{n} x^{n}(t) \tag{G.S}
\end{equation*}
$$

If $e_{1}$ and $e_{2}$ are linearly dependent, however, so are $x^{1}(t)$ and $x^{2}(t)$, and we do not have enough independent elementary solutions to span the solution space. To complete a basis for the solution space that will allow us to write the general solution, we need to find an additional solution to $(\mathrm{CH})$ that will be linearly independent from the elementary solutions. We will seek a solution of the form

$$
\begin{equation*}
\phi(t)=(a+b t) e^{\xi t}=a e^{\xi t}+b t e^{\xi t} \tag{1}
\end{equation*}
$$

that is, the product of a polynomial of order 1 ( 1 less than the multiplicity of $\xi$ ) in $t$ and the exponential term in the eigenvalue $\xi$. What restrictions must be placed on the vectors $a$ and $b$ so that $\phi(t)$ will indeed be a solution of the system, that is, will satisfy the equation $\phi^{\prime}(t)=A \phi(t)$ ? Write the general solution of the system.

We need to choose the vectors $a$ and $b$ so that $\phi(t)$ satisfies the homogeneous equation, that is, we need

$$
\begin{aligned}
& \phi^{\prime}(t)=A \phi(t) \Rightarrow \frac{d}{d t}\left[a e^{\xi t}+b t e^{\xi t}\right]=A\left[a e^{\xi t}+b t e^{\xi^{\xi t}}\right] \\
& \quad \Rightarrow \xi a e^{\xi t}+b t \xi e^{\xi_{t}}+b e^{\xi t}=A a e^{\xi t}+A b t e^{\xi t} \\
& \quad \Rightarrow[\xi a+b] e^{\xi t}+\xi b t e^{\xi t}=A a e^{\xi t}+A b t e^{\xi t}
\end{aligned}
$$

And setting the coefficients of $e^{\xi t}$ and $t e^{\xi t}$ on both sides equal to each other, we get

$$
\begin{gather*}
\left(\text { for } t e^{\xi_{t}}:\right) \xi b=A b \Rightarrow A b-\xi b=\underline{0} \\
\Rightarrow(A-\xi I) b=\underline{0}  \tag{2}\\
\quad\left(\text { for } e^{\xi t}:\right) \xi a+b=A a \\
\Rightarrow(A-\xi I) a=b \tag{3}
\end{gather*}
$$

That is, $b$ must be an eigenvector associated with the repeated eigenvalue (e.g., $b$ $=e_{1}$ ), and $a$ must satisfy the restriction given by (3) in order for $\phi(t)$ to be a solution to (1). If these conditions are satisfied, we can write the general solution to the homogeneous system with one eigenvalue of multiplicity $2\left(\lambda_{1}=\lambda_{2}=\xi\right)$ and all the rest $\lambda_{3}, \ldots, \lambda_{n}$ of multiplicity 1 as

$$
\begin{align*}
& x^{g}(t)=c_{1} x^{1}(t)+c_{2} \phi(t)+c_{3} x^{3}(t)+\ldots+c_{n} x^{n}(t) \\
& \quad \Rightarrow x^{g}(t)=c_{1} e^{\xi_{t}} e_{1}+c_{2}\left[a e^{\xi_{t} t}+t e_{1} e^{\xi_{t}}\right]+c_{3} \exp \left(\lambda_{3} t\right) e_{3}+\ldots+c_{n} \exp \left(\lambda_{n} t\right) e_{n} \tag{4}
\end{align*}
$$

Problem 4.1. Polar coordinates. When working with planar systems it is sometimes convenient to work in polar coordinates. Consider a point with Cartesian (ordinary) coordinates $(x, y)$. Its polar coordinates are $(r, \theta)$, where $r$ is the Euclidean distance from the origin to the point $(x, y)$, and $\theta$ is the angle formed by the line segment going from the origin to the point $(x, y)$ and the horizontal axis. Hence, $r$ and $\theta$ are defined by

$$
\begin{gather*}
r^{2}=x^{2}+y^{2}  \tag{1}\\
\theta=\arctan (y / x) \tag{2}
\end{gather*}
$$

and $\theta$ is such that

$$
\begin{equation*}
\cos \theta=x / r \quad \text { and } \quad \sin \theta=y / r \tag{3}
\end{equation*}
$$

Differentiating (1) and (2) implicitly with respect to time, show that

$$
\begin{align*}
& r \dot{r}=x \dot{x}+y \dot{y}  \tag{4}\\
& r^{2} \dot{\theta}=x \dot{y}-y \dot{x} \tag{5}
\end{align*}
$$

Differentiating (1) implicitly with respect to time, we have

$$
\begin{align*}
& 2 r \dot{r}=2 x \dot{x}-2 y \dot{y} \\
& \quad \Rightarrow r \dot{r}=x \dot{x}+y \dot{y} \tag{4}
\end{align*}
$$

Proceeding in a similar way with (2),

$$
\begin{align*}
\dot{\theta} & =\frac{(x \dot{y}-y \dot{x}) / x^{2}}{1+(y / x)^{2}}=\frac{(x \dot{y}-y \dot{x}) / x^{2}}{\left(x^{2}+y^{2}\right) / x^{2}}=\frac{x \dot{y}-y \dot{x}}{x^{2}+y^{2}} \\
& \Rightarrow r^{2} \dot{\theta}=x \dot{y}-y \dot{x} \tag{5}
\end{align*}
$$

Problem 4.2. Let $A$ be a $2 \times 2$ real matrix with complex eigenvalues $\lambda_{1}, \lambda_{2}=\alpha \pm i \mu$ and corresponding complex eigenvectors $e_{1}, e_{2}=u \pm i v$. It can be shown that the real vectors $u$ and $v$ are linearly independent, so the matrix $P=[u, v]$ is invertible.

(i) Show that

$$
P^{-1} A P=R=\left[\begin{array}{cc}
\alpha & -\mu  \tag{8}\\
\mu & \alpha
\end{array}\right]
$$

Equation (8) shows that if $A$ has complex eigenvalues, then the planar system $\dot{z}=A z$ can be written (after a coordinate change) in the form

$$
\left[\begin{array}{c}
\dot{x} \\
\dot{y}
\end{array}\right]=\left[\begin{array}{cc}
\alpha & -\mu \\
\mu & \alpha
\end{array}\right]\left[\begin{array}{l}
x \\
y
\end{array}\right]
$$

or, equivalently,

$$
\begin{align*}
& \dot{x}=\alpha x-\mu y  \tag{9}\\
& \dot{y}=\mu x+\alpha y \tag{10}
\end{align*}
$$

(ii) Rewrite the system (9)-(10) in polar coordinates and solve it, leaving the solution $(r(t), \theta(t))$ as a function of the initial values $r(0)$ and $\theta(0)$.

(iii) Using the trigonometric identities

$$
\begin{align*}
& \sin (a+b)=(\sin a)(\cos b)+(\cos a)(\sin b)  \tag{11}\\
& \cos (a+b)=(\cos a)(\cos b)-(\sin a)(\sin b) \tag{12}
\end{align*}
$$

recover the solution $(x(t), y(t))$ of the original system, written as a function of the initial values $x(0)$ and $y(0)$.

(i) Because $\lambda_{1}$ is an eigenvalue of $A$, and $e_{1}$ a corresponding eigenvector, we have $A e_{1}=\lambda_{1} e_{1}$, that is,

$$
A(u+i v)=(\alpha+i \mu)(u+i v)
$$

Expanding both sides of this expression,

$$
A u+i A v=\alpha u+i \alpha v+i \mu u+i^{2} \mu \nu=(\alpha u-\mu v)+i(\alpha v+\mu u)
$$

that is,

$$
A u=(\alpha u-\mu v) \text { and } A v=(\mu u+\alpha v)
$$

or, in matrix form,

$$
A[u, v]=[u, v]\left[\begin{array}{cc}
\alpha & -\mu \\
\mu & \alpha
\end{array}\right] \Leftrightarrow A P=P R
$$

and because $P$ is invertible (by the fact that $u$ and $v$ are linearly independent), this last expression yields the desired result (premultiplying both sides by $P^{-1}$ ).

(ii) Substituting (9) and (10) into (4), we have

$$
r \dot{r}=x(\alpha x-\mu y)+y(\mu x+\alpha y)=\alpha\left(x^{2}+y^{2}\right)=\alpha r^{2}
$$

from where

$$
\begin{equation*}
\dot{r}=\alpha r \tag{13}
\end{equation*}
$$

Similarly, using (5),

$$
r^{2} \dot{\theta}=x \dot{y}-y \dot{x}=x(\mu x+\alpha y)-y(\alpha x-\mu y)=\mu\left(x^{2}+y^{2}\right)=\mu r^{2}
$$

from where

$$
\begin{equation*}
\dot{\theta}=\mu \tag{14}
\end{equation*}
$$

We have, then, a system of two uncoupled equations in $(r, \theta)$. The solutions of (13) and (14) are of the form

$$
\begin{gather*}
r(t)=r(0) e^{\alpha t}  \tag{15}\\
\theta(t)=\theta(0)+\mu t \tag{16}
\end{gather*}
$$

(iii) To recover the solution in terms of the original variables, we use equation (7) and the trigonometric identities (11) and (12). Substituting (15) and (16) into (7), and using (11) and (12),

$$
\begin{aligned}
x(t) & =r(t) \cos \theta(t)=r(0) e^{\alpha t} \cos (\theta(0)+\mu t) \\
& =r(0) e^{\alpha t}[\cos \theta(0) \cos \mu t-\sin \theta(0) \sin \mu t] \\
& =r(0) e^{\alpha t}\left(\frac{x(0)}{r(0)} \cos \mu t-\frac{y(0)}{r(0)} \sin \mu t\right)=e^{\alpha t}[x(0) \cos \mu t-y(0) \sin \mu t]
\end{aligned}
$$

Similarly,

$$
\begin{aligned}
y(t) & =r(t) \sin \theta(t)=r(0) e^{\alpha t} \sin (\theta(0)+\mu t) \\
& =r(0) e^{\alpha t}[\sin \theta(0) \cos \mu t+\cos \theta(0) \sin \mu t] \\
& =r(0) e^{\alpha t}\left(\frac{y(0)}{r(0)} \cos \mu t+\frac{x(0)}{r(0)} \sin \mu t\right)=e^{\alpha t}[y(0) \cos \mu t+x(0) \sin \mu t]
\end{aligned}
$$

Problem 4.3. Consider the following system of differential equations:

$$
\begin{gather*}
\dot{x}=f(x, y)=y+x\left(c-x^{2}-y^{2}\right)  \tag{17}\\
\dot{y}=g(x, y)=-x+y\left(c-x^{2}-y^{2}\right) \tag{18}
\end{gather*}
$$

(i) Show that the point $(0,0)$ is the only steady state of the system for any value of $c$.

(ii) Linearize the system around the steady state and compute its eigenvalues.

What can we say about the stability and type of the steady state? (There are three possible cases, depending on the value of $c$.)

(iii) Show that the original system can be written in polar coordinates as

$$
\begin{gather*}
\dot{r}=r\left(c-r^{2}\right)  \tag{19}\\
\dot{\theta}=-1 \tag{20}
\end{gather*}
$$

Using these expressions, describe the behavior of the system, and compare the results with those obtained in (ii). Linearization should give accurate local results in two cases, but we can now "see" more things. What happens in the third case?

(i) The steady state $s=(\bar{x}, \bar{y})$ satisfies

$$
\begin{aligned}
& \dot{x}=0 \Rightarrow y+x\left(c-x^{2}-y^{2}\right)=0 \\
& \dot{y}=0 \Rightarrow-x+y\left(c-x^{2}-y^{2}\right)=0
\end{aligned}
$$

Clearly, $(0,0)$ is a solution to this system of equations. If $x=0$, then $y=0$, by the first equation; similarly, if $y=0$, then $x=0$, by the second equation. Finally, assume $x, y \neq 0$; then we can divide the first equation by $x$ and the second by $y$ to get

$$
-y / x=c-x^{2}-y^{2} \text { and } x / y=c-x^{2}-y^{2}
$$

from where

$$
-y / x=x / y \Rightarrow x^{2}=-y^{2}
$$

which is impossible for $x, y \neq 0$. Hence $s=(0,0)$ is the only steady state.

(ii) The partial derivatives of the functions $f()$ and $g()$ evaluated at the steady state are given by

$$
\begin{gathered}
f_{x}=x(-2 x)+1\left(c-x^{2}-y^{2}\right)=0+c=c \\
f_{y}=1+x(-2 y)=1-0=1 \\
g_{x}=-1+y(-2 x)=-1+0=-1 \\
g_{y}=1\left(c-x^{2}-y^{2}\right)+y(-2 y)=c+0=c
\end{gathered}
$$

Hence, the coefficient matrix of the linearized system is of the form

$$
A=\left[\begin{array}{cc}
c & 1 \\
-1 & c
\end{array}\right]
$$

To find the eigenvalues of $A$, we solve

$$
|A-\lambda I|=\left|\begin{array}{cc}
c-\lambda & 1 \\
-1 & c-\lambda
\end{array}\right|=0
$$

or

$$
(c-\lambda)^{2}+1=c^{2}-2 c \lambda+\lambda^{2}+1=\lambda^{2}-2 c \lambda+\left(1+c^{2}\right)=0
$$

By the quadratic formula,

$$
\lambda_{1}, \lambda_{2}=\frac{2 c \pm \sqrt{4 c^{2}-4-4 c^{2}}}{2}=c \pm i
$$

Hence, the eigenvalues of the system are complex numbers. If $c<0$, the steady state is a locally stable spiral point, and if $c>0$, the steady state is locally unstable. If $c=0$, the steady state is nonhyperbolic, and its stability cannot be determined without further information.

(iii) Substituting (17) and (18) into (4),

$$
\begin{aligned}
r \dot{r} & =x \dot{x}+y \dot{y}=x\left[y+x\left(c-x^{2}-y^{2}\right)\right]+y\left[-x+y\left(c-x^{2}-y^{2}\right)\right] \\
& =\left(x^{2}+y^{2}\right)\left(c-x^{2}-y^{2}\right)=r^{2}\left(c-r^{2}\right)
\end{aligned}
$$

and simplifying,

$$
\begin{equation*}
\dot{r}=r\left(c-r^{2}\right) \tag{19}
\end{equation*}
$$

Similarly, substituting (17) and (18) into (5),

$$
\begin{aligned}
r^{2} \dot{\theta} & =x \dot{y}-y \dot{x}=x\left[-x+y\left(c-x^{2}-y^{2}\right)\right]-y\left[y+x\left(c-x^{2}-y^{2}\right)\right] \\
& =-\left(x^{2}+y^{2}\right)=-r^{2}
\end{aligned}
$$

from where

$$
\begin{equation*}
\dot{\theta}=-1 \tag{20}
\end{equation*}
$$

Hence, the original system (17)-(18) reduces in polar coordinates to a set of two independent first-order equations: The behavior of the system can be determined directly by inspection of (19) and (20). First, notice that the angle $\theta$ decreases over time. Hence, the solution trajectories rotate clockwise, forming either spirals or circles. The exact shapes of the trajectories will depend on the behavior of $r$, the distance from the origin. Using (20), we see that if $c \leq 0$, then we have $\dot{r}=r\left(c-r^{2}\right)<0$ for all $r>0$, and all trajectories converge to the origin, which is a stable spiral point. If $c>0$, things are slightly more complicated. Notice that if $r=\sqrt{c}$, then $\dot{r}=0$, and $r$ remains constant over time. Hence, the system has a periodic orbit or cyclical solution. If $r>\sqrt{c}$, then $\dot{r}=r\left(c-r^{2}\right)<0$, and if $r<\sqrt{c}$ we have $\dot{r}=r\left(c-r^{2}\right)>0$.

In either case, we approach the periodic orbit. Hence, trajectories starting on either side of this closed curve converge to it as $t \rightarrow \infty$.

## Chapter 11

Problem 2.1. When the tax rate on dividends varies over time, our stock-pricing equation can be written in the form

$$
\begin{equation*}
\dot{v}=r v-b(t) \tag{1}
\end{equation*}
$$

where

$$
b(t)=\left(1-\tau_{t}\right) d
$$

Equation (1) is a nonautonomous linear equation of the type we studied in Section 5 of Chapter 9. Its solution can be written in the ("forward") form

$$
\begin{equation*}
v(t)=[v(0)-F(0)] e^{r t}+F(t) \tag{2}
\end{equation*}
$$

where

$$
\begin{equation*}
F(t)=\int_{t}^{\infty} b(s) e^{r(t-s)} d s \tag{3}
\end{equation*}
$$

the "fundamental solution" of (1), is the discounted value of the stream of future after-tax dividends, and $[v(0)-F(0)] e^{r}$ is a "bubble term" capturing possible deviations from the fundamental value of the stock. By the same logic as in our earlier discussion, we shall rule out bubbles and assume that $v(t)=F(t)$ for all $t$. Hence, the value of the stock at each point in time will be given by (3). We shall now show that this fundamental solution gives the same time path of stock prices in response to a preannounced future increase in dividend taxes as the procedure we followed earlier.

(i) Show that

$$
\begin{equation*}
\int_{t}^{b} e^{r(t-s)} d s=\frac{1}{r}\left(1-e^{r(t-b)}\right) \tag{4}
\end{equation*}
$$

(ii) As before, assume that an announcement is made at time zero that dividend taxes will increase at time $T$ from $\tau_{0}$ to $\tau_{1}$. Then

$$
\begin{align*}
b(t) & =\left(1-\tau_{0}\right) d & & \text { for } t \in[0, T) \\
& =\left(1-\tau_{1}\right) d & & \text { for } t \in[T, \infty) \tag{5}
\end{align*}
$$

Using (3) and (4), compute the trajectory of stock prices following the announcement.

(i) To compute the given integral, we will make a change of variable. Let

$$
u=u(s)=r(t-s)
$$

Then

$$
d u=-r d s, \quad \text { so } d s=\frac{-d u}{r}
$$

and

$$
\begin{aligned}
\int_{t}^{b} e^{r(t-s)} d s & =\frac{-1}{r} \int_{u(t)}^{u(b)} e^{u} d u=\frac{-1}{r}\left[e^{u}\right]_{u(t)}^{u(b)} \\
& =\frac{-1}{r}\left[e^{r(t-s)}\right]_{t}^{b}=\frac{-1}{r}\left(e^{r(t-b)}-e^{0}\right)=\frac{1}{r}\left(1-e^{r(t-b)}\right)
\end{aligned}
$$

(ii) We will consider two possible cases. First, let $t \geq T$. Then

$$
\begin{aligned}
v(t) & =F(t)=\int_{t}^{\infty} b(s) e^{r(t-s)} d s=\left(1-\tau_{1}\right) d \int_{t}^{\infty} e^{r(t-s)} d s=\frac{\left(1-\tau_{1}\right) d}{r} \lim _{b \rightarrow \infty}\left(1-e^{r(t-b)}\right) \\
& =\frac{\left(1-\tau_{1}\right) d}{r}(1-0)=\frac{\left(1-\tau_{1}\right) d}{r}=v^{*}\left(\tau_{1}\right)
\end{aligned}
$$

so the two solution procedures agree for $t \geq T$.

Next, if $t \in[0, T)$, we have

$$
\begin{aligned}
v(t) & =F(t)=\int_{t}^{\infty} b(s) e^{r(t-s)} d s=\int_{t}^{T} b(s) e^{r(t-s)} d s+\int_{T}^{\infty} b(s) e^{r(t-s)} d s \\
& =\int_{t}^{T}\left(1-\tau_{0}\right) d e^{r(t-s)} d s+\int_{T}^{\infty}\left(1-\tau_{1}\right) d e^{r(t-s+T-T)} d s \\
& =\frac{\left(1-\tau_{0}\right) d}{r}\left(1-e^{r(t-T)}\right)+e^{r(t-T)} \int_{T}^{\infty}\left(1-\tau_{1}\right) d e^{r(T-s)} d s \\
& =\frac{\left(1-\tau_{0}\right) d}{r}\left(1-e^{r(t-T)}\right)+e^{r(t-T)} \frac{\left(1-\tau_{1}\right) d}{r} \\
& =v^{*}\left(\tau_{0}\right)\left(1-e^{r(t-T)}\right)+e^{r(t-T)} v^{*}\left(\tau_{1}\right) \\
& =v^{*}\left(\tau_{0}\right)-\left[v^{*}\left(\tau_{0}\right)-v^{*}\left(\tau_{1}\right)\right] e^{r(t-T)}
\end{aligned}
$$

which is equation (18) in the text. Hence, the two procedures give the same result also for the transition period.

Problem 2.2. Cagan's model with perfect foresight. Consider the following specification of equilibrium in the money market:

$$
\begin{equation*}
m(t)-p(t)=-\lambda \pi(t), \quad \text { with } \lambda>0 \tag{1}
\end{equation*}
$$

where $m$ is the log of the nominal money supply, $p$ is the $\log$ of the price level, and $\pi=\dot{p}$ is the (both actual and expected) inflation rate (i.e., we are assuming perfect foresight). If we are willing to assume away real-side complications (e.g., assume that output is fixed at the natural rate), then the full equilibrium of the economy is determined by this equation.

Assume that the nominal money supply grows at a constant rate $\dot{m}=\mu$. Differentiating (1) with respect to time, we can obtain a differential equation in the inflation rate,

$$
\begin{align*}
& \mu-\pi=\dot{m}-\dot{p}=-\lambda \dot{\pi} \\
& \quad \Rightarrow \dot{\pi}=\theta(\pi-\mu), \quad \text { where } \theta \equiv 1 / \lambda \tag{2}
\end{align*}
$$

(i) Find the steady state of this equation, and write its general solution.

Setting $\dot{\pi}$ equal to zero in (2) and solving for $\pi$, we see that the steadystate rate of inflation is equal to the rate of growth of the money supply $(\bar{\pi}=\mu)$. As discussed in Section 3(a) of Chapter 9, the general solution of the linear equation (2) can be written

$$
\begin{equation*}
\pi(t)=\bar{\pi}+[\pi(0)-\bar{\pi}] e^{\theta t} \tag{3}
\end{equation*}
$$

where $\pi(0)$ is the initial inflation rate.

(ii) Assume that $\mu$ remains constant forever. From an economic point of view, which is the most reasonable particular solution of this equation? Why?

Because the coefficient $\theta$ is positive, the system is unstable. Thus, if initial inflation is not equal to the rate of money growth, the inflation rate either increases or decreases without bound. With a constant rate of money growth, such an explosive, hyperinflationary (or deflationary) outcome does not seem
very reasonable. Hence, we shall assume that the equilibrium of the model involves an immediate jump to the steady state.

(iii) Assume that we are at time zero and that $\mu$ has always been constant at some value $\mu_{0}$. Suddenly the government announces that at some time $T$ in the future the rate of money creation will increase to $\mu_{1}>\mu_{0}$ and will remain constant forever thereafter (and people believe the announcement).

Describe the evolution of the inflation rate following the announcement and your reasons for selecting this particular adjustment path. Write the particular solution corresponding to this behavior, and use it to solve for the jump in the price level at the time of the announcement. What factors determine the size of this jump?

At the time the policy change takes place we must be in the new steady state $\bar{\pi}_{1}=\mu_{1}$. Hence, we must have

$$
\begin{equation*}
\pi(T)=\mu_{1} \tag{4}
\end{equation*}
$$

During the period between zero and $T$ we must be on a solution trajectory of the old system, which is of the form (2), with $\bar{\pi}=\mu_{0}$ :

$$
\begin{equation*}
\pi(t)=\mu_{0}+\left[\pi(0)-\mu_{0}\right] e^{\theta t} \tag{5}
\end{equation*}
$$

Using (4) as a boundary condition in (5), we can solve for the initial inflation rate $\pi(0)$ :

$$
\pi(T)=\mu_{1}=\mu_{0}+\left[\pi(0)-\mu_{0}\right] e^{\theta T}
$$

from where

$$
\pi(0)-\mu_{0}=\left(\mu_{1}-\mu_{0}\right) e^{-\theta T}
$$

Hence, the immediate jump in the inflation rate (from its initial value of $\mu_{0}$ ) depends on the increase in the rate of money creation, the time from the announcement until the actual policy change, and the elasticity of the demand for money.

Problem 2.3. Construct the phase diagram for the system (L.s)-(L.p). Assume that $1-\alpha \sigma>0$. What does this assumption mean?

The system whose behavior we want to analyze is of the form

$$
\begin{gather*}
\dot{p}=\frac{\alpha}{1-\alpha \sigma}\left(\delta\left(s+p^{*}\right)-[\delta+(\sigma / \lambda)] p-\sigma \frac{\phi y-m}{\lambda}+g-y\right)  \tag{L.p}\\
\dot{s}=\frac{\phi y-m+p}{\lambda}-R^{*} \tag{L.s}
\end{gather*}
$$

- Setting $\dot{s}=0$ in (L.s) and solving for $p$, the equation of the first phase line is given by

$$
\begin{equation*}
\dot{s}=0 \Rightarrow p=m-\phi y+\lambda R^{*}(=\bar{p}) \tag{P.s}
\end{equation*}
$$

which is a horizontal line in phase space. Moreover,

$$
\frac{\partial \dot{s}}{\partial p}=1 / \lambda>0
$$

The sign of this derivative indicates that, starting from the phase line (where $\dot{s}=$ 0 ), a small increase in the value of $p$ puts us in the region in which $s$ is positive. Hence, $s$ increases over time in the region above the phase line, and the arrows of motion along the $s$ axis point to the right, as shown in Figure A11.1.

- Similarly, setting $\dot{p}=0$ in (L.p), we have
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-766.jpg?height=456&width=1300&top_left_y=179&top_left_x=104)

$\mathbf{S}$

Figure A11.1. Phase lines and arrows of motion.

$$
\begin{align*}
\dot{p} & =0 \Rightarrow[\delta+(\sigma / \lambda)] p=\delta\left(s+p^{*}\right)-\sigma \frac{\phi y-m}{\lambda}+g-y \\
& \Rightarrow p=\frac{1}{\delta+(\sigma / \lambda)}\left(\delta\left(s+p^{*}\right)-\sigma \frac{\phi y-m}{\lambda}+g-y\right) \tag{P.p}
\end{align*}
$$

Thus, the $\dot{p}=0$ phase line is upward-sloping, with slope

$$
\frac{d p}{d s}=\frac{\delta}{\delta+(\sigma / \lambda)}<1
$$

Differentiating (L.p) with respect to $p$, we obtain

$$
\frac{\partial \dot{p}}{\partial p}=-\frac{\alpha[\delta+(\sigma / \lambda)]}{1-\alpha \sigma}
$$

In principle, the sign of this expression is ambiguous. Under the assumption that $1-\alpha \sigma>0$, however, the derivative is negative, and $\dot{p}$ is negative in the region above the phase line. Hence, the arrows of motion along the $p$ axis point toward the phase line, and the output market is "stable" in the sense that prices fall if they are too high for the market to clear. Combining the two phase lines, we get the phase diagram shown in Figure A11.2.

Recall that the parameter $\alpha$ measures the speed of price adjustment. Hence, the assumption that

$$
1-\alpha \sigma>0 \text { or } \alpha<1 / \sigma
$$

requires that prices not adjust "too quickly." As we will see in the next problem, if this assumption does not hold, the system is unstable and displays "unreasonable" behavior.

Problem 2.4. Solution of Dornbusch's model.

(i) Compute the eigenvalues and eigenvectors of the system (L.s)-(L.p), and verify that the steady state is a saddle point.

Expressing $p$ and $s$ in deviations from the steady state, the system

(L.p)-(L.s) can be written in matrix form as

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-767.jpg?height=657&width=905&top_left_y=185&top_left_x=284)

Figure A11.2. Phase diagram.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-767.jpg?height=660&width=909&top_left_y=971&top_left_x=286)

Figure A11.3. Phase diagram and saddle path.

$$
\left[\begin{array}{c}
\dot{p} \\
\dot{s}
\end{array}\right]=\left[\begin{array}{cc}
\frac{-\alpha[\delta+(\sigma / \lambda)]}{1-\alpha \sigma} & \frac{\alpha \delta}{1-\alpha \sigma} \\
1 / \lambda & 0
\end{array}\right]\left[\begin{array}{c}
p-\bar{p} \\
s-\bar{s}
\end{array}\right]
$$

Observe that the determinant of the coefficient matrix,

$$
|A|=\eta_{1} \eta_{2}=0-\frac{\alpha \delta}{1-\alpha \sigma} \frac{1}{\lambda}<0
$$

is negative under the assumption that $1-\alpha \sigma>0$. Because the determinant of the coefficient matrix is equal to the product of the eigenvalues $\eta_{1}$ and $\eta_{2}$, it
follows that both roots of the system are real numbers and have different signs (say $\eta_{1}>0$ and $\eta_{2}<0$ ). Hence, the steady state is a saddle point. As we saw in Chapter 10, the system will converge to the steady state if its initial position lies on a straight line through this point, called the convergent subspace of the system or saddle path. There is also an anti-saddle path to which all other trajectories converge (Figure A11.3).

To write the general solution to the model we will need to find the eigenvectors of the coefficient matrix. Normalizing its second component to 1 , we can write the eigenvector associated with $\eta_{i}$ as $e_{i}=\left(x_{i}, 1\right)^{T}$. By definition, the eigenvector satisfies $A e_{i}=\eta_{i} e_{i}$, so we have

$$
\left[\begin{array}{cc}
\frac{-\alpha[\delta+(\sigma / \lambda)]}{1-\alpha \sigma} & \frac{\alpha \delta}{1-\alpha \sigma} \\
1 / \lambda & 0
\end{array}\right]\left[\begin{array}{c}
x_{i} \\
1
\end{array}\right]=\left[\begin{array}{c}
\eta_{i} x_{i} \\
\eta_{i}
\end{array}\right]
$$

Focusing on the second equation in this system (recall that we can work with whichever one is more convenient), we have

$$
(1 / \lambda) x_{i}+0=\eta_{i} \Rightarrow x_{i}=\lambda \eta_{i}
$$

Hence, the eigenvectors of the system are of the form

$$
e_{1}=\left(\lambda \eta_{1}, 1\right)^{T} \quad \text { and } \quad e_{2}=\left(\lambda \eta_{2}, 1\right)^{T}
$$

(ii) Write the general solution of the system. Find the particular solution of the system that corresponds to the saddle path, and discuss the equilibrium trajectory of the system from an arbitrary initial price level. Find the equation that describes the saddle path, and show that it has negative slope.

Because the model is linear, we can write its solution using the formulas derived in Section 2(f)(i) of Chapter 10:

$$
\begin{gather*}
p(t)-\bar{p}=k_{1} \lambda \eta_{1} \exp \left(\eta_{1} t\right)+k_{2} \lambda \eta_{2} \exp \left(\eta_{2} t\right) \\
s(t)-\bar{s}=k_{1} \exp \left(\eta_{1} t\right)+k_{2} \exp \left(\eta_{2} t\right) \tag{G.S}
\end{gather*}
$$

where $k_{1}$ and $k_{2}$ are arbitrary constants to be definitized by choice of an appropriate boundary condition. We rule out explosive paths and assume that for the given value of the predetermined variable $(p)$, the free variable $(s)$ adjusts continuously so as to keep the system on the unique convergent path, the saddle path. To impose this assumption, we set the constant $k_{1}$ associated with the explosive root $\left(\eta_{1}>0\right)$ equal to zero to obtain the particular solution

$$
\begin{equation*}
p(t)-\bar{p}=k_{2} \lambda \eta_{2} \exp \left(\eta_{2} t\right) \quad \text { and } \quad s(t)-\bar{s}=k_{2} \exp \left(\eta_{2} t\right) \tag{G.P}
\end{equation*}
$$

Differentiating the first equation with respect to time, we see that

$$
\dot{p}(t)=k_{2} \lambda \eta_{2} \exp \left(\eta_{2} t\right) \eta_{2}=\eta_{2}[p(t)-\bar{p}] \quad\left(\eta_{2}<0\right)
$$

That is, the speed with which prices adjust toward their long-run equilibrium level is directly proportional to the difference between the current and steady-state values. The speed of adjustment of the system then depends on the value of $\eta_{2}$, a function of the parameters of the system. By solving explicitly for $\eta_{2}$, you will see that high elasticities will increase the absolute value of $\eta_{2}$ and hence the speed of the price adjustment.

From (G.P) we can obtain the equation of the saddle path. Dividing the first equation by the second, we get

$$
\begin{align*}
& \frac{p(t)-\bar{p}}{s(t)-\bar{s}}=\lambda \eta_{2} \\
& \quad \Rightarrow p(t)-\bar{p}=\lambda \eta_{2}(s(t)-\bar{s}) \tag{S.P}
\end{align*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-769.jpg?height=439&width=677&top_left_y=177&top_left_x=409)

Figure A11.4. Effect of an unanticipated increase in government expenditures.

which describes a straight line in the phase plane going through the steady state.

Problem 2.5. Assume that the economy is initially (at time zero) at the steady state $S_{0}=\left(\bar{p}_{0}, \bar{s}_{0}\right)$ corresponding to values $m_{0}$ and $g_{0}$ of the money supply and government expenditures.

(i) Suppose the government announces an immediate and unanticipated permanent increase in its expenditure level on domestic goods to $g_{1}>g_{0}$. Discuss the impact on the steady state of the system, and describe the adjustment trajectory from the initial position to the new equilibrium.

Recall that the steady-state values of $p$ and $s$ are given by

$$
\begin{gather*}
\bar{p}=m-\phi y+\lambda R^{*}  \tag{ss.p}\\
\bar{s}=\bar{p}-p^{*}+(1 / \delta)\left(y+\sigma R^{*}-g\right) \tag{ss.s}
\end{gather*}
$$

Hence, an increase in $g$ has no effect on the price level and requires a decrease in $s$, which can take place through an appreciation of the home currency that deflects foreign demand away from domestic output. The adjustment is immediate and is illustrated in Figure A11.4.

(ii) Analyze the effect of an immediate, unanticipated, and permanent increase in the nominal money supply to $m_{1}>m_{0}$. It will be seen that the exchange rate temporarily "overshoots" its new long-run equilibrium value. Explain in what sense this is true, and discuss the economic mechanism that generates this result. What determines the degree of overshooting?

Consider the effect of a one-time surprise (permanent) increase in the nominal money supply, from $m_{0}$ to $m_{1}=m_{0}+\Delta m$. We recall that the steadystate values of the price level and the exchange rate are given by

$$
\begin{gather*}
\bar{p}=m-\phi y+\lambda R^{*}  \tag{ss.p}\\
\bar{s}=\bar{p}-p^{*}+(1 / \delta)\left(y+\sigma R^{*}-g\right) \tag{ss.s}
\end{gather*}
$$

Using subscripts to denote the steady-state values of $p$ and $s$ before and after the policy change, it is clear that

$$
\bar{p}_{1}-\bar{p}_{0}=m_{1}-m_{0}=\Delta m=\bar{s}_{1}-\bar{s}_{0}
$$

Hence, the steady state shifts northeast along a straight line with slope 1 . The long-run effect of a monetary expansion is simply to increase prices and exchange rates in the same proportion, leaving real variables unaffected. In the short run, however, a change in the money supply will have real effects.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-770.jpg?height=667&width=927&top_left_y=182&top_left_x=212)

Figure A11.5. Adjustment trajectory in response to an increase in the money supply.

Assuming that we are initially at the old steady state $S_{0}$ and that the exchange rate adjusts immediately to put us on the saddle path leading to the new steady state $S_{1}$, the adjustment path is as shown in Figure A11.5. The impact effect is an immediate depreciation of the currency ( $s$ increases) with a fixed price level; then the currency appreciates slowly, and prices rise along the saddle-path trajectory of the system.

Observe that (because the saddle path is downward-sloping) $s$ "overshoots" its new long-run equilibrium level $\bar{s}_{1}$. Overshooting occurs because output prices are sluggish to respond, so the full burden of the adjustment falls initially on asset prices, which are flexible. The instantaneous depreciation produces a disequilibrium in the goods market that is eliminated slowly over time as output prices adjust. Following the sudden depreciation, and with output prices given, domestic goods become cheaper relative to foreign goods, and that leads to an excess demand for them. The excess demand leads, in turn, to a gradual upward adjustment in the domestic price level through the Phillips relation.

Note also that with $p$ predetermined, the increase in $m$ is an increase in the real money supply and leads to a reduction in domestic interest rates. This increases demand for output and generates additional inflationary pressures. Moreover, at the lower $R$, the domestic currency will be held only if it is expected to appreciate in the future (otherwise, real returns on domestic bonds would be less than for foreign bonds). Such appreciation is possible only if the immediate adjustment puts $s$ above its long-run level; hence the need for overshooting. As the adjustment proceeds, domestic prices rise, reducing the real money supply and increasing the interest rate. This, in turn, leads to an appreciation of the home currency that reverses some of the initial depreciation.

It is clear from the figure that the extent of overshooting depends on the slope of the saddle path, which is given by $\lambda \eta_{2}$. In general, an increase in the absolute value of $\lambda \eta_{2}$ makes the saddle path steeper and reduces the overshooting. To interpret this observation, note that $\lambda$ is the interest

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-771.jpg?height=657&width=979&top_left_y=180&top_left_x=244)

Figure A11.6. Adjustment to an anticipated increase in the money supply.

elasticity of the demand for (domestic) money balances. A high elasticity implies that a given reduction in the money stock will induce only a small decline in interest rates and hence will require only a small appreciation to compensate for it. Second, we have seen that $\eta_{2}$ reflects the speed of price adjustment. This brings us back to the earlier comment that overshooting arises because asset markets adjust rapidly relative to output markets. Things that speed up price adjustment (high elasticities) also reduce overshooting.

Problem 2.6. Anticipated increase in the money supply. As before, assume that the economy is initially (at time zero) at the steady state $S_{0}=\left(\bar{p}_{0}, \bar{s}_{0}\right)$ corresponding to a value $m_{0}$ of the money supply. Now imagine that at time zero the government announces that at some time $T$ in the future the money supply will be permanently increased from the current level of $m_{0}$ to $m_{1}=m_{0}+\Delta m$. The change in the steady state will be as in the preceding problem, with the long-run equilibrium levels of $p$ and $m$ increasing proportionately by $\Delta m$. The adjustment path is sketched in Figure A11.6. Explain how this path is constructed, and explain how you would go about finding the coordinates of points $A$ and $B$ in the figure using the general solution of the system (derived earlier) and appropriate boundary conditions.

The logic is similar to what we used in the Cagan model. We need a continuous path, except for a possible jump at the time of the announcement. Discontinuities in the path of prices are ruled out by assumption. Discontinuities in the path of the exchange rate are possible, but only at the time of the announcement, because any future discontinuities would imply (anticipated but) unexploited profit opportunities. Moreover, the adjustment path must eventually converge to the new steady state $S_{1}$ and must obey the equations of motion of the "old" system (with $m=m_{0}$ ) for $t \in(0, T)$, and those of the "new" system (with $m=m_{1}$ ) for $t>T$.

Proceeding backward, there is only one path that will work: Because the path must converge to the steady state $S_{1}$ under the laws of motion of the "new"
system, at the time of the actual policy change $(T)$, the state vector $(s, p)$ must be on the saddle path for the new system (point $B$ ). We must get there while obeying the laws of motion of the old system; hence the path for $(0, T)$ must be an apparently explosive path of the old system, starting from point $A$. At time zero there is a jump in $s$, with $p$ fixed at the old level, which takes the system to point $A$. Notice that this initial adjustment must take the form of a depreciation of the currency (an increase in $s$ ). Otherwise, the starting position of the system would be to the left of the old steady state, and the arrows of motion of the system are such that no trajectory starting in this region would intersect the new saddle path.

To characterize the adjustment path more precisely, we need to find the points $A$ and $B$. We know that the orbit segment $A B$ must satisfy the general solution of the old system, that is,

$$
\begin{gather*}
p(t)-\bar{p}_{0}=k_{1} \lambda \eta_{1} \exp \left(\eta_{1} t\right)+k_{2} \lambda \eta_{2} \exp \left(\eta_{2} t\right) \\
s(t)-\bar{s}_{0}=k_{1} \exp \left(\eta_{1} t\right)+k_{2} \exp \left(\eta_{2} t\right) \tag{0}
\end{gather*}
$$

Now let the coordinates of $B$ be $\left(p_{T}, s_{T}\right)$ (because we reach this point at time $T$ ), and let those of $A$ be $\left(p_{0}, s_{0}\right)$. We know that $B$ must satisfy (G.S $\left.S_{0}\right)$. Hence

$$
\begin{gathered}
p_{\tau}-\bar{p}_{0}=k_{1} \lambda \eta_{1} \exp \left(\eta_{1} T\right)+k_{2} \lambda \eta_{2} \exp \left(\eta_{2} T\right) \\
s_{T}-\bar{s}_{0}=k_{1} \exp \left(\eta_{1} T\right)+k_{2} \exp \left(\eta_{2} T\right)
\end{gathered}
$$

Moreover, $B$ must be on the saddle path of the new system and therefore satisfies

$$
\begin{equation*}
p_{T}-\bar{p}_{1}=\lambda \eta_{2}\left(s_{T}-\bar{s}_{1}\right) \tag{}
\end{equation*}
$$

Similarly, we know that $A$ must satisfy (G.S $\mathrm{S}_{0}$ ), so we have

$$
\begin{gathered}
p_{0}-\bar{p}_{0}=k_{1} \lambda \eta_{1} \exp (0)+k_{2} \lambda \eta_{2} \exp (0)=k_{1} \lambda \eta_{1}+k_{2} \lambda \eta_{2} \\
s_{0}-\bar{s}_{0}=k_{1}(1)+k_{2}(1)
\end{gathered}
$$

and that in addition

$$
p_{0}=\bar{p}_{0}
$$

because prices are predetermined. This gives us a system of six equations in six unknowns that can be solved for the coordinates of $A$ and $B$ and the two arbitrary constants $k_{1}$ and $k_{2}$. Once we know these constants, we can determine the initial exchange rate $s_{0}$.

Problem 3.1. The Solow model with a Cobb-Douglas production function. Assume that the aggregate production function is Cobb-Douglas, with laboraugmenting technical progress

$$
\begin{equation*}
Y=K^{\alpha}(A L)^{1-\alpha} \tag{1}
\end{equation*}
$$

with $\dot{A} / A=g$. Write the intensive-production function $f(Z)$, giving output per efficiency unit of labor as a function of the capital/labor ratio in efficiency units, $Z$ $=K / A L$. Derive the law of motion for $Z$ under Solow's assumptions, and solve explicitly for the steady state of the system. What factors determine a country's long-term level of income?

Given the production function (1), output per worker is given by

$$
f(Z)=\frac{Y}{A L}=\frac{K^{\alpha}(A L)^{1-\alpha}}{A L}=\frac{(K / A L)^{\alpha} A L}{A L}=Z^{\alpha}
$$

Substituting this expression into equation (9) in the text, the growth rate of $Z$ is given by

$$
\begin{equation*}
\frac{\dot{Z}}{Z}=s \frac{f(Z)}{Z}-(\delta+n+g)=s Z^{\alpha-1}-(\delta+n+g) \tag{2}
\end{equation*}
$$

Setting $\dot{Z} / Z$ equal to zero in (2), we can solve for the steady-state value of the capital/labor ratio in efficiency units:

$$
s Z^{\alpha-1}=\delta+n+g \Rightarrow \bar{Z}=\left(\frac{s}{\delta+n+g}\right)^{1 /(1-\alpha)}
$$

Per-capita income in the steady-state path is given by

$$
\bar{Q}_{t}=A_{t} \bar{Z}^{\alpha}=A_{t}\left(\frac{s}{\delta+n+g}\right)^{\alpha /(1-\alpha)}
$$

where it can be seen that $\bar{Q}_{t}$ is an increasing function of the level of technical efficieny $\left(A_{t}\right)$ and the investment coefficient $(s)$ and a decreasing function of the rate of growth of the work force $(n)$ and the rate of depreciation $(\delta)$. An increase in the rate of technical progress, $g$, reduces $\bar{Q}$ for a given value of $A$, but also increases the growth rate of income.

Problem 3.2. Suppose the production function is of the form (1): $Y_{t}=$ $\left(B_{t} K_{t}\right)^{\alpha}\left(A_{t} L_{t}\right)^{1-\alpha}$, with both capital- and labor-augmenting technical progress at rates $\dot{B} / B=g_{B}$ and $\dot{A} / A=g_{A}$. Derive the equation of motion for the capital/labor ratio in effective units, $Z=B K / A L$, under the assumptions of the Solow model. Show that the system has a balanced-growth path (i.e., a constant- $Z$ solution) if and only if $g_{B}=0$ (i.e., if technical progress is only labor-augmenting). by

Under our assumptions, the instantaneous increase in the capital stock is given

$$
\begin{equation*}
\dot{K}=s Y-\delta K=s(B K)^{\alpha}(A L)^{1-\alpha}-\delta K=s A L Z^{\alpha}-\delta K \tag{2}
\end{equation*}
$$

Given that $Z=B K / A L$, we have, taking logs of both sides of this expression,

$$
\ln Z=\ln B+\ln K-\ln A-\ln L
$$

and differentiating with respect to time,

$$
\frac{\dot{Z}}{Z}=\frac{\dot{K}}{K}-\frac{\dot{L}}{L}+\left(g_{B}-g_{A}\right)
$$

Substituting (2) into this last expression and simplifying, we arrive at

$$
\begin{equation*}
\frac{\dot{Z}}{Z}=\frac{\dot{K}}{K}-\frac{\dot{L}}{L}+\left(g_{B}-g_{A}\right)=\frac{s L A B Z^{\alpha}-\delta K}{B K}-\left(n+g_{A}-g_{B}\right)=s B Z^{\alpha-1}-\left(n+\delta+g_{A}-g_{B}\right) \tag{3}
\end{equation*}
$$

Setting $\dot{Z} / Z$ equal to zero in this expression (and introducing time subscripts), we have

$$
\begin{equation*}
s B_{t} Z_{t}^{\alpha-1}=n+\delta+g_{A}-g_{B} \tag{4}
\end{equation*}
$$

If technical progress is purely labor-augmenting (i.e., if $g_{B}=0$ ), then $B_{t}$ is constant, and (4) has a constant $-Z$ solution. If this is not the case, however, $B$ changes over time, and so does the value of $Z$ that solves (4).

Problem 3.4. Prove Proposition 3.3 (properties of the savings function).

To sign the partials of the savings function, we will use the implicit-function theorem. Rewriting equation (2) in the text in the form

$$
\begin{equation*}
F\left(s ; y_{1}, y_{2}, R\right)=R U_{x}\left(y_{1}-s, y_{2}+s R\right)-U_{c}\left(y_{1}-s, y_{2}+s R\right)=0 \tag{3}
\end{equation*}
$$

and differentiating $F($ ), we obtain

$$
\begin{gathered}
F_{s}=R\left[U_{c x}(-1)+R U_{x x}\right]-\left[U_{c c}(-1)+R U_{c x}\right] \\
=-2 R U_{c x}+R^{2} U_{x x}+U_{c c}<0 \quad\left(=\partial^{2} U / \partial s^{2}\right) \\
F_{y_{1}}=R U_{c x}-U_{c c}>0 \\
F_{y_{2}}=R U_{x x}-U_{c x}<0 \\
F_{R}=R s U_{x x}+U_{x}-s U_{c x}=s\left(R U_{x x}-U_{c x}\right)+U_{x} \gtrless 0
\end{gathered}
$$

By the implicit-function theorem, then,

$$
\frac{\partial s()}{\partial y_{1}}=-\frac{F_{y_{1}}}{F_{s}}>0, \quad \frac{\partial s()}{\partial y_{2}}=-\frac{F_{y_{2}}}{F_{s}}<0, \quad \frac{\partial s()}{\partial R}=-\frac{F_{R}}{F_{s}} \gtrless 0
$$

That is, an increase in first-period income increases savings, as part of the new income is saved to increase second-period consumption. Similarly, an increase in second-period income induces the agent to consume more also in the first period, and savings fall. The sign of $z^{*} / \partial R$, on the other hand, may be positive or negative. To see why, note that

$$
\begin{equation*}
\frac{\partial s^{*}}{\partial R}=-F_{R} / F_{s}=\left(-1 / F_{s}\right)\left[s\left(R U_{x x}-U_{c x}\right)+U_{x}\right]=s^{*} \frac{\partial s^{*}}{\partial y_{2}}-\frac{U_{x}}{F_{s}} \tag{4}
\end{equation*}
$$

The first term in this expression measures the income effect and the second the substitution effect of a change in the interest factor. The substitution effect is always positive $\left[-\left(U_{x} / F_{s}\right)>0\right]$ - an increase in $R$ makes present consumption more expensive in terms of forgone future consumption and encourages people to defer consumption to the second period, increasing savings. The sign of the income effect depends on whether the individual is a saver or a borrower. An increase in $R$ makes borrowers ( $s \leq 0$ ) "poorer," forcing them to reduce consumption in both periods. As $c$ falls, savings increase (become "less negative"). Thus income and substitution effects work in the same direction for borrowers. Net lenders, on the other hand, become "richer" when $R$ increases. This leads to an increase in first-period (and second-period) consumption, and hence to a decline in $s$. The overall effect of a change in $R$ for net savers depends, therefore, on the relative strengths of the income and substitution effects.

Similar results can be obtained by replacing

$$
\begin{equation*}
U_{c c}, U_{x x}<0 \text { and } U_{c x}=U_{x c} \geq 0 \tag{A.2}
\end{equation*}
$$

with the assumption that $c$ and $x$ are both normal goods. A good is said to be normal if demand for it increases as income rises. Normality of consumption in both periods implies, therefore, that

$$
\frac{\partial c^{*}}{\partial y_{1}}, \frac{\partial c^{*}}{\partial y_{2}}, \frac{\partial x^{*}}{\partial y_{1}}, \frac{\partial x^{*}}{\partial y_{2}}>0
$$

To see the implications of this assumption for the partials of the savings function, observe that the optimal consumption and savings functions must satisfy the budget constraints identically. Hence, we have

$$
\begin{gather*}
y_{1}-c\left(y_{1}, y_{2}, R\right) \equiv s\left(y_{1}, y_{2}, R\right)  \tag{5}\\
x\left(y_{1}, y_{2}, R\right) \equiv y_{2}+R s\left(y_{1}, y_{2}, R\right) \tag{6}
\end{gather*}
$$

Combining these two expressions,

$$
\begin{equation*}
c\left(y_{1}, y_{2}, R\right)+\frac{x\left(y_{1}, y_{2}, R\right)}{R} \equiv y_{1}+\frac{y_{2}}{R} \tag{7}
\end{equation*}
$$

Differentiating (7) with respect to $y_{1}$ we find that

$$
\frac{\partial c^{*}}{\partial y_{1}}+\frac{1}{R} \frac{\partial x^{*}}{\partial y_{1}}=1
$$

It is obvious that if $\partial c^{*} / \partial y_{1}$ and $\partial x^{*} / \partial y_{1}$ are both to be positive, then $\partial c^{*} / \partial y_{1} \in$ $(0,1)$. But then it must be true that $\partial s / * \partial_{1} \in(0,1)$ as well, because differentiating (5) with respect to $y_{1}$ we see that

$$
1-\frac{\partial c^{*}}{\partial y_{1}}=\frac{\partial s^{*}}{\partial y_{1}}
$$

Similarly, (5) implies that

$$
-\frac{\partial c^{*}}{\partial y_{2}}=\frac{\partial s^{*}}{\partial y_{2}}
$$

so $\partial s^{*} / \partial y_{2}<0$ under the assumption of normality. This, in turn, implies, by (4), that $\partial s^{*} / \partial R>0$ for $s \leq 0$.

Another assumption that is commonly made is that first- and second-period consumptions are substitutes. Two goods are said to be substitutes if an increase in the (relative) price of one leads to increased demand for the other. As noted, $R$ reflects the "price" of current consumption in terms of forgone future consumption. If $c$ and $x$ are (strict) substitutes, an increase in $R$ that makes $x$ cheaper should reduce $c^{*}$. In other words, $\partial c^{*} / \partial R<0$. Because (5) implies that $\partial s^{*} / \partial R=-\partial c^{*} / \partial R$, it follows that under the substitutability assumption we have $\partial s^{*} / \partial R>0$, even for net lenders.

Problem 4.1. Measuring the speed of convergence. The eigenvalue $\lambda$ of the loglinearized Solow model provides a measure of the speed of convergence of an economy toward its steady state. Show that the half-life of the system described by equation (5) (defined as the time $H$ at which half the original deviation of $z$ from its steady-state value has been eliminated) is given by

$$
H=\frac{\ln 2}{\lambda}
$$

To compute the half-life of the system, notice that, by definition, $z_{H}$ satisfies

$$
z_{H}-\bar{z}=\frac{z_{0}-\bar{z}}{2}
$$

Substituting this expression into the solution of the log-linear approximation to the law of motion for $z$ (equation (6) in the text) evaluated at $t=H$, we have

$$
\left(z_{H}-\bar{z}\right)=\frac{z_{0}-\bar{z}}{2}=\left(z_{0}-\bar{z}\right) e^{-\lambda H}
$$

from where

$$
2=e^{\lambda H} \Rightarrow H=\frac{\ln 2}{\lambda}
$$

Problem 4.2. Determinants of long-run income dispersion. Assume that the evolution of income per capita in a given country can be described by the equation

$$
\begin{equation*}
y_{i,+1}=x_{i}+(1-\beta) y_{i, t}+\varepsilon_{i t} \quad \text { or } \quad \Delta y_{i, t}=x_{i}-\beta y_{i, t}+\varepsilon_{i t} \tag{1}
\end{equation*}
$$

where $y_{i, t}=\ln \left(Q_{i t} / Q_{t}\right)$ denotes the logarithm of income per capita in country $i$ in period $t\left(Q_{i t}\right)$ normalized by the sample mean of the same variable $\left(Q_{t}\right)$, and $\Delta y_{t, t}$ $=y_{i, t+1}-y_{i, t}$ is approximately equal to the growth rate of per-capita income in country $i$, measured in deviations from the average growth rate in the sample. In this expression, $\varepsilon_{i t}$ is a random disturbance, with zero mean and variance $\sigma_{\epsilon}^{2}$, independent and identically distributed over time and across countries and uncorrelated with $y_{l,}$ and $x_{i}$. The term $x_{i}$, which summarizes the "fundamental" determinants of growth in territory $i$, is constant over time and is distributed across countries, with zero mean and variance $\sigma_{x}^{2}$.

Taking the expected values for both sides of (1), given initial income $y_{i, 0}$, we obtain a nonstochastic equation in expected income $y_{i, i}^{e}$ :

$$
\begin{equation*}
y_{i, t+1}^{e}=x_{i}+(1-\beta) y_{i, t}^{e} \text {, with } y_{i, 0}^{e}=y_{i, 0} \tag{2}
\end{equation*}
$$

The solution of (2) is of the form

$$
\begin{equation*}
y_{i, t}^{e}=y_{i}^{*}+\left(y_{i, 0}-y_{i}^{*}\right)(1-\beta)^{t} \tag{3}
\end{equation*}
$$

where

$$
y_{i}^{*}=\frac{x_{i}}{\beta}
$$

is the steady-state value of $y_{i t}$. Equation (3) shows that the stability of the system depends on the value of the slope coefficient $\beta$. If $\beta \in(0,1)$, the term $(1-\beta)^{t}$ goes to zero as $t \rightarrow \infty$. The system is therefore stable, and the expected income of each nation converges monotonically to its steady state $y_{i}^{*}$ at a rate determined by $\beta$. Hence, we can interpret $y_{i}^{*}$ as the expected (relative) income level of country $i$ in a long-run equilibrium.

We want to use equation (1) to investigate the determinants of income inequality across countries in the long run. Let $\sigma_{t}^{2}$ denote the sample variance of $y_{i t}$, and $c_{t}=E x_{i} y_{i t}$ the covariance between current income and country fundamentals, and observe that if the number of countries is large, the sample variance and covariance will be approximately equal to their population values. Using (1), derive a system of difference equations in $\sigma_{t}^{2}$ and $c_{t}$, discuss its stability properties, and compute its steady state. What determines the degree of income inequality in the long run, measured by the steady-state value of $\sigma_{t}^{2}$ ?

Taking the variance of both sides of (1), we obtain

$$
\begin{equation*}
\sigma_{t+1}^{2}=(1-\beta)^{2} \sigma_{t}^{2}+\sigma_{\varepsilon}^{2}+\sigma_{x}^{2}+2(1-\beta) c_{t} \tag{4}
\end{equation*}
$$

where $c_{t}=\operatorname{cov}\left(y_{i}, x_{t}\right)$. Using (1) again,

$$
c_{t+1}=E x_{i} y_{1, t+1}=E x_{i}\left[x_{i}+(1-\beta) y_{i t}+\varepsilon_{t t}\right]=E x_{i}^{2}+(1-\beta) E x_{i} y_{i f}+E \varepsilon_{i t} x_{i}
$$

from where, given that $E \varepsilon_{i} x_{i}=0$ by assumption,

$$
\begin{equation*}
c_{t+1}=\sigma_{x}^{2}+(1-\beta) c_{t} \tag{5}
\end{equation*}
$$

The expected time path of the variance of income and the covariance of income and country characteristics is given by the solution of a simple system of difference equations:

$$
\left[\begin{array}{c}
\sigma_{t+1}^{2} \\
c_{t+1}
\end{array}\right]=\left[\begin{array}{cc}
(1-\beta)^{2} & 2(1-\beta) \\
0 & (1-\beta)
\end{array}\right]\left[\begin{array}{c}
\sigma_{t}^{2} \\
c_{t}
\end{array}\right]+\left[\begin{array}{c}
\sigma_{x}^{2}+\sigma_{\varepsilon}^{2} \\
\sigma_{x}^{2}
\end{array}\right]
$$

Because the coefficient matrix is diagonal, the eigenvalues of the system are the coefficients of the principal diagonal, $(1-\beta)^{2}$ and $(1-\beta)$. Hence, the system is
stable if and only if the absolute value of $1-\beta$ is smaller than 1 , i.e., if equation

(1) is stable.

Eliminating the time subscripts in (4) and (5) and solving for $\sigma$ and $c$, it is easy to see that the stationary values of these variables are given by

$$
\begin{equation*}
\bar{\sigma}^{2}=\frac{\sigma_{\varepsilon}^{2}+\sigma_{x}^{2}+2(1-\beta) \bar{c}}{1-(1-\beta)^{2}}, \quad \text { where } \bar{c}=\frac{\sigma_{x}^{2}}{\beta} \tag{6}
\end{equation*}
$$

Hence, if the system is stable and country characteristics do not change over time, the distribution of income per capita converges to a stationary distribution with a constant level of inequality. Equation (6) shows that the long-run dispersion of relative income depends on the variance of the shocks, $\sigma_{\varepsilon}^{2}$, and on the dispersion of country characteristics, summarized by $\sigma_{x}^{2}$. During the transition toward the stationary equilibrium, the value of $\sigma_{t}^{2}$ could either increase or decrease, depending on the relation between its initial and stationary values.

Problem 5.1. Homogeneous output is produced using two types of capital (private and public), $K$ and $P$, according to a technology of the form

$$
\begin{equation*}
Y_{t}=K_{t}^{\alpha} P_{t}^{\beta}, \quad \text { where } \alpha+\beta<1 \tag{1}
\end{equation*}
$$

Both types of capital depreciate completely upon use. In each period, the government taxes income at a rate $\tau$ and invests the proceeds in public capital for the next period. Agents save a fixed fraction $s$ of their after-tax income and invest it in private capital. Hence,

$$
\begin{equation*}
K_{t+1}=s(1-\tau) Y_{t} \tag{2}
\end{equation*}
$$

and

$$
\begin{equation*}
P_{t+1}=\tau Y_{t} \tag{3}
\end{equation*}
$$

Using (1)-(3), derive a single difference equation in $Y$ that describes the evolution of income. Call this equation (4). Solve for the steady-state value of $Y$, and show that the system is stable. How does steady-state income vary with $s$ and $\tau$ ? What value of $\tau$ should the government choose if it wants to maximize steadystate output?

Using (1), (2), and (3), we have

$$
\begin{equation*}
Y_{t+1}=K_{t+1}^{\alpha} P_{t+1}^{\beta}=\left[s(1-\tau) Y_{t}\right]^{\alpha}\left[\tau Y_{t}\right]^{\beta}=s^{\alpha}(1-\tau)^{\alpha} \tau^{\beta} Y_{t}^{\alpha+\beta} \tag{4}
\end{equation*}
$$

Eliminating the time subscripts in (4) and solving for $Y$,

$$
Y^{1-\alpha-\beta}=s^{\alpha}(1-\tau)^{\alpha} \tau^{\beta} \Rightarrow \bar{Y}=s^{\alpha /(1-\alpha-\beta)}(1-\tau)^{\alpha /(1-\alpha-\beta)} \tau^{\beta /(1-\alpha-\beta)}
$$

and taking logs of this expression,

$$
\begin{equation*}
\ln \bar{Y} \equiv \bar{y}=\frac{\alpha}{1-\alpha-\beta} \ln s+\frac{\alpha}{1-\alpha-\beta} \ln (1-\tau)+\frac{\beta}{1-\alpha-\beta} \ln \tau \tag{5}
\end{equation*}
$$

Notice that the slope of the phase line at the steady state is given by

$$
\frac{\partial Y_{t+1}}{\partial Y_{t}}=s^{\alpha}(1-\tau)^{\alpha} \tau^{\beta}(\alpha+\beta) \bar{Y}^{\alpha+\beta-1}=s^{\alpha}(1-\tau)^{\alpha} \tau^{\beta}(\alpha+\beta) s^{-\alpha}(1-\tau)^{-\alpha} \tau^{-\beta}=\alpha+\beta \in(0,1)
$$

Hence, the steady state is stable.

Differentiating (5) with respect to $s$ and $\tau$,

$$
\frac{\partial \bar{y}}{\partial s}=\frac{\alpha}{1-\alpha-\beta} \frac{1}{s}>0
$$

so steady-state output is an increasing function of the savings rate, and

$$
\frac{\partial \bar{y}}{\partial \tau}=\frac{\alpha}{1-\alpha-\beta} \frac{-1}{1-\tau}+\frac{\beta}{1-\alpha-\beta} \frac{1}{\tau}
$$

Notice that

$$
\frac{\partial \bar{y}}{\partial \tau} \geq 0 \text { if and only if } \frac{\alpha}{1-\alpha-\beta} \frac{1}{1-\tau} \leq \frac{\beta}{1-\alpha-\beta} \frac{1}{\tau}
$$

or, equivalently,

$$
\alpha \tau \leq \beta(1-\tau) \Leftrightarrow \tau \leq \frac{\beta}{\alpha+\beta}
$$

This expression shows that in order to maximize steady-state output, the government should set the tax rate equal to public capital's "relative weight" in the aggregate production function, i.e., $\tau=\beta /(\alpha+\beta)$.

Problem 5.2. Consider an economy endowed with an aggregate production function of the form

$$
\begin{equation*}
Y=K^{\alpha}(L H)^{1-\alpha} \tag{1}
\end{equation*}
$$

where $K$ is the aggregate stock of physical capital, $L$ is employment in goods production, and $H$ is the average stock of human capital. "Pure knowledge," $A$, increases over time at a constant exogenous rate $g$, that is,

$$
\begin{equation*}
A_{t+1}=(1+g) A_{t} \tag{2}
\end{equation*}
$$

Pure knowledge and teacher's time and human capital are combined to "produce" the next generation's human capital according to

$$
\begin{equation*}
H_{t+1}=\left(\tau H_{t}\right)^{\gamma} A_{t}^{1-\gamma} \tag{3}
\end{equation*}
$$

where $\tau$ is the fraction of the population employed as teachers, a variable chosen by the government.

Suppose that population is constant, and normalize it to 1 (so that the labor force is $L=1-\tau$ ), and suppose that capital depreciates completely upon use and that agents save a constant fraction $s$ of their income. Then the law of motion for the capital stock is of the form

$$
\begin{equation*}
K_{t+1}=s K_{t}^{\alpha} H_{t}^{1-\alpha}(1-\tau)^{1-\alpha} \tag{4}
\end{equation*}
$$

(i) Define $Z=K / A$ and $E=H / A$. Using the previous expressions, derive a system of difference equations in $Z$ and $E$ that will describe the evolution of the economy.

Dividing both sides of (4) by $A_{t+1}=(1+g) A_{t}$, we have

$$
\frac{K_{t+1}}{A_{t+1}}=\frac{s(1-\tau)^{1-\alpha}}{1+g} \frac{K_{t}^{\alpha}}{A_{t}^{\alpha}} \frac{H_{t}^{1-\alpha}}{A_{t}^{1-\alpha}}
$$

from where

$$
\begin{equation*}
Z_{t+1}=\frac{s}{1+g}(1-\tau)^{1-\alpha} Z_{t}^{\alpha} E_{t}^{1-\alpha} \tag{5}
\end{equation*}
$$

Similarly, dividing both sides of (3) by $A_{t+1}=(1+g) A_{t}$,

$$
\frac{H_{t+1}}{A_{t+1}}=\frac{\tau^{\gamma}}{1+g} \frac{H_{t}^{\gamma}}{A_{t}^{\gamma}} \frac{A_{t}^{1-\gamma}}{A_{t}^{1-\gamma}}
$$

and hence

$$
\begin{equation*}
E_{t+1}=\frac{\tau^{\gamma}}{1+g} E_{t}^{\gamma} \tag{6}
\end{equation*}
$$

(ii) Solve for the steady-state values of $Z$ and $E$, and compute the steady-state value of $Q=Y / A$.

Eliminating the time subscripts in (5) and (6), we have

$$
\text { (6) } \Rightarrow E=\frac{\tau^{\gamma}}{1+g} E^{\gamma} \Rightarrow \bar{E}=\left(\frac{\tau^{\gamma}}{1+g}\right)^{1 /(1-\gamma)}
$$

and

$$
\begin{aligned}
(5) & \Rightarrow Z=\frac{s}{1+g}(1-\tau)^{1-\alpha} Z^{\alpha} E^{1-\alpha} \Rightarrow Z^{1-\alpha}=\frac{s}{1+g}(1-\tau)^{1-\alpha} E^{1-\alpha} \\
& \Rightarrow \bar{Z}=\left(\frac{s}{1+g}\right)^{1 /(1-\alpha)}(1-\tau) \bar{E}
\end{aligned}
$$

from where

$$
\bar{Z}=(1-\tau)\left(\frac{s}{1+g}\right)^{1 /(1-\alpha)}\left(\frac{\tau^{\gamma}}{1+g}\right)^{1 /(1-\gamma)}
$$

Steady-state output per efficiency unit of labor, $\bar{Q}$, is given by

$$
\begin{align*}
\bar{Q} & =\frac{Y}{A}=\bar{Z}^{\alpha}(1-\tau)^{1-\alpha} \bar{E}^{1-\alpha}=(1-\tau)^{1-\alpha}\left(\frac{s}{1+g}\right)^{\alpha /(1-\alpha)}(1-\tau)^{\alpha} \bar{E}^{\alpha} \bar{E}^{1-\alpha} \\
& \Rightarrow \bar{Q}=(1-\tau)\left(\frac{s}{1+g}\right)^{\alpha /(1-\alpha)} \bar{E}=(1-\tau)\left(\frac{s}{1+g}\right)^{\alpha /(1-\alpha)}\left(\frac{\tau^{\gamma}}{1+g}\right)^{1 /(1-\gamma)} \tag{7}
\end{align*}
$$

(iii) Find the value of $\tau$ that will maximize steady-state $Q$.

To maximize $\bar{Q}$ with respect to $\tau$, we take logarithms of (7) and, disregarding the constant terms, maximize the function

$$
g(\tau)=\ln (1-\tau)+\frac{\gamma}{1-\gamma} \ln \tau
$$

The first-order condition for a maximum is of the form

$$
g^{\prime}(\tau)=\frac{-1}{1-\tau}+\frac{\gamma}{1-\gamma} \frac{1}{\tau}=0
$$

from where

$$
(1-\gamma) \tau=(1-\tau) \gamma, \quad \text { implying } \tau=\gamma
$$

(iv) Let $z=\ln Z$ and $e=\ln E$. The system derived in (i) should be linear in $e$ and $z$. Working with the system in logs, compute its eigenvalues, and discuss the stability of its steady state.

Taking logs of (5) and (6), the system can be written

$$
\begin{gather*}
z_{t+1}=\Gamma_{z}+\alpha z_{t}+(1-\alpha) e_{t}  \tag{8}\\
e_{t+1}=\Gamma_{e}+\gamma e_{t} \tag{9}
\end{gather*}
$$

where

$$
\Gamma_{z}=\ln \frac{s}{1+g}(1-\tau)^{1-\alpha} \quad \text { and } \quad \Gamma_{e}=\ln \frac{\tau^{\gamma}}{1+g}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-780.jpg?height=536&width=761&top_left_y=180&top_left_x=342)

Figure A11.7. The $\Delta e_{t}=0$ phase line.

Hence, the Jacobian of the coefficient matrix,

$$
J=\left[\begin{array}{cc}
\gamma & 0 \\
1-\alpha & \alpha
\end{array}\right]
$$

is diagonal, and the eigenvalues of the system are $\lambda_{1}=\alpha$ and $\lambda_{2}=\gamma$, both positive numbers smaller than 1 . The steady state is therefore stable.

(v) Draw the phase diagram for the system.

Equation (9) can be written

$$
\Delta e_{t}=\Gamma_{e}-(1-\gamma) e_{t}
$$

Setting $\Delta e_{t}$ equal to zero in this expression, the equation of the corresponding phase line is

$$
\bar{e}=\frac{\Gamma_{e}}{1-\gamma}
$$

so the $\Delta e_{t}=0$ phase line is a vertical line at $\bar{e}$. Notice that

$$
\frac{d \Delta e_{t}}{d e_{t}}=-(1-\gamma)<0
$$

Hence, $\Delta e_{t}<0$ when $e_{t}>\bar{e}$, and the arrows of motion along the $e$ axis point toward the phase line (Figure A11.7).

For the other phase line, we have

$$
\Delta z_{t}=\Gamma_{z}+(1-\alpha) e_{t}-(1-\alpha) z_{t}
$$

from where, setting $\Delta z_{t}=0$,

$$
z=\frac{\Gamma_{z}}{1-\alpha}+e
$$

(the phase line is upward-sloping), and

$$
\frac{d \Delta z_{t}}{d z_{t}}=-(1-\alpha)<0
$$

Hence $\Delta z_{t}<0$ in the region above the phase line, and the arrows of motion are as shown in Figure A11.8.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-781.jpg?height=558&width=763&top_left_y=180&top_left_x=357)

Figure A11.8. The $\Delta z_{t}=0$ phase line.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-781.jpg?height=592&width=754&top_left_y=911&top_left_x=334)

Figure A11.9. Phase diagram.

Finally, combining the two preceding graphs, we obtain the full phase diagram for the system (Figure A11.9).

Problem 5.3. A model of learning by doing. Starting from the Solow model with exogenous technical progress, we will develop a simple model of endogenous growth and examine some of its implications. Assume that the production function is of the form

$$
Y=K^{\alpha}(A L)^{1-\alpha}
$$

Then output per worker is given by

$$
\begin{equation*}
Q=A Z^{\alpha} \tag{1}
\end{equation*}
$$

where $A$ is an index of technical efficiency, and $Z=K / A L$ is the capital/labor ratio in efficiency units. Given a constant investment coefficient $s$, the growth rate of $Z$ is given by the equation

$$
\begin{equation*}
\frac{\dot{Z}}{Z}=s Z^{\alpha-1}-\left(\delta+n+g_{A}\right) \tag{2}
\end{equation*}
$$

where $n$ is the rate of population growth, and $g_{A}=\dot{A} / A$ is the rate of technical progress.

Instead of assuming that $g_{A}$ is a given constant, we will now assume that the rate of technical progress $g_{A}$ reflects the accumulation of knowledge with productive experience. In particular, we assume that the instantaneous increase of $A$ is proportional to output per worker, that is,

$$
\begin{equation*}
\dot{A}=\gamma Q=\gamma A Z^{\alpha} \tag{3}
\end{equation*}
$$

where the coefficient $\gamma$ measures the speed of learning.

(i) Show that under these assumptions the law of motion for the capital/labor ratio is of the form

$$
\dot{Z}=(s-\gamma Z) Z^{\alpha}-(\delta+n) Z
$$

Dividing both sides of (3) by $A$, the rate of technical progress is given by

$$
\begin{equation*}
g_{A}=\frac{\dot{A}}{A}=\gamma Z^{\alpha} \tag{4}
\end{equation*}
$$

Substituting (4) into (2) and regrouping terms, we have

$$
\begin{equation*}
\dot{Z}=(s-\gamma Z) Z^{\alpha}-(\delta+n) Z \tag{5}
\end{equation*}
$$

(ii) Construct the phase diagram for the system, and discuss the stability of its steady state. What is the growth rate of income per worker along the steadystate path?

To analyze the dynamics of equation (5), we will use Figure A11.10. In the upper panel we plot the functions $Z^{\alpha}$ and $s-\gamma Z$. The product of these two functions, which gives us the first term on the right-hand side of (5), is shown in the lower panel. Because the product $(s-\gamma Z) Z^{\alpha}$ must be equal to zero when either factor is zero, and positive when both factors are positive, the graph of this function has an inverted- $U$ shape and cuts the horizontal axis twice, one of those cuts being at the origin.

The lower panel of the figure shows the graph of $(\delta+n) Z$, which is a straight line through the origin. By (5), the vertical distance between the curve $(\mathrm{s}-\gamma Z) Z^{\alpha}$ and the line $(\delta+n) Z$ gives us the instantaneous increment of $Z$. Notice that there is a steady state, $\bar{Z}$, that corresponds to the point where the two lines cross. As in the Solow model, this steady state is stable, because $Z$ increases when its value is larger than $\bar{Z}$, and decreases otherwise.

Hence, the economy converges in the long run to a balanced-growth path in which the value of $Z$ is constant. Along this path, output per worker is given by

$$
\bar{Q}_{t}=A_{t} \bar{Z}^{\alpha}
$$

and increases, therefore, at the same rate as $A$. Using equation (4), the longrun rate of growth (of $A$ and hence of output per worker) is given by

$$
\bar{g}_{Q}=\bar{g}_{A}=\gamma \bar{Z}^{\alpha}
$$

The value of $\bar{g}_{A}$ can also be determined graphically. If we draw, in the upper panel of the figure, the function $\gamma Z^{\alpha}$, the height of this curve when $Z=\bar{Z}$ gives us the long-run growth rate.

(iii) Analyze the impact of an increase in the investment rate on the steady state and on the time path of the system. Things are now quite different from

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-783.jpg?height=1328&width=1118&top_left_y=180&top_left_x=177)

Figure A11.10. Dynamics of the learning-by-doing model.

what they were in the Solow model with exogenous technical progress. In what sense?

Consider now the effects of an increase in the investment rate. As shown in Figure A11.11, an increase in $s$ shifts the line $(s-\gamma Z)$ upward (in the upper panel) and, therefore, also the curve $(s-\gamma Z) Z^{\alpha}$ in the lower panel. The new steady state involves a higher value of $Z$ and a higher growth rate.

In this model (unlike the Solow model with exogenous technical progress), changes in economic policies can have permanent effects on the growth rate - that is, can affect not only the level of the balanced-growth path but also its slope, as shown in Figure A11.12.

(iv) Consider two countries that are identical except for their investment rates. Discuss the predictions of the current model and the Solow model with exogenous technical progress concerning the evolution of the relative income levels of the two countries.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-784.jpg?height=1324&width=1105&top_left_y=182&top_left_x=154)

Figure A11.11. Impact of an increase in the investment rate on the steady state.

A second important difference between this model and the ones we studied in the preceding section involves their implications for convergence. To illustrate this point, consider the case of two countries that differ only in their investment coefficients $s$. We have seen that when technical progress is exogenous and takes place at the same rate in both countries, they converge to balanced-growth paths with the same slope, although with different heights. This implies that the ratio of the per-capita incomes of the economies eventually stabilizes at a constant value. In the present case, however, the slopes of the balanced-growth trajectories will be different. In the steady state, income per capita will grow faster in the thriftier country. This implies that with the passage of time, income differences between countries will grow without bound. Small differences in investment rates (possibly due to differences in economic policies) can generate extremely large income differentials in the long run.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-785.jpg?height=679&width=893&top_left_y=176&top_left_x=301)

Figure A11.12. Effect of an increase in the investment rate on the path of output per worker.

Problem 5.4. An extended Solow model with human capital (Mankiw et al., 1992). Suppose the aggregate production function is of the form

$$
\begin{equation*}
Y=K^{\alpha} E^{\gamma}(A L)^{1-\alpha-\gamma}=A L Z^{\alpha} H^{\gamma} \tag{1}
\end{equation*}
$$

where $K$ and $E$ are the aggregate stocks of physical capital and human capital, $L$ is the size of the labor force, and $A$ is a productivity index that summarizes the current state of technical knowledge. The normalized variables $Z=K / A L$ and $H=$ $E / A L$ denote the stocks of physical capital and human capital per efficiency unit of labor.

We postulate constant rates of population growth and exogenous technical progress ( $\dot{L} / L=n$ and $\dot{A} / A=g$ ) and assume that the fractions of GDP devoted to investment in physical capital and human capital ( $s_{k}$ and $s_{h}$ ) remain constant over time. Under these assumptions, the accumulation of productive factors is described by the system

$$
\begin{equation*}
\dot{K}=s_{k} Y-\delta K \quad \text { and } \quad \dot{E}=s_{h} Y-\delta E \tag{2}
\end{equation*}
$$

where the depreciation rate $\delta$ is assumed to be the same for both types of capital. Using the fact that $\dot{Z} / Z=(\dot{K} / K)-n-g$, and $\dot{H} / H=(\dot{E} / E)-n-g$, the laws of motion for the stocks of physical capital and human capital can be rewritten in terms of the normalized variables,

$$
\begin{align*}
& \frac{\dot{Z}}{Z}=s_{k} Z^{\alpha-1} H^{\gamma}-(\delta+g+n)  \tag{3}\\
& \frac{\dot{H}}{H}=s_{h} Z^{\alpha} H^{\gamma-1}-(\delta+g+n) \tag{4}
\end{align*}
$$

(i) Find the steady-state values of $Z, H$, and output per efficiency unit of labor, $P=Y / A L$.

Setting $\dot{Z}$ and $\dot{H}$ equal to zero in (3) and (4), we can solve for the steadystate values of $Z$ and $H$. We have

$$
\begin{align*}
& \dot{Z}=0 \Rightarrow s_{k} Z^{\alpha-1} H^{\gamma}=(\delta+g+n)  \tag{5}\\
& \dot{H}=0 \Rightarrow s_{h} Z^{\alpha} H^{\gamma-1}=(\delta+g+n) \tag{6}
\end{align*}
$$

from where

$$
s_{k} Z^{\alpha-1} H^{\gamma}=s_{h} Z^{\alpha} H^{\gamma-1} \Rightarrow H=\frac{s_{h}}{s_{k}} Z
$$

Substituting this last expression into (5), we see that

$$
\begin{aligned}
& s_{k} Z^{\alpha-1}\left(\frac{s_{h}}{s^{k}} Z\right)^{\gamma}=(\delta+g+n) \Rightarrow s_{k}^{1-\gamma} s_{h}^{\gamma} Z^{\alpha+\gamma-1}=(\delta+g+n) \\
& \Rightarrow \bar{Z}=\left(\frac{s_{k}^{1-\gamma} s_{h}^{\gamma}}{\delta+g+n}\right)^{1 /(1-\alpha-\gamma)}
\end{aligned}
$$

and

$$
\begin{equation*}
\bar{H}=\frac{s_{h}}{s_{k}} \bar{Z}=\left(\frac{s_{k}^{\alpha} s_{h}^{1-\alpha}}{\delta+g+n}\right)^{1 /(1-\alpha-\gamma)} \tag{8}
\end{equation*}
$$

Finally, we define output per efficiency unit of labor,

$$
\begin{equation*}
P=\frac{Y}{A L}=Z^{\alpha} H^{\gamma} \tag{9}
\end{equation*}
$$

and compute its steady-state value:

$$
\begin{aligned}
\bar{P} & =\bar{Z}^{\alpha} \bar{H}^{\gamma}=\left(\frac{s_{k}^{1-\gamma} s_{h}^{\gamma}}{\delta+g+n}\right)^{\alpha /(1-\alpha-\gamma)}\left(\frac{s_{k}^{\alpha} s_{h}^{1-\alpha}}{\delta+g+n}\right)^{\gamma /(1-\alpha-\gamma)} \\
& =\left(\frac{s_{k}}{\delta+g+n}\right)^{\alpha /(1-\alpha-\gamma)}\left(\frac{s_{h}}{\delta+g+n}\right)^{\gamma /(1-\alpha-\gamma)}
\end{aligned}
$$

Using lowercase letters to indicate that we are taking logarithms, this expression can be rewritten in the form

$$
\begin{equation*}
\bar{p}=\alpha \bar{z}+\gamma \bar{h}=\frac{\alpha}{1-\alpha-\gamma} \ln \frac{s_{k}}{\delta+g+n}+\frac{\gamma}{1-\alpha-\gamma} \ln \frac{s_{h}}{\delta+g+n} \tag{10}
\end{equation*}
$$

(ii) We will now construct a log-linear approximation to the system and use it to derive a convergence equation similar to the one obtained in Section 4(a). Letting $z=\ln Z$ and $h=\ln H$ (from where $Z=e^{z}$ and $H=e^{h}$ ), rewrite the system (3)-(4) in terms of $z$ and $h$. Show that the linear approximation to the transformed system around the steady state is given by

$$
\begin{gather*}
\dot{z}=-(1-\alpha)(\delta+g+n) \tilde{z}+\gamma(\delta+g+n) \tilde{h}  \tag{11}\\
\dot{h}=\alpha(\delta+g+n) \tilde{z}-(1-\beta)(\delta+g+n) \tilde{h} \tag{12}
\end{gather*}
$$

where $\tilde{x}=x-\bar{x}$ denotes the current deviation of variable $x$ from its steadystate value. Discuss the stability of the system (11)-(12) (and hence that of the original system).

To rewrite the system in terms of the transformed variables, notice that

$$
Z=e^{z}, \quad H=e^{h}, \quad \dot{z}=\frac{\dot{Z}}{Z}, \quad \text { and } \quad \dot{h}=\frac{\dot{H}}{H}
$$

Using these expressions, we can rewrite (3) and (4) in the form

$$
\begin{align*}
& \dot{z}=s_{k} e^{(\alpha-1) z} e^{\gamma h}-(\delta+g+n) \equiv F(z, h) \\
& \dot{h}=s_{h} e^{\alpha z} e^{(\gamma-1) h}-(\delta+g+n) \equiv G(z, h)
\end{align*}
$$

Setting $\dot{z}$ and $\dot{h}$ equal to zero, we see that in the steady state,

$$
\begin{equation*}
s_{k} e^{(\alpha-1) z} e^{\gamma h}=\delta+g+n=s_{h} e^{(\gamma-1) h} \tag{13}
\end{equation*}
$$

Next, we compute the partial derivatives of the functions $F()$ and $G()$ with respect to $z$ and $h$, and, using (13), we evaluate them at the steady state.

$$
\begin{aligned}
& F_{z}=(\alpha-1) s_{k} e^{(\alpha-1) z} e^{\gamma h}=-(1-\alpha)(\delta+g+n) \\
& F_{h}=\gamma s_{k} e^{(\alpha-1) z} e^{\gamma h}=\gamma(\delta+g+n) \\
& G_{z}=\alpha s_{h} e^{\alpha z} e^{(\gamma-1) h}=\alpha(\delta+g+n) \\
& G_{h}=(\gamma-1) s_{h} e^{\alpha z} e^{(\gamma-1) h}=-(1-\gamma)(\delta+g+n)
\end{aligned}
$$

Using Taylor's formula to approximate $F()$ and $G()$ around the point $(\bar{z}, \bar{h})$, and observing that

$$
\tilde{p}=\alpha \tilde{z}+\gamma \tilde{h}
$$

we have

$$
\begin{aligned}
& F(z, h) \cong F_{z} \tilde{z}+F_{h} \tilde{h}=-(1-\alpha)(\delta+g+n) \tilde{z}+\gamma(\delta+g+n) \tilde{h}=(\delta+g+n)(\tilde{p}-\tilde{z}) \\
& G(z, h) \cong G_{z} \tilde{z}+G_{h} \tilde{h}=\alpha(\delta+g+n) \tilde{z}-(1-\gamma)(\delta+g+n) \tilde{h}=(\delta+g+n)(\tilde{p}-\tilde{h})
\end{aligned}
$$

where $\tilde{x}=x-\bar{x}$ denotes the deviation of the variable $x$ with respect to its steady state. Hence, the linear approximation to the system is of the form

$$
\begin{gather*}
\dot{z}=-(1-\alpha)(\delta+g+n) \tilde{z}+\gamma(\delta+g+n) \tilde{h}=(\delta+g+n)(\tilde{p}-\tilde{z})  \tag{11}\\
\dot{h}=\alpha(\delta+g+n) \tilde{z}-(1-\gamma)(\delta+g+n) \tilde{h}=(\delta+g+n)(\tilde{p}-\tilde{h}) \tag{12}
\end{gather*}
$$

The coefficient matrix is of the form

$$
A=\left[\begin{array}{cc}
-(1-\alpha)(\delta+g+n) & \gamma(\delta+g+n) \\
\alpha(\delta+g+n) & -(1-\gamma)(\delta+g+n)
\end{array}\right]
$$

Hence

$$
\operatorname{tr} A=-(2-\alpha-\gamma)(\delta+g+n)<0
$$

$$
\begin{aligned}
\operatorname{det} A & =(1-\alpha)(1-\gamma)(\delta+g+n)^{2}-\alpha \gamma(\delta+g+n)^{2} \\
& =(1-\alpha-\gamma+\alpha \gamma-\alpha \gamma)(\delta+g+n)^{2}=(1-\alpha-\gamma)(\delta+g+n)^{2}>0 \\
\Delta & =\operatorname{tr}^{2}-4 \operatorname{det}=(2-\alpha-\gamma)^{2}(\delta+g+n)^{2}-4(1-\alpha-\gamma)(\delta+g+n)^{2} \\
& =(\delta+g+n)^{2}\left\{[1+(1-\alpha-\gamma)]^{2}-4(1-\alpha-\gamma)\right\} \\
& =(\delta+g+n)^{2}\left[1+2(1-\alpha-\gamma)+(1-\alpha-\gamma)^{2}-4(1-\alpha-\gamma)\right] \\
& =(\delta+g+n)^{2}\left[1-2(1-\alpha-\gamma)+(1-\alpha-\gamma)^{2}\right] \\
& =(\delta+g+n)^{2}[1-(1-\alpha-\gamma)]^{2}=(\delta+g+n)^{2}(\alpha+\gamma)^{2}>0
\end{aligned}
$$

from where

$$
\begin{aligned}
\lambda_{1}, \lambda_{2} & =\frac{\operatorname{tr} \pm \sqrt{\operatorname{tr}^{2}-4 \mathrm{det}}}{2}=\frac{-(2-\alpha-\gamma)(\delta+g+n) \pm(\delta+g+n)(\alpha+\gamma)}{2} \\
& =(\delta+g+n) \frac{(\alpha+\gamma-2) \pm(\alpha+\gamma)}{2}
\end{aligned}
$$

and therefore

$$
\lambda_{1}=-(\delta+g+n) \text { and } \lambda_{2}=-(1-\alpha-\gamma)(\delta+g+n)
$$

Hence, the eigenvalues are negative real numbers, and the steady state of the system is stable.

(iii) Using the system (11)-(12) and the fact that $p=\alpha z+\gamma h$, derive a linear differential equation in $p$ that describes the approximate behavior of this variable, and solve it. Rewriting the solution in terms of output per worker, $q=p+a$, derive a convergence equation of the form

$$
\frac{q_{t+d}-q_{t}}{d}=g+\frac{1-e^{-\lambda d}}{d}\left[\bar{p}-\left(q_{t}-a_{t}\right)\right]
$$

where $d$ is the duration of the period, and $\lambda=(1-\alpha-\gamma)(\delta+g+n)$.

Because $p=\alpha z+\gamma h$, we have

$$
\dot{p}=\alpha \dot{z}+\gamma \dot{h}=(\delta+g+n)[\alpha(\tilde{p}-\tilde{z})+\gamma(\tilde{p}-\tilde{h})]=(\delta+g+n)[(\alpha+\gamma) \tilde{p}-\tilde{p}]
$$

or

$$
\begin{equation*}
\dot{p}=-\lambda \tilde{p} \tag{14}
\end{equation*}
$$

where $\lambda=(1-\alpha-\gamma)(\delta+g+n)$ and $\tilde{p}=p-\bar{p}$. If we consider the period from $t$ to $t+d$, the final value of $p$ is given by

$$
\begin{equation*}
p_{t+d}=p_{t} e^{-\lambda d}+\bar{p}\left(1-e^{-\lambda d}\right) \tag{15}
\end{equation*}
$$

Hence, output per efficiency unit of labor converges to its steady-state value at an exponential rate $\lambda$ that depends on the degree of returns to scale in reproducible factors $(1-\alpha-\gamma)$ and on the rates of depreciation, population growth, and technical progress.

Finally, because output per efficiency unit of labor is not observable, it will be convenient to rewrite (15) in terms of the log of output per worker, $q=p+a$. We have

$$
\begin{aligned}
q_{t+d} & =p_{t+d}+a_{t+d}=p_{t} e^{-\lambda d}+\bar{p}\left(1-e^{-\lambda d}\right)+a_{t+d} \\
& =\left(q_{t}-a_{t}\right) e^{-\lambda d}+\bar{p}\left(1-e^{-\lambda d}\right)+a_{t}+g d \\
& =q_{t} e^{-\lambda d}+\bar{p}\left(1-e^{-\lambda d}\right)+a_{t}\left(1-e^{-\lambda d}\right)+g d
\end{aligned}
$$

Subtracting $q_{t}$ from both sides of this expression and dividing through by the length of the period, $d$, we arrive at the desired expression:

$$
\frac{q_{t+d}-q_{t}}{d}=g+\frac{1-e^{-\lambda d}}{d}\left[\bar{p}-\left(q_{t}-a_{t}\right)\right]
$$

Notice that this expression is almost identical with the one we derived in Section 4(a). The only differences are that the steady state now depends also on the rate of investment in human capital and that the speed of convergence is now given by $\lambda=(1-\alpha-\gamma)(\delta+g+n)$, rather than by $(1-\alpha)(\delta+g+n)$. Hence, what matters for the speed of convergence is the sum of the coefficients of the reproducible factors, physical and human capital.

Problem 5.5. Diamond's model with variable labor supply. In the basic Diamond model, leisure does not enter the utility function of households. As a result, each worker supplies inelastically his or her endowment of labor time, and the level of employment is constant (on a per-capita basis). We will now relax this assumption.

To simplify things, we assume that the rate of population growth is zero $(n=0)$ and that individuals work in youth and consume only in old age. Young workers, on the other hand, enjoy their leisure and must therefore seek an optimal tradeoff between the disutility of working and the need for income. The utility function of a representative worker is given by

$$
U\left(x_{t+1}, L_{t}\right)=\frac{x_{t+1}^{1-\gamma}}{1-\gamma}-L_{t}
$$

where $\gamma \in(0,1), L$ is labor time supplied in youth, and $x$ is old-age consumption. The per-capita production function is

$$
y=\sqrt{k L}
$$

(i) Because consumption takes place only in old age, workers save their entire labor income $w L$ and consume their savings plus interest earnings $\left(w_{t} L_{t} R_{t+1}\right)$ in the second period of their lives. They solve, then

$$
\max _{x, L}\left\{U=\frac{x^{1-\gamma}}{1-\gamma}-L \text { subject to } x=w L R\right\}
$$

Solve this problem for the agent's labor supply $\left(L^{s}\right)$ and savings functions.

Substituting the constraint into the objective function, we get

$$
\max _{L} U=\frac{1}{1-\gamma}(w L R)^{1-\gamma}-L
$$

from where

$$
\begin{align*}
& \frac{\partial U}{\partial L}=(w L R)^{-\gamma} w R-1=0 \\
& \quad \Rightarrow L^{s}=\left(w_{t} R_{t+1}\right)^{(1-\gamma) / \gamma} \tag{1}
\end{align*}
$$

which is the labor supply function. The savings function is therefore of the form

$$
\begin{equation*}
s_{t}=s\left(w_{t}, R_{t+1}\right)=w L^{s}=w_{t}\left(w_{t} R_{t+1}\right)^{(1-\gamma) / \gamma} \tag{2}
\end{equation*}
$$

(ii) Firms maximize profits per worker, that is,

$$
\max _{k, L} \pi_{t}=y_{t}-R_{t} k_{t}-w_{t} L_{t}=\left(k_{t} L_{t}\right)^{1 / 2}-R_{t} k_{t}-w_{t} L_{t}
$$

Write the first-order conditions for this problem, solve for $w$ and $R$ as functions of $(k / L)$, and derive the firm's labor demand function.

The first-order conditions for the firm's problem are

$$
\begin{align*}
\frac{\partial \pi}{\partial L}= & (1 / 2)(k L)^{-1 / 2} k-w=0 \\
& \Rightarrow 2 w_{t}=\left(k_{t} / L_{t}\right)^{1 / 2}  \tag{3}\\
\frac{\partial \pi}{\partial k}= & (1 / 2)(k L)^{-1 / 2} L-R=0 \\
& \Rightarrow 2 R_{t}=\left(L_{t} / k_{t}\right)^{1 / 2} \tag{4}
\end{align*}
$$

These two equations can be interpreted as defining the firm's labor and capital demands $\left(k_{t}^{d}, L_{t}^{d}\right)$ or, alternatively, as defining factor prices as functions of input use.
(iii) In equilibrium, agents optimize, and labor and capital markets clear. Because population is constant, market clearing requires, in per-capita terms,

$$
\begin{align*}
& L_{t}^{s}=L_{t}^{d}  \tag{5}\\
& s_{t}=k_{t+1} \tag{6}
\end{align*}
$$

Show that the conditions for market clearing and individual optimization can be reduced to the following system of first-order difference equations in $k$ and $R$ :

$$
\begin{gather*}
k_{t+1}=R_{t} k_{t}  \tag{A}\\
R_{t+1}^{1-\gamma}=4 k_{t}^{\gamma} R_{t}^{1+\gamma} \tag{B}
\end{gather*}
$$

To begin, we use (3) and (4) to derive two convenient relationships; multiplying and dividing these two equations in turn we obtain

$$
\begin{gather*}
(3) *(4) \quad 4 w_{t} R_{t}=1 \Rightarrow w_{t}=1 / 4 R_{t}  \tag{7}\\
\text { (3) } /(4) \quad w_{t} / R_{t}=k_{t} / L_{t} \Rightarrow w_{t} L_{t}=k_{t} R_{t} \tag{8}
\end{gather*}
$$

Next, we substitute the savings function (6) into the capital-market clearing condition and use (8) to get (making implicit use of the labor-market clearing condition)

$$
k_{t+1}=w_{t} L_{t}=k_{t} R_{t}
$$

which is (A).

Then, labor-market clearing implies, using (3) and (1),

$$
L_{t}^{s}=L_{t}^{d} \Rightarrow\left(w_{t} R_{t+1}\right)^{(1-\gamma) / \gamma}=k_{t} / 4 w_{t}^{2}
$$

from where

$$
R_{t+1}^{(1-\gamma) / \gamma}=\frac{k_{t}}{4 w_{t}^{2} w_{t}^{(1-\gamma) / \gamma}} \Rightarrow R_{t+1}^{(1-\gamma) / \gamma}=\frac{k_{t}}{4 w_{t}^{(1+\gamma) / \gamma}}
$$

Raising both sides of this expression to the power $\gamma$,

$$
R_{t+1}^{1-\gamma}=\frac{k_{t}^{\gamma}}{4^{\gamma} w_{t}^{1+\gamma}}
$$

and using (7), $w_{t}=1 / 4 R_{t}$,

$$
R_{t+1}^{1-\gamma}=\frac{k_{t}^{\gamma} 4^{1+\gamma} R_{t}^{1+\gamma}}{4^{\gamma}} \Rightarrow R_{t+1}^{1-\gamma}=4 k_{t}^{\gamma} R_{t}^{1+\gamma}
$$

(iv) We have been able to reduce the model to a system of two first-order difference equations that describe the sequence of competitive equilibria in this economy. Note that if we take logs, the system becomes linear. Defining

$$
\kappa=\ln k \quad \text { and } \quad \rho=\ln R
$$

we can rewrite $(A)$ and $(B)$ as

$$
\begin{gather*}
\kappa_{t+1}=\rho_{t}+\kappa_{t} \\
(1-\gamma) \rho_{t+1}=\ln 4+\gamma \kappa_{t}+(1+\gamma) \rho_{t}
\end{gather*}
$$

Construct the phase diagram of the system, compute its solution, and analyze its dynamics. What would be a reasonable initial condition for this model?

Setting $\rho_{t}=\rho_{t+1}=\rho$ and $\kappa_{t}=\kappa_{t+1}=\kappa$ in $\left(\mathrm{A}^{\prime}\right)$ and $\left(\mathrm{B}^{\prime}\right)$, we obtain the equations of the phase lines:
![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-791.jpg?height=496&width=1260&top_left_y=182&top_left_x=107)

Figure A11.13. Phase lines and arrows of motion.

$$
\begin{gather*}
\left(A^{\prime}\right) \Rightarrow \kappa=\rho+\kappa \\
\Rightarrow \rho=0  \tag{P.A}\\
\left(B^{\prime}\right) \Rightarrow(1-\gamma) \rho=\ln 4+\gamma \kappa+(1+\gamma) \rho \\
\Rightarrow \rho=\frac{-1}{2 \gamma}(\ln 4+\gamma \kappa) \tag{P.B}
\end{gather*}
$$

The intersection of the phase lines gives us the steady state. From the first equation,

$$
\bar{\rho}=0 \Rightarrow \bar{R}=e^{\rho}=1
$$

Using this in (P.B), we get

$$
0=\ln 4+\gamma \kappa \Rightarrow \bar{\kappa}=-\frac{\ln 4}{\gamma}=\ln (1 / 4)^{1 / \gamma} \Rightarrow \bar{k}=e^{\kappa}=(1 / 4)^{1 / \gamma}
$$

Graphically, (P.A) describes a horizontal line at $\rho=0$. From $\left(\mathrm{A}^{\prime}\right)$ we have

$$
\Delta \kappa_{t}=\kappa_{t+1}-\kappa_{t}=\rho_{t} \Rightarrow \frac{\partial \Delta \kappa_{t}}{\partial \rho_{t}}=1>0
$$

Hence, an increase in $\rho_{t}$ increases $\Delta \kappa_{t}$, which is zero along the phase line. It follows that in the region above the phase line we have $\Delta \boldsymbol{\kappa}_{t}>0$, and $\boldsymbol{\kappa}_{t}$ increases over time. The arrows of motion point to the right above the phase line (Figure A11.13).

Similarly, (P.B) is downward-sloping in $\kappa$, and from ( $\left.\mathrm{B}^{\prime}\right)$,

$$
\frac{\partial \Delta \rho_{t}}{\partial \rho_{t}}=\frac{\partial \rho_{t+1}}{\partial \rho_{t}}-1=\frac{1+\gamma}{1-\gamma}-1=\frac{2 \gamma}{1-\gamma}>0
$$

so $\Delta \rho_{t}>0$ above the phase line, and $\rho_{t}$ increases over time in that region, as indicated by the arrows of motion in Figure A11.13.

Combining the two graphs above, we obtain the phase diagram for the system (Figure A11.14). The pattern of motion indicated by the arrows suggests the existence of a saddle-point equilibrium. That this is indeed the case will be shown next.

In matrix form, the system $\left(\mathrm{A}^{\prime}\right)-\left(\mathrm{B}^{\prime}\right)$ can be written

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-792.jpg?height=596&width=838&top_left_y=179&top_left_x=333)

Figure A11.14. Phase diagram.

$$
\left[\begin{array}{c}
\kappa_{t+1} \\
\rho_{t+1}
\end{array}\right]=\left[\begin{array}{cc}
1 & 1 \\
\frac{\gamma}{1-\gamma} & \frac{1+\gamma}{1-\gamma}
\end{array}\right]\left[\begin{array}{l}
\kappa_{t} \\
\rho_{t}
\end{array}\right]+\left[\begin{array}{c}
0 \\
\ln 4
\end{array}\right]
$$

The eigenvalues of the coefficient matrix are therefore the solutions to the following equation:

$$
\left|\begin{array}{cc}
1-\lambda & 1 \\
\frac{\gamma}{1-\gamma} & \frac{1+\gamma}{1-\gamma}-\lambda
\end{array}\right|=(1-\lambda)\left(\frac{1+\gamma}{1-\gamma}-\lambda\right)-\frac{\gamma}{1-\gamma}=\frac{1}{1-\gamma}\left[(1-\gamma) \lambda^{2}-2 \lambda+1\right]=0
$$

from where

$$
\lambda=\frac{2 \pm \sqrt{4-4(1-\gamma)}}{2(1-\gamma)}=\frac{2 \pm \sqrt{4 \gamma}}{2(1-\gamma)}=\frac{1 \pm \sqrt{\gamma}}{1-\gamma}
$$

and hence

$$
\lambda_{1}=\frac{1+\sqrt{\gamma}}{1-\gamma} \quad \text { and } \quad \lambda_{2}=\frac{1-\sqrt{\gamma}}{1-\gamma}
$$

By assumption, $\gamma \in(0,1)$, and therefore both eigenvalues are real and positive, with $\lambda_{1}>1$. Moreover, $\sqrt{\gamma}>\gamma$, so $\lambda_{2}<1$, and the steady state is a saddle point.

To find the eigenvectors of the coefficient matrix, we solve $A e_{i}=\lambda_{i} e_{t}$, that is, normalizing the second component of the eigenvector to $1\left(e_{i 1}=1\right)$,

$$
\left[\begin{array}{cc}
1 & 1 \\
\frac{\gamma}{1-\gamma} & \frac{1+\gamma}{1-\gamma}
\end{array}\right]\left[\begin{array}{c}
e_{i 1} \\
1
\end{array}\right]=\left[\begin{array}{c}
\lambda_{i 1} e_{i 1} \\
\lambda_{t 1}
\end{array}\right]
$$

from where

$$
e_{i}+1=\lambda_{i} e_{i} \Rightarrow e_{i}=\frac{1}{\lambda_{i}-1}
$$

so, with

$$
\begin{aligned}
& \lambda_{1}=\frac{1+\sqrt{\gamma}}{1-\gamma} \Rightarrow e_{11}=\frac{1-\gamma}{\gamma+\sqrt{\gamma}} \\
& \lambda_{2}=\frac{1-\sqrt{\gamma}}{1-\gamma} \Rightarrow e_{21}=\frac{1-\gamma}{\gamma-\sqrt{\gamma}}
\end{aligned}
$$

we can now write the general solution to the system as

$$
\begin{gather*}
\kappa_{t}-\bar{\kappa}=c_{1} \frac{1-\gamma}{\gamma+\sqrt{\gamma}} \lambda_{1}^{t}+c_{2} \frac{1-\gamma}{\gamma-\sqrt{\gamma}} \lambda_{2}^{t}  \tag{GS.1}\\
\rho_{t}-\bar{\rho}=c_{1} \lambda_{1}^{t}+c_{2} \lambda_{2}^{t} \tag{GS.2}
\end{gather*}
$$

where $c_{1}$ and $c_{2}$ are arbitrary constants. Any sequence $\left\{\kappa_{t}, \rho_{t}\right\}$ that satisfies these two equations is a solution to the system $\left(\mathrm{A}^{\prime}\right)-\left(\mathrm{B}^{\prime}\right)$. To definitize the solution, we have a natural initial condition, $\kappa_{0}=\ln k_{0}$, because the initial capital stock of the economy is given. On the other hand, $\rho_{t}$ is a "free variable," and its starting value is not constrained by an initial condition. ${ }^{2}$ This observation leaves us with too many solutions. A reasonable thing to do, following the discussion in Section 2, is to assume that the economy does not embark on an explosive path, but instead moves along the unique trajectory that converges to the steady state, i.e., the saddle path of the system.

To impose this (economic) assumption on the solution, we set the constant $c_{1}$ equal to zero in (GS.1) and (GS.2) and "kill off" the explosive root of the system $\left(\lambda_{1}>1\right)$. This yields

$$
\begin{gather*}
\kappa_{t}-\bar{\kappa}=c_{2} \frac{1-\gamma}{\gamma-\sqrt{\gamma}} \lambda_{2}^{t}  \tag{9}\\
p_{t}-\bar{p}=c_{2} \lambda_{2}^{t} \tag{10}
\end{gather*}
$$

Dividing these two equations to eliminate $c_{2} \lambda_{2}^{t}$, we get the equation of the saddle path

$$
\begin{equation*}
\rho_{t}-\bar{\rho}=\frac{\gamma-\sqrt{\gamma}}{1-\gamma}\left(\kappa_{t}-\bar{\kappa}\right) \tag{S}
\end{equation*}
$$

To obtain an explicit expression for the saddle-path solution, we need to determine the corresponding value of the arbitrary constant $c_{2}$ in the system (9)-(10). This can be done using the natural initial condition on the capital stock. At time zero, $\kappa_{t}$ is a given constant $\kappa_{0}$, and (9) yields

$$
\begin{align*}
\kappa_{0}-\bar{\kappa}= & c_{2} \frac{1-\gamma}{\gamma-\sqrt{\gamma}} \lambda_{2}^{0} \\
& \Rightarrow c_{2}=\frac{\gamma-\sqrt{\gamma}}{1-\gamma}\left(\kappa_{0}-\bar{\kappa}\right) \tag{11}
\end{align*}
$$

Substituting this result into (9) and (10), we get

$$
\begin{gather*}
\kappa_{t}-\bar{\kappa}=\left(\kappa_{0}-\bar{\kappa}\right) \frac{\gamma-\sqrt{\gamma}}{1-\gamma} \frac{1-\gamma}{\gamma-\sqrt{\gamma}} \lambda_{2}^{t}=\left(\kappa_{0}-\bar{\kappa}\right) \lambda_{2}^{t}=\left(\kappa_{0}-\bar{\kappa}\right)\left(\frac{1-\sqrt{\gamma}}{1-\gamma}\right)^{t}  \tag{12}\\
\rho_{t}-\bar{\rho}=\left(\kappa_{0}-\bar{\kappa}\right) \frac{\gamma-\sqrt{\gamma}}{1-\gamma}\left(\frac{1-\sqrt{\gamma}}{1-\gamma}\right)^{t} \tag{13}
\end{gather*}
$$

which is the solution we seek.

Problem 5.6. Social security in Diamond's model. Consider a Diamond economy like the one analyzed in Example 3.6. Population grows at a constant rate $n$, preferences are of the form

$$
\begin{equation*}
U(c, x)=\ln c+\beta \ln x \tag{U}
\end{equation*}
$$

with $\beta \in(0,1)$, and the production function is Cobb-Douglas,

$$
Y=K^{\alpha} L^{1-\alpha}
$$

with $\alpha \in(0,1)$.

We assume that wages are taxed at a proportional rate $\tau$ and that proceeds are used to finance a balanced pay-as-you-go social-security scheme. Hence, firstperiod after-tax income for an agent born at time $t$ is given by

$$
y_{1}=(1-\tau) w_{t}
$$

and his second-period retirement subsidy is equal to

$$
y_{2}=\tau(1+n) w_{t+1}
$$

(because there are $1+n$ young agents for each old agent).

(i) Maximize $U(c, x)$ subject to the appropriate budget constraint, and solve for the agent's savings function $s^{*}=s\left(y_{1}, y_{2}, R\right)$ and his indirect utility function $v\left(w_{t}, w_{t+1}, R_{t+1}, \tau\right)$. Taking factor prices as given, when is the agent's welfare an increasing function of the social-security tax rate?

The agent maximizes $U(c, x)$ subject to the constraints

$$
c=y_{1}-s \text { and } x=y_{2}+s R
$$

Solving these expressions for $s$ and substituting the result into the utility function, the agent solves

$$
\max _{s} W(s)=\ln \left(y_{1}-s\right)+\beta \ln \left(y_{2}+s R\right)
$$

The first-order condition for the problem is

$$
W^{\prime}(s)=\frac{-1}{y_{1}-s}+\beta \frac{R}{y_{2}+s R}=0
$$

Solving this expression for $s$, we obtain the savings function

$$
\begin{equation*}
s^{*}=s\left(y_{1}, y_{2}, R\right)=\frac{\beta}{1+\beta} y_{1}-\frac{1}{1+\beta} \frac{y_{2}}{R} \tag{1}
\end{equation*}
$$

Using (1), we have

$$
c^{*}=y_{1}-s^{*}=\frac{y_{1}}{1+\beta}+\frac{y_{2}}{R(1+\beta)} \quad \text { and } \quad x^{*}=y_{2}+R s^{*}=\frac{\beta R y_{1}}{1+\beta}+\frac{\beta y_{2}}{1+\beta}
$$

Substituting these expressions into $U(c, x)$, we obtain the indirect-utility function

$$
v\left(R, y_{1}, y_{2}\right)=U\left(c^{*}, x^{*}\right)=\ln \left(\frac{y_{1}}{1+\beta}+\frac{y_{2}}{R(1+\beta)}\right)+\beta \ln \left(\frac{\beta R y_{1}}{1+\beta}+\frac{\beta y_{2}}{1+\beta}\right)
$$

or

$$
\begin{align*}
v\left(R, y_{1}^{*}, y_{2}^{*}\right) & =\ln \left(\frac{1}{1+\beta}\right)+\beta \ln \left(\frac{\beta}{1+\beta}\right)+\ln \left(y_{1}+\frac{y_{2}}{R}\right)+\beta \ln \left(R y_{1}+y_{2}\right) \\
& =\ln \left(\frac{1}{1+\beta}\right)+\beta \ln \left(\frac{\beta}{1+\beta}\right)+(1+\beta) \ln \left(R y_{1}+y_{2}\right)-\ln R \tag{2}
\end{align*}
$$

Taking factor prices as given, the agent's welfare increases with the socialsecurity tax whenever his lifetime income

$$
I(\tau)=R y_{1}+y_{2}=R_{t+1}(1-\tau) w_{t}+\tau(1+n) w_{t+1}
$$

is an increasing function of $\tau$ for given values of $R_{t+1}, w_{t}$, and $w_{t+1}$. Because

$$
I^{\prime}(\tau)=-R_{t+1} w_{t}+(1+n) w_{t+1}
$$

this will be the case when

$$
\begin{equation*}
(1+n) \frac{w_{t+1}}{w t}>R_{t+1} \tag{3}
\end{equation*}
$$

that is, when population growth and the rate of wage increase are sufficiently high to guarantee the agent a "return" on his social-security payments that is higher than the market interest factor.

(ii) Derive the law for motion of the capital/labor ratio, $Z=K / L$, and compute the steady-state values of $Z$ and factor prices as functions of $\tau$. Call these functions

$$
\bar{Z}=Z_{s}(\tau), \quad \bar{w}=w_{s}(\tau), \quad \text { and } \quad \bar{R}=R_{s}(\tau)
$$

Under what conditions is it true that $1+n>R_{s}(0)$ ?

With a Cobb-Douglas production function, equilibrium factor prices are given by

$$
\begin{equation*}
w_{t}=(1-\alpha) Z_{t}^{\alpha} \quad \text { and } \quad R_{t+1}=\alpha Z_{t+1}^{\alpha-1} \tag{4}
\end{equation*}
$$

The savings function (1) can be written

$$
\begin{equation*}
s_{t}^{*}=s\left[(1-\tau) w_{t},(1+n) \tau w_{t+1}, R_{t+1}\right]=\frac{\beta}{1+\beta}(1-\tau) w_{t}-\frac{1}{1+\beta} \frac{(1+n) \tau w_{t+1}}{R_{t+1}} \tag{5}
\end{equation*}
$$

and the capital-market clearing condition requires

$$
K_{t+1}=L_{i} s_{t}
$$

or, dividing both sides of this expression by $L_{t+1}=(1+n) L_{t}$,

$$
\begin{equation*}
Z_{t+1}=\frac{1}{1+n} s_{t} \tag{6}
\end{equation*}
$$

Substituting (4) and (5) into (6) and simplifying,

$$
\begin{aligned}
& Z_{t+1}=\frac{1}{1+n}\left(\frac{\beta}{1+\beta}(1-\tau) w_{t}-\frac{1}{1+\beta} \frac{(1+n) \tau w_{t+1}}{R_{t+1}}\right)=\frac{1}{1+\beta}\left(\frac{\beta}{1+n}(1-\tau) w_{t}-\frac{\tau w_{t+1}}{R_{t+1}}\right) \\
& \quad \Rightarrow(1+\beta) Z_{t+1}=\frac{\beta}{1+n}(1-\tau)(1-\alpha) Z_{t}^{\alpha}-\frac{\tau(1-\alpha) Z_{t+1}^{\alpha}}{\alpha Z_{t+1}^{\alpha-1}} \\
& \quad \Rightarrow\left(1+\beta+\frac{\tau(1-\alpha)}{\alpha}\right) Z_{t+1}=\frac{\beta}{1+n}(1-\tau)(1-\alpha) Z_{t}^{\alpha}
\end{aligned}
$$

we obtain the law of motion for $Z$ :

$$
\begin{equation*}
Z_{t+1}=\frac{\beta(1-\tau)(1-\alpha)}{(1+n)\left(1+\beta+\frac{\tau(1-\alpha)}{\alpha}\right)} Z_{t}^{\alpha} \tag{7}
\end{equation*}
$$

Eliminating the time subscripts in (7), we can solve for the steady-state capital/labor ratio,

$$
\begin{equation*}
\bar{Z}=\left(\frac{\beta(1-\tau)(1-\alpha)}{(1+n)\left(1+\beta+\frac{\tau(1-\alpha)}{\alpha}\right)}\right)^{1 /(1-\alpha)} \tag{8}
\end{equation*}
$$

The steady-state interest factor is then given by

$$
\begin{equation*}
\bar{R}=R_{s}(\tau)=\alpha \bar{Z}^{\alpha-1}=\frac{\alpha(1+n)\left(1+\beta+\frac{\tau(1-\alpha)}{\alpha}\right)}{\beta(1-\tau)(1-\alpha)} \tag{9}
\end{equation*}
$$

and when $\tau=0$, it reduces to

$$
R_{s}(0)=\frac{\alpha(1+n)(1+\beta)}{\beta(1-\alpha)}
$$

Notice that $1+n>R_{s}(0)$ if

$$
\frac{\alpha(1+\beta)}{\beta(1-\alpha)}<1
$$

(iii) What are the effects of an increase in $\tau$ on steady-state $Z$ and factor prices? Compute the following derivatives evaluated at $\tau=0$ :

$$
\frac{Z_{s}^{\prime}(\tau)}{Z_{s}(\tau)}, \frac{w_{s}^{\prime}(\tau)}{w_{s}(\tau)}, \text { and } \frac{R_{s}^{\prime}(\tau)}{R_{s}(\tau)}
$$

Taking logarithms of (8), we have

$$
z_{s}(\tau)=\ln \bar{Z}=\frac{1}{1-\alpha}\left(\ln \frac{\beta(1-\alpha)}{1+n}+\ln (1-\tau)-\ln \left(1+\beta+\frac{\tau(1-\alpha)}{\alpha}\right)\right)
$$

and differentiating this expression with respect to $\tau$,

$$
\begin{equation*}
z_{s}^{\prime}(\tau)=\frac{Z_{s}^{\prime}(\tau)}{Z_{s}(\tau)}=\frac{1}{1-\alpha}\left(\frac{-1}{1-\tau}-\frac{\frac{1-\alpha}{\alpha}}{\left(1+\beta+\frac{\tau(1-\alpha)}{\alpha}\right)}\right)<0 \tag{10}
\end{equation*}
$$

we see that an increase in the social-security tax always reduces the steadystate capital/labor ratio. Evaluating (10) at $\tau=0$,

$$
\begin{equation*}
z_{s}^{\prime}(0)=-\frac{1}{1-\alpha}\left(1+\frac{1-\alpha}{\alpha(1+\beta)}\right) \tag{11}
\end{equation*}
$$

Finally, because $w_{t}=(1-\alpha) Z_{t}^{\alpha}$, we have

$$
\ln w_{t}=\ln (1-\alpha)+\alpha \ln Z_{t}
$$

and therefore

$$
\begin{equation*}
\frac{w_{s}^{\prime}(0)}{w_{s}(0)}=\frac{d \ln w_{s}(0)}{d \tau}=\alpha z_{s}^{\prime}(0)=-\frac{\alpha}{1-\alpha}\left(1+\frac{1-\alpha}{\alpha(1+\beta)}\right) \tag{12}
\end{equation*}
$$

and because $R=\alpha Z^{\alpha-1}$,

$$
\begin{equation*}
\frac{R_{s}^{\prime}(0)}{R_{s}(0)}=\frac{d \ln R_{s}(0)}{d \tau}=(\alpha-1) z_{s}^{\prime}(0)=1+\frac{1-\alpha}{\alpha(1+\beta)} \tag{13}
\end{equation*}
$$

(iv) One of the advantages of working with a model in which individual preferences are clearly specified is that this gives us a natural criterion for evaluating the desirability of possible policy alternatives. Using your previous results, and considering only its effects on steady-state welfare, when will it be a good idea to introduce a social-security scheme? To answer this question, compute the derivative of a representative individual's (maximized) welfare with respect to $\tau$, taking into account both the direct effects of the tax and its indirect effect through the induced change in steady-state factor prices, and evaluate it at $\tau=0$.

At a steady state we have

$$
\begin{equation*}
R y_{1}+y_{2}=[R(1-\tau)+\tau(1+n)] w \tag{14}
\end{equation*}
$$

Using (2) and (14), steady-state welfare can be written

$$
\begin{align*}
V(\tau)= & v\left[R_{s}(\tau), w_{s}(\tau), \tau\right] \\
= & \ln \left(\frac{1}{1+\beta}\right)+\beta \ln \left(\frac{\beta}{1+\beta}\right)+(1+\beta) \ln w_{s}(\tau) \\
& +(1+\beta) \ln \left[R_{s}(\tau)(1-\tau)+\tau(1+n)\right]-\ln R_{s}(\tau) \tag{15}
\end{align*}
$$

Hence,

$$
V^{\prime}(\tau)=(1+\beta) \frac{w_{s}^{\prime}(\tau)}{w_{s}(\tau)}+(1+\beta) \frac{-R_{s}(\tau)+(1-\tau) R_{s}^{\prime}(\tau)+(1+n)}{R_{s}(\tau)(1-\tau)+\tau(1+n)}-\frac{R_{s}^{\prime}(\tau)}{R_{s}(\tau)}
$$

and

$$
\begin{aligned}
V^{\prime}(0) & =(1+\beta) \frac{w_{s}^{\prime}(0)}{w_{s}(0)}+(1+\beta) \frac{-R_{s}(0)+R_{s}^{\prime}(0)+(1+n)}{R_{s}(0)}-\frac{R_{s}^{\prime}(0)}{R_{s}(0)} \\
& =(1+\beta) \frac{w_{s}^{\prime}(0)}{w_{s}(0)}+\beta \frac{R_{s}^{\prime}(0)}{R_{s}(0)}-(1+\beta)+\frac{(1+\beta)(1+n)}{R_{s}(0)} \\
& =(1+\beta) \frac{w_{s}^{\prime}(0)}{w_{s}(0)}+\beta \frac{R_{s}^{\prime}(0)}{R_{s}(0)}-(1+\beta)+\frac{\beta(1-\alpha)}{\alpha}
\end{aligned}
$$

Using (12) and (13), this expression becomes

$$
\begin{aligned}
V^{\prime}(0) & =(1+\beta) \alpha z_{s}^{\prime}(0)-(1-\alpha) \beta z_{s}^{\prime}(0)-\frac{(1+\beta) \alpha-(1-\alpha) \beta}{\alpha} \\
& =[(1+\beta) \alpha-(1-\alpha) \beta]\left(z_{s}^{\prime}(0)-\frac{1}{\alpha}\right)
\end{aligned}
$$

Now, because $z_{s}^{\prime}(0)<0$, the second term of this expression is negative, and $V^{\prime}(0)>0$ if and only if

$$
(1+\beta) \alpha<(1-\alpha) \beta \Leftrightarrow \frac{\alpha(1+\beta)}{\beta(1-\alpha)}<1 \Leftrightarrow R_{s}(0)<1+n
$$

Hence, social security may increase welfare even though it reduces savings and lowers the steady-state capital stock. This will be the case when the no-socialsecurity steady-state interest factor is "too low," i.e., when in some sense the economy has a tendency to overaccumulate capital. (To make this more precise, consider a social planner who wants to maximize the welfare of steady-state generations subject to a resource constraint. What will be the optimal value of $Z$ and the implied interest factor?)

## Chapter 12

Problem 1.2. A violation of the principle of optimality

Consider an agent who lives three periods and maximizes a utility function of the form

$$
V_{1}=U_{1}+\alpha U_{2}+\beta U_{3}
$$

where utility in period $i, U_{i}$, is a function of current and (expected) future consumption, i.e.,

$$
U_{1}\left(c_{1}, c_{2}, c_{3}\right)=\ln \left(c_{1} c_{2} c_{3}\right), \quad U_{2}\left(c_{2}, c_{3}\right)=\ln \left(c_{2} c_{3}\right), \quad \text { and } \quad U_{3}\left(c_{3}\right)=\ln c_{3}
$$

and the budget constraint is of the form

$$
A_{t+1}=A_{t}-c_{t} \quad\left(A_{1} \text { given, and } A_{4}=0\right)
$$

where $A$ is wealth.

Notice that the return function is additive, but not separable over periods, as the period-1 utility, for example, depends on (expected) consumption at times 2 and 3. Hence, the assumptions of Theorem 1.1 do not hold, and as we will see, the principle of optimality fails.

(i) Compute the optimal consumption plan from the perspective of time 1, $c^{1}=\left(c_{1}^{1}, c_{2}^{1}, c_{3}^{1}\right)$.

The objective function from the perspective of period 1 can be written

$$
\begin{equation*}
V_{1}=\ln c_{1}+(1+\alpha) \ln c_{2}+(1+\alpha+\beta) \ln c_{3} \tag{1}
\end{equation*}
$$

Substituting the flow budget constraints recursively into each other, we obtain a single restriction requiring the sum of consumption expenditures to add up to initial wealth $A_{1}$ :

$$
\begin{equation*}
c_{1}+c_{2}+c_{3}=A_{1} \tag{2}
\end{equation*}
$$

Solving (2) for $c_{3}$, and substituting the result into (1), the agent solves the following problem at time 1:

$$
\begin{equation*}
\max V_{1}\left(c_{1}, c_{2}\right)=\ln c_{1}+(1+\alpha) \ln c_{2}+(1+\alpha+\beta) \ln \left(A_{1}-c_{1}-c_{2}\right) \tag{P.1}
\end{equation*}
$$

The first-order conditions for this problem are given by

$$
\begin{gather*}
\frac{\partial V_{1}}{\partial c_{1}}=\frac{1}{c_{1}}-\frac{1+\alpha+\beta}{A_{1}-c_{2}-c_{3}}=0 \\
\Rightarrow \frac{1}{c_{1}}=\frac{1+\alpha+\beta}{A_{1}-c_{2}-c_{3}}  \tag{3}\\
\frac{\partial V_{1}}{\partial c_{2}}=\frac{1+\alpha}{c_{2}}-\frac{1+\alpha+\beta}{A_{1}-c_{2}-c_{3}}=0 \\
\Rightarrow \frac{1+\alpha}{c_{2}}=\frac{1+\alpha+\beta}{A_{1}-c_{2}-c_{3}} \tag{4}
\end{gather*}
$$

Using (3) and (4), we have

$$
\begin{align*}
\frac{1}{c_{1}}= & \frac{1+\alpha}{c_{2}} \\
& \Rightarrow c_{2}=(1+\alpha) c_{1} \tag{5}
\end{align*}
$$

and substituting (5) into (3),

$$
\begin{aligned}
& (1+\alpha+\beta) c_{1}=A_{1}-c_{1}-c_{2}=A_{1}-c_{1}-(1+\alpha) c_{1} \\
& \Rightarrow c_{1}^{1}=\frac{A_{1}}{3+2 \alpha+\beta}
\end{aligned}
$$

Using (2), (5), and (6), the remainder of the consumption plan is given by

$$
\begin{gather*}
c_{2}^{1}=(1+\alpha) c_{1}^{1}=(1+\alpha) \frac{A_{1}}{3+2 \alpha+\beta}  \tag{7}\\
c_{3}^{1}=A_{1}-c_{1}^{1}-c_{2}^{1}=A_{1}-(2+\alpha) c_{1}^{1}=(1+\alpha+\beta) \frac{A_{1}}{3+2 \alpha+\beta} \tag{8}
\end{gather*}
$$

(ii) Next, consider what happens as the agent begins to implement this plan. At time 1, he consumes $c_{1}^{1}$, receives utility $U_{1}$, and has leftover wealth $A_{2}=$ $A_{1}-c_{1}^{1}$. He then faces the problem of maximizing utility over the remainder of his life,

$$
\max V_{2}=\alpha U_{2}+\beta U_{3}
$$

subject to $c_{2}+c_{3}=A_{2}$. Compute the new optimal plan, $c^{2}=\left(c_{2}^{2}, c_{3}^{2}\right)$, and compare it with the last portion of $c^{1}$. Has the consumer changed his mind? How and why? Does the Bellman equation hold?

At time 2, the agent solves

$$
\begin{equation*}
\max V_{2}\left(c_{2}\right)=\alpha \ln c_{2}+(\alpha+\beta) \ln \left(A_{2}-c_{2}\right) \tag{P.2}
\end{equation*}
$$

where

$$
\begin{equation*}
A_{2}=A_{1}-c_{1}^{1}=A_{1}-\frac{A_{1}}{3+2 \alpha+\beta}=\frac{(2+2 \alpha+\beta) A_{1}}{3+2 \alpha+\beta} \tag{9}
\end{equation*}
$$

The first-order condition,

$$
\begin{align*}
V_{2}^{\prime}\left(c_{2}\right)= & \frac{\alpha}{c_{2}}-\frac{\alpha+\beta}{A_{2}-c_{2}}=0 \\
& \Rightarrow \frac{\alpha}{c_{2}}=\frac{\alpha+\beta}{A_{2}-c_{2}} \tag{10}
\end{align*}
$$

can be solved for $c_{2}^{2}$ as a function of $A_{2}$ :

$$
\begin{equation*}
c_{2}^{2}=\frac{\alpha A_{2}}{2 \alpha+\beta} \tag{11}
\end{equation*}
$$

Using (9) and (7), we have

$$
\begin{align*}
c_{2}^{2} & =\frac{\alpha}{2 \alpha+\beta} \frac{(2+2 \alpha+\beta) A_{1}}{3+2 \alpha+\beta} \frac{1+\alpha}{1+\alpha}=\frac{\alpha(2+2 \alpha+\beta)}{(2 \alpha+\beta)(1+\alpha)} \frac{(1+\alpha) A_{1}}{3+2 \alpha+\beta} \\
& =\frac{2 \alpha+2 \alpha^{2}+\alpha \beta}{2 \alpha+\beta+2 \alpha^{2}+\alpha \beta} c_{2}^{1}<c_{2}^{1} \tag{12}
\end{align*}
$$

Hence, revised second-period consumption is lower than in the original plan. The agent has changed his mind because once period 1 has passed, he no longer cares about the effect of planned second- and third-period consumption on period-1 utility.

Problem 1.7. Prove Theorem 1.6: Let $(X, d)$ be a complete metric space, and let $T: X \rightarrow X$ be a contraction with fixed point $v \in X$. Further, let $Y$ be a closed
subset of $X$, and assume that $T$ maps points in $Y$ into some subset $Z$ of $Y$ (i.e., $T: Y \rightarrow Z)$. Then the unique fixed point $v$ of $T$ in $X$ will be in $Z$.

Because $(Y, d)$ is a complete metric space, $v$ must be in $Y$. To show that it in the subset $Z$, note that, by assumption, $T$ maps points in $Y$ into points in $Z$; hence, $T v$ must be in $Z$, but because $v$ is a fixed point, $T v=v \in Z$.

Problem 1.11. Prove Lemma 1.10: Let $T: C(X) \rightarrow C(X)$ be the operator defined by

$$
T \nu(x)=\max _{u \in \Gamma(x)}\{F(x, u)+\beta v[m(x, u)]\}
$$

and assume that Assumption 1.9 (monotonicity) holds. Then $T$ maps nondecreasing functions into strictly increasing functions.

Let $v()$ be a nondecreasing function, and $x_{0}$ and $x_{1} \in X$ two arbitrary points in its domain, with $x_{1}>x_{0}$. Then $v\left(x_{1}\right) \geq v\left(x_{0}\right)$, and because $F$ is assumed to be strictly increasing in $x, F\left(x_{1}, u\right)>F\left(x_{0}, u\right)$ if $u$ is the same, and $v\left[m\left(x_{1}, u\right)\right] \geq v\left[m\left(x_{0}, u\right)\right]$, by our monotonicity assumptions on $v()$ and $m()$. Moreover, the constraint set corresponding to $x_{1}, \Gamma\left(x_{1}\right)$, contains $\Gamma\left(x_{0}\right)$. Hence,

$$
T v\left(x_{1}\right)=\max _{u \in \Gamma\left(x_{1}\right)}\left\{F\left(x_{1}, u\right)+\beta v\left[m\left(x_{1}, u\right)\right]\right\}>\max _{u \in \Gamma\left(x_{0}\right)}\left\{F\left(x_{0}, u\right)+\beta v\left[m\left(x_{0}, u\right)\right]\right\}=T v\left(x_{0}\right)
$$

and we conclude that $T v$ is strictly increasing.

Problem 1.14. Prove Lemma 1.13: Consider the normed vector space $\left[C(X),\|\cdot\|_{s}\right]$, where $\|\cdot\|_{s}$ is the sup norm, and assume $X$ is a convex set. The set of (weakly) concave functions in $C(X)$ is a closed subset of $C(X)$.

We will show that any convergent sequence of concave functions in $C(X)$ has a concave limit. Given a sequence of concave functions $\left\{f_{n}\right\}$ convergent to $f$, let $x_{0}$ and $x_{1}$ be arbitrary points in $X$, and consider the sequence of real numbers

$$
\left\{f_{n}\left[(1-\lambda) x_{0}+\lambda x_{1}\right]-(1-\lambda) f_{n}\left(x_{0}\right)-\lambda f_{n}\left(x_{1}\right)\right\}
$$

By the concavity of $f_{n}$, this is a sequence of nonnegative real numbers, and because $\left\{f_{n}\right\} \rightarrow f$ (in the sup norm and hence pointwise), the sequence has a nonnegative limit

$$
L=f[(1-\lambda) x+\lambda y]-(1-\lambda) f(x)-\lambda f(y) \geq 0
$$

This proves the lemma.

Problem 1.17. Prove Lemma 1.16: Let $T: C(X) \longrightarrow C(X)$ be the operator defined by

$$
T v(x)=\max _{u \in \Gamma(x)}\{F(x, u)+\beta v[m(x, u)]\}
$$

and assume that the concavity and monotonicity assumptions hold. Then $T$ maps weakly concave functions into strictly concave functions.

Let $v$ be weakly concave, take two arbitrary points in its domain, $x_{0}$ and $x_{1}$ in $X$, with $x_{0} \neq x_{1}$, and assume that $u_{0} \in \Gamma\left(x_{0}\right)$ and $u_{1} \in \Gamma\left(x_{1}\right)$ solve the maximization problems for $x_{0}$ and $x_{1}$, respectively. Hence, $u_{0} \in \Gamma\left(x_{0}\right)$ achieves $T v\left(x_{0}\right)$, and $u_{1} \in \Gamma\left(x_{1}\right)$ achieves $T v\left(x_{1}\right)$. To simplify the notation, define

$$
\begin{gathered}
y_{0}=m\left(x_{0}, u_{0}\right), \quad y_{1}=m\left(x_{1}, u_{1}\right) \\
x^{\lambda}=(1-\lambda) x_{0}+\lambda x_{1}, \quad u^{\lambda}=(1-\lambda) u_{0}+\lambda u_{1}, \quad y^{\lambda}=(1-\lambda) y_{0}+\lambda y_{1}
\end{gathered}
$$

The assumption that $\Gamma$ is convex can then be written as $u^{\lambda} \in \Gamma\left(x^{\lambda}\right)$. Note that

$$
\begin{aligned}
T v\left(x^{\lambda}\right)= & \max _{u \in \Gamma\left(x^{\lambda}\right)}\left\{F\left(x^{\lambda}, u\right)+\beta v\left[m\left(x^{\lambda}, u\right)\right]\right\} \geq F\left(u^{\lambda}, x^{\lambda}\right)+v\left[m\left(x^{\lambda}, u^{\lambda}\right)\right] \\
& \geq F\left(u^{\lambda}, x^{\lambda}\right)+v\left[(1-\lambda) m\left(x_{0}, u_{0}\right)+\lambda m\left(x_{1}, u_{1}\right)\right]=F\left(u^{\lambda}, x^{\lambda}\right)+v\left(y^{\lambda}\right) \\
& >\left[(1-\lambda) F\left(x_{0}, u_{0}\right)+\lambda F\left(x_{1}, u_{1}\right)\right]+\left[(1-\lambda) v\left(y_{0}\right)+\lambda v\left(y_{1}\right)\right] \\
= & {\left[(1-\lambda) \operatorname{Tv}\left(x_{0}\right)+\lambda \operatorname{Tv}\left(x_{1}\right)\right] }
\end{aligned}
$$

where the first inequality holds because, by the convexity of the constraint correspondence, $u^{\lambda}$ is feasible for $x^{\lambda}\left(u^{\lambda} \in \Gamma\left(x^{\lambda}\right)\right.$ ), but is not necessarily optimal. The second holds by the concavity of $m()$ and the monotonicity assumption, which ensures that $v()$ is increasing. The third holds by the concavity of $F()$ (strict) and $v()$.

## Chapter 13

Problem 2.7. Apply the implicit-function theorem (IFT) to compute the partial derivatives of the function $\phi\left(k_{t}, c_{t}\right)$, defined implicitly by equation (16) in the text, and determine their signs.

Rewriting (16) in the form

$$
F\left(c_{t+1} ; k_{t}, c_{t}\right)=\beta U^{\prime}\left(c_{t+1}\right) f^{\prime}\left[f\left(k_{t}\right)-c_{t}\right]-U^{\prime}\left(c_{t}\right)=0
$$

we have, by the IFT, that provided $F_{c t+1} \neq 0$,

$$
\phi_{k}=\frac{\partial c_{t+1}}{\partial k_{t}}=-\frac{F_{k t}}{F_{c t+1}} \quad \text { and } \quad \phi_{c}=\frac{\partial c_{t+1}}{\partial c_{t}}=-\frac{F_{c t}}{F_{c t+1}}
$$

where

$$
\begin{gathered}
F_{c t+1}=\beta U^{\prime \prime}\left(c_{t+1}\right) f^{\prime}\left(k_{t+1}\right)<0 \\
F_{k t}=\beta U^{\prime}\left(c_{t+1}\right) f^{\prime \prime}\left(k_{t+1}\right) f^{\prime}\left(k_{t}\right)<0 \\
F_{c t}=\beta U^{\prime}\left(c_{t+1}\right) f^{\prime \prime}\left(k_{t+1}\right)(-1)-U^{\prime \prime}\left(c_{t}\right)>0
\end{gathered}
$$

and therefore

$$
\begin{aligned}
& \phi_{k}=\frac{\partial c_{t+1}}{\partial k_{t}}=-\frac{F_{k t}}{F_{c t+1}}=-(-) /(-)<0 \\
& \phi_{c}=\frac{\partial c_{t+1}}{\partial c_{t}}=-\frac{F_{c t}}{F_{c t+1}}=-(+) /(-)>0
\end{aligned}
$$

Problem 2.8. Setting $c_{t}=c_{t+1}=c$ and $k_{t}=k_{t+1}=k$ in equations (15) and (16) in the text, draw the phase lines $\Delta k_{t}=0$ and $\Delta c_{t}=0$ for the system. To complete the phase diagram, determine the directions of motion along the $c$ and $k$ axes in each of the four regions in which the state plane $(c, x)$ is divided by the phase lines.

The equations of the phase lines are obtained by setting in turn $\Delta k_{t}=k_{t+1}-k_{t}=$ 0 and $\Delta c_{t}=c_{t+1}-c_{t}=0$ (i.e., $c_{t}=c_{t+1}=c$ and $k_{t}=k_{t+1}=k$ ) in (15) and (16):

$$
\begin{gather*}
(15) \Rightarrow k=f(k)-c \\
\Rightarrow \Delta k_{t}=0: c=f(k)-k  \tag{P.1}\\
(16) \Rightarrow U^{\prime}(c)=\beta U^{\prime}(c) f^{\prime}[f(k)-c] \\
\Rightarrow \Delta c_{t}=0: \beta f^{\prime}[f(k)-c]=1 \tag{P.2}
\end{gather*}
$$

- Working with (P.1), we have

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-802.jpg?height=488&width=865&top_left_y=188&top_left_x=306)

Figure A13.1. The $\Delta k_{t}=0$ phase line.

$$
\left.\frac{d c}{d k}\right|_{\Delta k=0}=f^{\prime}(k)-1 \text { and }\left.\frac{d^{2} c}{d k^{2}}\right|_{\Delta k=0}=f^{\prime \prime}(k)<0
$$

Hence the phase line $c=c(k)$ is concave. It achieves a maximum at the point $k^{m}$ where $f^{\prime}\left(k^{m}\right)=1$. In addition, $f(0)=0$, so the line goes through the origin; it rises at first to the maximum and then declines, intersecting the $k$ axis again at the point where $f(k)=k$.

This information allows us to draw the phase line. To determine the direction of the arrows of motion, note that we can write, using (15),

$$
\Delta k_{t}=k_{t+1}-k_{t}=f\left(k_{t}\right)-k_{t}-c_{t}
$$

Differentiating this expression with respect to $c$, we find that

$$
\frac{\partial \Delta k_{t}}{\partial c_{t}}=-1<0
$$

that is, an increase in $c$ reduces the value of $\Delta k_{l}$. In particular, because $\Delta k_{t}=0$ along the phase line, an increase in $c$ (which will put us above the line) makes $\Delta k_{t}$ negative. Hence, $k$ is decreasing over time above the phase line, and increasing below it, as shown in Figure A13.1. This is intuitively obvious, as a consumption level that is "too high" must necessarily reduce the capital stock.

- Similarly,

$$
\begin{equation*}
\Delta c_{t}=0 \Rightarrow G(c ; k)=\beta f^{\prime}[f(k)-c]-1=0 \tag{P.2}
\end{equation*}
$$

Differentiating this equation implicitly with respect to $k$, we get

$$
\beta\left(f^{\prime \prime}() f^{\prime}(k)+f^{\prime \prime}() \frac{d c}{d k}(-1)\right)=\left.0 \Rightarrow \frac{d c}{d k}\right|_{\Delta c=0}=f^{\prime}(k)>0
$$

so the phase line is upward-sloping. Comparing this expression with $(d c / d k)_{\Delta k=0}$, we see that the second phase line is steeper than the first one in the region in which the latter has positive slope. Differentiating again,

$$
\left.\frac{d^{2} c}{d k^{2}}\right|_{\Delta c=0}=f^{\prime \prime}<0
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-803.jpg?height=529&width=745&top_left_y=181&top_left_x=359)

Figure A13.2. The $\Delta c_{t}=0$ phase line.

so the phase line is concave. Moreover, the horizontal intercept is positive, as with $c=0$ we have

$$
f^{\prime}[f(k)-0]=1 / \beta
$$

Because $f^{\prime}()$ is monotonically decreasing with $f^{\prime}(0)=\infty$, the last expression holds only with $f(k)>0$, which in turn requires $k>0$.

To draw the arrows of motion corresponding to this phase line, observe that

$$
\begin{equation*}
U^{\prime}\left(c_{t}\right)=\beta U^{\prime}\left(c_{t+1}\right) f^{\prime}\left[f\left(k_{t}\right)-c_{t}\right] \Leftrightarrow c_{t+1}=\phi\left(k_{t}, c_{t}\right) \tag{2}
\end{equation*}
$$

implies that

$$
\Delta c_{t}=c_{t+1}-c_{t}=\phi\left(k_{t}, c_{t}\right)-c_{t}
$$

so

$$
\frac{\partial \Delta c_{t}}{\partial k_{t}}=\phi_{k}<0
$$

This result tells us that $c$ is decreasing over time to the right of the phase line, as shown in Figure A13.2.

- Combining what we know about the two phase lines, we can draw the phase diagram for the system. It is clear that the two lines will intersect in the first quadrant, yielding a steady state $(\bar{c}, \bar{k})$. Figure A13.3 shows the intersection at a point where the two lines are upward-sloping. To see that this is indeed the case, recall that the slope of the first phase line is given by

$$
\left.\frac{d c}{d k}\right|_{\Delta k=0}=f^{\prime}(k)-1
$$

At the steady state we must have $f^{\prime}(k)=1 / \beta>1$, so $d c /\left.d k\right|_{\Delta k=0}>0$.

Problem 2.9. The phase diagram you have just drawn should suggest that the steady state is a saddle point. Check that this is true by showing that the eigenvalues of the Jacobian matrix for the system are positive real numbers lying on opposite sides of 1 .

We have

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-804.jpg?height=523&width=865&top_left_y=182&top_left_x=306)

Figure A13.3. Phase diagram.

$$
\begin{gather*}
k_{t+1}=f\left(k_{t}\right)-c_{t} \equiv \varphi\left(k_{t}, c_{t}\right)  \tag{15}\\
U^{\prime}\left(c_{t}\right)=\beta U^{\prime}\left(c_{t+1}\right) f^{\prime}\left[f\left(k_{t}\right)-c_{t}\right] \Leftrightarrow c_{t+1}=\phi\left(k_{t}, c_{t}\right) \tag{16}
\end{gather*}
$$

From Problem 2.7, we know that

$$
\begin{aligned}
& \phi_{k}=\frac{\partial c_{t+1}}{\partial k_{t}}=-\frac{F_{k t}}{F_{c t+1}}=-\frac{\beta U^{\prime}\left(c_{t+1}\right) f^{\prime \prime}\left(k_{t+1}\right) f^{\prime}\left(k_{t}\right)}{\beta U^{\prime \prime}\left(c_{t+1}\right) f^{\prime}\left(k_{t+1}\right)} \\
& \phi_{c}=\frac{\partial c_{t+1}}{\partial c_{t}}=-\frac{F_{c t}}{F_{c t+1}}=-\frac{\beta U^{\prime}\left(c_{t+1}\right) f^{\prime \prime}\left(k_{t+1}\right)(-1)-U^{\prime \prime}\left(c_{t}\right)}{\beta U^{\prime \prime}\left(c_{t+1}\right) f^{\prime}\left(k_{t+1}\right)}
\end{aligned}
$$

At a steady state, we have $k_{t+1}=k_{t}=k, c_{t+1}=c_{l}=c$, and $\beta f^{\prime}(k)=1$. Hence we can simplify these expressions to

$$
\begin{gathered}
\bar{\phi}_{k}=-\frac{U^{\prime}(c) f^{\prime \prime}(k) f^{\prime}(k)}{U^{\prime \prime}(c) f^{\prime}(k)}=-\frac{U^{\prime} f^{\prime \prime}}{U^{\prime \prime}} \\
\bar{\phi}_{c}=-\frac{\beta U^{\prime}(c) f^{\prime \prime}(k)+U^{\prime \prime}(c)}{\beta U^{\prime \prime}(c) f^{\prime}(k)}=\frac{\beta U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}+1
\end{gathered}
$$

Moreover,

$$
\bar{\varphi}_{k}=f^{\prime}(k) \quad \text { and } \quad \bar{\varphi}_{c}=-1
$$

The Jacobian matrix evaluated at the steady state is then

$$
J(\bar{c}, \bar{k})=\left[\begin{array}{ll}
\bar{\varphi}_{k} & \bar{\varphi}_{c} \\
\bar{\phi}_{k} & \bar{\phi}_{c}
\end{array}\right]=\left[\begin{array}{cc}
f^{\prime} & -1 \\
\frac{-U^{\prime} f^{\prime \prime}}{U^{\prime \prime}} & 1+\frac{\beta U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}
\end{array}\right]
$$

Hence,

$$
\lambda_{1}+\lambda_{2}=\operatorname{tr} J=f^{\prime}+\frac{\beta U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}+1>2
$$

because $f^{\prime}(k)=1 / \beta>1$ at the steady state,

$$
\lambda_{1} \lambda_{2}=\operatorname{det} J=f^{\prime}+\frac{\beta f^{\prime} U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}-\frac{U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}=f^{\prime}+\frac{U^{\prime} f^{\prime \prime}\left(\beta f^{\prime}-1\right)}{U^{\prime \prime}}=f^{\prime}>1
$$

and

$$
\begin{aligned}
\Delta & =\operatorname{tr}^{2}-4 \operatorname{det}=\left(\frac{\beta U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}+\left(1+f^{\prime}\right)\right)^{2}-4 f^{\prime} \\
& =\left(\frac{\beta U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}\right)^{2}+2 \frac{\beta U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}\left(1+f^{\prime}\right)+\left(1+f^{\prime}\right)^{2}-4 f^{\prime} \\
& =\left(\frac{\beta U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}\right)^{2}+2 \frac{\beta U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}\left(1+f^{\prime}\right)+1+2 f^{\prime}+\left(f^{\prime}\right)^{2}-4 f^{\prime} \\
& =\left(\frac{\beta U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}\right)^{2}+2 \frac{\beta U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}\left(1+f^{\prime}\right)+\left(1-f^{\prime}\right)^{2}>0
\end{aligned}
$$

Because $\Delta>0$, the eigenvalues of the Jacobian are distinct real numbers, and because both their product and their sum are positive, they are both positive. Finally, notice that

$$
p(1)=1-\operatorname{tr}+\operatorname{det}=1-f^{\prime}-\left(\beta U^{\prime} f^{\prime \prime} / U^{\prime \prime}\right)-1+f^{\prime}=-\frac{\beta U^{\prime} f^{\prime \prime}}{U^{\prime \prime}}<0
$$

so $\lambda_{1}$ and $\lambda_{2}$ lie on different sides of 1 on the real line; see Section $2(f)(i i)$ of Chapter 10 . Hence, the steady state is a saddle point, with one eigenvalue in $(0,1)$ and the other in $(1, \infty)$.

Problem 2.11. Show that the function $U\left(k_{t}, k_{t+1}\right)$ defined in the proof of Proposition 2.10 is concave.

From (1) and (2) in the proof of Proposition 2.10 we have

$$
\begin{gathered}
U_{11}\left(k_{t}, k_{t+1}\right)=U^{\prime}\left[f\left(k_{t}\right)-k_{t+1}\right] f^{\prime \prime}\left(k_{t}\right)+f^{\prime}\left(k_{t}\right) U^{\prime \prime}\left[f\left(k_{t}\right)-k_{t+1}\right] f^{\prime}\left(k_{t}\right)<0 \\
U_{12}\left(k_{t}, k_{t+1}\right)=U_{21}\left(k_{t}, k_{t+1}\right)=-U^{\prime \prime}\left[f\left(k_{t}\right)-k_{t+1}\right] f^{\prime}\left(k_{t}\right)>0 \\
U_{22}\left(k_{t}, k_{t+1}\right)=U^{\prime \prime}\left[f\left(k_{t}\right)-k_{t+1}\right]<0
\end{gathered}
$$

The determinant of the Jacobian matrix is given by

$$
\left|\begin{array}{ll}
U_{11} & U_{12} \\
U_{21} & U_{22}
\end{array}\right|=\left|\begin{array}{cc}
U^{\prime} f^{\prime \prime}+U^{\prime \prime}\left(f^{\prime}\right)^{2} & -f^{\prime} U^{\prime \prime} \\
-f^{\prime} U^{\prime \prime} & U^{\prime \prime}
\end{array}\right|=\left[U^{\prime} f^{\prime \prime}+U^{\prime \prime}\left(f^{\prime}\right)^{2}\right] U^{\prime \prime}-\left(f^{\prime}\right)^{2}\left(U^{\prime \prime}\right)^{2}=U^{\prime} f^{\prime \prime} U^{\prime \prime}>0
$$

Hence, the Jacobian matrix is negative definite, and $U\left(k_{t}, k_{t+1}\right)$ is concave (see Theorem 2.17 in Chapter 6).

Problem 4.1. A social planner maximizes the utility of the representative individual,

$$
\int_{0}^{\infty} \frac{C_{t}^{1-\sigma}}{1-\sigma} e^{-\rho t} d t
$$

subject to the resource constraint

$$
\dot{K}_{t}=F\left(K_{t}, A_{t}\right)-\delta K_{t}-C_{t}, \quad \text { with } \frac{\dot{A}}{A}=g
$$

Write the necessary conditions for this problem, and show that they reduce to equations (20) and (21) in the text whenever there are no taxes or subsidies.

Hence, under these conditions, the competitive equilibrium will be a social optimum.

The current-value Hamiltonian for the planner's problem is

$$
H^{c}=\frac{C^{1-\sigma}}{1-\sigma}+\lambda\{F(K, A)-\delta K-C\}
$$

This yields the following Pontryagin conditions:

$$
\begin{gather*}
\frac{\partial H^{C}}{\partial C}=C^{-\sigma}-\lambda=0  \tag{1}\\
-\frac{\partial H^{c}}{\partial K}=-\lambda\left[F_{k}(K, A)-\delta\right]=\dot{\lambda}-\rho \lambda  \tag{2}\\
\Rightarrow \frac{\dot{\lambda}}{\lambda}=\rho-f^{\prime}(Z)-\delta
\end{gather*}
$$

Differentiating (1) with respect to time, and substituting $\left(2^{\prime}\right)$ in the resulting expression, we have

$$
\begin{equation*}
\frac{\dot{C}}{C}=-\frac{1}{\sigma} \frac{\dot{\lambda}}{\lambda}=\frac{1}{\sigma}\left\{f^{\prime}(Z)-\delta-\rho\right\} \tag{3}
\end{equation*}
$$

This expression easily yields equation (20) in the text when $\tau_{r}=0$. A simple manipulation of the planner's resource constraint will similarly yield equation (21) in the text when $x=0$.

Problem 4.2. Assuming a Cobb-Douglas production function (i.e., $f(Z)=Z^{\alpha}$ ), solve for the steady-state savings rate as a function of $\tau_{r}$ and the other parameters of the model.

Using equations (22) and (23), the steady state savings ratio $s^{*}$ is given by

$$
s^{*}=\frac{Y-L C}{Y}=\frac{A L Z^{\alpha}-A L c}{A L Z^{\alpha}}=1-\frac{c}{Z^{\alpha}}=1-\frac{Z^{\alpha}-(\delta+g) Z}{Z^{\alpha}}=(\delta+g) Z^{1-\alpha}
$$

from where

$$
s^{*}=\frac{\alpha(\delta+g)}{\delta+\left((g \sigma+\rho) /\left(1-\tau_{r}\right)\right)}
$$

Hence, $s^{*}$ is an increasing function of the elasticity of output with respect to capital $(\alpha)$, the rate of population growth $(n)$, and the elasticity of intertemporal substitution $(1 / \sigma)$, and it is a decreasing function of the rate of discount $(\rho)$ and the tax rate on capital income $\left(\tau_{r}\right.$ ).

Problem 4.3. One limitation of the approach we have followed is that it assumes that the economy is initially at a steady state. Otherwise the coefficients of the variational equation (the law of motion for $Z_{\tau}$ ) change over time, and this makes it difficult to evaluate $V^{\prime}\left(\tau_{r}\right)$. It is still possible (and in fact much easier) to show that a zero tax on capital income is optimal by showing that when $\tau_{r}=0$ the equilibrium path for the economy solves a closely related planning problem.

Consider, in particular, the problem faced by a social planner, similar to the one described in Problem 2.1, who maximizes the utility of the representative agent subject to the standard resource constraint and the additional restriction that he must "throw away" an amount of output equal to $x A$ at each point in time. Write the planning problem, derive the necessary conditions for an optimum, and verify that they reduce to equations (20) and (21) when $\tau_{r}=0$ in this system.

The planner maximizes

$$
\begin{equation*}
\int_{0}^{\infty} \frac{C_{t}^{1-\sigma}}{1-\sigma} e^{-\rho t} d t \tag{1}
\end{equation*}
$$

subject to the resource constraint

$$
\begin{equation*}
\dot{K}_{t}=F\left(K_{t}, A_{t}\right)-\delta K_{t}-C_{t}-x A_{t} \tag{2}
\end{equation*}
$$

where $A$ increases over time at a constant exogenous rate $g$ (i.e., $\dot{A} / A=g$ ). The necessary conditions for an optimum are almost exactly the same as in Problem 4.1 , and in particular we have

$$
\frac{\dot{C}}{C}=\frac{1}{\sigma}\left\{f^{\prime}(Z)-\delta-\rho\right\}
$$

from which it is easy to derive equation (20) with $\tau_{r}=0$. In addition, the resource constraint can be written in the form

$$
\frac{\dot{K}}{K}=\frac{f(Z)}{Z}-\delta-\frac{C / A}{Z}-\frac{x}{Z}
$$

which is equation (18) in the text. Equation (21) then follows easily.

Hence, the planning problem yields exactly the same system of equations we have derived in the text, provided we set $\tau_{r}=0$ in the latter. Hence, we can achieve the optimal path by eliminating taxes on interest. The equivalence to the planning problem brings out the reason why taxes on capital are inefficient.

Because labor supply is perfectly inelastic, wage levies are, in effect, lump-sum taxes in this model, whereas taxes on capital affect the rate of return on savings and thus distort the intertemporal allocation of resources.

## Problem 5.1

(i) Let $V_{e}(s)$ be the expected lifetime utility of an employed worker who shirks, $V_{e}(n)$ the expected lifetime utility of an employed non-shirker, and $V_{u}$ the expected lifetime utility of an unemployed worker. Write the valuation equations defining $V_{e}(s)$ and $V_{e}(n)$, and explain their meaning.

Consider first a discrete-time formulation in which each period has length $h$ and workers solve

$$
\max _{e} \sum_{t=0}^{\infty}(w-E) h \beta(h)^{t}
$$

Then the value of an employed shirker is given by

$$
\begin{equation*}
V_{e}(s)=(w-0) h+\beta(h)\left\{(b+q) h V_{u}+[1-(b+q) h] V_{e}(s)\right\} \tag{2}
\end{equation*}
$$

In the stationary environment we have assumed, expected lifetime utility for a shirker tomorrow is the same as today. Thus if the worker chooses to shirk today, he will make the same choice tomorrow. Hence, we can define $V_{e}(s)$ recursively: If the worker shirks, today he gets the wage $w$ times the length of the period. There is, however, a probability $(b+q) h$ that he will lose his job. If that is the case, next period he will get $V_{u}$; otherwise he will remain employed, continue to shirk, and get the same value $V_{e}(s)$ again. Because this will happen one period hence, the expression within the curly brackets (tomorrow's expected lifetime utility) must be multiplied by the time discount factor to get it in present-value terms.

To go to continuous time, let the discount factor be $\beta(h)=e^{-\rho h}$. Subtracting $\beta(h) V_{e}(s)$ from both sides of (2), dividing by $h$, and taking the limit as $h \rightarrow 0$, we have

$$
\lim _{h \rightarrow 0} \frac{1-\beta(h)}{h} V_{e}(s)=\lim _{h \rightarrow 0} w+\beta(h)(b+q)\left[V_{u}-V_{e}(s)\right]
$$

or

$$
\begin{gather*}
\rho V_{e}(s)=w+(b+q)\left[V_{u}-V_{e}(s)\right]  \tag{3}\\
\Rightarrow V_{e}(s)=\frac{w+(b+q) V_{u}}{\rho+b+q}
\end{gather*}
$$

Similarly, in the case of a non-shirker, the current "dividend" is $w-x$, and the probability of job separation is $b$. Hence,

$$
\begin{align*}
& \rho V_{e}(n)=(w-x)+b\left[V_{u}-V_{e}(n)\right]  \tag{4}\\
& \quad \Rightarrow V_{e}(n)=\frac{w-x+b V_{u}}{\rho+b}
\end{align*}
$$

(ii) An employed worker will choose not to shirk if $V_{e}(n) \geq V_{e}(s)$. Show that this "no-shirking" condition implies that $V_{e}(s) \geq V_{u}$, so that workers prefer to be employed, and use it to solve for the minimum wage $w_{m}$ at which workers will find it optimal not to shirk. What factors determine $w_{m}$ ?

An employed worker will choose not to shirk if $V_{e}(n) \geq V_{e}(s)$. Using (3) and (4), we can write the non-shirking condition (NSC) as

$$
\begin{equation*}
V_{e}(n) \geq V_{e}(s) \Rightarrow \frac{w+(b+q) V_{u}}{\rho+b+q} \geq \frac{w-x+b V_{u}}{\rho+b} \tag{5}
\end{equation*}
$$

or, rearranging terms,

$$
\begin{equation*}
w \geq \rho V_{u}+(r+b+q)(x / q) \equiv w_{m} \tag{6}
\end{equation*}
$$

Alternatively, using ( $\left.3^{\prime}\right)$ and $\left(4^{\prime}\right)$, we have

$$
\begin{equation*}
q\left[V_{e}(s)-V_{u}\right] \geq x \tag{7}
\end{equation*}
$$

Equation (6) defines $w_{m}$, the minimum wage the firm has to pay in order to prevent shirking. Note that $w_{m}$ increases with the level of effort, the expected utility of unemployed workers (which lowers the cost of job loss), the exogenous quit rate (if one is leaving, one may as well cheat), and the discount rate ("punishment," which comes in the future, is discounted more heavily); it decreases with the probability of detection.

Equation (7) tells us that in order to ensure that workers will not shirk, wages have to be high enough that workers will prefer to work. This implies that the unemployment rate will be positive - otherwise, a worker who was fired could get another job immediately, and $V_{e}(s)=V_{u}$, so (7) could not hold.

Problem 5.2. We will now characterize a stationary equilibrium of the model.

(i) Let $w_{u}$ be the unemployment benefit. Derive the expected lifetime utility of an unemployed worker, $V_{u}$, as a function of $w_{u}$ and the value of an employed worker, $V_{e}$.

By the same reasoning as in Problem 5.1, the value of an unemployed worker, $V_{u}$, must satisfy

$$
\begin{equation*}
\rho V_{u}=w_{u}+a\left(V_{e}-V_{u}\right) \tag{9}
\end{equation*}
$$

where $a$ is the rate at which workers find jobs and come out of the pool of unemployed.
(ii) Using the expressions for $V_{e}\left(=V_{e}(n)\right)$ and $V_{u}$ derived earlier, solve for $V_{e}$ and $V_{u}$ as functions of $a$ and the parameters of the model. Rewrite the noshirking condition, replacing $V_{u}$ by its equilibrium value. How do unemployment benefits and the probability of finding employment affect the minimum non-shirking wage?

Using (4) and (9), we have

$$
\rho V_{e}-\rho V_{u}=(w-x)+b\left(V_{u}-V_{e}\right)-w_{u}-a\left(V_{e}-V_{u}\right)
$$

from where

$$
\begin{equation*}
V_{e}-V_{u}=\frac{(w-x)-w_{u}}{\rho+a+b} \tag{10}
\end{equation*}
$$

Substituting (10) into (4) and (9), we obtain

$$
\begin{align*}
& \rho V_{e}=\frac{(\rho+a)(w-x)+b w_{u}}{\rho+a+b}  \tag{11}\\
& \rho V_{u}=\frac{a(w-x)+(\rho+b) w_{u}}{\rho+a+b} \tag{12}
\end{align*}
$$

Substituting (12) into (6), with $w=w_{m}$,

$$
w_{m}=\rho V_{u}+(r+b+q)(x / q)=\frac{a\left(w_{m}-x\right)+(\rho+b) w_{u}}{\rho+a+b}
$$

and rearranging, the no-shirking condition can be written

$$
\begin{equation*}
w \geq w_{m} \equiv w_{u}+x+(x / q)(\rho+a+b) \tag{12}
\end{equation*}
$$

Hence, the critical wage increases with the size of the unemployment benefit and the rate of flow out of unemployment, both factors that tend to increase $V_{u}$.

(iii) Let $N$ be the given labor supply. In a steady-state equilibrium, the flows into unemployment and out of it must be equal. Using this condition, solve for the probability of finding employment, $a$, as a function of $b, L$, and $N$, and substitute the result into the no-shirking condition. Interpret the resulting condition. The equilibrium wage and unemployment levels are determined by the intersection of the non-shirking condition and the labor demand schedule $f^{\prime}(L)=w_{m}$. Draw both functions in the $(w, L)$ plane, and verify that the equilibrium involves an excess supply of labor.

In a steady-state equilibrium, the flow into unemployment $(b L)$ and out of it $(a(N-L))$ must be equal; hence,

$$
\begin{equation*}
a=\frac{b L}{N-L} \tag{13}
\end{equation*}
$$

Substituting this expression into (12), the no-shirking condition can be rewritten

$$
\begin{equation*}
w \geq w_{u}+x+(x / q)\left(\rho+\frac{b N}{N-L}\right) \equiv w_{m} \tag{NSC}
\end{equation*}
$$

This expression defines an upward-sloping curve in the $(w, L)$ plane, as illustrated in Figure A13.4. As employment increases, wages must also rise, to prevent shirking. The reason is that a decrease in the unemployment rate tends to lower the expected value of the "punishment" to detected shirkers.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-810.jpg?height=715&width=939&top_left_y=185&top_left_x=269)

Figure A13.4. Equilibrium wage and employment levels.

To compensate for this, wages must rise, so that the loss of being fired increases.

The equilibrium wage and unemployment levels are determined by the intersection of the non-shirking condition and the labor demand schedule $f(L)=w_{m}$, as illustrated in Figure A13.4. As noted earlier, the equilibrium will involve involuntary unemployment. In spite of the excess supply of labor, $w^{*}$ is the equilibrium wage, because firms have no incentive to either increase (because workers are supplying effort) or decrease wages (because they are on their labor demand schedule). Unemployed workers would be happy to take a job, but cannot make a credible commitment not to shirk if the wage is lowered.

## Problem 5.3

(i) Derive an expression that describes the evolution of the unemployment rate over time as a function of the instantaneous rate of separation $(s)$ and the probability of finding employment, $\theta^{1-\alpha}$. Set $\dot{u}=0$ and solve for the steadystate unemployment rate as a function of the rates of flow into and out of unemployment (assuming $\theta$ is constant).

The instantaneous change in the unemployment rate is the difference between the flows into and out of unemployment normalized by the total population. At a given point in time, a fraction $(1-u)$ of the population is employed. Multiplying this number by the instantaneous probability of separation, $s$, we obtain the flow into unemployment. Similarly, the flow into employment is equal to the current unemployment rate times the probability of finding a job, given by (3). Hence, we have

$$
\begin{equation*}
\dot{u}=(1-u) s-u \theta^{1-\alpha} \tag{4}
\end{equation*}
$$

Setting $\dot{u}$ equal to zero in (4), we can solve for the steady-state rate of unemployment as a function of $\theta$ :

$$
\begin{equation*}
u=\frac{s}{s+\theta^{1-\alpha}} \tag{5}
\end{equation*}
$$

(ii) Let $V$ be the value of a vacancy, $J$ the value of a filled job, and $r$ the discount rate. Taking into account the relevant transition probabilities and the flows of costs and benefits for an occupied job and vacant job, write the valuation equations for these two assets, $J$ and $V$. Explain their meaning. Using the two asset-valuation equations (subtract one from the other), derive an expression for $J-V$ as a function of $y, c, w, r$, and the relevant transition probabilities.

As in the discussion in Section 1 of the text, the general idea is the same for all the valuation equations: The expected return on each "asset," given by its current dividend plus expected capital gain expressed as a fraction of its value, must be equal to the discount (interest) rate. In the case of a vacant firm, the dividend is negative (the maintenance cost, $c$ ), and the expected capital gain is equal to the difference between the value of a filled job, $J$, and that of a vacant one, $V$, multiplied by the instantaneous probability that a vacancy will be filled, given in equation (2). Hence,

$$
\begin{equation*}
r V=-c+\theta^{-\alpha}(J-V) \tag{6}
\end{equation*}
$$

In the case of an active firm, the dividend is the current profit (the difference between output and the wage), and the expected capital gain depends on the probability $(s)$ that the match will be exogenously destroyed:

$$
\begin{equation*}
r J=y-w+s(V-J) \tag{7}
\end{equation*}
$$

Using these two expressions,

$$
r J-r V=y-w-s(J-V)+c-\theta^{-\alpha}(J-V)
$$

Rearranging terms and solving for $J-V$,

$$
\begin{equation*}
J-V=\frac{y+c-w}{r+s+\theta^{-\alpha}} \tag{8}
\end{equation*}
$$

(iii) Let $E$ and $U$ be the "values" of an employed worker and an unemployed worker, respectively. Write and explain the corresponding asset valuation equations, and derive an expression for $E-U$.

By the same logic as in (ii), we have

$$
\begin{gather*}
r U=b+\theta^{1-\alpha}(E-U)  \tag{9}\\
r E=w+s(U-E) \tag{10}
\end{gather*}
$$

from where

$$
\begin{align*}
& r(E-U)=w-s(E-U)-b-\theta^{1-\alpha}(E-U)  \tag{11}\\
& \quad \Rightarrow E-U=\frac{w-b}{r+s+\theta^{1-\alpha}}
\end{align*}
$$

Problem 5.4. Using the results of Problem 5.3, solve for the equilibrium wage.

We have to solve

$$
\max _{w}(E-U)^{\beta}(J-V)^{1-\beta}=\left(\frac{w-b}{r+s+\theta^{1-\alpha}}\right)^{\beta}\left(\frac{y+c-w}{r+s+\theta^{-\alpha}}\right)^{1-\beta}
$$

Taking logs, this is equivalent to

$$
\max \beta \ln (w-b)+(1-\beta) \ln (y+c-w)
$$

Setting the derivative of this function with respect to $w$ equal to zero,

$$
\frac{\beta}{w-b}-\frac{1-\beta}{y+c-w}=0 \Rightarrow \beta(y+c-w)=(1-\beta)(w-b)
$$

and solving for $w$,

$$
\begin{equation*}
w=\beta(y+c)+(1-\beta) b \tag{12}
\end{equation*}
$$

Problem 5.5. In equilibrium, new firms enter until the value of a vacant job drops to zero, i.e., until $V=0$.

(i) Using the valuation equations for $V$ and $J$, show that

$$
\begin{equation*}
\frac{y-w}{r+s}=c \theta^{\alpha} \tag{13}
\end{equation*}
$$

With $V=0$ the valuation equations (6) and (7) yield

$$
J=c \theta^{\alpha} \quad \text { and } \quad J=\frac{y-w}{r+s}
$$

Thus

$$
\begin{equation*}
\frac{y-w}{r+s}=c \theta^{\alpha} \tag{13}
\end{equation*}
$$

a condition that summarizes the "supply of jobs" in equilibrium.

(ii) Using equation (13), along with the expression for the equilibrium wage obtained in Problem 5.4 and the formula for the steady-state unemployment rate obtained in Problem 5.3, solve for the equilibrium values of $u, w$, and $\theta$. Draw a diagram in the $(u, \theta)$ plane illustrating the determination of equilibrium.

Collecting previous results, we have

$$
\begin{gather*}
y-w=c(r+s) \theta^{\alpha} \\
w=\beta(y+c)+(1-\beta) b  \tag{12}\\
u=\frac{s}{s+\theta^{1-\alpha}} \tag{5}
\end{gather*}
$$

Using the first two equations, we can solve for $\theta^{*}$,

$$
\begin{equation*}
\theta^{\alpha}=\frac{(1-\beta)(y-b)-\beta c}{c(r+s)} \tag{14}
\end{equation*}
$$

and equation (5) then gives the equilibrium rate of unemployment.

Graphically, equation (14) defines a vertical line in the $(\theta, u)$ plane, and equation (5) a downward-sloping line, as shown in Figure A13.5.

Notice that in order for $\theta^{*}$ to be positive, it must be the case that

$$
\begin{equation*}
y-b \geq \frac{\beta c}{1-\beta} \tag{15}
\end{equation*}
$$

Hence, we need to impose this condition on the parameters in order to get a sensible equilibrium.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-813.jpg?height=635&width=835&top_left_y=178&top_left_x=321)

Figure A13.5. Determination of the steady-state unemployment rate.

(iii) What are the effects on the equilibrium unemployment rate of an increase in workers' bargaining power $(\beta)$, an increase in the unemployment benefit $(b)$, and an increase in the probability of structural shocks $(s)$ ?

Using equation (14), it is clear that an increase in $b$ reduces the equilibrium value of $\theta$, shifting the vertical line to the left. Because the other equation is not affected, an increase in the unemployment benefit increases the equilibrium rate of unemployment. The effect on $\theta$ of an increase in $s$ is similar. Moreover, this parameter change also shifts the second line upward, which raises the unemployment rate further. Finally, it is easy to see, using equations (14) and (15), that an increase in workers' bargaining power also increases the unemployment rate.

Problem 5.6. Define the variables

$$
\begin{equation*}
X=\frac{c}{Z^{\alpha}} \quad \text { and } \quad R=Z^{\alpha-1} \tag{6}
\end{equation*}
$$

(i) Rewrite the system (4)-(5) in terms of $X$ and $R$. Solve for the steady-state values of $X$ and $Z$.

Notice that

$$
\frac{c}{Z}=\frac{c}{Z^{\alpha} Z^{1-\alpha}}=X R
$$

Hence, we can rewrite (4) and (5) in the form

$$
\begin{align*}
\frac{\dot{c}}{c} & =\frac{1}{\sigma}\{\alpha R-(\rho+\delta)\}-g \\
\frac{\dot{Z}}{Z} & =(1-X) R-(\delta+g+n)
\end{align*}
$$

We can use these expressions to solve for the steady-state values of $X$ and $R$. Setting $\dot{c}$ and $\dot{Z}$ equal to zero, we have

$$
\begin{equation*}
R^{*}=\frac{\rho+\delta+g \sigma}{\alpha} \tag{7}
\end{equation*}
$$

$$
\begin{equation*}
S^{*}=1-X^{*}=\frac{\delta+g+n}{R}=\frac{\alpha(\delta+g+n)}{\rho+\delta+g \sigma} \tag{8}
\end{equation*}
$$

Notice that the condition for utility to be bounded, given in equation (3), implies that $S^{*}=1-X^{*}<\alpha$.

Using (6), moreover, we have

$$
\frac{\dot{X}}{X}=\frac{\dot{c}}{c}-\alpha \frac{\dot{Z}}{Z}=\frac{1}{\sigma}\{\alpha R-(\rho+\delta)\}-g-\alpha(1-X) R+\alpha(\delta+g+n)
$$

or

$$
\begin{equation*}
\frac{\dot{X}}{X}=\alpha R\left(\frac{1}{\sigma}-(1-X)\right)-\frac{\rho+\delta+g \sigma}{\sigma}+\alpha(\delta+g+n) \tag{9}
\end{equation*}
$$

and

$$
\begin{equation*}
\frac{\dot{R}}{R}=(\alpha-1) \frac{\dot{Z}}{Z}=(1-\alpha)(\delta+g+n)-(1-\alpha)(1-X) R \tag{10}
\end{equation*}
$$

(ii) Construct the log-linearization of the system obtained in (i). Compute the eigenvalues of its coefficient matrix, and show that the steady state is a saddle point. Compute the eigenvector associated with the negative eigenvalue, and relate the slope of the saddle path to the size of the negative eigenvalue. Does anything look familiar? form

Let $x=\ln X$ and $r=\ln R$. Then the system (9)-(10) can be written in the

$$
\begin{gather*}
\dot{x}=\alpha e^{r}\left(\frac{1}{\sigma}-\left(1-e^{x}\right)\right)-\frac{\rho+\delta+g \sigma}{\sigma}+\alpha(\delta+g+n) \equiv F(x, r) \\
\dot{r}=(1-\alpha)(\delta+g+n)-(1-\alpha)\left(1-e^{x}\right) e^{r} \equiv G(x, r)
\end{gather*}
$$

Evaluating the partial derivatives of $F()$ and $G()$ at the steady state, we obtain

$$
\begin{gathered}
F_{x}=\alpha e^{r} e^{x}=\alpha R^{*} X^{*} \\
F_{r}=\alpha e^{r}\left(\frac{1}{\sigma}-\left(1-e^{x}\right)\right)=\alpha R^{*}\left(\frac{1}{\sigma}-\left(1-X^{*}\right)\right)=\frac{\rho+\delta+g \sigma}{\sigma}-(\delta+g+n) \\
G_{x}=(1-\alpha) e^{r} e^{x}=(1-\alpha) R^{*} X^{*} \\
G_{r}=-(1-\alpha)\left(1-e^{x}\right) e^{r}=-(1-\alpha)\left(1-X^{*}\right) R^{*}=-(1-\alpha)(\delta+g+n)
\end{gathered}
$$

Hence, the Jacobian of the system is of the form

$$
J=\left[\begin{array}{ll}
F_{x} & F_{r} \\
G_{x} & G_{r}
\end{array}\right]=\left[\begin{array}{cc}
\alpha R^{*} X^{*} & \alpha R\left(\frac{1}{\sigma}-\left(1-X^{*}\right)\right) \\
(1-\alpha) R^{*} X^{*} & -(1-\alpha)\left(1-X^{*}\right) R^{*}
\end{array}\right]
$$

and we have

$$
\begin{aligned}
\operatorname{tr} J & =\alpha R^{*} X^{*}-(1-\alpha)\left(1-X^{*}\right) R^{*}=-\left(1-X^{*}-\alpha\right) R^{*}>0 \\
\operatorname{det} J & =-(1-\alpha)\left(1-X^{*}\right) \alpha X^{*} R^{* 2}-(1-\alpha) \alpha X^{*} R^{* 2}\left(\frac{1}{\sigma}-\left(1-X^{*}\right)\right) \\
& =-\frac{(1-\alpha) \alpha X^{*} R^{* 2}}{\sigma}<0
\end{aligned}
$$

Notice that because $\operatorname{det} J<0$, the steady state is a saddle point, as claimed.

The eigenvalues of the system are given by

$$
-\lambda, \omega=\frac{\operatorname{tr} \pm \sqrt{\operatorname{tr}^{2}-4 \mathrm{det}}}{2}=\frac{\operatorname{tr}}{2}\left(1 \pm \sqrt{1-\frac{4 \mathrm{det}}{\mathrm{tr}^{2}}}\right)
$$

where

$$
\begin{aligned}
\Delta & =\operatorname{tr}^{2}-4 \operatorname{det}=\left(1-X^{*}-\alpha\right)^{2} R^{* 2}+\frac{4(1-\alpha) \alpha X^{*} R^{* 2}}{\sigma} \\
& =R^{* 2}\left(\left(1-X^{*}-\alpha\right)^{2}+\frac{4(1-\alpha) \alpha X^{*}}{\sigma}\right)>0
\end{aligned}
$$

Let $e_{\lambda}$ be the second component of the eigenvector corresponding to the negative eigenvalue, $-\lambda$, and normalize the first component to 1 , so that $e_{\lambda}$ is the inverse of the slope of the saddle path at the steady state. Then $e_{\lambda}$ solves

$$
J e_{\lambda}=-\lambda e_{\lambda} \Leftrightarrow\left[\begin{array}{ll}
F_{x} & F_{r} \\
G_{x} & G_{r}
\end{array}\right]\left[\begin{array}{c}
1 \\
e_{\lambda}
\end{array}\right]=\left[\begin{array}{c}
-\lambda \\
-\lambda e_{\lambda}
\end{array}\right]
$$

from where

$$
\begin{align*}
& G_{x}+G_{r} e_{\lambda}=-\lambda e_{\lambda} \\
& \Rightarrow \frac{1}{e_{\lambda}}=\frac{-\left(G_{r}+\lambda\right)}{G_{x}}=\frac{(1-\alpha)(\delta+g+n)-\lambda}{(1-\alpha) R^{*} X^{*}} \tag{11}
\end{align*}
$$

Hence, the slope of the saddle path depends on the sign of the difference $(1-\alpha)(\delta+g+n)-\lambda$, where the first term, as the reader will recall from Section 4(a) in Chapter 11, is the rate of convergence in the Solow model. As we will see later, this difference can be either positive or negative, so in principle the savings rate can be either an increasing or decreasing function of the interest rate, depending on parameter values.

Problem 5.7. Next, we will consider a special case. Assume that the following restriction on the parameters holds:

$$
\begin{equation*}
\rho+\delta+g \sigma=\alpha \sigma(\delta+n+g) \tag{12}
\end{equation*}
$$

Construct the phase diagram for the system, and compute its negative eigenvalue and the associated eigenvector.

Given condition (12), equation (9) reduces to

$$
\begin{equation*}
\dot{x}=\frac{\dot{X}}{X}=\alpha R\left(\frac{1}{\sigma}-(1-X)\right) \tag{13}
\end{equation*}
$$

Hence, $\dot{x} \geq 0$ if

$$
\begin{align*}
\frac{1}{\sigma} & \geq(1-X) \\
& \Leftrightarrow X \geq \frac{\sigma-1}{\sigma} \equiv X^{*} \tag{14}
\end{align*}
$$

Notice that, given (3), equation (12) requires that $\sigma>1 / \alpha>1$; hence $X^{*}>0$. Figure A13.6 shows the corresponding phase line and arrows of motion.

Working with

$$
\begin{equation*}
\dot{r}=\frac{\dot{R}}{R}=(1-\alpha)(\delta+g+n)-(1-\alpha)(1-X) R \tag{10}
\end{equation*}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-816.jpg?height=572&width=826&top_left_y=182&top_left_x=325)

Figure A13.6. The $\dot{x}=0$ phase line.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-816.jpg?height=572&width=801&top_left_y=898&top_left_x=338)

Figure A13.7. The $\dot{r}=0$ phase line.

the equation of the $\dot{r}=0$ phase line is

$$
\begin{equation*}
X=1-\frac{\delta+g+n}{R} \tag{15}
\end{equation*}
$$

and

$$
\frac{\partial \dot{r}}{\partial R}=-(1-\alpha)(1-X)<0
$$

Hence, the $\dot{r}=0$ phase line is upward-sloping, with a positive $R$ intercept and a horizontal asymptote at $x=1$, and $R$ decreases over time in the region to the right of the phase line, as shown in Figure A13.7.

Combining the two phase lines, we obtain the phase diagram shown in Figure A13.8. Notice that, given the pattern of the arrows of motion, the saddle path coincides with the $\dot{x}=0$ phase line. Hence, the savings ratio remains constant over time in equilibrium, as in the Solow model.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-817.jpg?height=576&width=831&top_left_y=178&top_left_x=323)

Figure A13.8. Phase diagram.

To compute the eigenvalues of the system, notice that under the assumption

$$
\begin{equation*}
\rho+\delta+g \sigma=\alpha \sigma(\delta+n+g) \tag{12}
\end{equation*}
$$

equations (7) and (8) become

$$
\begin{gather*}
R^{*}=\frac{\rho+\delta+g \sigma}{\alpha}=\sigma(\delta+n+g)  \tag{16}\\
1-X^{*}=\frac{1}{\sigma} \Rightarrow X^{*}=\frac{\sigma-1}{\sigma} \tag{17}
\end{gather*}
$$

Using these expressions and previous results, we have

$$
\operatorname{tr} J=-\left(1-X^{*}-\alpha\right) R^{*}=-\left(\frac{1}{\sigma}-\alpha\right) \sigma(\delta+n+g)=-(1-\alpha \sigma)(\delta+n+g)
$$

and

$$
\begin{aligned}
\frac{\Delta}{R^{* 2}} & =\left(1-X^{*}-\alpha\right)^{2}+\frac{4(1-\alpha) \alpha X^{*}}{\sigma}=\frac{(1-\alpha \sigma)^{2}}{\sigma^{2}}-\frac{4(1-\alpha) \alpha}{\sigma} \frac{1-\sigma}{\sigma} \\
& =\frac{1}{\sigma^{2}}\left[(1-\alpha \sigma)^{2}-4(1-\alpha) \alpha(1-\sigma)\right]
\end{aligned}
$$

To simplify this expression, notice that

$$
(1-\alpha \sigma)^{2}=[(1-\alpha)+\alpha(1-\sigma)]^{2}=(1-\alpha)^{2}+\alpha^{2}(1-\sigma)^{2}+2(1-\alpha) \alpha(1-\sigma)
$$

Hence,

$$
\begin{aligned}
\frac{\Delta}{R^{* 2}} & =\frac{1}{\sigma^{2}}\left[(1-\alpha)^{2}+\alpha^{2}(1-\sigma)^{2}-2(1-\alpha) \alpha(1-\sigma)\right] \\
& =\frac{1}{\sigma^{2}}[(1-\alpha)-\alpha(1-\sigma)]^{2}=\frac{(1-2 \alpha+\alpha \sigma)^{2}}{\sigma^{2}}
\end{aligned}
$$

and, using (16),

$$
\Delta=(1-2 \alpha+\alpha \sigma)^{2}(\delta+n+g)^{2}
$$

Now, the negative eigenvalue is given by

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-818.jpg?height=482&width=542&top_left_y=196&top_left_x=143)

Case i: $\mu>0$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-818.jpg?height=488&width=601&top_left_y=197&top_left_x=712)

Case ii: $\mu<0$

Figure A13.9. The $\dot{x}=0$ phase line.

$$
-\lambda=\frac{1}{2}(\operatorname{tr}-\sqrt{\Delta})=\frac{-(\delta+n+g)}{2}[(1-\alpha \sigma)+(1-2 \alpha+\alpha \sigma)]=-(1-\alpha)(\delta+n+g)
$$

and, using (11),

$$
\frac{1}{e_{\lambda}}=\frac{(1-\alpha)(\delta+g+n)-\lambda}{(1-\alpha) R^{*} X^{*}}=0
$$

Problem 5.8. Let us now return to the general case of the model. Define the parameter $\mu$ by

$$
\begin{equation*}
1+\mu \equiv \frac{\rho+\delta+g \sigma}{\alpha \sigma(\delta+n+g)} \tag{18}
\end{equation*}
$$

and notice that if $\mu=0$, then we are in Problem 5.7. Write the negative eigenvalue of the system and the corresponding eigenvector as functions of $\mu$, and relate the slope of the saddle path to the sign of $\mu$. Draw the phase diagram of the system for $\mu>0$ and $\mu<0$.

Using (18), equation (9) can be written

$$
\begin{aligned}
\dot{x} & =\frac{\dot{X}}{X}=\alpha R\left(\frac{1}{\sigma}-(1-X)\right)-\frac{\rho+\delta+g \sigma}{\sigma}+\alpha(\delta+g+n) \\
& =\alpha R\left(\frac{1}{\sigma}-(1-X)\right)-(1+\mu) \alpha(\delta+g+n)+\alpha(\delta+g+n)
\end{aligned}
$$

or

$$
\begin{equation*}
\dot{x}=\alpha R\left(\frac{1}{\sigma}-(1-X)\right)-\mu \alpha(\delta+g+n) \tag{19}
\end{equation*}
$$

Hence, $\dot{x} \geq 0$ if

$$
\begin{equation*}
X \geq \frac{\mu \alpha(\delta+g+n)}{\alpha R}+\frac{\sigma-1}{\sigma} \tag{20}
\end{equation*}
$$

Hence, the $\dot{x}=0$ phase line has a horizontal asymptote at $X=(\sigma-1) / \sigma$. If $\mu>0$, the phase line lies above the asymptote and is downward-sloping, and if $\mu<0$ the line lies below the asymptote and is upward-sloping. In both cases, $X$ increases over time in the region above the phase line, as shown in Figure A13.9.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-819.jpg?height=511&width=599&top_left_y=181&top_left_x=106)

Case i: $\mu>0$

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-819.jpg?height=494&width=706&top_left_y=210&top_left_x=671)

Case ii: $\mu<0$

Figure A13.10. Phase diagram.

Combining this figure with the $\dot{r}=0$ phase line, which does not depend on $\mu$, we obtain the phase diagram shown in Figure A13.10. Notice that if $\mu>0$, the consumption rate is a decreasing function of the interest factor. If the economy approaches its steady-state capital/labor ratio from below, the interest factor decreases over time, and the consumption rate increases. Hence, the savings rate falls with income. If $\mu<0$, on the other hand, the savings rate increases with income as the economy approaches its steady state.

To compute the negative eigenvalue, notice that with

$$
\begin{equation*}
1+\mu \equiv \frac{\rho+\delta+g \sigma}{\alpha \sigma(\delta+n+g)} \tag{18}
\end{equation*}
$$

equations (7) and (8) become

$$
\begin{gather*}
R^{*}=\frac{\rho+\delta+g \sigma}{\alpha}=(1+\mu) \sigma(\delta+n+g)  \tag{21}\\
1-X^{*}=\frac{\alpha(\delta+g+n)}{\rho+\delta+g \sigma}=\frac{1}{(1+\mu) \sigma} \Rightarrow X^{*}=\frac{(1+\mu) \sigma-1}{(1+\mu) \sigma} \tag{22}
\end{gather*}
$$

Using these expressions and previous results, we have

$$
\begin{aligned}
\operatorname{tr} J & =-\left(1-X^{*}-\alpha\right) R^{*}=-\left(\frac{1}{(1+\mu) \sigma}-\alpha\right)(1+\mu) \sigma(\delta+n+g) \\
& =-[1-\alpha(1+\mu) \sigma](\delta+n+g)
\end{aligned}
$$

and

$$
\begin{aligned}
\frac{\Delta}{R^{* 2}} & =\left(1-X^{*}-\alpha\right)^{2}+\frac{4(1-\alpha) \alpha X^{*}}{\sigma}=\frac{[1-\alpha(1+\mu) \sigma]^{2}}{(1+\mu)^{2} \sigma^{2}}-\frac{4(1-\alpha) \alpha}{\sigma} \frac{1-(1+\mu) \sigma}{(1+\mu) \sigma} \\
& =\frac{1}{(1+\mu)^{2} \sigma^{2}}\left\{[1-\alpha(1+\mu) \sigma]^{2}-4(1-\alpha) \alpha(1+\mu)[1-(1+\mu) \sigma]\right\}
\end{aligned}
$$

To simplify this expression, notice that

$$
\begin{aligned}
{[1-\alpha(1+\mu) \sigma]^{2} } & =\{(1-\alpha)+\alpha[1-(1+\mu) \sigma]\}^{2} \\
& =(1-\alpha)^{2}+\alpha^{2}[1-(1+\mu) \sigma]^{2}+2(1-\alpha) \alpha[1-(1+\mu) \sigma]
\end{aligned}
$$

Hence,

$$
\begin{aligned}
\frac{(1+\mu)^{2} \sigma^{2}}{R^{* 2}} \Delta= & (1-\alpha)^{2}+\alpha^{2}[1-(1+\mu) \sigma]^{2}+2(1-\alpha) \alpha[1-(1+\mu) \sigma] \\
& -4(1-\alpha) \alpha[1-(1+\mu) \sigma]-4 \mu(1-\alpha) \alpha[1-(1+\mu) \sigma] \\
= & (1-\alpha)^{2}+\alpha^{2}[1-(1+\mu) \sigma]^{2}-2(1-\alpha) \alpha[1-(1+\mu) \sigma] \\
& -4 \mu(1-\alpha) \alpha[1-(1+\mu) \sigma] \\
= & \{(1-\alpha)-\alpha[1-(1+\mu) \sigma]\}^{2}-4 \mu(1-\alpha) \alpha[1-(1+\mu) \sigma] \\
= & {[1-2 \alpha+\alpha(1+\mu) \sigma]^{2}-4 \mu(1-\alpha) \alpha[1-(1+\mu) \sigma] } \\
= & {[1-2 \alpha+\alpha(1+\mu) \sigma]^{2}[1-B(\mu)]^{2} }
\end{aligned}
$$

with

$$
\begin{equation*}
1-B(\mu)=\sqrt{1-\frac{\mu 4(1-\alpha) \alpha[1-(1+\mu) \sigma]}{[1-2 \alpha+\alpha(1+\mu) \sigma]^{2}}} \tag{23}
\end{equation*}
$$

where the expression under the square-root radical is positive, because we know that $\Delta>0$.

Using (21),

$$
\begin{aligned}
\Delta & =\frac{R^{* 2}}{(1+\mu)^{2} \sigma^{2}}[1-2 \alpha+\alpha(1+\mu) \sigma]^{2}[1-B(\mu)] \\
& =(\delta+n+g)^{2}[1-2 \alpha+\alpha(1+\mu) \sigma]^{2}[1-B(\mu)]^{2}
\end{aligned}
$$

Now, the negative eigenvalue is given by

$$
\begin{aligned}
-\lambda & =\frac{1}{2}(\operatorname{tr}-\sqrt{\Delta})=\frac{-(\delta+n+g)}{2}\{[1-\alpha(1+\mu) \sigma]+[1-2 \alpha+\alpha(1+\mu) \sigma][1-B(\mu)]\} \\
& =\frac{-(\delta+n+g)}{2}\{2-2 \alpha-B(\mu)[1-2 \alpha+\alpha(1+\mu) \sigma]\}
\end{aligned}
$$

or

$$
\begin{equation*}
-\lambda=-[1-\alpha-D(\mu)](\delta+n+g) \tag{24}
\end{equation*}
$$

where

$$
\begin{equation*}
D(\mu)=\frac{B(\mu)[1-2 \alpha+\alpha(1+\mu) \sigma]}{2} \tag{25}
\end{equation*}
$$

Using (11), (21), and (22),

$$
\begin{equation*}
\frac{1}{e_{\lambda}}=\frac{(1-\alpha)(\delta+g+n)-\lambda}{(1-\alpha) R^{*} X^{*}}=\frac{D(\mu)(\delta+n+g)}{(1-\alpha) R^{*} X^{*}}=\frac{D(\mu)}{(1-\alpha)(1+\mu) \sigma X^{*}}=\frac{D(\mu)}{(1-\alpha)[(1+\mu) \sigma-1]} \tag{26}
\end{equation*}
$$

Notice that by (22), $X^{*}>0$ requires

$$
\begin{equation*}
(1+\mu) \sigma-1>0 \tag{27}
\end{equation*}
$$

Hence, the denominator of (26) is positive, and

$$
(1-\alpha)-\alpha[1-(1+\mu) \sigma]=(1-\alpha)+\alpha[(1+\mu) \sigma-1]>0
$$

so the factor multiplying $B(\mu)$ in (25) is also positive, and it follows that the sign of the slope of the saddle path is the same as the sign of $B(\mu)$. Now,

$$
B(\mu)=1-\sqrt{1-\frac{\mu 4(1-\alpha) \alpha[1-(1+\mu) \sigma]}{[1-2 \alpha+\alpha(1+\mu) \sigma]^{2}}}=1-\sqrt{1+\frac{\mu 4(1-\alpha) \alpha[(1+\mu) \sigma-1]}{[1-2 \alpha+\alpha(1+\mu) \sigma]^{2}}}
$$

By (27), the expression multiplying $\mu$ under the square-root radical is also positive. Thus, the slope of the saddle path is positive if the expression under the radical is less than 1 (i.e., if $\mu<0$ ). This agrees with our earlier graphical analysis.

## Problem 5.9

(i) Taking as given the time path of $p$, write the necessary conditions for a solution to the consumer's problem. Derive an equation describing the evolution of consumption over time.

From the current-value Hamiltonian

$$
H^{c}=\frac{c^{1-\sigma}}{1-\sigma}+\lambda\left\{(1-\tau) k^{1-\alpha} p^{\alpha}-c\right\}
$$

we obtain

$$
\begin{gather*}
\frac{\partial H^{c}}{\partial c}=c^{-\sigma}-\lambda=0 \\
\Rightarrow c^{-\sigma}=\lambda  \tag{4}\\
-\frac{\partial H^{c}}{\partial k}=-\lambda\left\{(1-\tau)(1-\alpha) k^{-\alpha} p^{\alpha}\right\}=\dot{\lambda}-\rho \lambda \\
\Rightarrow \frac{\dot{\lambda}}{\lambda}=\rho-(1-\tau)(1-\alpha) k^{-\alpha} p^{\alpha} \tag{5}
\end{gather*}
$$

Using (4) and (5),

$$
\begin{equation*}
\frac{\dot{c}}{c}=\frac{-1}{\sigma} \frac{\dot{\lambda}}{\lambda}=\frac{1}{\sigma}\left\{(1-\tau)(1-\alpha) k^{-\alpha} p^{\alpha}-\rho\right\} \tag{6}
\end{equation*}
$$

(ii) Assume that $p=\tau y$, that is, that all tax revenue is used to finance public services. Substituting the production function in this last expression, solve for $p$ as a function of $\tau$ and $k$. Substitute the result into the flow budget constraint and the transition equation for consumption. Call $\gamma$ the growth rate of consumption, obtained from this step, and let $\beta$ be the coefficient of $k$ in the law of motion for $k$. Notice that $\beta$ can be written as a simple function of $\gamma$.

We have $p=\tau y=\tau k^{1-\alpha} p^{\alpha}$. Solving for $p$,

$$
\begin{equation*}
p=\tau^{1 /(1-\alpha)} k \tag{7}
\end{equation*}
$$

and substituting (7) into (3) and (6),

$$
\begin{gather*}
\dot{k}=(1-\tau) \tau^{\alpha /(1-\alpha)} k-c \equiv \beta k-c \\
\frac{\dot{c}}{c}=\frac{1}{\sigma}\left\{(1-\tau)(1-\alpha) \tau^{\alpha /(1-\alpha)}-\rho\right\} \equiv \gamma
\end{gather*}
$$

Notice that $\left(6^{\prime}\right)$ can be written

$$
\gamma=\frac{1}{\sigma}\{(1-\alpha) \beta-\rho\}
$$

Hence,

$$
\begin{equation*}
\beta=\frac{\rho+\gamma \sigma}{1-\alpha} \tag{8}
\end{equation*}
$$

(iii) Observe that consumption grows at a constant exponential rate. Hence, once we determine its initial level, we have characterized its entire path.

Integrating the flow budget constraint and imposing the transversality condition, we obtain

$$
\begin{equation*}
k_{0}=\int_{0}^{\infty} c_{t} e^{-\beta t} d t \tag{9}
\end{equation*}
$$

Use this expression to solve for $c_{0}$.

Solving the integral in (9),

$$
k_{0}=\int_{0}^{\infty} c_{t} e^{-\beta t} d t=\int_{0}^{\infty} c_{0} e^{\gamma t} e^{-\beta t} d t=\int_{0}^{\infty} c_{0} e^{-(\beta-\gamma) t} d t=\frac{c_{0}}{\beta-\gamma}
$$

from where

$$
\begin{equation*}
c_{0}=(\beta-\gamma) k_{0} \tag{10}
\end{equation*}
$$

where, by (8),

$$
\begin{equation*}
\beta-\gamma=\frac{\rho-(1-\sigma-\alpha) \gamma}{1-\alpha} \tag{11}
\end{equation*}
$$

## Problem 5.10

(i) Substitute the equilibrium path of consumption into the agent's objective function to obtain utility as a function of $\gamma($ or $\tau), U(\gamma)$. What condition must we impose in order to guarantee that utility is bounded? Assume that this condition holds.

We shall write the utility of the representative agent as a function of $\gamma$. Using (10) and (11), we have

$$
\begin{align*}
U(\gamma) & =\int_{0}^{\infty} \frac{c_{t}^{1-\sigma}}{1-\sigma} e^{-\rho t} d t=\frac{1}{1-\sigma} \int_{0}^{\infty} c_{0}^{1-\sigma} e^{(1-\sigma) \gamma t} e^{-\rho t} d t \\
& =\frac{c_{0}^{1-\sigma}}{(1-\sigma)[\rho-(1-\sigma) \gamma]}=\frac{k_{0}^{1-\sigma}(\beta-\gamma)^{1-\sigma}}{(1-\sigma)[\rho-(1-\sigma) \gamma]}=\frac{k_{0}^{1-\sigma}}{(1-\alpha)^{1-\sigma}} \frac{[\rho-(1-\sigma-\alpha) \gamma]^{1-\sigma}}{(1-\sigma)[\rho-(1-\sigma) \gamma]} \tag{12}
\end{align*}
$$

Hence, utility will be bounded whenever

$$
\begin{equation*}
\rho-(1-\sigma) \gamma>0 \tag{13}
\end{equation*}
$$

We shall assume in what follows that this condition holds.

(ii) Find the optimal value of $\tau$. Does the result "look right"? Why or why not?

Notice that we can write (12) in the form

$$
U(\gamma)=B \frac{[\rho-(1-\sigma-\alpha) \gamma]^{1-\sigma}}{(1-\sigma)[\rho-(1-\sigma) \gamma]}
$$

where

$$
B=\frac{k_{0}^{1-\sigma}}{(1-\alpha)^{1-\sigma}}
$$

is a positive constant. Differentiating (12'),

$$
\begin{aligned}
U^{\prime}(\gamma) & =B \frac{\left[(1-\sigma)[\rho-(1-\sigma) \gamma](1-\sigma)[\rho-(1-\sigma-\alpha) \gamma]^{-\sigma}\right][-(1-\sigma-\alpha)]-[\rho-(1-\sigma-\alpha) \gamma]^{1-\sigma}(1-\sigma)[-(1-\sigma)]}{(1-\sigma)^{2}[\rho-(1-\sigma) \gamma]^{2}} \\
& =B \frac{\left[-(1-\sigma)^{2}[\rho-(1-\sigma) \gamma][\rho-(1-\sigma-\alpha) \gamma]^{-\sigma}\right](1-\sigma-\alpha)+[\rho-(1-\sigma-\alpha) \gamma]^{1-\sigma}(1-\sigma)^{2}}{(1-\sigma)^{2}[\rho-(1-\sigma) \gamma]^{2}} \\
& \left.=B \frac{[\rho-(1-\sigma-\alpha) \gamma]^{-\sigma}}{[\rho-(1-\sigma) \gamma]^{2}}\{\rho-(1-\sigma-\alpha) \gamma]-(1-\sigma-\alpha)[\rho-(1-\sigma) \gamma]\right\}
\end{aligned}
$$

Hence, $U^{\prime}(\gamma)>0$ provided

$$
\rho-(1-\sigma) \gamma+\alpha \gamma>(1-\sigma-\alpha)[\rho-(1-\sigma) \gamma] \Leftrightarrow \alpha \gamma>-(\sigma+\alpha)[\rho-(1-\sigma) \gamma]
$$

and this last expression holds by the boundedness condition (13).

Because utility is increasing in the growth rate of consumption, $\gamma$, the government should choose $\tau$ so as to maximize

$$
\gamma=\frac{1}{\sigma}\left\{(1-\tau)(1-\alpha) \tau^{\alpha /(1-\alpha)}-\rho\right\}
$$

that is, so as to maximize $(1-\tau) \tau^{\alpha(1-\alpha)}$. Taking logarithms of this expression and differentiating with respect to $\tau$, it is easy to see that the optimal policy involves setting the tax rate equal to the coefficient of public services in the production function (i.e., $\tau^{*}=\alpha$ ).

In some sense this is precisely what we should expect. Recall that given a constant-returns-to-scale Cobb-Douglas technology, the share of output of each factor in a competitive equilibrium is equal to its coefficient in the production function. Hence, by setting $\tau^{*}=\alpha$, the government is essentially selling its services at their competitive price.

Problem 5.11. It will be convenient in what follows to work with the growth rate of per-capita consumption, denoted by $g$. Assuming that the share of employment in goods production, $L_{x}$, remains constant over time, solve for $L_{x}$ as a function of $g$. Keep an eye out for scale effects, that is, reasons why a larger economy (as measured by the size of the labor force, $L$ ) may be able to grow faster.

Differentiating the reduced-form per-capita production function with respect to time, and holding the share of industrial employment constant, we can express the growth rate of output per worker as a function of the rate of technical progress. Because goods-market clearing, moreover, requires per-capita consumption to equal average output per worker, we obtain, using (2) and the labor-market clearing condition, $L_{n}+L_{x}=L$,

$$
g=\frac{1-\alpha}{\alpha} \frac{\dot{n}}{n}=\frac{1-\alpha}{\alpha} a L_{n}=\frac{1-\alpha}{\alpha} a\left(L-L_{x}\right)
$$

and, solving for $L_{x}$ as a function of $g$,

$$
\begin{equation*}
L_{x}=L-\frac{\alpha}{1-\alpha} \frac{g}{a} \tag{3}
\end{equation*}
$$

Notice that this expression gives us a first clue to the source of scale effects. For the same growth rate, a larger economy can have larger employment in goods production and therefore, given the same $n$, higher output. Because profit is, for given $n$, a fixed fraction of output, the incentive to do R\&D will be greater in the larger economy.

Problem 5.12. Using equations (5) and (6), together with the expressions for equilibrium factor prices derived in Section 5(a) of Chapter 8, derive the following relationship between the interest rate and the growth rate of consumption:

$$
\begin{equation*}
r=\frac{a(1-\alpha)}{\alpha} L-\frac{\alpha}{1-\alpha} g \tag{II}
\end{equation*}
$$

Interpret this condition.

Using the results of Problem 5.3 in Chapter 8, together with equations (1) and (3), we can compute the equilibrium values of $w$ and $v$ :

$$
\begin{gather*}
w=\frac{\alpha L Q}{L_{x}}=\frac{\alpha Y}{L_{x}}=\alpha n^{(1-\alpha) / \alpha}  \tag{7}\\
\pi=\frac{(1-\alpha) Y}{n}=(1-\alpha) n^{(1-2 \alpha) / \alpha} L_{x}=(1-\alpha) n^{(1-2 \alpha) / \alpha}\left(L-\frac{\alpha}{1-\alpha} \frac{g}{a}\right) \tag{8}
\end{gather*}
$$

(Second clue on scale effects: Wages are independent of population size, but profits are increasing in it, and decreasing in $g$, as more research reduces output and profits.)

We will use equation (8) to compute the value of the firm, $v$. Notice that the only thing in this expression that is changing over time in equilibrium is $n$, which grows at the constant rate $\alpha \mathrm{g} /(1-\alpha)$. Hence,

$$
\begin{equation*}
n_{t+s}=n_{t} \exp \left(\frac{\alpha g}{1-\alpha} s\right) \tag{9}
\end{equation*}
$$

and, substituting (8) and (9) into (6), the equilibrium value of the firm at time $t$ is given by

$$
v_{t}=(1-\alpha) n_{t}^{(1-2 \alpha) / \alpha}\left(L-\frac{\alpha}{1-\alpha} \frac{g}{a}\right) \int_{t}^{\infty} \exp \left(\frac{1-2 \alpha}{\alpha} \frac{\alpha g}{1-\alpha} s\right) e^{-r s} d s
$$

from where

$$
\begin{equation*}
v_{t}=\frac{(1-\alpha) n_{t}^{(1-2 \alpha) / \alpha}\left(L-\frac{\alpha}{1-\alpha} \frac{g}{a}\right)}{r-\frac{1-2 \alpha}{1-\alpha} g} \tag{10}
\end{equation*}
$$

Next, we return to the equal-compensation condition, (5). Using (7) and (10), equation (5) implies that

$$
(w=) \quad \alpha n^{(1-\alpha) / \alpha}=a n \frac{(1-\alpha) n_{t}^{(1-2 \alpha) / \alpha}\left(L-\frac{\alpha}{1-\alpha} \frac{g}{a}\right)}{r-\frac{1-2 \alpha}{1-\alpha} g} \quad(=a n v)
$$

Simplifying and rearranging terms,

$$
r-\frac{1-2 \alpha}{1-\alpha} g=\frac{a(1-\alpha)}{\alpha}\left(L-\frac{\alpha}{1-\alpha} \frac{g}{a}\right)=\frac{a(1-\alpha)}{\alpha} L-g
$$

and

$$
\begin{equation*}
r=\frac{a(1-\alpha)}{\alpha} L-\frac{\alpha}{1-\alpha} g \tag{II}
\end{equation*}
$$

This is the second relationship we wanted. The production side of the model implies a negative relationship between the interest rate and the rate of growth. Intuitively, the reason is the following. In equilibrium, labor must be allocated between its two uses (goods production and R\&D) in such a way that its (private) marginal return is the same in both sectors. The rate of return on R\&D investment is determined by the present value of the stream of monopoly profits earned by a component producer. An increase in the interest rate will reduce the discounted value of this sum and thus the market value of the firm and the incentive to do research. In equilibrium, the level of research employment must fall, implying a lower rate of growth.

Problem 5.13. Solve for the equilibrium values of $g$ and the fraction of the labor force employed in research $\left(L_{n} / L\right)$. Discuss the determinants of the equilibrium growth rate and the impact on both variables of an increase in the size of the labor force, $L$. Consider also the effects of "merging" two isolated economies into a larger, integrated one. Does anything change? To what extent is the answer to this question sensitive to the details of the specification we have used?

Using (II) and (SS) it is easy to see that the equilibrium growth rate is given by ${ }^{3}$

$$
\begin{equation*}
g^{*}=\frac{\frac{a(1-\alpha)}{\alpha} L-\rho}{\sigma+\frac{\alpha}{1-\alpha}} \tag{11}
\end{equation*}
$$

and that the fraction of the labor force employed in research in equilibrium is equal to

$$
\begin{equation*}
\frac{L_{n}}{L}=\frac{(1-\alpha)-\frac{\alpha \rho}{a L}}{(1-\alpha) \sigma+\alpha} \tag{12}
\end{equation*}
$$

Hence, the growth rate increases with population $(L)$, the market power of firms (of which $\alpha$ is an inverse index), the elasticity of intertemporal substitution $\left(\sigma^{-1}\right)$ and the productivity of $R \& D(a)$, and it decreases with the rate of time discount $(\rho)$.

Consider the effect of an increase in population size in the current model. Inspection of the equilibrium conditions shows that an increase in $L$ will shift the II schedule upward, yielding a higher equilibrium value of $g$. This increase in the growth rate comes from two sources. First, because in our specification the rate of innovation depends on total (rather than per-capita) R\&D employment (i.e., $\dot{n} / n=a L_{n}$ ), a large economy will grow faster than a small one, even if both devote the same fraction of resources to R\&D. Second, equation (12) shows that R\&D employment in the large economy will also be higher in relative terms. The reason is that, given the number of firms, a larger market size implies larger profits, and therefore a greater incentive to invest in research.

![](https://cdn.mathpix.com/cropped/2024_03_09_cadcaead52b46766b4a0g-826.jpg?height=565&width=781&top_left_y=181&top_left_x=337)

Figure A13.11. Effect of market enlargement of R\&D intensity.

Suppose now that we merge two isolated economies into a larger, integrated one. In this case, both population and the number of firms will increase, and there are two separate effects to consider. The size of the market is now larger, but so is the number of competitors. The impact on profits and on the incentive to invest in $R \& D$ is uncertain ex ante. In the current model, the equilibrium value of $g$ is independent of the number of firms, and hence the net effect will still be a higher rate of growth, but this result depends to a large extent on the details of the model's specification. In particular, we have assumed that $n$ measures both the number of firms and the stock of technical knowledge available to potential innovators. An increase in $n$, then, reduces profits through lower margins, but it also reduces the cost of developing new products. In the current specification, both effects just cancel out. Hence, if integration implies the automatic pooling of (nonoverlapping) national stocks of technical knowledge, the net result will be an increase in overall R\&D intensity. If this is not the case, as seems more likely, the reduction of price markups induced by greater competition will tend to lower profits, offsetting, at least partially, the positive effect of a larger market size. ${ }^{4}$

## Bibliography

Cohen, W., and Levin, R. 1989. Empirical Studies of Innovation and Market Structure. In: Handbook of Industrial Organization, ed. R. Schmalensee and R. Willig, pp. 1059-107. Amsterdam: Elsevier.

Kamien, M., and Schwartz, N. 1982. Market Structure and Innovation. Cambridge University Press.

Scherer, F. 1984. Innovation and Growth: Schumpeterian Perspectives.

Massachusetts Institute of Technology Press.

## Notes

1 Recall from Chapter 1 that a complex number $c$ can be written as

$$
c=a+i b=r(\cos \theta+i \sin \theta)=r e^{i \theta}
$$

where the last step follows from Euler's formula. Its conjugate is defined as

$$
\bar{c}=a+i b=r(\cos \theta-i \sin \theta)=[\cos (-\theta)+i \sin (-\theta)]=r e^{-t \theta}
$$

2 It is true that in equilibrium the interest factor must be equal to the marginal product of capital and that initial capital is given. But $R$ also depends on labor input, which is a free variable.

3 To guarantee that the II and SS schedules cross in the positive quadrant, some restrictions on parameter values must be satisfied. When this condition does not hold, we have a corner equilibrium in which R\&D employment is zero.

4 The impact of market structure on the rate of innovation is a complex matter. Firms with some degree of market power may be better able to appropriate the benefits of their research, but may also be under less pressure to innovate. The literature on the topic is extensive and not very conclusive. See, for example, Kamien and Schwartz (1982), Scherer (1984), and Cohen and Levin (1989).

## Subject index

absolute value, 35

action space, for a game, 376

adaptive expectations, 495

in a model of stock prices, $504 \mathrm{ff}$

shortcomings of, 506-7

adding-up property, 341

affine combination, 121

affine hull, 240

affine space, 121

aggregate production function, 518

aggregate supply function, 547

algebraic structure, 25

allocation, 355

anticipated policy change, 621

archimedean property, 33

arcwise connected set, 103

associative operation, 25

autonomous dynamical system, 401

axiom of choice, 23

axiom of completeness, 31

backward induction, 554

backward solution, 428

balanced-growth path, 524

ball, open and closed, 45

Banach space (def), 81

basin of attraction, 410

basis, 119

change of, 144

Bellman's equation, 554

Bernoulli inequality, 56

best-response mapping, 376

better-than set, 330

bifurcation, 228

Blackwell's sufficient conditions, 89

Bolzano-Weierstrass theorem, 52

bound, upper and lower, 31

boundary, of a set, 59

boundary conditions, 395

choice of in economics models, $508 \mathrm{ff}, 606$

bounded

function, 45

linear function, 133

sequence, 50

set, 31,45

boundedness, relationship with completeness, 97 bounded-utility condition, 629

Brouwer's fixed point theorem, 221

bubble term, 429,512

budget correspondence, 340

continuity of, 341

$C(X), 83$

completeness of, 83

$C^{k}$, functions of class, 180

Cagan model, 512

canonical basis, 119

Cardano formula, 153

cardinality of a set, 24

Cartesian product, 15, 24

Cass-Koopmans (optimal growth) model, $622 \mathrm{ff}$

catastrophes, 228

Cauchy convergence, 80

Cauchy sequences, 80

Cauchy's mean-value theorem, 162

Cauchy-Schwarz inequality, 42

Cauchy-Schwarz-Bunyakovsky inequality, 43

center, 477

CES (constant elasticity of substitution) function, 189

chain rule, 176

characteristic

equation, 146

polynomial, 146

root, see eigenvalue

vector, see eigenvector

closed correspondences, 112

closedness

relationship with compactness, 95, 97

relationship with completeness, 82

closed sets (def), 58

characterizations of, 60,62

properties of, 59

closure of a set, 60

cluster point

of a sequence, 48

of a set, 61

Cobb-Douglas function, 188, 518

column space of a matrix, 198

commutative operation, 25

compactness (def), 90

characterizations of, 91, 94
of the product space, 100

relationship with closedness, 95, 97

relationship with completeness, 96

sequential (def), 91

comparative dynamics, 418,427

an example of, 631ff

comparative statics, 195

of compensated demand functions, 351

computation of derivatives of implicit functions, $202 \mathrm{ff}$

without differentiability, 318

of fixed points, 88

and the implicit function theorem, 200

of maximization problems, 309ff

competitive equilibrium, $355 \mathrm{ff}$

existence of, $360 \mathrm{ff}$

welfare properties of, 368-ff

complement, of a set, 5

complementary function, 420

complementary slackness conditions, 292

completeness

of Euclidean spaces, 83

of finite-dimensional normed vector spaces, 121

of a metric space (def), 81

of an ordering or preordering, 18

of the preference relation, 329

relationship with boundedness, 97

relationship with closedness, 82

relationship with compactness, 96

of the set of real numbers, 82

complex numbers, $36 \mathrm{ff}$

composite-function theorem, $70 \mathrm{ff}$

composition

of correspondences, 113

of functions, 21

differentiability of, 176

of relations, 16

concavifiability, 267

concavity (def), 246

characterizations of, $246 \mathrm{ff}$

for smooth functions, $258 \mathrm{ff}$

and continuity, 252

and differentiability, 257

and quasiconcavity, 262

of transformations of concave functions, 251-2

of the value function in dynamic programming, 565

of the value function in static optimization problems, 313

conjugate, 36

conjunction, 7

connectedness

arcwise, 103

and arcwise connectedness, 103

and continuous functions, 102

of the indifference sets, 337

of a set (def), 100

constraint qualification

in Kuhn--Tucker problems, 293, 298

in Lagrange problems, 288

constraint, binding or active, 291

constraint set, 275

consumer theory, $339 \mathrm{ff}$ consumption, in an intertemporal setting, 622

continuation, of the solution to a differential equation, 437

continuity

of the budget correspondence, 341

of concave functions, 252

of the constraint correspondence in KuhnTucker problems, 303

of contractions, 85

of correspondences (def), 108

of a function (def), 66

characterizations, 68,70

of the inversion mapping for linear operators, 143

of linear functions, 132

of the preference relation, 329

preservation of by equivalent metrics, 105

relative to a set, 115

of solutions of dynamical systems in initial conditions and parameters, $399,444 \mathrm{ff}$ uniform, 73

continuous functions

in compact sets, properties of, 98

and connectedness, 102

and preservation of sign, 68

properties of real, $74 \mathrm{ff}$

contract curve, 373

contraction (def), 85

Blackwell's sufficient conditions for, 89

existence and uniqueness of fixed points for, 86

contraction-mapping theorem, 86

contradiction, proof by, 13

convergence equation, derivation of, $534 \mathrm{ff}$

convergence, of sequences, 46

of bounded sequences, 52

in the sense of Cauchy, 80

in Euclidean spaces, 55

of monotonic sequences, 49

in product spaces, 56

convergence, speed of, 536

convex

body, 229

combination, 229, 231

function, 246

hull, 231

convex sets, 229

characterizations, 231

intersections of, 230

linear combinations of, 230

relative interior and boundary of, $237 \mathrm{ff}$

topological properties of, $234 \mathrm{ff}$

convexity

for functions, 246

of preferences, 331

of the value function in static optimization problems, 313

coordinate, 130

correspondence (def), 23, 108

closed, 112

closed-valued, 108

compact-valued, 108

composition of, 113

continuity of, 108

sum of, 113
upper and lower hemicontinuity of (def), 108 characterizations, $109 \mathrm{ff}$

properties, $113 \mathrm{ff}$

costate variables, 567

Cournot duopoly and oligopoly, 378, 383ff

cover, 90

Cramer's rule, 199

critical equilibria, 207, 214

critical point, 175

critical value, 175

current value function, 556

degrees of freedom, 212

demand

aggregate, $356 \mathrm{ff}$

conditions for it being utility-generated, 360

compensated or Hicksian, 347

properties of, 347,351

ordinary or Marshallian, 340

properties of, 341, with homothetic utility, 343,360

relationship between compensated and ordinary, 352

De Morgan's laws, 6, 11-12

dense set, 217

derivative (def), 156, 171

directional, $163 \mathrm{ff}$

of concave functions, 256

and continuity, 168

partial, 164

of higher order, 166

derived set, 61

diagonalization, 151

and solution of linear dynamical systems, $460 \mathrm{ff}$

Diamond growth model, $527 \mathrm{ff}$

social security in, 545

with variable labour supply, 544

Diamond search model, $590 \mathrm{ff}$

diffeomorphism, 183

difference equation, 392

existence and properties of solutions, 398ff

solution of linear equations with constant coefficients, $419 \mathrm{ff}$

difference, of two sets, 5

differentiability, $156,169 \mathrm{ff}$

of composite functions, 176

of concave functions, 257

continuous, 179

and continuity, 157, 172

and existence of partial derivatives, 174

differential equation, ordinary, 391

continuation of solutions to, 438

existence and properties of solutions, 430ff

maximal solutions of, 437

solution of linear equations with constant coefficients, 412

solution of nonautonomous linear equations, $428 \mathrm{ff}$

solutions of, 392

differential of a function, 171

dimension

of a convex set, 240

of a hyperplane, 238 of a vector space, 119

discounting, 556

disjunction, of two properties, 7

distance function, see metric

distance

between a point and a set, 45

between two sets, 45

distributive law, 26

Dornbusch's overshooting model, $513 \mathrm{ff}$

duality principle, 6

duopoly, 378, 379

dynamic programming, $549 \mathrm{ff}$

dynamical system

autonomous, 401

discrete vs. continuous, 391

geometrical interpretation, 393

linear, general results on, $457 \mathrm{ff}$

reduction to first order, 392

solution of, 394, 396

particular vs. general, $394 \mathrm{ff}$

$\varepsilon$-net, 92

efficiency wages, 644

eigenspace, 147

eigenvalues (def), 146

and diagonalization, 151

of power and inverse matrices, 147

of real matrices, 148

and sign definiteness of quadratic forms, 268

eigenvector (def), 146

envelope theorems, 315

epigraph, 246

equilibrium, $325 \mathrm{ff}$

competitive in an exchange economy, $355 \mathrm{ff}$

Nash, 376

equivalence

of metrics and norms, 105 in $R^{n}, 107$

of properties, 11

relations, $17-18$

Euclidean space, 41

completeness of, 83

convergence in, 55

Euler equation, $601,604 \mathrm{ff}$

Euler's formula, 37

Euler's theorem, 187

excess entry, 384

exchange economy, 355

exchange rate determination, $513 \mathrm{ff}$

existence

of equilibrium, $218 \mathrm{ff}$

of solutions for linear systems of equations, 199

expenditure function, 347

properties of, 347

expenditure minimization, relationship with utility maximization, 353

exterior of a set, 59

extreme-value theorem, 75, 99

factor demand functions, 282,317

factor prices, in a neoclassical one-sector model, $518 \mathrm{ff}$

feasible direction, 278

feasible set, 275
field, 26

field axioms for the real number system, 30

finite intersection property, 94

fiscal policy, effect of in Dornbusch's overshooting model, 516

fixed points (def), 86, 221

of contractions, existence and uniqueness of, 86

comparative statics of, 88

existence of, $221 \mathrm{ff}$

theorems, $86,224 \mathrm{ff}$

flow, 391,444

continuity of, $399,447 \mathrm{ff}$

differentiability of, 399,450

of autonomous systems, properties of, $402 \mathrm{ff}$

flow equivalence, 488

forward solution, 429

free goods, 365

function (def), 20

bijective, 21

bounded, 45

composition of, 21

epigraph of, 246

homogeneous, $187 \mathrm{ff}$

homothetic, 190

hypograph of, 246

injective, 21

monotonic, 78

one-to-one, 21

onto, 21

surjective, 21

fundamental solution, 429

fundamental theorem of demand theory, 345 , 354

game, in normal form, 375

general solution of a dynamical system, 395

genericity, 217

generic property, 214, 217

geometric series, 57

Giffen good, 346

government spending, in a growth model, 649

gradient, 166

graph, of a correspondence, 112

Grobman-Hartman theorem, 488

Gronwall's lemma, 444

group, 26

half-life, 536

Hamel basis, 118

Hamiltonian, 567

Heine-Borel theorem, 97

homeomorphic metric spaces, 74

homeomorphism, 74

linear, 134

topological, 134

homogeneous functions (def), 187

geometric properties of 189

homothetic function, 190

Hotelling's lemma, 318

human capital, in an extended Solow model, 543

hyperbolic steady state, 417, 427, 488

hyperplane (def), 237 dimension of, 238

separating, 241

supporting, 241

hypograph, 246

## image

of a linear function, 123

of a set under a function, 20

of a set under a relation, 15

imaginary eigenvalues, and solutions of linear dynamical systems, 463

imaginary numbers, 36

imperfect competition, $379 \mathrm{ff}$

implication, 9-11

implicit contract models, $319 \mathrm{ff}$

over- and under-employment in, 730

implicit function theorem, $200 \mathrm{ff}$

Inada conditions, 518,523

incentive-compatibility constraints, 321

increasing returns

to scale, 519

to specialization, 380

indifference relation, 328

indifference sets and curves, $334 \mathrm{ff}$

induction principle, 12

modified, 14

inferior good, 346

infimum, 32

infinite horizon problems

in dynamic programming, 557

in optimal control, $576 \mathrm{ff}$

infinite limit

of a function, 66

of a sequence, 54

initial-value problem, $394 \mathrm{ff}$

installation function, 610

interest parity, 514

interior of a set, 59

intermediate-value theorem, 76

and existence of equilibrium, 219

interval, 34, 101

interval of definition, of the solution to a dynamical system, 396

invariant set, 408

inverse

of a correspondence, 108

element, 25

image, of a set under a relation, 15

of a linear function, 126

inverse-function theorem, $181 \mathrm{ff}$

investment, $609 \mathrm{ff}$

IS-LM model

dynamic, 494

open economy, $513 \mathrm{ff}$

static, 224

isolated point, 62

isomorphic vector spaces, 127

isomorphism, 127

iteration of a map, 403

Jacobian matrix, 172

Kakutani's fixed point theorem, 224

kernel of a linear function, 123

Kuhn-Tucker problem, 291ff

Kuhn-Tucker theorem, 293

L'Hôpital's rule, 162

$L\left(R^{n}\right), 139$

$L\left(R^{n}, R^{m}\right), 137$

$L(X, Y), 122$

Lagrange

multipliers, 283

as shadow prices, $283,292,316$

problem, $282 \mathrm{ff}$

theorem, 285

Lagrangian function, 283, 285, 291

largest element, 19

law of internal composition, 25

learning by doing, 542

Lebesgue number for an open cover, 92

level effects, of policy changes, 524

level set, 189

limit point

of the orbit of a dynamical system, 408

of a set, 61

limits

algebra of, 52, 65

of a function (def), 64

at infinity, 66

uniqueness of, 65

and preservation of equalities and inequalities, 65

right-handed and left-handed. 115

of a sequence, 46

limit set, 408

linear

combination, 117

dependence, 117

independence, 117

linear function (def), 122

bounded, 133

composition of, 138

continuity of, 132

inverse of, 126, 140

matrix representation of, 130

norm of, 135

linearization, 487

of difference equations, 423

of differential equations, 416

line segment, 178

Lipschitz

condition, 73

constant, 73

equivalence, of metrics and norms, 43, 106

function, 73, 100

logical connectives, 7

manifold, smooth, 213

market socialism, 373

matching function, 646

Mathematica, 538, 638

matrices

diagonalization of, 151

similarity of, 146

matrix representation, of a linear function, 130

maximal element, 19 maximal interval of existence, of the solution to a differential equation, 437

maximization

with a convex constraint set, $277 \mathrm{ff}$

without differentiability, 297

with equality constraints, $282 \mathrm{ff}$

with inequality constraints, $291 \mathrm{ff}$

with integral objective and constraint functions, 296

with nonnegativity constraints, 279

in an open set, 279

maximum, 19,32

maximum principle, $567 \mathrm{ff}$

mean-value theorem, 159,178

Cauchy's, 162

measure zero, 215

metrics (def), 40

$C^{r}, 45$

equivalence of, 105

$L^{2}, 44$

product, 43

sup, 44

metric space, 40

minimal element, 19

modulus

of a contraction, 85

of a complex number, 36

monetary policy

in Dornbusch's overshooting model, 517

in a dynamic IS-LM model, 501

monopolistic competition, $380 \mathrm{ff}$

monotonic

functions, 78

preference relations, 330

sequences, 49

Nash equilibrium (def), 376

existence of, 377

negation, of a property, 7

node, 475

nonhyperbolic steady state, 417,427

nonlinear programming, $274 \mathrm{ff}$

nonstationary function, 265

norms (def), 41

equivalence of, 105

of a linear function, 135

Lipschitz-equivalence of, 43

normal form, of a game, 375

normal, to a hyperplane, 238

normed vector space, 40

nullspace, see kernel

numerical solution, of differential equations, $538 \mathrm{ff}, 635 \mathrm{ff}$

objective function, 275

open sets (def), 58

characterizations of, 60

properties of, 58

operation, 25

operator, 85,139

optimal control, $566 \mathrm{ff}$

optimal growth, $598 \mathrm{ff}$

orbit, 396

order axioms, 31
order, of a differential or difference equation, 392

ordering, 18

overlapping generations, 527

## Pareto

dominance, 369

efficiency, 368

optimality, 369

participation externalities, 589

partition, 5

of a set into classes, 17

perfect foresight, 507

phase diagram, 403

construction of for planar continuous systems, 484

construction of for scalar difference equations, 421

construction of for scalar differential equations, 414

example of construction of, $496 \mathrm{ff}$

phase line, 414,484

Phillips curve, 495

polar coordinates, 489

policy function, 554

polynomial equations, 152

Pontryagin's conditions, 569

positive-definite quadratic form, 268

preannaounced policy changes, 517

preference relations, $327 \mathrm{ff}$

preferences, $327 \mathrm{ff}$

representation by a utility function, $332 \mathrm{ff}$

smoothness of, 338

preimage, 20

preordering, 18

complete, 18

principal minor, 269

principle of optimality, 551

product metric, 43

product spaces, 43

compactness of, 100

convergence in, 56

production function

aggregate, 518

per capita, 519

profit function, $317 \mathrm{ff}$

profit maximization, $317 \mathrm{ff}$

proof

by construction, 49

by contradiction, 13

by deduction, 11

methods of, 11-15

properties, 6

composite, 7

equivalent, 11

negation of, 7

pseudoconcavity, 265

purchasing power parity, 515

## $q$ theory, see investment

quadratic form (def), 268

conditions for positive and negative definiteness, 268

conditions for sign definiteness under constraints, 271 quadratic formula, 153

quantifiers, 4, 8-9

quasiconcavity (def), 261

characterizations, $262 \mathrm{ff}$

quotient set, 18

$R \& D$, in an endogenous growth model, 650

rank, of a family of vectors, 124

rationality, postulate of, 274,325

real number system, 29

axioms of, $30 \mathrm{ff}$

regular

equilibrium, 206, 214

maximizer, 280, 289

point, 175

value, 175

regular-value theorem, 213

relation, 15

order, $18-20$

repeated eigenvalues, and solutions of linear dynamical systems, 465

representation theorems, 333-34

representative agent, 360

reservation wage, 584

returns to scale, 519

and sustained growth, 523

Rolle's theorem, 159

Roy's identity, 346

saddle path, 476

saddle point, 470,476

salvage value function, 555

Sard's theorem, 215

savings function, properties of in an OLG model, 529

savings rate, behavior of, 647

Schwarz's theorem, 166

scrap value function, 555

search models, $582 \mathrm{ff}$

separability, of topological spaces, 333

separated set, 100

separating-hyperplane theorem, 244

separation theorems, $241 \mathrm{ff}$

separation of variables, method of, 412,436

sequences (def), 23

convergence of, 46

sequential compactness, 91

set, 3-6

arcwise connected, 103

boundary of, 59

bounded, 31,45

cardinality of, 24

closed with respect to an operation, 25

closure of, 60

compact, 90

complement of, 5

connected, 100

convex, 229

countable, 24

cover of, 90

dense, 217

diameter of, 45

empty, 3

exterior of, 59

finite, 24
infimum of, 32

infinite, 24

interior of, 59

largest element of, 19

maximal element of, 19

open and closed, 58

ordered, 18

power set, 3

quotient set, 18

separated, 100

smallest element of, 19

supremum of, 32

totally bounded, 92

universal, 3

sets

difference of, 5

disjoint, 5

distance between, 45

family of, 3

intersection of, 4 properties of, 4

numerically equivalent, 24

pairwise disjoint, 5

union of, 4 properties of, 4

Shephard's lemma, 350

similarity, of matrices, 146

sink, 470

Slater's condition, 298

Slutsky equation, 353

Slutsky matrix, 345

Slutsky theorem, 345

smallest element of a set, 19

smooth function, 180

smooth preferences, 338

social security, in Diamond's model, 545

Solow model, $522 \mathrm{ff}$

with human capital, 543

source, 470

specialization, increasing returns to, 380

spectrum, 146

speculative bubble, 508

spiral point, 477

stability, 410

asymptotic (def), 410

conditions for, 413, 416, 421, 423, 466, 488

stable manifold theorem, 489

stable space or manifold, $470 \mathrm{ff}$

Stackelberg duopoly, 379

state vector, 391

steady or stationary state, 409

hyperbolic vs. nonhyperbolic, 417, 427, 488

stock prices, $503 \mathrm{ff}, 617 \mathrm{ff}$

strategy space, 375

subfield, 27

subrelation, 16

subsequence, 23

subset, 3

successive approximations, method of, 88,432

sum of correspondences, 113

sup norm, 83

superdifferentiability, 247

supergradient, 248 and partial derivatives, 257

supply function, 317

supporting-hyperplane theorem, 243

supremum, 32

supremum property, 32

surjective function, 21

symmetric element, 25

Tarsky's fixed point theorem, 223

tatonnement, 363

taxation of factor incomes, $625 \mathrm{ff}$

Taylor's formula, 160,181

technological progress, factor augmenting, 521, 527

theorem of the maximum, 301

time consistency, 553

time-elimination method, 636

topological equivalence

of dynamical systems, 488

of metrics and norms, 105

topological properties, 74

totally bounded set, 92

transition function, see flow

transversality conditions, $572 \mathrm{ff}$

in the optimal growth model, 607

transversality-density theorem, 216

triangle inequality, 35

trigonometric form, of a complex number, 36

truth-telling constraints, 321

unemployment

as a discipline device, 644

in a matching model, 646

upper contour set, 251

utility function (def), 332

construction of, $334 \mathrm{ff}$

indirect, 340

properties of, 341

ordinal vs. cardinal, 333

utility maximization, relationship with expenditure minimization, 353

value function

in dynamic programming, 550 properties of, $562 \mathrm{ff}$

in static optimization problems, 275, 312

variational problem, 451

vector dominance, 16

vector field, 394

vector spaces (def), 28

basis of, 119

dimension of, 119

normed, 40

isomorphic, 127

Walras' law, 359

Walrasian auctioneer, 378

Walrasian equilibrium, $355 \mathrm{ff}$

Weierstrass theorem, 99

Welfare theorems, 369-70

well-ordering principle, 14

zero, of a polynomial, 152

## Author index

Araujo, A., 581

Arrow, K., 266

Barro, R., 535, 548, 648, 649

Bazaraa, M., 272

Benveniste, L., 257

Border, K., 224

Bronsted, A., 272

Calvo, G., 508

Cass, D., 527

Cohen, W., 826

Cooper, R., 730

Crouzeix, J. P., 266

Debreu, G., 333, 378

Diamond, P., 527, 589

Dixit, A., 379, 380, 387

Enthoven, A., 266

Ethier, W., 379, 387

Ferland, J., 266

Fudenberg, D., 589

Grossman, G., 379, 656

Guillemin, 213, 222

Hadley, G., 270

Helpman, E., 379, 656

Hildenbrand, W., 116

Kamien, M., 826

Koopmans, T., 527

Levin, R., 826

Mankiw, G., 535, 543, 548

Marshall, A., 380

Mas-Colell, 339
Milnor, 213, 222

Mulligan, C., 656

Nash, J., 375

Norman, V., 380

Perko, L., 489

Pissarides, C., 646

Pollack, 213, 222

Ramsey, F., 527

Rockafellar, R. T., 257

Romer, D., 535, 548

Romer, P., 379, 656

Ruelle, D., 489

Sala-i-Martin, X., 535, 548, 648, 656

Samuelson, P., 345

Santos, M., 581

Sargent, T., 508

Scheinkman, J., 257

Scherer, F., 826

Schwartz, N., 826

Shapiro, C., 644

Shetty, C., 272

Simmons, G., 656

Smith, A., 380

Solow, R., 522

Stiglitz, J., 379, 387, 644, 730

Swan, T. W., 548

Tobin, J., 655

Vives, X., 324

Walras, L., 387

Wallace, N., 508

Weil, D., 535, 548

Young, A., 380

